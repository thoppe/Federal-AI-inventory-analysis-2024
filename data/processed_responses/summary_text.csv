2_use_case_name,summary_text
Non-Intrusive Inspection (NII) 3D Imaging Tool,"The Non-Intrusive Inspection (NII) 3D Imaging Tool leverages AI and machine learning to produce high-resolution images of concealed objects quickly and efficiently. It enhances existing inspection processes by generating 3D images without causing significant delays and introduces a new capability for detecting narcotics in packages, complete with alerts for items of interest."
Babel,"Babel is a tool utilized by CBP for conducting targeted queries in open source research to assess potential threats and identify travelers needing further inspection. It integrates AI modules for text detection, translation, and image recognition to streamline analysis, allowing analysts to review possible matches in a single interface. The tool aids in uncovering additional open source information and identifiers, which can help eliminate the need for further screening of travelers."
Fivecast ONYX,"Fivecast ONYX enhances the capability of Customs and Border Protection (CBP) to monitor and assess border security threats by processing extensive open-source data. The system aggregates information from various sources, including social media and the dark web, to identify potential risks and trends related to illegal activities, ultimately providing actionable intelligence for real-time decision-making and strategic planning."
Public Information Compilation for Travel  Threat Analysis (Dataminr),"The Public Information Compilation for Travel Threat Analysis tool, developed by Dataminr, streamlines the process of gathering open-source information related to national security and border safety for users. It aids CBP employees in quickly identifying potential threats related to air, sea, and land travel by providing organized, publicly available information, which they further research for verification."
Anomaly Detection in Non-Intrusive Inspection,"The project focuses on developing a model for anomaly detection in non-intrusive inspection systems, aiming to identify irregularities that may signal concealed contraband or threats. This approach enhances security by pinpointing specific areas within scanned images that require further scrutiny while minimizing the overall review time."
Advanced Analytics for X-ray Images (AAXI),"The Advanced Analytics for X-ray Images (AAXI) project focuses on improving anomaly detection in empty commercial vehicles at U.S. land border ports. By utilizing AI models that analyze past X-ray images, AAXI enables the identification of anomalies in vehicles entering the country, enhancing human capability to detect suspicious items and increasing clearance rates for compliant vehicles. The system produces bounding boxes around unidentified or anomalous objects in X-ray images for further investigation."
Automated Data Annotation,"The Automated Data Annotation system is designed to manage and process large volumes of raw data for AI/ML applications, specifically tailored to support CBP missions. Its primary function is to generate high-quality, domain-specific training datasets in JSON format, complete with metadata for annotation metrics and quality insights, thereby improving the accuracy and confidence in model development."
AI Enabled Autonomous Underwater Vehicle,"The AI Enabled Autonomous Underwater Vehicle project aims to enhance the Customs and Border Patrol's capabilities by utilizing a small submarine drone to autonomously detect potential contraband or safety risks in vessels entering and exiting ports. This system is designed to provide real-time indicators of suspected anomalies, improving situational awareness and mission planning while ensuring the safety of agents and officers. Additionally, the drone's autonomous navigation capabilities enable it to navigate obstacles and currents effectively, further optimizing operations."
Relocatable Multi-Sensor System,"The Relocatable Multi-Sensor System utilizes advanced sensor technology to accurately identify valid items of interest, such as unmanned aircraft systems and humans, while filtering out false alarms from environmental objects. By combining radar and sensor data, the system enhances situational awareness for CBP personnel, improving operational efficiency at border and security checkpoints. Its real-time outputs support informed decision-making and allow for a focused response to legitimate risks."
AI/LLM to generate testable synthetic data,"This project leverages AI to generate realistic test data for trade partners, addressing existing issues where test data does not accurately reflect production data. By providing more accurate synthetic data, the initiative aims to reduce testing times and expedite the delivery of enhancements and capabilities. The AI-generated test data will avoid including personally identifiable information (PII) or other sensitive trade information, ensuring compliance and security."
Anomaly Detection COV Structure,"The Anomaly Detection COV Structure is an AI algorithm designed to assist CBP officers in analyzing large-scale Non-Intrusive Inspection (NII) x-ray images by identifying regions of interest and detecting anomalies within Commercially Owned Vehicles (COV). This solution aims to enhance the review process by providing bounding boxes around unidentified objects, ultimately reducing the time required for NII image adjudication."
Anomaly Detection Homogenous Cargo,"Anomaly Detection Homogenous Cargo is an AI algorithm designed to help CBP officers analyze Non-intrusive Inspection (NII) x-ray images by identifying anomalies in homogenous cargo within commercially owned vehicles. This solution aids CBP image analysts by highlighting unidentifiable objects with bounding boxes, ultimately reducing the overall review time for NII images."
Anomaly Detection POV Structure,"The Anomaly Detection POV Structure project develops an AI algorithm to aid CBP officers in analyzing Non-Intrusive Inspection (NII) x-ray images of Privately Owned Vehicles (POVs). This solution identifies regions of interest and detects anomalies, streamlining the review process and reducing overall adjudication time while promoting legitimate trade and travel. The algorithm marks anomalies with bounding boxes to highlight unidentifiable objects within the images."
CBP Careers Bot - Leo,"The CBP Careers Bot, named Leo, is a decision-tree based chatbot designed to assist visitors on the U.S. Customs and Border Protection careers website. It aims to provide users with important career-related information and guide them towards actions like contacting a recruiter or applying for a job. By incorporating Natural Language Processing (NLP), the bot enhances user interactions with more natural and accurate responses."
Computer Vision for Aerial Detection of Land and Open Water Items of Interest,"The project focuses on developing computer vision technology for the automated detection, classification, and tracking of maritime threats, enhancing cross-border security efforts. It will equip system operators with real-time alerts and tracking information through a user-friendly workstation interface."
AI for Software Delivery,"The project seeks to integrate AI into the software development process to enhance code review efficiency within the continuous integration pipeline. By identifying potential problems and inefficiencies in code modifications, the AI aims to reduce review time and improve initial software quality. The AI model will help developers by identifying coding errors, recommending fixes, and suggesting improvements, while the request reviewer will make the final determination on code approval."
Optical Counter - UAS Detection,"The Optical Counter - UAS Detection project aims to enhance border surveillance by automating the detection, classification, and tracking of air and ground threats. It will provide system operators with real-time alerts and tracking information through a user-friendly workstation interface."
Thermal Power Generation with Geoseismic IoI Detection and Classification,"The project involves using seismic sensor data to detect and classify Items of Interest (IOIs) in deployed locations, enhancing situational awareness in challenging environments. The sensors operate on self-charging technology, minimizing the need for battery replacements, and provide alerts indicating the presence of an IOI along with a confidence interval for accurate classification of detected seismic activity."
Underwater ROV,"The Underwater ROV project aims to enhance maritime security by enabling users to swiftly identify potential threats and contraband on ship hulls without the need for a dive team. Through an AI system, it delivers informed assessments regarding the presence of threats or contraband, thereby streamlining investigations."
Wellness and Physical Fitness Application ,"The Wellness and Physical Fitness Application is an AI-powered personal workout coach designed for Customs and Border Patrol staff. It enhances user awareness of physical health through personalized fitness assessments, real-time monitoring, and program adjustments, while also providing metrics and trend analyses to promote health and wellness awareness. This initiative aims to reduce human capital costs by addressing physical fitness needs effectively."
API Security Vulnerability Technology,"The API Security Vulnerability Technology is designed to continuously run custom attack scenarios against APIs to identify security vulnerabilities before production deployment. This AI system provides real-time monitoring and alerts for new vulnerabilities, as well as detailed reports that include risk assessments and tailored remediation guidance specific to the applications and environments tested."
Cyber Threat Detection,"The Cyber Threat Detection technology utilizes decoy file-sharing capabilities to monitor and alert users on unauthorized access and interactions with these decoys across various cloud environments. By accurately detecting malicious activities, it provides actionable insights that assist leadership in identifying and mitigating threats efficiently, while also reducing the cost of traditional security defenses. Users receive alerts regarding detected compromises and can evaluate the effectiveness of the decoys created for security purposes."
Multi-media Insight Tool,"The Multi-media Insight Tool enhances CBP's surveillance capabilities by enabling real-time detection and tracking of anomalies in USBP camera footage. It improves situational awareness and accelerates decision-making through real-time alerts and visual annotations of items of interest, thereby boosting security and operational efficiency."
Position Description Generation and Evaluation,"The project aims to streamline the creation and evaluation of position descriptions (PDs) to enhance accuracy and reduce administrative burdens on both field operations and headquarters. By ensuring that PDs are generated more quickly and verified by Human Resources Specialists, the initiative enables the agency to operate more efficiently with fewer staff."
Source Code Development Tool,The Source Code Development Tool utilizes a generative artificial intelligence coding assistant to help end users develop software more quickly and efficiently. It generates functional software code to streamline the coding process for users.
AI Curated Synthetic Data,"The AI Curated Synthetic Data project aims to address the scarcity of rare event and labeled data for training Automated Threat Recognition (ATR) algorithms. By enhancing existing libraries of true positives and normal scans from CBP Non-Intrusive Inspection (NII) systems, the technology improves detection performance in identifying items of interest. This allows end users to significantly upgrade their existing, deployed algorithms."
Integrated Defense and Security Solutions (IDSS),The Integrated Defense and Security Solutions (IDSS) system enhances the efficiency and accuracy of contraband detection in international express consignment and mail inspection. It provides segmented images that highlight anomalies for further examination by Customs and Border Protection (CBP) personnel.
Advance RPM Maintenance Operating Reporter (ARMOR),"The Advance RPM Maintenance Operating Reporter (ARMOR) project aims to reduce the service, repair, and maintenance time for radiation portal monitors by two weeks, enhancing resource distribution and potentially decreasing costs by 25-50%. Additionally, ARMOR will improve radiological and nuclear security at US borders by minimizing outage times and predicting equipment degradation. The system will categorize malfunctioning RPMs by issue severity and projected failure dates, facilitating the creation of service tickets."
RAPTOR (Rapid Tactical Operations Reconnaissance),"RAPTOR (Rapid Tactical Operations Reconnaissance) enhances domain awareness and intelligence-driven operations for law enforcement and border control. The AI technology streamlines the analysis of stationary camera footage, automating the identification of boat identifiers and transcription of vessel registration data, which allows personnel to respond more efficiently to potential threats."
Vessel Detection,"The Vessel Detection project aims to enhance surveillance technology by implementing machine-assisted classification for identifying and tracking potential illicit vessels among legitimate traffic. This system will support human operators in distinguishing between legitimate and illegitimate vessels, leading to more efficient detection and resolution of Items of Interest (IOIs) during periods of high traffic volume. The outcome will improve overall monitoring effectiveness and increase operational efficiency."
AI for Autonomous Situational Awareness,"The AI for Autonomous Situational Awareness project aims to utilize IoT sensor kits and an AI-enhanced motion image/video system to covertly detect and track illicit cross-border traffic in remote areas. By enabling vehicle detection and direction determination, the system minimizes the burden of camera monitoring on operators, allowing them to focus on other tasks. The detections of items of interest are visually represented with bounding boxes, categorizing them as ""human, animal, or vehicle."""
RVSS Legacy Overhauled System Project,"The RVSS Legacy Overhauled System Project involves the implementation of Video Computer Aided Detection (VCAD), software that allows CBP users to create and share trained computer vision models for recognizing objects, people, and events in video streams. VCAD provides real-time monitoring and efficient searching of recorded video data, enabling users to receive detection reports and alerts for significant events. Additionally, the detection data is accessible through a robust API for integration with CBP applications."
Agent Portable Surveillance,"The Agent Portable Surveillance system is a mobile backpack unit designed for individual agent use, utilizing AI/ML to analyze data from cameras and radar to identify relevant border activities. Upon detection, the system relays information to agents via the Team Awareness Kit (TAK), enhancing operational efficiency and safety for agents and officers. This use case is currently inactive, and further details can be found in the intended purpose and expected benefits."
Open-Source News Aggregation,"The Open-Source News Aggregation platform leverages AI and machine learning to provide rapid intelligence assessments by analyzing diverse open-source data, such as news and social media. It aims to improve decision-making by forecasting emerging global events, thus enhancing threat recognition and predictive intelligence capabilities. This innovative approach transforms traditional monitoring methods, enabling a proactive focus on future geopolitical, social, and economic developments."
Autonomous Aerostat,"The Autonomous Aerostat project incorporates three tethers and advanced weather sensors to allow for autonomous operation during inclement weather. It utilizes AI and machine learning to determine optimal launch and recovery times, eliminating the need for on-site staffing and thereby saving time and manpower. This innovative approach enhances operational efficiency and safety."
Geospatial Imagery Utilizing Annotation,"The project utilizes a constellation of Synthetic Aperture Radar (SAR) satellites to capture geospatial imagery of any location on Earth, regardless of weather conditions or time of day. It employs advanced AI technologies for machine vision, object detection, and change detection to identify airframes, military vehicles, and marine vessels, catering to disaster response missions. However, the current use case is inactive."
Use of technology to identify proof of life,"The project focuses on utilizing technology, specifically mobile applications, for liveness detection to verify the authenticity of users and prevent the submission of spoofed or fraudulent images. Ensuring that users can be confidently identified as who they claim to be is essential for the app's functionality within agency settings. Currently, this use case is inactive, and further details are outlined under its intended purpose and expected benefits."
Integrated Digital Environment,"The Integrated Digital Environment enhances managers' insights into end-user workflows and application usage, identifying areas for optimization. By leveraging AI/ML models on user activity data, it aims to improve system configurations, resource utilization, and application development for the CBP. The environment also facilitates customized analytics and automation, promoting better connectivity, security, and overall management of applications."
Data and Entity Resolution,"The project focuses on entity resolution for multiple independent valid requirements, utilizing machine learning and human input to effectively leverage data attributes for resolution, moving beyond traditional brute force methods. It automates the unification of data sources and resolves entities efficiently at an enterprise level."
Port of Entry Risk Assessments,"CBP employs AI to enhance its risk assessment processes for evaluating trade and travel data in real-time. The AI methods applied to CBP data are continuously evaluated for accuracy and precision, supporting the agency's core mission within a layered risk assessment strategy. However, this specific use case is currently inactive."
Traveler Verification Service (TVS),"The Traveler Verification Service (TVS) offers a biometric system for the Customs and Border Protection (CBP) to track the entry and exit of travelers in the United States. It utilizes facial comparison technology by creating localized photo galleries from various sources, which are then converted into secure templates for identity verification. When travelers arrive or depart, their live images are matched against these templates to facilitate their processing by CBP officers."
I4 Viewer Matroid Image Analysis,"I4 Viewer Matroid Image Analysis is a software platform that allows users to create and share vision detectors for recognizing objects, people, and events in images and video streams. Once trained, these detectors can monitor real-time video or search through recorded data, providing detection information through reports and alerts. The detection data is also accessible through a robust API for integration into various applications."
Autonomous Maritime Awareness,"The Autonomous Maritime Awareness technology enables real-time surveillance of maritime activities in harsh conditions, including low temperatures, ice, and snow. It enhances detection capabilities to identify threats like unauthorized vessels or smuggling, providing real-time notifications, continuous tracking data, and detailed threat assessments for effective enforcement actions."
Advanced Trade Analytics Platform (ATAP),"The Advanced Trade Analytics Platform (ATAP) aims to enhance the efficiency and insight generation in the U.S. Customs and Border Protection's trade operations by utilizing data analytics, machine learning, and AI. It delivers actionable insights through dashboards and visualizations that aid operators in their assessments and decision-making processes."
CBP Employee Experience,"The CBP Employee Experience project aims to analyze and utilize employee experience data from surveys and operational metrics to provide real-time insights into the experiences of USBP recruits, applicants, and employees. These insights are designed to inform HRM leadership on opportunities for process improvement, enabling the achievement of hiring targets and the retention of a qualified workforce."
Passive Body Scanner,"The Passive Body Scanner (PBS) is designed to improve situational awareness for CBP officers during pedestrian traveler processing by identifying areas on a person's body where concealed objects may be present. It uses an algorithm to detect deviations in expected body heat, highlighting these areas on live video for real-time monitoring. This technology aids in the timely detection of potential weapons or contraband, supporting CBP's border search authority."
Unmanned Aircraft Collision Avoidance (Skydio),"The Unmanned Aircraft Collision Avoidance system, developed by Skydio, utilizes video feeds to power its obstacle avoidance capabilities in the Skydio X2D aircraft. It enhances the intake process while ensuring accurate identity verification, and notifies the pilot of potential collisions through visual alerts on the hand controller."
CBP Translate,"CBP Translate is an AI-driven tool designed to improve communication between border officers and non-English speakers by providing real-time translations of spoken and written interactions. It promotes inclusivity by supporting multiple languages, minimizes misunderstandings during critical procedures, and generates logs for review. For formal documentation and law enforcement questioning, it refers to standard translation services for sworn statements and official communications."
Entity Resolution,The project focuses on entity resolution to identify and analyze potential forced labor within supply chains using an analytical AI platform. It aims to enhance detection capabilities for labor exploitation in various supply chain processes.
Supervised Traveler Identity Verification Services (Officer Initiated),"The Supervised Traveler Identity Verification Services is a cloud-based biometric matching system that allows CBP to verify passenger identities via facial recognition. By utilizing DHS's facial matching technologies, it enhances traveler facilitation while decreasing the need for manual identity checks. This service is designed to streamline the identity verification process throughout the travel continuum."
Semi-Supervised Traveler Identity Verification Services (Traveler Initiated),"The Semi-Supervised Traveler Identity Verification Services project involves a cloud-based biometric matching service that allows CBP to verify passengers' identities using facial recognition technology. This service enhances traveler facilitation by providing instant match or no-match responses, thereby reducing the need for manual identity verification processes."
3rd Party Traveler Identity Verification Services,"The TVS Biometric Air Exit solution is a cloud-based service that utilizes facial biometric matching to verify passenger identities for CBP, External Partners, and Other Government Agencies. By leveraging DHS facial matching technologies, it enhances traveler facilitation and minimizes the need for manual identity verification."
Mobile Traveler Identity Verification,The TVS Biometric matching service is a cloud-based solution that enhances the identity verification process for travelers by matching their facial biometric data against trusted sources. This service improves traveler facilitation and reduces the need for manual identity checks by providing clear match or no match responses throughout the travel continuum.
Traveler Identity Verification Services (Vetting),"CBP's Traveler Identity Verification Services (Vetting) employs facial recognition technology to improve threat identification by comparing travelers' biometrics to records of concern. When a potential match is found, CBP personnel perform a manual facial comparison to assess the likelihood of association with the identified record."
Customs Broker License Exam - Proctor Support,"The project focuses on providing proctor support for the Customs Broker License Exam, promoting remote proctoring to maintain the integrity of the testing process. It ensures secure exam conditions, prevents cheating, and confirms the identity of exam candidates while generating integrity reports, compliance feedback, and test results."
ERNIE,"The ERNIE model improves threat detection by prioritizing high-risk targets, which enhances operational efficiency and national security. It provides real-time risk assessments and alerts for potential threats identified by Radiation Portal Monitors, along with prioritized recommendations for further screening based on radiation data analysis."
Autonomous Surveillance Tower (AST),"The Autonomous Surveillance Tower (AST) enhances the U.S. Border Patrol's operational efficiency by enabling a single user to monitor a larger area than traditional surveillance methods. The AI-driven system alerts users to the presence of various objects of interest, such as persons or vehicles, allowing trained agents to assess and classify activities effectively. This technology aims to improve resource allocation and allow agents to focus on more complex tasks."
Automated Item of Interest Detection,"The Automated Item of Interest Detection software analyzes images and video from operational equipment to identify individuals crossing into the U.S. at unauthorized locations or evading capture. It overlays a visual box around suspected human subjects, enabling Border Patrol agents to quickly assess and confirm the presence of people in those images."
CBP One,"CBP One utilizes facial recognition technology to verify identities in real-time by comparing live or uploaded images against CBP's database. This automated system improves border process efficiency, increases accuracy, and minimizes fraud, providing outputs such as identity match confirmations, fraud alerts, and traveler status updates."
Unified Processing/Mobile Intake,"The Unified Processing/Mobile Intake project aims to enhance the biometric identification process for individuals encountered by Customs and Border Protection (CBP), ensuring expedited processing. It utilizes CBP's facial matching technologies to deliver quick match or no match responses."
Cyber Threat Analysis (Recorded Future),"Cyber Threat Analysis from Recorded Future enables rapid retrieval of query results related to adversary tactics, techniques, and procedures, creating comprehensive threat scorecards. It also offers cyber risk evaluations for third-party vendors and organizations, delivering actionable intelligence that supports Security Operations Center (SOC) and Cyber Risk Management (CRM) efforts."
Vault Access Log (SPVAA),"The Vault Access Log (SPVAA) project enhances security by improving monitoring and reducing the risk of unauthorized access to seized property. It utilizes DHS facial matching technologies to deliver either a match or no match response, thereby strengthening security protocols."
HTS Classifier,"The HTS Classifier improves trade compliance and cargo risk assessment by streamlining the classification of goods and enhancing integration with machine learning systems. It accurately categorizes items based on their descriptions and attributes, thereby identifying potential threats and refining risk evaluations. The classifier's outputs, which map cargo descriptions to probable tariff codes, support predictive risk assessments and enhance security while facilitating trade."
CISAChat,CISAChat is a Generative AI solution designed to assist multiple CISA program offices in reviewing pre-production content and internal materials by generating summaries and key themes. This initiative enhances customer experience and saves staff time by automating content analysis through large language model (LLM) responses.
Critical Infrastructure Network Anomaly Detection,"The Critical Infrastructure Network Anomaly Detection project enhances government capabilities by automating the detection of malicious threat actors on critical infrastructure networks. It streamlines data fusion and correlation, enabling CISA analysts to prioritize threat hunting. Additionally, the project offers an interface for querying cybersecurity data and provides dashboards displaying alerts and detected anomalies through predictive models and rule-based heuristics."
Malware Reverse Engineering,"The Malware Reverse Engineering project enhances internal government tools for analyzing malware, thereby accelerating the development of cyber threat intelligence for government and CISA partners. By employing machine learning and other analytical tools, the project automates various aspects of the manual reverse engineering process, allowing analysts to focus on adversary response. This automation ultimately increases efficiency and compels threat actors to invest more resources in creating new malware."
Draft Tailored Summaries of Media Materials for Different Publication Channels,"The project involves using Large Language Models (LLMs) to create tailored summaries of media materials from historical publications and pre-production documents. An interface allows users to upload these documents, after which the system generates messaging using approved templates and tags them for review before publication."
Security Information and Event Management (SIEM) Alerting Models,"The project aims to enhance Security Information and Event Management (SIEM) capabilities for CISA Threat Hunting and SOC analysts by utilizing AI-assisted agents to automate the detection of cyber threats from terabytes of log data. By integrating advanced automated tooling, analysts can efficiently refine alerts and generate complex search queries to identify significant anomalies, allowing for prompt and accurate threat detection. Although the use case is currently inactive, it is designed to support high-fidelity anomaly detection through probabilistic modeling and curated expertise."
Advanced Analytic Enabled Forensic Investigation,"CISA deploys forensic specialists to investigate cyber events across various governmental levels and critical infrastructure partners. Utilizing advanced analytics with AI tools, forensic analysts can efficiently identify anomalies and threats by engaging with AI-assisted agents that help formulate complex search queries. This automated approach enhances the detection of high-fidelity anomalies in a timely manner."
Advanced Network Anomaly Alerting,"The Advanced Network Anomaly Alerting project aims to enhance the capabilities of threat hunting and Security Operations Center analysts by leveraging terabytes of data from the National Cybersecurity Protection System's Einstein sensors. It employs automated tooling alongside probabilistic models to refine detection alerts and identify high-fidelity network anomalies efficiently. Although currently inactive, the project is designed to improve anomaly detection and response times in cybersecurity operations."
Cyber Threat Intelligence Feed Correlation,"The Cyber Threat Intelligence Feed Correlation project employs AI technology to enhance the correlation of various incoming data feeds, resulting in quicker enrichment of shared threat information. It utilizes learning algorithms to optimize efficiency and allows for the development of custom algorithms to maintain continuous monitoring of threat actors' Tactics, Techniques, and Procedures (TTPs). However, this use case is currently inactive."
Cyber Incident Reporting,"The Cyber Incident Reporting project utilizes advanced automation tools, including machine learning and Natural Language Processing, to enhance the processing of data from various cyber threat intelligence channels. These tools improve data accuracy for human analysts, aggregate incident information for reporting, and identify vulnerability trends by correlating them with established frameworks and prior incidents to better understand attackers' techniques. Although currently inactive, the project aims to support critical infrastructure entities in effectively managing cyber incidents."
Cyber Vulnerability Reporting,"The Cyber Vulnerability Reporting project focuses on providing vulnerability analysts with advanced automation tools that utilize machine learning and natural language processing to enhance the accuracy and relevance of data from various reporting channels. These tools facilitate the aggregation and automated sharing of information, allowing for improved analysis and decision-making regarding known exploits and vulnerabilities. However, it is noted that this use case is currently inactive."
AI Security and Robustness,"The AI Security and Robustness project focuses on creating frameworks, processes, and testing tools to manage the lifecycle of AI technologies within federal enterprises, particularly at CISA. It leverages AI-enhanced tools utilizing machine learning and natural language processing to improve the evaluation and reliability of AI systems, ensuring their secure and robust operations. This use case is currently inactive and further details can be found in the intended purpose and expected benefits section."
Operational Activities Explorer,"The Operational Activities Explorer project aimed to integrate an AI tool into a dashboard for analyzing cyber and physical incidents affecting critical infrastructure. However, CISA chose not to proceed with the project due to challenges related to event data nuances and limited resources. Consequently, this use case is currently inactive."
Security Operation Center (SOC) Network Anomaly Detection,"The Security Operation Center (SOC) Network Anomaly Detection project enhances internal government tools for identifying malicious threat actors on federal civilian networks. By automating data fusion and correlation, it enables CISA analysts to concentrate on adversary hunting, while providing an interface for querying cybersecurity data and dashboards that display potential alerts and detected anomalies."
Automated Detection of Personally Identifiable Information (PII) in Cybersecurity Data,"The Automated Detection of Personally Identifiable Information (PII) in Cybersecurity Data project employs analytics to identify potential PII in submissions and routes flagged cases to CISA analysts for review. AI assists the analysts in confirming or rejecting detections, while privacy experts oversee the system's performance and provide feedback for continuous improvement. Regular audits maintain the system's trustworthiness and compliance with privacy regulations, ultimately enhancing its efficiency by minimizing false positives."
Confidence Scoring for Cybersecurity Threat Indicators,"The project involves generating confidence scores for cybersecurity threat indicators using an AI-driven decision tree process. These scores help CISA's Automated Indicator Sharing (AIS) partners contextualize the threat information, enabling them to effectively integrate the data into their systems. The confidence scores are included alongside other fields in the indicator data set."
Report Analysis and Archive System (RAAS),"The Report Analysis and Archive System (RAAS) helps users find relevant documents and specific information within a Test and Evaluation document archive by allowing them to ask natural language questions. It provides detailed responses, context summaries for better indexing, and facilitates further inquiries to refine the information retrieved. The system aims to enhance user experience by summarizing content based on the user's interests and questions."
RelativityOne,"RelativityOne is a document review platform designed to streamline large-scale document review for litigation, FOIA, and other contexts. It is actively employed by multiple components and offices within the Department of Homeland Security (DHS). The platform features a Review Center that enhances the review process by predicting document categorization based on user inputs."
Commercial Generative AI for Text Generation (AI Chatbot),"DHS employees are authorized to utilize commercially available generative AI tools for text generation, often referred to as AI Chatbots. These tools leverage Natural Language Processing and Large Language Models to produce coherent written content for various applications, including drafting documents, conducting research, and preparing briefing materials. Outputs from these tools may include written content, answers to queries, and search results based on user inputs."
Commercial Generative AI for Image Generation,"DHS employees can utilize commercially available generative AI tools for image generation in their daily tasks. These tools leverage Natural Language Processing and Machine Learning techniques like Generative Adversarial Networks and Diffusion Models to create diverse graphical content based on user-submitted text prompts. The generated images can vary in style and type, reflecting the user's input."
Commercial Generative AI for Code Generation,DHS employees can utilize commercially available generative AI tools for code generation in their daily tasks. These tools leverage Natural Language Processing (NLP) and Large Language Models (LLM) to generate functional code in various programming languages based on user prompts. The output varies according to the specific inputs provided by the user.
OCFO Code Assist GPT,"Code Assist GPT is an internal GenaAI tool designed to enhance the FEMA workforce by facilitating the generation and troubleshooting of queries across various established programming languages. By providing improved queries and enabling rapid iterations, the tool significantly reduces the time required for query development by 80-90%. It also allows users to continue refining their queries in real-time while ensuring that all session data is not stored after the session ends, maintaining user privacy."
Geospatial Damage Assessments,"The Geospatial Damage Assessments project integrates automated imagery-based tools into RGO processes to assist FEMA geospatial analysts in quickly identifying and characterizing building damage. AI models generate recommendations such as points or polygons indicating likely areas of damage or debris, enabling prioritized analysis and efficient response in large-scale incidents. This automation reduces the time needed for traditional damage assessments, streamlining rapid response and recovery efforts."
Hazard Mitigation Assistance Chatbot,"The Hazard Mitigation Assistance Chatbot is an AI-powered tool designed to improve efficiency, consistency, and decision-making for FEMA staff by providing quick access to accurate information and resources related to HMA policies and procedures. It aims to accelerate the onboarding of new hires, ensure compliance with guidelines, and support FEMA's mission by streamlining workflows and enhancing service delivery. The chatbot offers clear explanations of eligibility, funding priorities, and application processes, while also compiling and analyzing publicly available HMA data to produce insightful reports with visualizations."
Planning Assistant for Resilient Communities (PARC),"The Planning Assistant for Resilient Communities (PARC) aims to streamline the development of Hazard Mitigation Plans for State, Local, Tribal, and Territorial governments by generating customizable draft elements and offering guidance on regulatory compliance. Utilizing the Beta Release GenAI Plan Generator and PARC Assistant, the project enhances planners' efficiency by providing detailed responses and assistance throughout the plan creation process. This support ultimately empowers more communities to engage with stakeholders, apply for funding, and improve their resilience against disasters."
Recovery and Resilience Resource (RRR) Portal,"The Recovery and Resilience Resource (RRR) Portal aims to enhance access and navigation of federal resources for state, local, tribal, and territorial (SLTT) partners through an AI-driven smart matching wizard. This AI layer, which is currently unfunded, will utilize a large language model to analyze user behavior and connect SLTT partners with relevant resources from a vast database, benefiting various stakeholders involved in community recovery and resilience efforts. The initiative supports nearly 80,000 local governments and over 25 federal agencies, promoting equity in access to disaster recovery resources and best practices."
Digital Processing Procedure Manual (D-PPM),"The Digital Processing Procedure Manual (D-PPM) project leverages AI to enhance the efficiency of agents responding to survivor inquiries by streamlining the search process through dynamic information retrieval from extensive policy documents. This innovative approach is expected to drastically reduce response times, improve answer accuracy, and enable agents to manage more complex cases, ultimately leading to cost savings and increased survivor satisfaction. The AI will provide real-time, relevant search results, allowing agents to access the necessary information quickly without making final decisions."
FEMA OCFO GPT,"FEMA OCFO GPT is an internal GenAI tool designed to support FEMA's workforce by generating initial responses to record-related questions, significantly reducing the time analysts spend on data gathering. By leveraging both public and internal documents, the tool produces draft responses that can be refined prior to formal submission, cutting initial research effort by 80%. It enhances efficiency without replacing the roles of analysts or Agency leadership in the review process."
OCFO Response Augmentation Suite,"The OCFO Response Augmentation Suite includes three internal facing GenAI tools: FEMA OCFO GPT, Travel Policy GPT, and Fiscal Policy GPT. These tools enhance the FEMA workforce's efficiency by generating preliminary responses to inquiries related to organizational policies and issues, significantly reducing the time analysts spend on data gathering and initial responses by up to 90%. They are designed to support the formal response process without replacing the necessary review and oversight by agency leadership and analysts."
Incident Management Workforce Deployment Model (depmod),"The Incident Management Workforce Deployment Model (depmod) analyzes big data to identify patterns and simulate real-world processes, generating predictions based on these insights. It produces relatable, mission-centric metrics that can be summarized as actionable recommendations for effective incident management."
Individual Assistance (IA) & Public Assistance (PA) Projections,"The Individual Assistance (IA) and Public Assistance (PA) supervised learning models are designed to generate predictions for various quantities of interest relevant to disaster response and recovery. These models aim to enhance decision-making by providing timely, reliable predictions and quantifying uncertainty, which can inform resource allocation and funding considerations. The outputs will be disseminated internally via business intelligence tools, ensuring that key personnel have access to essential data-driven insights for operational planning."
Voice Analytics for Investigative Data,"Homeland Security Investigations (HSI) has developed Voice Analytics to efficiently process large volumes of live and recorded audio content encountered during investigations. By utilizing machine learning and advanced speech processing, this technology enables multilingual speech transcription and translation, enhancing the ability to identify leads and analyze data against law enforcement datasets. The system significantly improves the efficiency and effectiveness of investigations compared to traditional manual processes."
Semantic Search and Summarization for Investigative Reports,"The Semantic Search and Summarization project focuses on enhancing the analysis of large volumes of unstructured investigative reports by employing advanced methods for extracting and summarizing contextually relevant information. This approach surpasses traditional lexical search techniques, facilitating faster identification of persons of interest, revealing trends, and improving network or fraud detection. Overall, it aims to optimize investigative processes and outcomes."
Virtual Agent Chatbot for Human Capital,"The ServiceNow Virtual Agent chatbot is designed to streamline user interactions by providing automated support for common Human Capital inquiries. It utilizes natural language understanding (NLU) to deliver accurate responses and direct users to relevant resources, thereby reducing the volume of manual inquiries processed by the Office of Human Capital (OHC) and minimizing the number of clicks required for users to find information."
Machine Learning Translation Technology Initiative,"The Machine Learning Translation Technology Initiative aims to provide real-time communication and translation services to assist U.S. Immigration and Customs Enforcement (ICE) Enforcement and Removal Operations (ERO) in supporting limited English proficient (LEP) noncitizens. Developed under the sponsorship of the U.S. Coast Guard and DHS Science and Technology Directorate, this technology will deliver voice and text translations in at least 21 languages, ensuring effective communication while maintaining the necessity of human oversight for critical situations. The initiative is projected to meet operational requirements by January 2026."
Policy Analyst Assistant,"The Policy Analyst Assistant project for the Student and Exchange Visitor Program (SEVP) leverages AI technology to streamline the workflow of policy analysts by quickly identifying and summarizing relevant visa rules and regulations. This tool enhances the efficiency of policy staff, enabling them to respond more rapidly to inquiries and focus on complex policy matters, while ensuring that all responses are derived from pre-vetted authoritative sources. Ultimately, the project aims to improve response consistency and capacity without increasing staffing needs."
SEVP Response Center Chatbot - SID (SEVIS Interactive Dialog),"The SEVP Response Center Chatbot, SID, utilizes AI to understand voice inquiries and automate responses to routine questions from callers, alleviating the need for a help desk agent in many cases. When a complex issue arises that requires human assistance, SID generates a ticket with a transcript of the interaction, ensuring agents can focus on more intricate cases. Additionally, the chatbot integrates with the Student and Exchange Visitor Program Automated Management System (SEVPAMS) to streamline the inquiry process."
Title III Semantic Search and Summarization for Translated Content,"The Title III Semantic Search and Summarization project enhances translation and transcription services through machine learning and natural language processing, enabling efficient extraction and summarization of relevant data. This functionality accelerates investigative analysis by quickly identifying key individuals, trends, and fraudulent networks, thus significantly reducing the time required for manual evaluation. HSI will utilize this tool to generate leads, which will aid investigators and analysts in their comprehensive investigative processes."
Digital Records Manager (DRM) User Assistance Chatbot,"The Digital Records Manager (DRM) User Assistance Chatbot is designed to enhance the efficiency of investigators by providing immediate answers to frequently asked questions, thereby minimizing the need for users to consult documentation or submit help desk tickets. This AI-driven tool will generate natural language responses utilizing a custom Knowledge Base of DRM documentation, leveraging advanced language model capabilities to streamline the information retrieval process. The implementation of this chatbot is expected to reduce the volume of help desk tickets submitted by users."
Burlington Finance Center Voice Bot,"The Burlington Finance Center Voice Bot is designed to identify and verify callers, retrieve bond statuses, and address administrative FAQs. It utilizes Natural Language Understanding and Natural Language Processing for voice-to-text and text-to-voice translations, enabling it to recognize voices and meanings. The bot operates deterministically, without reliance on Generative AI."
RAVEn Compliance Automation Tool (CAT),"The RAVEn Compliance Automation Tool (CAT) is being developed to modernize HSI's Form I-9 inspection process by leveraging machine learning and automation to enhance the speed and efficiency of data processing. It features an easy-to-use front-end interface that minimizes manual entry and increases productivity, utilizing Optical Character Recognition (OCR) technology for identifying and extracting text from forms. The project is also exploring open-source ML Object Detection models to further improve text identification accuracy."
Data Tagging and Classification,"The Homeland Security Investigations (HSI) Innovation Lab is creating the Repository for Analytics in a Virtualized Environment (RAVEn) to enhance analytical capabilities in enforcing U.S. laws. RAVEn utilizes data tagging and classification through tools like the Email Analytics Tool and the Lead Tracker to streamline evidence analysis, improve lead management, and enhance the identification of criminal networks from mobile device data. The project aims to centralize information and boost the effectiveness of investigations."
Facial Recognition Service,"The Facial Recognition Service is utilized by Homeland Security Investigations (HSI) to identify known individuals and extract faces related to serious offenses such as child exploitation and human rights violations. This project is part of the DHS HSI Innovation Lab/RAVEn initiative, which supports complex analytical tasks to aid in the enforcement and investigation of U.S. laws. Currently, this use case is inactive, and further details can be found in its intended purpose and expected benefits documentation."
"Machine Translation
(Previously Language Translator)","The Machine Translation project enhances the RAVEn platform by enabling the translation of text in various languages into English, supporting analysis and standardization of searches across data sources. It utilizes Natural Language Processing and machine learning to facilitate conversions of plain text, word documents, and portable document formats during data ingestion or on an ad hoc basis. Currently, this use case is inactive, and further details are available under the ""intended purpose and expected benefits."""
Investigative Prioritization Aggregator,"The Investigative Prioritization Aggregator project leverages machine learning to quantify the significance of evidence linked to specific subjects or entities in criminal investigations, particularly in the counter-opioid and fentanyl mission. By assigning point values to various data inputs, the system helps HSI personnel identify high-priority targets and assess the impact of neutralizing influential actors within criminal networks. This innovative approach enhances the ability to analyze overwhelming data and improve the efficiency of investigations."
Hurricane Score,"The Hurricane Score is an AI-generated tool designed to assist Immigration and Customs Enforcement (ICE) officers by evaluating the risk of noncitizens absconding from monitoring programs. It assigns a risk score from 1 to 5, with higher scores indicating greater risk, to help inform decision-making and reduce human error due to officer workload. This model aims to streamline case management and improve monitoring effectiveness for noncitizen individuals released from detention."
ICE Mobile Check-in Application,"The ICE Mobile Check-in Application is designed for low-risk adult noncitizens to securely check in online, reducing the need for in-person visits and decreasing manual processing workload. Utilizing AI and machine learning, the app performs identity verification through face detection and tracking, ensuring compliance with check-in requirements. If verification fails, an officer can intervene to either retry the process or direct the user to schedule an in-person appointment."
AI Assisted Compromise Email Detector (AACED),"The AI Assisted Compromise Email Detector (AACED) was developed to aid ICE SOC analysts in efficiently reviewing emails between ICE personnel and Microsoft related to ED 24-02. It employs Named Entity Recognition (NER) to identify PII and relevant keywords, significantly reducing the time and effort needed for analysis. The system provides outputs that include named entities, generated text for specific inquiries, and a chat interface for context-based Q&A."
Intelligent Document Processing for Workflow Automation,"The Intelligent Document Processing platform automates repetitive tasks within business units at ICE, such as invoice processing and form entry validation. By utilizing Optical Character Recognition and machine learning models, it verifies, extracts, and classifies information from ICE forms, enhancing data quality and saving personnel time while enabling automation."
"Cybersecurity Threat Management, Detection, and Response","The project utilizes Machine Learning to analyze historical cybersecurity data and establish activity baselines for detecting anomalous behaviors. By integrating ML with advanced analytics and correlation rules, it enhances the ability of Security Operations Center (SOC) analysts to identify and respond to security threats rapidly. The result is an improved anomaly detection system that generates alerts based on identified patterns in security tool data."
Translation and Transcription for Investigative Data,"The Translation and Transcription Service aims to facilitate HSI investigators by translating data from various languages into English and transcribing voice recordings using advanced neural machine translation and deep learning models. This process allows for the rapid analysis of large datasets to identify critical information, with essential data subsequently reviewed by certified human translators for court use. The service ensures efficient allocation of government resources by focusing on necessary translations and transcriptions."
Biometric Check-in for ATD-ISAP (SmartLINK),"The ISAP Biometric Monitoring App enables participants to check in using their smartphones by verifying their identity and location while collecting status change information. This technology reduces the need for in-person interactions during routine check-ins and allows for more effective allocation of resources to manage non-compliant participants and complex cases. The app's outputs include either a biometric match, resulting in a successful check-in, or a pending review status for further human evaluation."
Email Analytics for Investigative Data,"The Email Analytics application streamlines the preparation of large volumes of multilingual email data for HSI personnel by automating processes such as spam classification, translation, and entity extraction using machine learning. This reduces the time and resources needed for data preparation, enhances the analytic utility of the data, and enables quicker analysis by HSI investigators. The expected output includes processed email data with classified spam, translated content, and extracted entities like names, organizations, and locations."
Mobile Device Analytics for Investigative Data,"The project focuses on developing mobile device analytics to assist investigators in efficiently reviewing and analyzing large volumes of data extracted from mobile devices obtained through legal processes. It utilizes machine learning algorithms to identify crucial evidence and geo-location patterns, such as 'stops' and 'overlaps' from seized phones, thereby enhancing the effectiveness of investigations. This technology is designed to accelerate the analytical process, aiding in the disruption of criminal networks and bolstering national security efforts."
Identification Card and Travel Document Code Detection,"The Identification Card and Travel Document Code Detection service uses mobile phone cameras and machine learning to accurately read 2D Data Matrix Codes and Machine Readable Zones on identification documents. This solution automates the extraction of relevant information, populating it into mobile app text fields and thereby reducing manual data entry and enhancing the efficiency of in-person interactions. The result is a structured dataset of identification data."
Normalization Services,"HSI employs artificial intelligence to enhance the accuracy and efficiency of data normalization processes, which include verifying and correcting addresses, phone numbers, names, and ID numbers. This service reduces data entry errors, detects misidentification, and connects information across various datasets, enabling quicker and more effective investigations. By producing normalized data, HSI improves search capabilities and allows for the identification of leads that may have been overlooked without manual intervention."
JES and Appropriations Insight,"The JES and Appropriations Insight project aims to transform scanned financial tables from PDFs into structured, machine-readable data while preserving multi-year spending relationships. This process eliminates manual data entry, reduces errors, and accelerates the consolidation of historical financial data from legacy documents by providing structured tables instead of free text."
CFO Companion,"CFO Companion is an intuitive tool that allows authorized staff to easily query and analyze Department of Homeland Security CFO financial data and reports using a conversational interface. This system democratizes access to financial information, reduces the time needed to search through documents, and facilitates quick self-service analytics without requiring specialized database knowledge. It utilizes natural language processing for on-demand information retrieval."
Climate Change Assessment Tool,"The Climate Change Assessment Tool aims to enhance the Department of Homeland Security's understanding and prediction of extreme weather impacts on its assets and workforce as outlined in the DHS Climate Action Plan. This AI pilot will facilitate the assessment of cost/benefit data to inform decision-making regarding facility locations and maintenance projects, ultimately leading to increased cost savings, improved workforce health and safety, and better access to critical information. Key outputs include early detection of extreme weather risks and cost-benefit recommendations for DHS operations."
Spending Analysis and Budget Execution Risk (SABER) Model,"The Spending Analysis and Budget Execution Risk (SABER) Model predicts potential budget execution issues by analyzing historical spending patterns across Treasury accounts. It facilitates early identification of spending anomalies, enabling proactive budget management to mitigate the risks of under or overspending through alerts and flags for review and comparison."
AdaptiveMFA,"Adaptive Multi-factor Authentication (AMFA) enhances security for DHS systems by integrating contextual authentication data, such as device, network, location, and external information. This approach allows for the dynamic adjustment of security and authentication policies, generating risk ratings of HIGH, MEDIUM, or LOW for each authentication attempt. These ratings can be configured to enforce stricter access control measures as needed."
ESEC Inquiry (STORM) Summarization,"ESEC-STORM AI utilizes Generative Artificial Intelligence to automate document summarization, streamlining the integration of these summaries into the STORM system for enhanced management of correspondence and information requests. When a user uploads a letter while creating a new work package, a Power Apps workflow is triggered to generate the summary."
One Health Threat Detection and Risk Assessment Platform (OH-TREADS) / Planner,"The One Health Threat Detection and Risk Assessment Platform (OH-TREADS) utilizes AI and machine learning to analyze various data sources and create machine-readable information, enhancing health security threat detection and risk assessment. The platform aims to provide comprehensive situational awareness and support decision-making through anomaly detection, risk identification, and disease prediction, all represented visually on a map alongside critical infrastructure. Ultimately, OH-TREADS facilitates global monitoring of health risks and aids in early warning systems and public health responses."
Sentiment Analysis and Topic Modeling (SenTop),"The Sentiment Analysis and Topic Modeling (SenTop) project is a versatile text analytics solution developed by DHS to analyze unstructured text, initially focused on contracting survey responses but applicable across various domains. It features advanced capabilities such as integrating sentiment analysis and topic modeling, automated topic modeling, and multi-model analyses. Currently, access to the tool is limited to one individual per customer request, and the specific use case for HR topics is inactive."
DHS-Chat,"DHS-Chat is a secure chatbot utilizing Large Language Models (LLM) designed exclusively for internal use by DHS employees. It generates written content from user prompts and aids in producing draft documents, synthesizing research, and developing briefing materials, all while handling non-classified but sensitive information like FOUO and CUI. The tool enhances efficiency in DHS operations by leveraging AI for various business applications."
User and Entity Behavior Analytics (UEBA),"The User and Entity Behavior Analytics (UEBA) project focuses on enhancing threat detection by identifying deviations in user behaviors that may indicate potential security risks. It implements continuous risk assessment through real-time monitoring and establishes behavioral baselines for individuals to facilitate anomaly detection and risk scoring. The system also enables improved incident response by generating automated alerts and reports for security personnel, allowing for timely interventions in high-risk scenarios."
Text Analytics for Survey Responses (TASR),"Text Analytics for Survey Responses (TASR) is an application that utilizes Natural Language Processing (NLP) to analyze open-ended survey responses from DHS Pulse Surveys. The tool extracts significant topics/themes and sentiment classifications from unstructured text data, providing valuable insights to DHS leadership to enhance employee satisfaction and address their basic needs. The outputs include inferred topics and sentiment classifications derived from the raw comments."
MiX Phenotyping,"The MiX Phenotyping project utilizes AI and machine learning to analyze electronic medical records, transforming them into machine-readable data to uncover health security insights. It aims to identify clinical patterns and automate the detection of emerging trends, providing valuable alerts and decision support for medical and public health professionals. Ultimately, the project will generate interpretable models through human-in-the-loop collaboration, enhancing the understanding of clinical patterns over time and location."
MiX Indicators,"The MiX Indicators project utilizes AI and machine learning to monitor online news for emerging health security threats by identifying key terms and predicting normal trends. This system focuses on anomaly detection by comparing actual mentions of health threat terms in news stories against predicted trends, allowing for quick identification of unusual spikes that could indicate a potential threat. The goal is to enhance preparedness and response to health security challenges through efficient news analysis."
MiX MedINT (Medical Intelligence Dashboard and Canvas),"MiX MedINT is a project that utilizes AI and machine learning to transform a diverse array of online health data into structured, machine-readable formats. It identifies and ranks relevant health-related articles, categorizing them by terms related to locations and diseases of interest. The resulting dataset supports the creation of comprehensive visual tools in MedINT Canvas and Dashboard, enabling analysts to monitor health security threats effectively."
Low Probability of False Alarm (Low-Pfa) Algorithm for on-person screening.,"The Low Probability of False Alarm (Low-Pfa) Algorithm enhances on-person screening by reducing alarm rates and ensuring gender-neutral detection, thereby improving passenger throughput and overall experience. This machine learning-based algorithm eliminates the need for gender selection prior to scanning, increases advanced imaging technology (AIT) utilization, and outputs target coordinates to the operator as bounding boxes on a human figure. Once trained, the algorithm is locked and ceases further learning."
Automated Target Recognition (ATR) Developments for Standard Screening,"The project focuses on enhancing Automated Target Recognition (ATR) algorithms to minimize privacy concerns by eliminating the need for Transportation Security Officers (TSOs) to view Advanced Imaging Technology (AIT) images. It aims to increase detection rates, reduce false alarms, and enhance overall efficiency and passenger experience. The system visually represents threat locations as bounding boxes on a human figure to assist TSOs in threat resolution."
Accessible Property Screening (APS) Checkpoint CT Prohibited Items (PI) Detection,"The Accessible Property Screening (APS) Checkpoint CT Prohibited Items (PI) Detection project aims to enhance airport security by developing AI/ML algorithms that automate the detection of non-explosive prohibited items, such as guns and knives, during luggage screening. These algorithms provide continuous monitoring and generate bounding boxes around suspected items, enabling Transportation Security Officers (TSOs) to focus on high-priority threats efficiently. The implementation of this AI solution improves overall threat detection, thereby creating a more secure environment for the public."
Walk-Through Metal Detector (WTMD) Alternative Automated Target Recognition (ATR) Developments,"The project focuses on the development of AI-enhanced millimeter wave detectors as an alternative to traditional walk-through metal detectors (WTMDs) for passenger screening. These advanced detectors can identify both metallic and non-metallic threats, improving security and enhancing the passenger experience by providing target coordinates displayed as a bounding box on a representative human figure."
Conversation Training and Feedback Simulator,"The TSA's Training and Development office utilizes an on-demand learning platform that features commercial training tailored to individual interests and skill levels. A key component of this platform incorporates a large language model (LLM) to facilitate interactive dialogue-style training, helping employees develop essential soft skills like customer service and communication on challenging topics. This approach supports personalized training plans and fosters professional growth among TSA staff."
Answer Engine,"The TSA is developing the Answer Engine to improve its data management and analysis capabilities, resulting in enhanced security operations and optimized workflows. This platform will leverage AI to deliver intelligent, context-aware responses and insights."
Automated Field Data Collection,"The Automated Field Data Collection project utilizes AI to analyze CCTV footage for extracting and visualizing passenger processing times in TSA screening environments. This capability allows for data-driven decision-making regarding new screening equipment, while also identifying anomalies and establishing real-world standards. The implementation of this AI system reduces the need for data collection teams and significantly accelerates the generation of insights regarding screening performance and passenger wait times."
Plan of Day Staff Optimization,"The Plan of Day project aims to automate the optimization of TSA screening staff operations. It will create models to manage staffing needs, including the opening and closing of screening lanes, adjusting for operational peaks, and maintaining appropriate gender and certification ratios. Additionally, it will provide recommendations for overtime scheduling, shift adjustments, lane rotation plans, and align with national TSA staffing requirements in response to changes in airline schedules."
TSA Contact Center Virtual Assistant,"The TSA Contact Center Virtual Assistant aims to enhance customer service by providing timely and accurate responses to inquiries, improving operational efficiency without requiring additional resources. Operating as a Predictive AI tool, it will utilize existing content from the TCC's knowledge library and generate transactional data on customer inquiries to identify areas for improvement and enhance overall customer experience. This initiative focuses on gathering insights that will inform improvements in public information and service offerings."
Machine Learning Analysis Applied to Cyber Threat Hunt Data,"The project applies machine learning analysis to cyber threat hunt data to enhance the efficiency and accuracy of detecting suspicious behavior. By leveraging machine learning models, it aims to analyze large datasets more effectively than humans, leading to faster identification of anomalies. Development is ongoing, focusing on improving the identification of potential anomalies within the system."
Synthetic Data for Improved Automated Threat Recognition (ATR) in Checkpoint Screening,"The project aims to create synthetic data to enhance Automated Threat Recognition (ATR) algorithm development for checkpoint screening. By producing synthetic data more quickly, the initiative seeks to improve the effectiveness of ATR systems in adapting to new threats. Accessible Property Screening (APS) and On-Person Screening (OPS) are collaborating with vendors to evaluate AI-based synthetic data generation techniques to expand the training data pool for machine learning algorithms used in ATR applications."
OTA Automated Passenger Screening Gate System,"The OTA Automated Passenger Screening Gate System utilizes AI to manage passenger flow and minimize human interaction by assessing body positioning and automatically starting the screening process when the passenger is optimally positioned. The system conducts an Automatic Identification Technology (AIT) scan, directing passengers either for additional screening or to a re-composure area based on the scan results, allowing for efficient transit into the sterile area."
Axon Capture Application,"The Axon Capture Application, used by the Transportation Security Administration (TSA), employs AI technology to transcribe and translate video footage from body-worn cameras. This advancement significantly reduces investigative processing time and enhances accuracy, while TSA staff review and certify the final usable data produced by the system. The AI generates a printable artifact from the transcribed audio and video data, ensuring reliable documentation."
Contract Requirement Automation,"The Contract Requirement Automation project streamlines document creation for procurement needs, significantly reducing manual labor and errors while improving accuracy and consistency. By automating document generation and providing contextual recommendations, the system enhances the management and verification of requirement documents, leading to cost savings and better resource allocation. Final outputs always undergo human verification to ensure compliance and quality before approval."
TSA Case Handling Platform,"The TSA Case Handling Platform automates administrative tasks for case workers, allowing them to focus more on case management. It streamlines the collection process and facilitates the creation of custom reports, centralizing all steps within each case. The platform also offers automation capabilities to compile and export essential documents throughout the complaint process."
CDC Airport Hotspot Throughput (PageRank),"The TSA's ""Stay Healthy. Stay Secure."" campaign introduces the CDC Airport Hotspot Throughput, which identifies domestic airports with the highest ranks of connecting flights during the holiday season to mitigate COVID-19 spread. This initiative uses an AI model based on historical non-PII travel data to analyze airport rankings through the PageRank algorithm. While TSA does not influence flight cancellations or airport closures, it remains committed to adapting safety procedures as more information about the virus becomes available."
Airport Throughput Predictive Model,"The Airport Throughput Predictive Model aims to forecast passenger volume based on Security Operations throughput counts at checkpoints, facilitating better airport staffing. Monthly data ingestion and model training enable accurate predictions of airport checkpoint throughput."
Credential Authentication Technology with Camera System (CAT-2) and AutoCAT (CAT-2 in an e-gate form factor),"The Credential Authentication Technology with Camera System (CAT-2) and AutoCAT enhances identity verification at TSA checkpoints using AI-based facial matching. This system increases the speed and accuracy of identifying travelers, while also helping to detect imposters. If a mismatch occurs, the Transportation Security Officer is tasked with further verification of the traveler's identity."
PreCheck Touchless Identity Solution (TIS),"The PreCheck Touchless Identity Solution (TIS) allows the TSA to use Facial Comparison technology to verify passenger identities quickly and securely at checkpoints and CMAP locations. This system, utilizing the CBP Traveler Verification Service (TVS), is optional for travelers and crew members who wish to expedite their TSA PreCheck or ID verification process, with the choice to opt-out for standard verification by a Transportation Security Officer available at any time."
Silicon Valley Innovation Program (SVIP) Language Translator,"The Silicon Valley Innovation Program (SVIP) is developing a handheld voice translator designed for U.S. Coast Guard (USCG) personnel to facilitate communication during high-tension situations involving non-English speaking individuals or multiple languages. This offline language translator will enable accurate and swift translation of critical information, enhancing the decision-making process of commanders during rescues and ensuring effective communication between USCG boarding teams and vessel occupants."
Adaptive Risk Model for Inspected Small Passenger Vessels,"The Adaptive Risk Model for Inspected Small Passenger Vessels utilizes machine learning and expert input to develop a quantitative tool that assesses marine casualties and assigns risk scores to vessels in the U.S. fleet. By employing logistic regression and machine learning techniques, the model enhances the allocation of marine inspectors, targets risks effectively, and promotes increased safety for passengers. It provides a numerical score that enables comparison of predicted safety risks among different vessels."
Intelligent Document Processing (IDP) for I-539 Form Digitization,"The Intelligent Document Processing (IDP) project for the I-539 form aims to digitize and categorize all documents related to the benefit application, improving processing efficiency for adjudicators. The AI-enhanced tool transforms a single scanned file into multiple individual digital files, ensuring compliance with NARA standards and enhancing the organization of supporting documents. Unidentified pages are referred to humans for resolution to ensure all documents are accurately accounted for and properly stored."
Large Language Models for an Officer Training Tool,"The Large Language Model (LLM) for an Officer Training Tool leverages Generative AI to enhance the training of immigration officers by producing personalized and dynamic training materials tailored to individual needs. This tool focuses on providing comprehensive knowledge about current policies and laws, delivering training through human-like conversational text similar to AI chatbots, but specifically designed for RAIO Officer training."
User Entity and Behavior Analytics (UEBA) for Security Operations (SecOps) Anomaly Identification,"User Entity and Behavior Analytics (UEBA) for Security Operations focuses on analyzing USCIS system logs to identify anomalous actions by various entities, including workstations, servers, and internal accounts. The system ingests logs and applies manually created models to generate risk scores, which are then utilized to create cases for Security Operations analyst review. This process not only assists in prioritizing cyber events for investigation but also allows for continuous improvement of risk scoring through machine learning feedback."
I-765 - USCIS Face Capture Mobile App,"The I-765 - USCIS Face Capture Mobile App enables users to complete biometric verification remotely, eliminating the need for in-person appointments at Applicant Support Centers. This innovation decreases the burden on applicants and optimizes resources at USCIS. The app utilizes advanced face detection and validation technology to ensure submitted photos meet USCIS requirements and provides feedback on the biometric match status through IDENT."
Case Processing Improvements in FDNS-DS NexGen,"USCIS is exploring the use of artificial intelligence and machine learning in the FDNS-DS NexGen system to improve case processing, prioritize investigations, and identify duplicate cases. The integration of AI/ML aims to enhance predictive modeling for system advancements and enable more effective fraud detection through comprehensive investigations of individuals with multiple identities. Although specific requirements are not yet defined, potential outcomes include recommendations, prioritization, and anomaly detection to support fraud management."
USCIS Translation Service,The USCIS Translation Service project aims to enhance document translation and real-time interpretation for immigration-related materials by integrating AI and GenAI models tailored to relevant subject matters. This initiative focuses on providing fast and accurate translations of written documents and facilitating efficient communication through advanced speech translation tools within the Department of Homeland Security (DHS). The overall goal is to support operations and adjudications across all DHS components by addressing language translation and transcription needs.
Verification Match Model,"The Verification Match Model utilizes AI to enhance the USCIS verification matching process by improving system accuracy, minimizing human error through automated match scoring, and increasing matching capacity beyond traditional methods. This model provides a recommendation score reflecting person-and-record match probability, thereby optimizing the performance of E-verify and SAVE systems for more accurate initial responses."
Sentiment Analysis -FOD Field Offices Complaints and Reviews,"The Sentiment Analysis project for FOD Field Offices focuses on evaluating feedback received by the U.S. Citizenship and Immigration Services (USCIS) to identify positive, negative, or neutral sentiments. The analysis is presented through an Excel dashboard that categorizes survey results, accompanied by a graph created in Databricks to visualize sentiment distribution, aiding in the enhancement of customer service without offering specific recommendations or decisions."
Asylum Text Analytics,"The Asylum Text Analytics project aims to enhance the affirmative asylum application process overseen by USCIS by utilizing machine learning and data graphing techniques to detect plagiarism-based fraud in asylum applications. This capability involves scanning the narrative sections of applications for common language patterns, thereby supporting the integrity of the asylum program. However, the initiative is currently inactive."
Biometrics Enrollment Tool (BET) Fingerprint Quality Score,"The Biometrics Enrollment Tool (BET) has integrated the NIST Fingerprint Image Quality 2 (NFIQ2) algorithm to assess fingerprint quality, assigning scores from 0 to 100 based on image clarity. A higher score indicates a greater likelihood of successful fingerprint matching during future captures. Currently, this use case is inactive; for more details, refer to the ""intended purpose and expected benefits."""
Timeseries Analysis and Forecasting,"USCIS implemented a timeseries analysis and forecasting project to manage the increasing volume of green card applications (Form I-90) by employing exploratory data analysis and machine learning techniques. Specifically, the organization utilized Autoregressive Integrated Moving Average (ARIMA) models to predict the number of I-90 forms over a two-year period, enhancing the model for better performance and reusability. This capability has been effectively deployed in production for over a year."
Testing Performance of ML Model using H2O,"USCIS employed H2O machine learning models to analyze and predict workloads associated with the increasing number of I-90 green card applications. By leveraging exploratory data analysis and machine learning, USCIS successfully identified the most accurate model for timeseries analysis and forecasting related to these applications. This initiative aimed to streamline the processing of lawful immigration applications effectively."
USCIS  Consular Consolidated Database (CCD) Facial Recognition (FR) On Demand Report (VISA Only),"The USCIS Facial Recognition On Demand Report for Visa applications is utilized to prevent fraud by comparing applicants' photos against the Department of State's Consular Consolidated Database. This process identifies individuals whose fingerprints are not in IDENT, allowing for a match or no match response to enhance visa application integrity."
Sentiment Analysis - Employee Satisfaction Surveys,"The project involves conducting sentiment analysis on employee satisfaction surveys, categorizing responses as positive, negative, or neutral. The results are presented in an Excel dashboard, along with a graph that highlights different sentiment trends. The analysis aims to inform improvements in customer service but does not provide specific recommendations or decisions."
Sentiment Analysis - ELIS Case Notes,"The project involves conducting sentiment analysis on ELIS case notes, resulting in survey data categorized into positive, negative, or neutral sentiments presented in an Excel dashboard. A data-driven graph visualizes the sentiments to identify areas for improving customer service but does not offer any specific recommendations or decisions."
Predicted to Natzuralize,"The Predicted to Naturalize model forecasts the eligibility timeline for Legal Permanent Residents to naturalize and aims to provide updated addresses for these individuals. While originally intended to facilitate communication from USCIS regarding resident status and potential benefits, this use case is currently inactive."
I-485 Family Matching,"The I-485 Family Matching project aimed to develop AI models to accurately match family members with I-485 petitions, which are tied to immigrant petitions. The challenge stemmed from limited data availability, primarily relying on the Alien-number (A-number) and shared addresses. However, the project did not progress past the ideation stage due to technical feasibility issues, and no AI model was developed."
Topic Modeling on Request For Evidence (RFE) Data Sets,"The project focuses on topic modeling for Request For Evidence (RFE) datasets, aiming to identify and organize related topics and documents. It employs methods that aid in uncovering hidden themes, classifying documents, and enhancing text data accessibility. However, the use case is currently inactive, and further details can be found in the ""intended purpose and expected benefits"" section."
I-539 approval prediction,"The I-539 approval prediction project aims to develop models for topic modeling, which involve organizing, understanding, and summarizing text data by identifying related topics and documents. This approach can uncover hidden themes within a document collection and facilitate the classification of documents into these themes. However, the project is currently inactive, and further details can be found in the intended purpose and expected benefits."
Text Analytics Data Science Sentence Similarity Model,"The Text Analytics Data Science Sentence Similarity Model enhances the identification of potential fraud, national security, and public safety concerns across jurisdictions, improving the efficiency and integrity of immigration programs. It serves as a research tool that detects patterns without making predictions or decisions, allowing trained staff to evaluate and validate such patterns for potential concerns. This approach ultimately strengthens officers' confidence in their work and reduces customer wait times."
Biometrics Enrollment Tool (BET) Fingerprint Maximization,"The Biometrics Enrollment Tool (BET) uses machine learning models to evaluate the quality of fingerprints to ensure they meet FBI standards for acceptance. It provides immediate feedback on whether a fingerprint is likely to be rejected, mitigating the risk of additional encounters with applicants. BET generates a numerical fingerprint quality score, which is assessed against established thresholds to comply with FBI specifications."
ELIS Evidence Classifier Machine Learning (ML) Tagging Solution,"The ELIS Evidence Classifier Machine Learning tagging solution streamlines the navigation of evidence documents by automatically identifying and tagging specific document types within large PDF files. Users benefit from clickable ""bookmarks"" in the user interface, enabling them to quickly access relevant documents without manually scrolling through extensive content. The system processes scanned documents and applies labels to recognized classes, facilitating faster case processing."
Automated Name and Date of Birth (DOB) Harvesting from Existing Records,"The project aims to automate the extraction of unique names and dates of birth (DOBs) from identity history summary (idHS) reports to minimize manual adjudication time during case processing. This system will suggest names and DOBs for review only if they are not already present in the ELIS database, allowing users to accept or reject the suggestions while retaining human oversight in the decision-making process."
Automated Realtime Global Organization Specialist (ARGOS) for Company Registration Submissions to E-Verify,"The Automated Realtime Global Organization Specialist (ARGOS) streamlines company registration submissions to E-Verify by performing sentiment analysis and keyword extraction, which helps Management and Program Analysts (MPAs) identify critical information during open-source investigations. This automation conserves thousands of man hours and provides a comprehensive, accessible dashboard for MPAs, facilitating faster application processing and quicker referrals for suspected company fraud. The system ensures that MPAs receive pertinent data and risk scores, enhancing the efficiency of their investigative efforts."
ELIS Card Photo Validation via myUSCIS,"The ELIS Card Photo Validation project by USCIS employs computer vision and machine learning to verify that ID photos meet requirements before card production. This system enhances efficiency by identifying correct photos and providing feedback to users, who can choose whether to accept the recommendations or proceed with their uploads regardless."
I-765 - USCIS Facial Recognition through IDENT (1:1 Face Recognition/Validation),The I-765 project implements facial recognition technology through IDENT to enable biometric verification without requiring users to attend in-person appointments at Applicant Support Centers. This innovation not only eases the process for beneficiaries but also alleviates pressure on USCIS resources. The system provides a match or no match response from IDENT for validation purposes.
Person-Centric Identity Services Deduplication Model,"The Person-Centric Identity Services (PCIS) Deduplication Model employs machine learning to enhance entity resolution and provide a comprehensive overview of an individual's immigration history. This model allows users to access an organized summary, including the individual's latest photo, full immigration history, and all associated identifiers, presented in reverse chronological order. A numerical likelihood score, with a high threshold of .98, assesses the accuracy of matching records to individuals."
Person-Centric Identity Services A-Number Management Model,"The Person-Centric Identity Services A-Number Management Model leverages machine learning to enhance the accuracy of identifying and managing the associations between individuals and their assigned A-numbers, unique identifiers for noncitizens by DHS. It utilizes a numerical likelihood score, with a high threshold of .98, to validate whether a presented A-number correctly corresponds to the individual in question. This approach is critical for retrieving an individual's associated records across the system."
Identity Match Option (IMO) Tool for Record Compilation,"The Identity Match Option (IMO) Tool is utilized by USCIS for person-centric research and analytics to consolidate identities from multiple systems for applicants and beneficiaries. The tool features a user-friendly dashboard that presents data patterns without enabling predictions or decision-making. IMO, a commercial off-the-shelf product by Informatica, incorporates various algorithms for identity resolution."
Criminal Investigations (OBIM),"The Criminal Investigations AI project enables USSS INV personnel to submit photographs or video stills to other government agencies for facial recognition comparisons against their image galleries. This process aids in generating investigative leads to identify victims or suspects by providing potential matches from known individuals. Additionally, personnel can request one-to-one comparisons of specific images for further investigation."
GitHub Copilot for Code Modernization,"The GitHub Copilot for Code Modernization project aims to enhance the efficiency and quality of code modernization at BEA. It automates the initial conversion of legacy code into modern programming languages, which is subsequently reviewed and refined by human developers before being implemented in applications."
Azure OpenAI Chat Prototype,"The Azure OpenAI Chat Prototype enables staff to interact with a large language model (LLM) similar to ChatGPT, while ensuring that all data remains within the BEA's network boundary. This project focuses on text and data analysis, facilitating efficient communication and insights for the staff."
Sentinel One Purple AI,Sentinel One Purple AI enhances the BEA cybersecurity program by accelerating and improving incident response times. It utilizes advanced log analysis techniques to ensure comprehensive and efficient handling of security incidents.
Real Time Classification for the Economic Census,"The project utilizes two machine learning models, BEACON and SINCT, to enhance the real-time classification of Primary Business Activity (PBA) and Products during the Economic Census. By automating the classification process, the project successfully reduced the number of NAICS and NAPCS write-ins by 58% and 78%, respectively, in the 2022 Census compared to previous years. This improved accuracy and efficiency streamline responses and minimize the need for manual processing."
Automated Change Detection,"The Census Bureau's Geography Division is utilizing AI for Automated Change Detection to identify updates in the built environment twice a year in preparation for the 2030 Decennial Census. By analyzing Sentinel-2 imagery through Google Earth Engine, the project extracts geographic features like roads and building footprints to enhance national coverage and inform the use of high-resolution imagery."
School staff information extraction from web page text,"This project focuses on extracting school staff information from publicly available web pages, specifically targeting staff rosters at public and private schools. The AI system predicts links to staff directories and extracts names and titles of teachers and principals, enhancing the quality and coverage of educational staff data."
Census Bureau Demographic Frame Person-Place Model,"The Census Bureau's Demographic Frame Person-Place Model (PPM) utilizes machine learning to accurately associate individuals with their residential locations, generating predicted probabilities for person-address records. This innovative approach enhances data precision for demographic analyses and population estimates, supporting the Census Bureau's mission to deliver reliable data. By accommodating diverse data sources, the PPM improves the accuracy of governmental operations and informs policy-making and service delivery for the public."
Race and Ethnicity Autocoding,The Race and Ethnicity Autocoding project focuses on creating an automated system for coding write-in entries related to race and ethnicity. Its objective is to enhance the quality and efficiency of this coding process by providing standardized concept codes that correspond to the written responses.
Information extraction for web scraped data for Group Quarters frame enhancement,"This project focuses on extracting information from publicly available web data to enhance the quality and coverage of the Group Quarters (GQ) frame. The initiative aims to identify specific elements such as the capacity, address components, and concepts like dates and building names using pretrained Named Entity Recognition (NER) models."
Current Population Survey (CPS) Name Screening Tool,The Current Population Survey (CPS) Name Screening Tool utilizes AI to analyze and classify survey data entries to determine the validity of names provided. The objective of this tool is to improve the efficiency and accuracy of data processing and future data collection by identifying invalid name responses.
Linkage and Matching Program (LaMP),"The Linkage and Matching Program (LaMP) utilizes probabilistic record linkage to connect various person-level datasets, facilitating research on economic, demographic, and other subjects. The AI model predicts potential matches between records by generating pairs that exceed a set similarity threshold, along with a score reflecting their similarity. This process enhances the quality and efficiency of multiple Census operations."
Census Research Exploration and Analysis Tool (CREAT),"The Census Research Exploration and Analysis Tool (CREAT) is an experimental data tool developed by the Center for Economic Studies (CES) at the US Census Bureau, employing natural language processing to analyze and categorize economic research from CES working papers. Its primary objective is to facilitate connections among research, foster new collaborations, and organize papers by various criteria using NLP techniques for tag extraction and similarity determination. CREAT enhances the accessibility and interconnectedness of economic research publications by allowing users to sort and explore papers effectively."
Dr. NAICS LLM,"The Dr. NAICS LLM is designed to accurately assign NAICS codes to business descriptions, addressing challenges posed by the complexity of the NAICS classification system. It analyzes incoming emails and voicemails, providing recommendations to enhance code classification decisions based on the provided text. Ultimately, the AI generates a suggested set of NAICS codes that align best with the specified business activities."
Automating Multilingual Census Data Processing: An AI and Transformer-Based Pipeline for Efficient Language Detection and Translation for Short-Text,"The project develops an AI-driven pipeline that automates the processing of multilingual, short-text census data, focusing on language detection, translation, and entity recognition. By leveraging transformer-based models and natural language processing techniques, the system enhances accuracy and efficiency, reducing reliance on human translators while ensuring inclusive representation of diverse populations. The output facilitates streamlined data processing, delivering validated translations and improved demographic insights for better resource allocation and policy-making."
FAQ for SMaRT,"The FAQ search tool for the 2025 Census Test is designed to help the public find accurate Census Bureau answers to common questions using a machine-learning model that incorporates semantic similarity to enhance search effectiveness. Building on previous small-scale tests, this tool will provide over 50 FAQs on its landing page, offering support for users who may not use exact terms. If successful, it could be applied in future Census Tests, enabling better access to official information for the public."
Statistical package syntax development and debugging,"The project involved the development and debugging of SPSS syntax for various statistical analyses, including the generation of interaction terms for moderated multiple regression and the creation of racial codes based on participant self-identifications. The use of AI facilitated the production of complex regression analysis syntax and allowed for comparison of self-identified race across surveys, marking consistency for protected class standings. The final deliverables included SPSS syntax and recommendations for its configuration."
DSD Python Code Translation,"The DSD Python Code Translation project aims to facilitate the conversion of SAS code to Python for DSD data processing, supporting the Census's mission to adopt enterprise-wide solutions and decrease reliance on expensive proprietary software. The project will produce translated Python code that accurately mirrors the original SAS code, followed by a comparison of outputs to ensure correctness until the desired results are attained."
Census API GPT,"The Census API GPT aids users in retrieving statistical information by guiding them on how to formulate accurate API requests for various data categories, including demographic and economic data. It provides clear explanations of datasets, parameters, and methods, ensuring users can access relevant information easily while emphasizing the importance of specificity in their queries. Additionally, it displays the returned data directly, helping users understand the outcomes of their API calls."
Natural Language Search for data.census.gov,"The project aims to enhance the search functionality of data.census.gov by implementing a natural language search interface powered by a large language model (LLM) using a retrieval augmented generation (RAG) architecture. This new system will allow users to pose queries in natural language, leading to more accurate and accessible retrieval of statistics, datasets, and filters. Ultimately, this will improve the overall search experience for users of varying backgrounds."
"ACES CAPEX (structures, equipment, other) Machine Learning","The ACES CAPEX project utilized machine learning to improve the classification of capital expenditures items, specifically structures, equipment, or ""other."" Although the survey is no longer active and the machine learning system has been discontinued, it aimed to enhance the accuracy of categorizing items as either structures or equipment."
FirstNet Authority OCIO MS CoPilot Project,"The FirstNet Authority OCIO MS CoPilot Project aims to enhance content creation and user productivity using Microsoft 365 Copilot within Microsoft Office applications. By leveraging this tool, users can generate and improve content more efficiently, facilitating better communication of ideas while maximizing the use of existing organizational knowledge and information."
FirstNet Authority Communications Topaz Labs Photo Editing,"The FirstNet Authority project involves the use of AI tools from Topaz Labs to enhance the quality of digital photo and video files. It focuses on improving picture clarity, smoothing video, and scaling images without loss of quality. This initiative aims to leverage advanced editing technology for superior visual content."
Global Business Navigator Chatbot,"The Global Business Navigator Chatbot, developed by ITA, leverages artificial intelligence to provide clear and accurate responses to common export-related questions. It helps users navigate Export Solutions resources and directs more complex inquiries to trade specialists for tailored assistance. Additionally, the chatbot offers multilingual support, enhancing accessibility for a diverse range of users."
Generative AI Tools Pilot - Global Markets,"The Generative AI Tools Pilot in Global Markets aims to enhance report production by automating the generation of initial drafts of market research reports using public data sources. This initiative allows analysts to concentrate on strategic tasks, reduces costs, and improves overall efficiency, leading to superior client service and quicker decision-making. Additionally, the project integrates seamlessly with existing workflows, assisting analysts in refining and finalizing actionable reports."
Generative AI Tools Pilot - Enterprise & Solutions Architecture,"The Generative AI Tools Pilot in Enterprise and Solutions Architecture aims to minimize manual effort in architecture documentation by automating the drafting of technical documents and reference models using standardized templates. It seeks to accelerate solution design, improve operational efficiency, and enhance service quality while summarizing complex data sets for quicker decision-making. Additionally, the project will facilitate compliance checks by applying relevant frameworks and standards."
WAWENETS,"WAWENETS is a project focused on developing a comprehensive network for collecting, analyzing, and sharing data related to specific themes and topics. It aims to enhance collaboration among stakeholders and improve decision-making processes in various fields. The project's infrastructure supports efficient information exchange and fosters innovation through data-driven insights."
Streamline Spectrum Activities,"The project aims to enhance the efficiency of the NTIA Office of Spectrum Management (OSM) by streamlining processes and improving federal spectrum management using Azure and CoPilot capabilities. OSM CoPilot will facilitate general office productivity, streamline current spectrum management functions, and accelerate processes by reducing unnecessary steps, all under the oversight of spectrum stakeholders."
Spectrum Visualizations,Spectrum Visualizations is a project that focuses on creating visual representations of spectral data. The aim is to enhance understanding and analysis of various types of spectrum information through clear and insightful graphical displays. This initiative presents a valuable tool for researchers and practitioners in fields that rely on spectral analysis.
Use of Lexis. Other searches for legal research ,"The project focuses on utilizing Lexis as a primary tool for legal research, exploring its features and capabilities in retrieving relevant legal information. Additionally, it examines alternative search methods and resources that can complement Lexis to enhance the effectiveness of legal research strategies. The goal is to improve the overall process of obtaining pertinent legal data for various applications."
Grants Program Administration,"The project focuses on integrating AI into the administration of a grants program, aiming to enhance knowledge management for the internal team. It will facilitate the review of post-award reports by identifying trends and inconsistencies through machine learning and compliance-based analytics."
Grammarly,"The project focuses on enhancing written communication by improving grammar, punctuation, and style. It aims to assist users in idea generation and refining their tone, ultimately increasing the quality of their writing."
Science Data Portal Autosuggest Search ,"The Science Data Portal Autosuggest Search project aims to enhance user experience by facilitating the discovery, access, and re-use of scientific, engineering, and technical information from the bureau. It features dynamically generated search terms that are filtered and ranked based on their frequency of use. This system will assist end users in navigating the vast array of information available."
FathomNet,FathomNet is a project focused on the annotation of ocean images to create datasets for training machine learning models. It aims to enhance understanding of marine environments by providing accurate labels and categorizations for various marine species and habitats. The project contributes to advancing marine research and conservation efforts through improved image recognition technology.
Coastal Change Analysis Program (C-CAP),The Coastal Change Analysis Program (C-CAP) focuses on developing high-resolution land cover data for the United States. This initiative aims to enhance the understanding of coastal land use changes and inform decision-making related to environmental management and conservation.
"CoralNet: Ongoing operational use, improvement, and development, of machine vision point classification",CoralNet is a project focused on the operational use and enhancement of machine vision for classifying points in coral reef monitoring. It leverages computer vision technology to support conservation efforts by providing accurate assessments of coral health and biodiversity. The project aims to continuously improve its methodologies to better serve the needs of reef conservation.
Coral Reef Watch,Coral Reef Watch utilizes remote sensing data to monitor and predict coral reef health and conditions. The project focuses on interpreting satellite imagery and environmental data to provide insights into coral bleaching and other threats facing marine ecosystems. Its aim is to support conservation efforts and inform stakeholders about the status of coral reefs globally.
Steller sea lion brand sighting ,The project involves using a U-net model to analyze Steller sea lion sightings. It utilizes the R programming language and the specialized TLC package to enhance the accuracy of the data classification. This initiative aims to improve the understanding and monitoring of Steller sea lion populations.
"CoralNet: Ongoing operational use, improvement, and development, of machine vision point classification.",CoralNet is focused on the operational use and enhancement of machine vision technology for point classification in coral reef monitoring. This project utilizes Fully Convolutional Neural Networks (FCNN) to improve accuracy and efficiency in analyzing coral health and biodiversity. Ongoing development efforts aim to refine the machine learning models and expand their applications in ecological studies.
"BANTER, a machine learning acoustic event classifier","BANTER is a machine learning model designed to classify acoustic events. It analyzes audio data to identify and categorize different sounds, improving the understanding and processing of acoustic information. The project aims to enhance applications in various fields such as surveillance, environmental monitoring, and user interfaces."
Operational satellite product quality monitoring AI-ready training data,"The project aims to enhance anomaly detection in NOAA's satellite product quality monitoring by leveraging AI technology. Traditionally reliant on manual inspection, this approach will automate the identification of satellite product anomalies, improving efficiency and accuracy in monitoring. By implementing AI, the project seeks to reduce the burden on personnel, allowing for a more streamlined alert system."
LightningCast: AI for lightning prediction,"LightningCast uses artificial intelligence to predict lightning events, offering advanced warnings before the threat materializes. It enables users to assess the probability of lightning occurring at a specific location within the next 60 minutes, allowing for proactive measures to safeguard life and property."
CyberSecurity Hardening & Automation,"The CyberSecurity Hardening & Automation project focuses on the analysis of cybersecurity architecture, documentation, and vulnerabilities to improve security measures. It aims to identify remediation and automation opportunities while ensuring continuous monitoring and effective responses to data calls. Additionally, the project includes conducting architectural risk assessments and generating necessary documentation for ongoing risk management."
AI based Community Radiative Transfer Model,"The AI-based Community Radiative Transfer Model enables rapid radiative transfer calculations to support enhanced weather forecasts and the creation of satellite products. It simulates satellite radiances and provides sensitivity analyses (Jacobian) for satellite data, addressing the growing demands for accurate satellite information."
Operational Enterprise Cloud Mask,The Operational Enterprise Cloud Mask project focuses on developing internal ECM algorithm classifiers to enhance cloud detection across various surface types and atmospheric conditions. This initiative aims to improve the accuracy and efficiency of cloud identification in cloud-related applications.
AI Snowfall Detection and Snowfall Rate estimation,"This project focuses on developing artificial intelligence algorithms to detect snowfall and estimate snowfall rates. By leveraging advanced data analysis techniques, it aims to improve the accuracy and efficiency of snowfall monitoring to enhance weather forecasting and related applications."
AI Rain Rate estimation,"The AI Rain Rate Estimation project focuses on utilizing artificial intelligence techniques to accurately estimate the rate of rainfall in real-time. By leveraging machine learning algorithms and historical weather data, the project aims to improve the precision of rain forecasts, which can enhance weather monitoring and inform decision-making in various sectors."
AI Total Precipitable Water estimation,The AI Total Precipitable Water estimation project utilizes artificial intelligence techniques to accurately measure and predict total precipitable water in the atmosphere. This involves analyzing various meteorological data inputs to enhance forecasting and understanding of water vapor distribution. The objective is to improve weather prediction models and support climate research.
AI Cloud Liquid Water estimation,"The AI Cloud Liquid Water estimation project focuses on developing advanced algorithms to accurately measure liquid water content in clouds using artificial intelligence techniques. This project aims to enhance the understanding of cloud properties and improve weather prediction models by leveraging data analytics and machine learning approaches. By utilizing satellite imagery and atmospheric data, it seeks to provide valuable insights into cloud dynamics and precipitation forecasting."
AI retrieval for patent search,"The project focuses on developing an AI-driven tool to enhance patent searches for examiners. It analyzes both published and unpublished applications to recommend relevant prior art areas, allowing users to sort results based on concept similarity. This augmentation aims to improve the efficiency and effectiveness of the patent examination process."
AI use for CPC classification,"The project focuses on utilizing AI to automate the assignment of Cooperative Patent Classification (CPC) symbols to patent utility documents, enhancing efficiency in the classification process. This system aims to decrease classification time, reduce agency costs, and ensure greater consistency in classification practices by predicting relevant CPC symbols for each inputted utility patent document."
AI retrieval for TM design coding and image search,"The project involves developing an AI retrieval system for trademark design coding and image searches using Clarivate's COTS solution. This system will aid examiners in identifying similar trademark images, assigning appropriate design codes, and assessing the acceptability of goods and services identifications. It will process both incoming and registered trademark images to produce relevant design codes and related images."
Enriched Citation,"The Enriched Citation project develops a data dissemination system that identifies references cited in patent application office actions, including their bibliographic information, relevant claims, and sections utilized by examiners. The system employs AI to extract and summarize data from unstructured text, resulting in operational cost savings. Additionally, it presents this structured information via a public-facing API."
Inventor Search Assistant (iSAT),"The Inventor Search Assistant (iSAT) is a service designed to assist inventors in identifying relevant documents, figures, and classification codes for conducting novelty searches. It offers continuity in access to public search capabilities, particularly during COVID-19 closures that restricted in-person assistance. Users can input a short description of their invention and receive a tailored set of recommended resources to aid their search."
Patent Design Image Search (DesignVision),"DesignVision is a SaaS AI-driven image search tool specifically engineered to facilitate the examination of design applications. It analyzes uploaded images to return similar design results, enhancing access to and retrieval of information from Industrial Design collections."
USPTO Virtual Assistant (Public-facing chatbot),"The USPTO Virtual Assistant is a public-facing chatbot designed to provide answers to inquiries related to trademarks and patents. It assists users by addressing common questions about trademark and patent processes, enhancing accessibility to essential information."
Patent Automatic Document Code Determination,"The project focuses on the automatic determination of document codes for patent applications, aiming to enhance the quality control of customer-applied document labels. It seeks to ensure accurate labeling and organization of documents related to patents. This automation process is designed to improve efficiency and reduce errors in document management."
Patents - Skill Group Matching,"The project aims to utilize AI to automate the assignment of Skill Group designations to patent applications, facilitating a more efficient classification system than the outdated US Patent Classification (USPC). This automation is expected to reduce costs related to Skill Group designation workloads, enhance metrics data availability, and improve management of unexamined patent inventory and workforce allocation. Additionally, the AI system will provide predictions for the appropriate Skill Group for each patent application, accompanied by a confidence score reflecting the accuracy of these predictions."
Groundwater Modeling,The groundwater modeling project focuses on predicting the flow of contaminants in underground groundwater. It emphasizes parameter estimation to enhance the accuracy of groundwater models.
OpenText for Records Management (Email Auto-Classification),"The OpenText for Records Management project focuses on automating the classification of email records to streamline the process. By leveraging OpenText's capabilities, each email message will be automatically categorized into the appropriate category, significantly reducing the time required for manual classification."
Applications of Natural Language Processing and Similarity Measures for Similarity Ranking,"This project focuses on showcasing the capabilities of artificial intelligence by applying natural language processing and similarity measures for similarity ranking. It aims to achieve cost savings through the sharing of algorithms, methodologies, and insights from evaluations and deployments in the ES&H DAMaL Tools. The project will also deliver customized outputs, such as ranked records based on the analysis."
"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data:  Classification, Robotic Process Automation and Data Visualization","The DAMaL project focuses on developing tools that leverage data analytics and machine learning to improve the analysis of Environment, Safety, and Health (ES&H) data. Key features include AI-driven data visualization, enhanced efficiency in extracting insights from ES&H data, and the creation of dynamic data visualization charts. The initiative aims to streamline processes and provide better analytical capabilities in the field of environmental, safety, and health data management."
"Data Analytics and Machine Learning (DAMaL) Tools for Analysis of Environment, Safety and Health (ES&H) data:  Similarity Based Information Retrieval","The DAMaL project focuses on developing tools for the analysis of Environment, Safety, and Health (ES&H) data using data analytics and machine learning techniques. It aims to enhance the efficiency of information retrieval through AI by implementing similarity-based methods to rank records effectively, thereby facilitating easier access to relevant data."
"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data:  Unsupervised Machine Learning Text Clustering","The DAMaL project focuses on utilizing data analytics and machine learning tools to analyze Environment, Safety, and Health (ES&H) data through unsupervised machine learning text clustering. It aims to enhance the efficiency of report grouping by identifying and highlighting significant data trends and topics within ES&H records. The outcome will facilitate improved insights and decision-making by clustering records based on key terms and themes."
Fast AI for real-time/online diagnostics and calibration; AI-based autonomous system control/operation optimization (including anomaly/failure detection),"The project focuses on developing Fast AI technologies for real-time diagnostics and calibration of accelerator-based scientific facilities. It aims to enhance efficiency and quality in facility operations through AI and machine learning, enabling better anomaly detection and operational optimization. This will lead to increased scientific throughput, improved energy efficiency, and the introduction of new capabilities at Office of Science user facilities."
"AI for system design optimization (e.g., detector, accelerator)","The project focuses on utilizing AI/ML models to enhance system design optimization for detectors and accelerators by accurately predicting future data points from small datasets in a high-dimensional parameter space. This predictive capability boosts the convergence efficiency of optimization algorithms, streamlining the time-intensive design process. The AI system employs a non-parametric data fitting model to deliver predicted function values and associated uncertainties for new solutions."
PARSGPT,PARSGPT enables PM Analysts to safely engage with LLM technology through a user-friendly chatbot that offers free-form text responses to inquiries. This tool enhances accessibility and streamlines interactions with advanced language models.
CrowdStrike,"CrowdStrike utilizes advanced predictive technology to forecast malicious behavior and offers actionable recommendations. The platform effectively blocks harmful activities, ensuring enhanced cybersecurity."
SCMC AWS Data Infrastructure,The SCMC AWS Data Infrastructure project aims to automate various manual processes while enhancing data quality and governance. The system will initially employ machine learning to identify inconsistent data and predict optimal data organization.
ServiceNow Predictive Intelligence,"ServiceNow Predictive Intelligence aims to enhance the accuracy and consistency of ticket classification within the ServiceNow platform. By leveraging advanced algorithms, it processes field classification data to improve the handling and categorization of support requests. This initiative ultimately leads to more efficient service management and better user experiences."
AI-Enhanced Lab Assist,"The AI-Enhanced Lab Assist project focuses on integrating learned lessons into Lab Assist Activity Planning to boost operational efficiency and improve information sharing through best practices. It will utilize AI for trend detection in planning and control data, promoting a culture of continuous improvement."
Microsoft 365 Copilot (Productivity Suite),"Microsoft 365 Copilot is being implemented at PNNL to enhance productivity by streamlining workflows and improving efficiency. The tool will enable researchers to concentrate on innovation rather than administrative tasks, ultimately accelerating scientific research and operational effectiveness. Key benefits include improved document quality, insightful data analysis, enhanced collaboration, and automated workflows."
NLCOO AI for Lessons Learned tool ,"The NLCOO AI for Lessons Learned tool enhances the ability to search and extract insights from existing lessons learned. It enables users to efficiently find relevant documents, ultimately improving work processes."
" Spot for automated sensing, inspection, and capture","Spot is a mobile robot designed for automated sensing, inspection, and data capture in hazardous or difficult-to-access environments. Equipped with advanced sensors and cameras, it enhances efficiency and increases the accuracy of sensor research data."
Microsoft Power Platform capability that provides AI to automate processes in Power Apps and Power Automate,"The Microsoft Power Platform introduces AI capabilities to automate processes within Power Apps and Power Automate. This automation enables PNNL to streamline routine tasks like data entry and reporting, allowing researchers and staff to concentrate on more significant activities. Ultimately, this leads to increased productivity, decreased human error, and improved management of research projects and resources."
CAISY,"CAISY is an AI-powered platform that offers interactive, scenario-based learning experiences, enabling users to practice new skills in a safe environment. Learners engage with an AI-generated avatar, utilizing speech-to-text and text-to-speech services for natural interaction, and receive personalized feedback and evaluation after each session. This innovative approach allows for adaptive learning tailored to individual development needs."
ServiceNow Virtual Agent,"The ServiceNow Virtual Agent assists employees with IT-related issues through a chat interface, providing troubleshooting support. It delivers automated responses to common queries, streamlining the process of resolving technology problems. This project enhances employee efficiency and satisfaction by offering immediate assistance."
Databricks AI for Cloud Data Warehouse,The Databricks AI for Cloud Data Warehouse project focuses on enhancing the efficiency of analytics and the deployment of artificial intelligence and machine learning models. It provides recommendations based on analytic input to optimize data-driven decision-making. This initiative aims to streamline processes and improve overall performance in data management and analytics tasks.
DOE Technical Standards,The project focuses on enhancing the quality and accuracy of technical standards to support the Department of Energy's commitment to safety excellence. It includes gathering recommendations and feedback for continuous improvement in these standards.
Microsoft Copilot for Security,"Microsoft Copilot for Security is designed to proactively identify, mitigate, and respond to threats within an organization. It enhances security through real-time monitoring, automated incident responses, and thorough vulnerability management, ultimately providing outputs such as improved threat detection, compliance reports, and reduced cyber risk. The implementation of this tool at PNNL aims to ensure sustained operational continuity and enhanced data protection."
Text To Speech Audio Generation,"The Text-to-Speech Audio Generation project utilizes AI to produce audio files for training content, facilitating quicker development to align with company requirements. This approach results in cost savings for both the initial creation and subsequent modifications of training materials. The generated output is in MP4 audio file format."
Lex Natural Language Interface ,"The Lex Natural Language Interface is designed to allow users to efficiently query project data, including funding, allocation units, project focus, and fiscal years, using natural language prompts. It executes queries against a PostgreSQL database and presents both a textual summary of the query results and the generated queries in an accessible format."
Scopus AI,"Scopus AI assists researchers by streamlining the process of finding relevant research, thereby reducing the time needed for literature searches. It enhances the quality and accuracy of identified citations, abstracts, and summaries, ultimately improving the research experience."
EnerGPT,"EnerGPT is designed to improve user productivity by generating answers to questions, thereby minimizing the time spent on repetitive tasks. Its primary goal is to streamline user workflows and enhance overall efficiency."
MAPPRITE,"MAPPRITE is an AI-driven application designed to automate the data mining, ingesting, and indexing of diverse organizational information related to safeguards and security (S&S). Its implementation aims to enhance EHSS-51 business workflows by making relevant S&S support data easily accessible and searchable for policy subject matter specialists, thereby improving strategic decision-making and policy management while reducing the need for manual searches through numerous data sources."
MI8 Collimators Surogate Model,"The MI8 Collimators Surrogate Model project aims to develop a machine learning surrogate model for the existing MI8 collimation system to optimize its settings for accelerator operations. The model will provide predictions on the performance of the collimation system based on its settings and beam characteristics, with plans to extend these techniques to other sub-systems and a new MI8 collimation system."
Records Digitization,SEPA is utilizing artificial intelligence and machine learning to improve metadata tagging and ensure quality control in the records digitization process. This includes precise metadata assignment that adheres to SEPA's NARA-approved file plan and records schedule.
Machine Learning components within Splunk Enterprise Security,"This project focuses on implementing machine learning components within Splunk Enterprise Security to enable big data analysis and trend identification in large datasets. SLAC aims to utilize these capabilities for data clustering, trend analysis, classification, and regression through the application of prediction and clustering models."
Machine Learning components within CrowdStrike,"CrowdStrike employs machine learning to analyze security events, generating alerts for the SLAC Cybersecurity team regarding potential detections and incidents. This technology enhances SLAC's visibility into security threats, enabling improved analysis and response to possible cybersecurity events."
AskOEDI,"AskOEDI aims to enhance data accessibility and usability for the public by utilizing Retrieval-Augmented Generation technology. The system identifies semantically relevant content and employs AI language models to provide concise summaries, thereby improving user interaction with the data catalog."
Hanford Search,"The Hanford Search project aims to consolidate multiple applications into a single, user-friendly interface that leverages AI technology for improved search results. Users can interact with the system using natural language, allowing for more intuitive inquiries about grounded data related to the Hanford Search Index. This approach enhances accessibility and relevance in information retrieval."
AI Chat Bot for IT User Services,"The AI Chat Bot for IT User Services is an interactive retrieval-augmented generation model designed to assist users with tier 1 IT issues. It is trained on existing, updated, and new IT resource documentation, providing user-friendly recommendations and instructions based on input from IT administrators. This platform aims to enhance user support by guiding them to the appropriate resources and solutions."
Hanford Popfon Search,"The Hanford Popfon Search project aims to consolidate employee look-up functionality into a single, user-friendly application that allows for natural language queries. This new AI-driven interface will replace an outdated application, enhancing safety, security, and cost-effectiveness. It enables users to access grounded data on employee contact and organizational information efficiently."
AI for Intelligent Automation,"The project focuses on leveraging generative AI to enhance manual work processes by automating comparisons and decision-making based on established procedures and documents. Humans will retain the role of final validators and approvers, ensuring quality control. This initiative aims to improve both the timeliness and quality of workflows."
Hanford Ai Liaison,"The Hanford Ai Liaison tool is designed to offer a secure prompt-to-text interface, allowing users to ask questions and receive generative responses through a trained model. This tool addresses the needs of users who previously relied on external ChatGPT tools by providing a safe environment where prompts and document data remain within an accredited boundary. It utilizes large language modeling techniques to generate text responses based on user input."
Tritium Accountancy for Fusione Energy,"The Tritium Accountancy project focuses on enhancing data accuracy and predictive capabilities for tritium management in commercial fusion power systems. It aims to provide real-time tritium data with minimized uncertainty, facilitating adaptive learning for the operation of continuously functioning fusion plants. This framework is designed for comprehensive application across full system operations."
ServiceNow Now Assist,"ServiceNow Now Assist enhances the efficiency and quality of service desk transactions by optimizing incident search, resolution processes, and incorporating AI-assisted workflow coding. The project aims to deliver outputs that align with industry standards for commercial service desk products, focusing on the effective search, creation, and closure of service requests."
Enhancing ClimRR Capabilities to Better Support Electric Utility Applications and Technical Assistance,"The project focuses on enhancing the capabilities of ClimRR by integrating CALLM (Climate Action through Large Language Models), which simplifies complex climate projections and scientific literature for electric sector stakeholders. This tool aims to improve communication of climate science, empowering stakeholders to effectively address climate change impacts and enhance climate resilience planning. The AI-generated outputs, based on vetted data and research, provide accessible information, including risk summaries and tailored adaptation strategies, thereby facilitating better-informed decision-making and potential cost savings."
WCD-AI,"WCD-AI is a project that recommends keyword-based searches to find pertinent Lessons Learned available on DOE OPEXShare. It generates suggested keywords for searching, which are tailored based on the content of user-authored Work Control Documents."
OpenText for Records Management (File share auto-classification),"The OpenText for Records Management project aims to streamline the classification of legacy records accumulated over the past 20 years. By utilizing OpenText's capabilities, the project will automatically categorize files stored on network drives, significantly reducing the time required for manual classification."
OPQ-AI,"OPQ-AI automates the review process for incoming people registrations by recommending the most likely matches with existing database records, significantly reducing the time required for manual reviews. It provides suggestions for either matching existing records or creating new person records when no match is found. This technology enhances efficiency and accuracy in managing registrations."
Funding Finder,The Funding Finder project will consolidate funding opportunity announcements (FOAs) from various Department of Energy (DOE) sources. It will allow users to ask questions to assist in identifying relevant opportunities and developing proposals related to those FOAs.
PDF Analyzer,PDF Analyzer is a tool designed for teams within the DOE to upload large PDF documents and generate content or answers to questions related to those files. It provides users with responses along with the corresponding sections of the PDF that informed the answers.
Hanford  Service Ticket Lookup,"The Hanford Service Ticket Lookup is designed to offer customers an intuitive interface for accessing service tickets without navigating complex menus or search functions. It aims to consolidate service tickets from various platforms into a single system, allowing users to inquire in natural language. The system generates text responses based on user requests for information related to service ticket requests."
INL AI Virtual Assitant (AiVA),"The INL AI Virtual Assistant (AiVA) is a chatbot designed to answer questions, coach users on processes, enhance communication, and generate code in multiple formats. Starting in 2025, INL plans to incorporate internal non-CUI data using Retrieval-Augmented Generation (RAG) technology, including documents like the employee handbook. The outputs produced by AiVA align with those of commercial chatbot products, such as ChatGPT."
Unleashing AI Transformer Models on FPGAs for Accelerating LHC and Particle Physics,"The project aims to implement AI Transformer models on Field Programmable Gate Arrays (FPGAs) to enhance particle physics experiments, particularly for the CMS level-1 trigger at the High-Luminosity LHC and real-time magnet quench detection. By integrating advanced AI techniques, it seeks to overcome the limitations of conventional event identification methods. The AI system will serve dual purposes: representation learning for the LHC Trigger and developing multi-modal magnet quench detection algorithms."
Hanford Procedure Search,The Hanford Procedure Search project aims to improve employee access to relevant procedures by providing an AI-driven search interface. This system enhances search effectiveness by delivering more accurate results and allowing users to interact using natural language questions instead of predefined criteria. It outputs text responses based on user queries related to the Hanford Procedure System.
LLM EV ,"The LLM EV project aims to enhance the accessibility of NREL's electric vehicle data for researchers, thereby accelerating advancements in the field. The initiative also involves the analysis of research results from the referenced study, contributing to a deeper understanding of electric vehicle dynamics and trends."
AskPRIMR,"AskPRIMR is a project designed to enhance data accessibility and usability for the public. It utilizes Retrieval-Augmented Generation to identify semantically relevant content, which is then summarized by an AI language model to provide users with concise descriptions of pertinent information within a data catalog."
Coupa,"Coupa incorporates AI functionality to enhance its search capabilities and improve the efficiency of sourcing and procurement processes. Additionally, it utilizes predictive analysis to optimize decision-making and streamline operations."
GitHub Copilot with the OpenAI Codex,"GitHub Copilot, powered by OpenAI Codex, enhances productivity for developers by streamlining coding tasks. This enables researchers to concentrate on innovation and speed up the creation of high-quality software solutions for scientific purposes."
First Alert DataMinr AI,"First Alert DataMinr AI enhances situational awareness and emergency reporting for the NNSA and DOE Sites by automating incident monitoring and response operations. This AI service reduces the need for a large development team, ultimately resulting in cost savings for the Federal government. It effectively aggregates data and provides insights for more efficient emergency management."
Yurts AI search function,The Yurts AI search function is designed to enhance data accessibility at SLAC by efficiently locating relevant information across multiple data sources. This project aims to provide users with improved access to data through comprehensive summaries and recommendations.
"Interactive platform to help review and create ""Promoting Inclusive and Equitable Research"" Plans","This interactive platform utilizes a trained AI model to review and enhance ""Promoting Inclusive and Equitable Research"" (PIER) plans. It provides revision suggestions to ensure accuracy and consistency while aligning with specific PPPL Diversity, Equity, Inclusion, and Accessibility (DEIA) goals. Additionally, the platform guides users in creating research plans that are cohesive with previously submitted and approved plans."
Energy Wizard,"Energy Wizard enhances accessibility to NREL data for researchers by utilizing Retrieval-Augmented Generation technology. This system identifies semantically relevant content, which the AI then summarizes, effectively conveying pertinent information from selected publications and research profiles to end users."
LANL AI Portal,"The LANL AI Portal provides democratized access to open-source Large Language Models (LLMs) aimed at enhancing office productivity, AI research, software development, and operational efficiency. It features interactive text chat responses, document summarization for Retrieval Augmented Generation (RAG), and API query replies to support enterprise and scientific applications."
Position Description Tool,"The Position Description Tool aims to streamline the creation of position descriptions for hiring federal employees. Currently, requirements are being gathered to enhance this tool, which is a crucial element in the federal hiring process. The ultimate objective is to improve efficiency and consistency in developing these documents."
ChatGPT Enterprise,"ChatGPT Enterprise enhances business productivity by providing interactive text chat responses based on user prompts. It includes the capability to summarize open and public documents submitted by users, utilizing Retrieval Augmented Generation (RAG) through CustomGPTs for efficient research and analysis of AI models."
Argo,"Argo is a tool designed for the Argonne community that utilizes text-based generative AI to provide tailored responses based on Argonne-specific information and sensitive data, including Controlled Unclassified Information (CUI). It enables users to interact with a large language model to generate prediction-based outputs in response to their prompts."
AI Chat Bot for Facility Sustainability Practices,"The project involves developing an AI chat bot that provides guidance on facility sustainability practices, specifically focusing on recycling, composting, and trash disposal. This interactive model aims to reduce confusion around waste disposal practices and enhance the proper recycling of items at PPPL by offering tailored recommendations and instructions based on its training data."
AskGDR,"AskGDR is a project focused on enhancing data accessibility and user-friendliness for the public. It utilizes Retrieval-Augmented Generation to identify semantically relevant content, which is then summarized by an AI language model to effectively convey essential information from the data catalog."
Topic Modeling for Energy.gov ,"The project involves implementing topic modeling techniques to automate the categorization of 100,000 Energy.gov webpages, reducing the manual effort needed for reading and tagging. The goal is to generate a list of five relevant tags for each webpage to streamline content management and improve resource accessibility."
In-Situ Monitoring of Additively Manufactured Parts,"The project focuses on in-situ monitoring of additively manufactured parts to identify print defects during the printing process. It aims to produce layerwise annotated images of defects on the print bed, which can be used for post-print analysis or to prompt corrective actions, potentially preventing material waste."
Boston Dynamics Spot Robotics,"The Boston Dynamics Spot Robotics project focuses on automating the movements of robotic systems. It involves the development and testing of robots for security and emergency response applications, with an emphasis on optimizing their navigation and decision-making processes to determine the most effective paths for movement."
Elastic Stack Technology (ELK),The project focuses on leveraging Elastic Stack Technology (ELK) to enhance media cataloging for improved data discovery. It utilizes ElasticSearch for efficient content searching and integrates Logstash and Kibana for data processing and visualization. This approach aims to streamline the collection and retrieval of media content.
Raytheon Multimedia Monitoring System (M3S),"The Raytheon Multimedia Monitoring System (M3S) facilitates off-cloud transcription of pre-recorded video media to enhance data discoverability. This system utilizes voice-to-text technology to convert spoken content into text format, making it easier to access and analyze video information."
Cognitive Prescreen Tool (CPT),"The Cognitive Prescreen Tool (CPT) functions as a recommender for Derivative Classifiers, enhancing document review by improving accuracy and efficiency. It focuses on detecting sensitive information in accordance with Department of Energy classification guidelines, aiming to minimize information loss and reduce the risk of inadvertent disclosure."
Machine Learning for Linac Improved Performance,"The project focuses on improving the performance of the Linac by addressing daily fluctuations in Ion Source conditions and environmental changes that impact beam quality. It employs AI-based optimization techniques, including Bayesian Optimization, to develop real-time RF compensation solutions aimed at stabilizing beam energy and reducing beam loss. The anticipated outcome includes proposed adjustments to RF system parameters to enhance overall accelerator efficiency."
Next-Generation Beam Cooling and Control with Optical Stochastic Cooling,"The project aims to improve the real-time control of circulating particle beams using optical stochastic cooling, enhancing performance and operational flexibility at DOE accelerator facilities. An AI system will continuously assess beam distribution and implement reinforcement learning-based control strategies to optimize beam dynamics. This innovative approach is expected to expand the scientific capabilities of future accelerator technologies."
high level synthesis for machine learning (previously hls4ml),"High level synthesis for machine learning, formerly known as hls4ml, facilitates the implementation of specialized AI algorithms in embedded hardware to enable real-time processing. This capability enhances scientific discovery and accelerates research timelines, resulting in significant cost savings and increased prestige for the Department of Energy. The technology supports various AI applications, including prediction, data compression, and decision-making control."
Streamining intelligent detectors for sPHENIX/EIC,"The project focuses on developing AI tools for real-time embedded inference in scientific experiments like sPHENIX and the upcoming EIC. These intelligent detectors aim to enhance scientific discovery, reduce time to results, and achieve significant cost savings while elevating the prestige of the Department of Energy (DOE). The AI algorithms span tasks from prediction to data compression and decision-making."
In-pixel AI for future tracking detectors,The project focuses on integrating AI algorithms directly into tracking detectors' on-board electronics to minimize data size and facilitate high-speed processing. It proposes using AI classifiers to determine data retention and offers rapid inference of track parameters to enhance selection efficiency in data handling.
SONIC: AI acceleration as a service,"SONIC is an AI acceleration service designed to enhance AI workloads on coprocessors for scientific experiments. By improving efficiency in areas such as prediction, data compression, and decision-making, SONIC accelerates scientific discovery and reduces costs, ultimately contributing to the prestige of the Department of Energy (DOE)."
READS: Real-time Edge AI for Distributed Systems,"The READS project focuses on implementing real-time Edge AI for distributed systems within particle accelerators. It includes two sub-projects: the first streams live beam loss monitor data to an AI model on an FPGA for real-time identification of beam loss sources, and the second enhances resonant beam extraction regulation using AI to optimize the Spill Duty Factor in the Fermilab Delivery Ring and Mu2e. The outcomes provide insights into beam loss origins and recommendations for improved regulation."
Extreme data reduction for the edge,"The project focuses on developing AI tools for embedded inference in real-time processing systems, specifically designed for scientific experiments. By providing capabilities such as prediction, data compression, and decision-making, these tools aim to enhance scientific discovery, reduce time to science, and ultimately lead to significant cost savings and increased prestige for the Department of Energy (DOE)."
Machine Learning for Accelerator Operations Using Big Data Analytics / L-CAPE,"The L-CAPE project utilizes machine learning models for fault detection and labeling in the FNAL Linac, enhancing operational efficiency and preventive maintenance. This system also features a dashboard that displays fault labels, predicts downtime, and suggests possible corrective actions. It is noted as the first global implementation of a machine learning system for accelerator operations."
Soil Moisture Modeling,"The Soil Moisture Modeling project aims to forecast soil moisture levels using existing data, eliminating the need for additional monitoring wells. This approach enhances efficient resource management and provides valuable insights for agricultural and environmental applications."
DOIChatGPT AI Chatbot,"The DOIChatGPT AI Chatbot is a secure platform designed for DOI users to interact with a Large Language Model within a controlled security environment. It utilizes a customized version of Microsoft's Govchat repository, deployed as an Azure app service on the internal network, and incorporates Entra authentication, with DOIChatGPT APIM serving as the backend AI service provider."
DOIChatGPT API Management Instance,"The project involves setting up an Azure OpenAI instance secured by an Azure API Management (APIM) layer within an internal network, facilitating secure access and cost tracking through subscription keys. This service layer will support various project activities, although specific outputs are currently undocumented and will be updated once more data is collected."
DOIChatGPT API Management Development Environment,"The DOIChatGPT API Management Development Environment is designed as a public-facing platform for training and validating proof-of-concept applications using the DOIChatGPT API and Azure OpenAI, utilizing sanitized data. Documentation of outputs is currently lacking, and the Department of the Interior (DOI) plans to update use cases as more data becomes available from users."
Cost Estimation Using EDL Database Data,The project focuses on utilizing AI/ML to improve the accuracy of estimating environmental remediation costs by analyzing historical data from the EDL database. It aims to enhance budget planning and contractor evaluations by comparing new sites with similar archived records to provide more reliable cleanup cost estimates. The AI/ML tool will serve as a supplementary resource for decision-making in financial planning and contractor proposal assessments.
Adobe Firefly Generative Images,"Adobe's Firefly generative image AI model was utilized in Photoshop to create artistic sketches of nature scenes for the StoryMap by San Juan Island National Historical Park. These AI-generated images provided a more efficient and cost-effective alternative to traditional artistic methods, and they were manually edited to ensure accuracy. The final StoryMap featuring these sketches is available for viewing online."
RAG knowledge base of agent procedures,"The project focuses on developing a customized AI chatbot to improve the efficiency of internal customer service agents and enhance external customer support. This solution aims to provide quick and accurate responses by streamlining access to knowledge, thereby reducing agent workload and response times while increasing customer satisfaction. The implementation of this chatbot will also minimize the number of support inquiries handled by human agents."
Use of AI to Enhance Flash Flood Forecast Tool,"The University of Illinois has developed a rainfall prediction model for the Great Smoky Mountains National Park, which is being enhanced with AI in collaboration with IBM to forecast flash flooding events with a lead time of over 24 hours. This initiative aims to improve the accuracy of the National Weather Service's Quantitative Precipitation Forecast. The National Park Service is involved as an end-user of the flood forecast tool but is not participating in its development or direct use of the AI."
Liable Party Research,This project involves the development of a supervised machine learning model designed to scrape leasing documents for the purpose of identifying current liable party ownership. The model aims to enhance the efficiency of determining ownership and liability in leasing agreements.
Data Extraction Using MS Power Automate AI Functionality,"The project involves leveraging MS Power Automate's AI functionality to train a pre-built machine learning model for extracting data from various document formats. This process aims to convert the extracted data into a consistent structured format, enhancing business operations and improving documentation efficiency."
CESU project to detect of bird nests using deep learning to support annual colonial bird monitoring,"The CESU project aims to enhance annual monitoring of colonial nesting birds by developing a deep learning-based system to automatically detect bird nests from aerial photographs. This initiative is in collaboration with Florida International University and seeks to streamline the time-consuming manual processing currently required by the National Park Service. By implementing an object detection model, the project will improve efficiency in monitoring bird populations and reduce the variability in observer detection over time."
Image Generation and Audio Video Editing,"The project focuses on developing tools for the efficient creation and editing of images, audio, and video content. It aims to streamline workflows and enhance productivity in multimedia production. The tools will incorporate advanced features to facilitate seamless editing and generation processes."
Use of AI for developing bioacoustic and remote camera imagery wildlife species classifiers for noni,"The University of Illinois is collaborating with IBM to develop an AI-driven system that predicts flooding events in Great Smoky Mountains National Park, building on a model for watershed-scale rainfall prediction. The aim is to enhance the accuracy of flood forecasts with a 24+ hour lead time, improving upon the National Weather Service's Quantitative Precipitation Forecast. The National Park Service is involved as an end-user of this tool, while project documentation will be updated once more data is available."
Machine Learning Model Optimization,"The project focuses on optimizing and fitting machine learning models using Alteryx to identify the best model for a given dataset. It includes features for refining models by recommending variable removal in cases of detected autocorrelation issues. Documentation of outputs is pending, and use cases will be updated following additional data collection from the submitter."
NPS Acquisition Management Workload Software,"The NPS Acquisition Management Workload Software assists employees in creating procurement packages by drafting necessary documents and summarizing relevant content. This software streamlines the procurement process, enhancing efficiency and clarity in documentation."
Caseguard Studio,"CaseGuard Studio is utilized by our office to improve the accuracy and efficiency of video and audio redactions for law enforcement and public records. It effectively protects sensitive information while ensuring compliance with privacy laws and FOIA requirements, thereby reducing manual workload."
Azure based Internal Controls Testing App for Award Descriptions,"The project entails the development of an Azure-based Internal Controls Testing Application in collaboration with Microsoft. This application will enable bureau financial assistance policy personnel to conduct self-testing of project descriptions within a secure environment, allowing them to compare results with FY 2023 and identify areas for improvement."
Internal Controls Testing - SAM.gov certifications,"The project focuses on internal controls testing related to SAM.gov certifications, ensuring that awarding officers verify the eligibility of entities for Federal funds and check that Points of Contact (POCs) are not debarred. It utilizes a large language AI model to analyze and score SAM.gov PDF documents based on the date of the awards. Documentation of outputs is currently lacking, and the Department of the Interior plans to update the use cases after collecting further data from the submitter."
Potential Applications of AI Models to UAS Post-fire Mapping Data Analysis and Image Processing,"The project evaluates potential applications of AI models in analyzing UAS post-fire mapping data to address multiple concerns such as post-fire damage assessment, vegetation recovery prediction, and soil erosion risk mapping. It focuses on enhancing rehabilitation efforts through efficient resource allocation, habitat restoration planning, water quality monitoring, and environmental impact assessments. Additionally, the initiative aims to improve communication among experts and assist in ongoing monitoring of ecological effects, promoting informed community awareness and customized rehabilitation strategies."
Proposal for the I-NEPA System: Leveraging Artificial Intelligence (AI) for Enhanced Efficiency in E,"The I-NEPA System proposes the use of Artificial Intelligence to improve the efficiency of environmental reviews, enhance public engagement, and enable advanced searching, tracking, and reporting of NEPA actions within the Department of the Interior. By utilizing the Retrieval Augmented Generation (RAG) process, I-NEPA will combine NEPA and policy documents with user input to generate customized outputs for various projects using a large language model."
Public Comment Analysis Tool (PCAT): Leveraging Artificial Intelligence (AI) for Enhanced Efficiency,"The Public Comment Analysis Tool (PCAT) utilizes artificial intelligence (AI) to automate the processing and analysis of public comments related to federal actions, especially under the National Environmental Policy Act (NEPA). By enhancing accuracy and efficiency, PCAT addresses the labor-intensive challenges faced by federal agencies in managing large volumes of responses to controversial topics, ultimately streamlining environmental reviews and permitting processes."
Pilot: Using Machine Learning to Harvest Data for Standardized Species Conservation,"The U.S. Fish and Wildlife Service is developing a new database for standardized species conservation data, utilizing machine learning and large language modeling to collect and streamline information on species' biological and physical needs. This initiative aims to enhance the organization and accessibility of species conservation data while evaluating the necessary infrastructure for integration within the current ecosystem. The project includes vetting harvested data and incorporating tailored AI into workflows for comprehensive reporting and analytics."
Summarization of documents and output to ECOSphere species workflow,"The U.S. Fish and Wildlife Service intends to utilize natural language processing (NLP) or machine learning (ML) to summarize a substantial collection of documents. This summarized data will then be integrated into the ECOSphere species workflows through a tailored AI framework or API, enhancing reporting and analytics related to species information."
Prediction of Suitable Habitat for ESA-listed Species,"The project involves using machine learning algorithms to develop species distribution models that predict suitable habitats for ESA-listed threatened and endangered species. The U.S. Fish and Wildlife Service collaborates with field biologists to validate these predictions, which inform users about potential impacts on these species and identify areas for reintroductions or additional surveys. The ultimate goal is to locate new populations and enhance conservation efforts through robust reporting and analytics workflows."
Computer Vision Model to Rapidly Identify Habitat Change,"The U.S. Fish and Wildlife Service is collaborating with the Chesapeake Conservancy to create a computer vision model that identifies habitat loss early, addressing a key threat to biodiversity. This model will enable rapid detection of both natural and human-induced disturbances, facilitating timely responses and more accurate assessments of habitat loss. Improved estimates will lead to better management strategies and potentially faster recovery for threatened and endangered species."
Applying Deep Learning to Detect and Classify Ocean Wildlife,"The project applies advanced deep learning techniques to automate the detection and classification of ocean wildlife, specifically focusing on marine birds. In partnership with multiple agencies and institutions, a workflow is being established to process imagery from remote sensors, allowing for accurate species detection and counting with an accuracy rate of 80 to 90%. Ongoing improvements to the AI model will employ a human-in-the-loop approach to enhance its generalization by FY25."
Enhancing Migratory Bird Surveys with Thermal Imagery and Deep Learning,"The U.S. Fish and Wildlife Service (USFWS) Division of Migratory Bird Management seeks to enhance migratory bird surveys by integrating aerial remote sensing and deep learning to automate bird count processes. This approach aims to improve accuracy in wildlife counts while minimizing risks to pilots by enabling surveys at higher altitudes. Collaborating with the College of William and Mary, USFWS has previously validated the use of thermal remote sensing and deep learning for precise night counts of sandhill cranes during their vital migration stopover in Nebraska."
SOCS documents analysis,"The SOCS environmental information portal managed by BOEM houses over 900 documents related to environmental assessments and studies of the Outer Continental Shelf. The project explores the integration of AI and LLM technology to enhance document analysis, including generating resource impact sections based on existing Environmental Impact Statements and summarizing key findings across multiple studies. Outputs from this initiative are currently undocumented, with a commitment to update use cases as new data becomes available."
ONRR Video Hosting Platform [OVHP],"The ONRR Video Hosting Platform (OVHP) is an internal secure site designed to host various videos such as training content, all-hands meetings, and health & wellness events. It utilizes AI technology to generate captions, subtitles, metadata, and chapters, enhancing the efficiency of video hosting, editing, and searching while ensuring compliance with Section 508 requirements."
Video Creation and Editing,"The project focuses on developing a system for creating and editing various multimedia content, including videos, photos, and audio. It aims to enhance efficiency in generating captions, subtitles, and text-to-speech features. Overall, the goal is to streamline the video production process with advanced editing capabilities."
"Predictive AI Applications for Wildlife Monitoring: SeeOtter, a custom built software solution for a","SeeOtter is a custom software solution developed to assist in sea otter population monitoring, utilizing AI technology based on the YoloV5 algorithm to analyze large datasets of images for stock assessments under the Marine Mammal Protection Act. Although federal agencies like USFWS, USGS, and NPS have adopted this image-based methodology, they face challenges due to the lack of permanent AI experts and the need for continual model maintenance and updates, often relying on contractors. The project aims to make SeeOtter accessible to various stakeholders, including partners, tribes, and researchers, to enhance wildlife monitoring efforts and improve collaboration for future large-scale surveys planned for 2025/26."
Non-Generative AI use for Trust Information Analysis and Reporting Tool,"The project utilizes Non-Generative AI to enhance Trust Information Analysis and Reporting by focusing on blank page identification, document classification, title extraction, and date extraction. It employs Azure Computer Vision and Document Intelligence Read for detecting blank pages, while Azure AI Search Services is being considered for the other functionalities but is currently on hold."
Intelligent Optical Character Recognition,"Intelligent Optical Character Recognition (IOCR) is a machine learning software designed to automate the process of document collection and data entry, particularly in invoice processing. The software learns from data input over time, correcting common errors and improving data flow to certifying officers for expedited review and payment. IOCR will be integrated with Robotics Process Automation to provide comprehensive automation solutions while ensuring thorough testing and validation prior to deployment."
Seasonal/Temporary Wetland/Floodplain Delineation using Remote Sensing and Deep Learning,"Reclamation aimed to assess the effectiveness of convolutional neural networks in deep learning for mapping seasonal and temporary wetlands and floodplains using high-resolution remote sensing data. The improved mappings could enhance the management of protected species and support decision-making in operational planning. Outputs from the project have not yet been documented, and updates will follow once more data is gathered from the submitter."
Data Driven Sub-Seasonal Forecasting of Temperature and Precipitation ,"The project focuses on enhancing sub-seasonal forecasting of temperature and precipitation in the western U.S. by leveraging data-driven methods developed through two year-long competitions. Participants surpassed NOAA's benchmark forecasts, and Reclamation is collaborating with the Scripps Institute of Oceanography to refine and pilot the most effective methodologies, with the goal of improving water management outcomes. Documentation of outputs is pending further data collection."
Data Driven Streamflow Forecasting,"Reclamation, in collaboration with CEATI partners, conducted a year-long evaluation of 10-day streamflow forecasting technologies, including a public prize competition. The evaluation revealed that UpstreamTech, a private AI/ML forecasting company, delivered the best performance among the forecasts, while several competitors also surpassed NOAA's benchmark. Reclamation plans to further assess UpstreamTech's products and the top competitors from the prize competition."
Snowcast Showdown ,"The Snowcast Showdown was a prize competition organized by Reclamation in collaboration with various agencies and organizations, aimed at developing machine learning methods for estimating distributed snow information from multiple data sources. Participants created flexible and efficient algorithms for real-time snow prediction, with winning approaches now being incorporated into a subsequent project with NOAA's River Forecast Centers. Outputs from the competition are yet to be documented, and updates on use cases will follow as additional data is collected."
PyForecast ,"PyForecast is a water supply forecasting software developed by Reclamation that employs various statistical and machine learning methods. The outputs of the software are currently undocumented, and the Digital Object Identifier (DOI) will update the use cases once further data is collected from the submitter."
Improved Processing and Analysis of Test and Operating Data from Rotating Machines,"The project aims to enhance the analysis of DC ramp test data from rotating machines by utilizing machine learning and AI tools, specifically linear regression, to automate the recognition of characteristic curves in voltage versus current plots. This shift from manual engineering analysis to computer software is expected to provide a faster and more reliable assessment of DC ramp testing conducted in the field. Outputs from the project are currently undetermined, and further use cases will be documented once additional data is collected."
Improving UAS-derived photogrammetric data and analysis accuracy and confidence for high-resolution data sets using artificial intelligence and machine learning,"The project aims to enhance the accuracy and confidence of UAS-derived photogrammetric data through the application of artificial intelligence and machine learning, addressing the challenges of manual analysis and data accuracy. By developing a standard reference protocol, the project seeks to enable detailed analysis of Reclamation's assets, ultimately leading to more informed decision-making. Outputs will be documented, and use cases will be updated as more data is collected."
Photogrammetric Data Set Crack Mapping Technology Search ,"The project investigates the use of photogrammetric products for efficient crack mapping analysis at Reclamation facilities, replacing traditional methods that require rope access. By establishing a standard reference protocol and utilizing machine learning and AI, the aim is to improve the assessment of Reclamation assets, promoting informed decision-making. Documentation of outputs is pending, and the Department of the Interior will update use cases as more data is gathered."
Effects of vehicle traffic on space use and road crossings of caribou in the Arctic,"The project investigates the impact of vehicle traffic on the space use and road crossings of barren-ground caribou in the Central Arctic Herd, focusing on the influence of human activity amid rising industrial development in Arctic Alaska. It aims to understand how varying traffic volumes affect the caribou's behavior and whether managing these activity levels can help mitigate the adverse effects of infrastructure on wildlife. By addressing this gap in knowledge, the research seeks to inform conservation practices and wildlife management strategies in the context of energy expansion."
Automated Walrus Haulout Monitoring,"The Automated Walrus Haulout Monitoring software utilizes pre-trained CNN models to analyze unlabeled image datasets for insights on walrus coastal haulout patterns. It also processes images with manually assigned keywords to evaluate the model's performance against human-assigned labels, employing metrics such as accuracy, precision, recall, and F1-score for performance assessment. Additionally, the project incorporates screening-level predictions for potential deformations in structures due to seismic activities."
Forecasting Earthquake Ground Motion Time Series,"The project focuses on creating deep learning models to forecast earthquake ground motion time series, which can be utilized for Earthquake Early Warning, Operational Aftershock Forecasting, and the National Seismic Hazard Model. Documentation of outputs is pending, and a DOI will be updated once further data is obtained from the submitter."
CONUS EcoFlows Planning & Prototype,"The CONUS EcoFlows Planning & Prototype project aims to develop models that provide benchmark estimates of long-term unaltered flow conditions across the U.S. by utilizing unaltered USGS gage data and natural landscape datasets. These models are then applied to predict hypothetical near-reference flow conditions at sites influenced by human activities, allowing for the assessment of flow departures from natural norms and informing subsequent ecological modeling. Output documentation will be updated by the DOI once additional data is collected from the submitter."
Prioritized Constituents: Sediment,"The project aims to predict suspended sediment concentration in unmonitored rivers within the Delaware, Illinois, and Colorado River Basins to enhance understanding of sediment transport. Outputs from the project are currently undocumented, and the Department of the Interior plans to update the use cases following the collection of additional data."
Avian population estimates from passive acoustic monitoring,"The project focuses on obtaining reliable estimates of avian populations using passive acoustic monitoring techniques. Initial outputs of the study were not documented, and the dataset will be enhanced and updated with additional data from the submitter in the future. A DOI will be assigned to the use cases once this data is available."
FEMA mixed population flood-frequency analysis,"The project involves conducting a flood-frequency analysis for FEMA, which classifies historical floods according to their causal mechanisms to enhance the estimation of flood reoccurrence intervals. Documentation of the outputs is currently lacking, and the Department of the Interior plans to update the use cases once more data is gathered from the contributors."
"Nutrient, Salinity, and temperature model development","The project focuses on developing machine learning models to simulate nutrient levels (phosphorus and nitrate), temperature, and salinity in streams throughout the United States. These models aim to enhance the understanding of environmental conditions and their impacts on aquatic ecosystems. The work reflects a comprehensive approach to stream environmental monitoring and management."
Data-Driven Streamflow Drought,"The project aims to develop prototype forecasts for streamflow drought conditions using machine learning techniques at USGS gage locations throughout the continental United States. Although the initial outputs have not been documented, the DOI plans to enhance the use cases once supplementary data is obtained from the submitter."
AI/ML for aquatic science,"The project focuses on creating advanced computational frameworks and AI algorithms for the individual recognition of fish using AI, computer vision, and deep learning techniques. Key objectives include developing baseline AI models, enhancing recognition performance in dynamic environments, assessing the detection of diseased fish through melanistic markings, and evaluating deep learning models for individual identification and respiration rate analysis from video data in various settings."
National-Extent Groundwater Quality Prediction for the National Water Census and Regional Integrated,"The project aims to deliver nationally consistent predictions of groundwater quality, focusing on salinity and nutrient levels that impact both human and ecological health, as well as their effects on surface water. Additionally, it seeks to create strategies for integrating these predictions into comprehensive water-availability assessments, including the National Water Census and regional Integrated Water Availability Assessments. Outputs have yet to be documented, and the Department of the Interior will update the use cases following further data collection."
Use of artificial intelligence tools for optimization and documentation for computer codes,"This project leverages artificial intelligence tools, specifically ChatGPT, to optimize and document computer codes for the USGS National Seismic Hazard Model and other earthquake hazard research initiatives. The focus is on implementing earthquake rupture forecasts and ground-motion models, although the outputs have not yet been documented, with plans to update the use cases once more data is gathered from the submitter."
Improved earthquake detection for research studies,"Deep learning techniques are being implemented to enhance earthquake detection, resulting in more comprehensive and high-resolution catalogs for research purposes. These catalogs will aid in understanding earthquake occurrences, rupture processes, and seismic hazards. Documentation of outputs is pending, with plans to update use cases after additional data collection."
NGWOS External R&D - Using advanced computing techniques for image-based monitoring,"The NGWOS External R&D project focuses on applying advanced computing techniques, specifically AI and ML, for image-based water monitoring. Multiple research initiatives are underway, but documented outputs are currently lacking; a DOI will be issued to update the use cases once further data is obtained from the submitter."
Water Use Model Development,"The project focuses on creating process-based and machine learning models to estimate various categories of water use across the United States. While the outputs have not yet been documented, the Department of the Interior plans to update the use cases following the collection of additional data from the submitter."
National Temperature Observations,"The National Temperature Observations project aims to alleviate the workload for Science Centers regarding the management of quality assurance data, thereby facilitating an increase in the number of water temperature sensors deployed. Key activities include enhancing software for processing and storing water temperature data, establishing workflows and quality assurance checks in data collection tools, and initiating a pilot program to assist Science Centers with five-point temperature evaluations."
Downscaling and assimilation of meteorology data for local estimates of irrigation water demand.,"This project focuses on improving local estimates of irrigation water demand by downscaling and assimilating meteorological data, addressing significant errors caused by high-frequency, low-resolution reanalysis datasets. It highlights the use of deep learning techniques, such as LSTM and Graph Neural Networks, to integrate local meteorological observations with terrain and land use data for better accuracy. The ultimate goal is to develop software that enhances existing meteorological datasets, particularly benefiting regions lacking comprehensive meteorological resources."
National-Extent Groundwater Quality Prediction for the Integrated Water Availability Assessments,"The project aims to create nationwide predictions of groundwater quality, focusing on salinity and nutrients that affect both human and ecological uses, as well as surface water. It also seeks to integrate these predictions into broader water availability assessments, including the National Water Census. Outputs are pending documentation, and updates will follow once new data is obtained from the project submitter."
Building capacity for assessment and prediction of post-wildfire water availability,"The project aims to enhance the assessment and prediction of water availability after wildfires by developing models that forecast the impacts of wildfires on water quality, specifically concerning suspended sediment and salinity levels. This initiative targets areas in the western U.S. that are prone to wildfires. It seeks to improve understanding and management of post-wildfire water resources."
Mapping sagebrush from drones to satellites,"The project involves mapping sagebrush in the Dakotas using machine learning and imagery from drones, aircraft, and satellites to create accurate vegetation maps. These maps are essential for identifying seasonal habitats of sage-grouse and have applications in habitat modeling, restoration evaluation, and understanding ecological impacts of invasive species. Outputs will be updated once additional data is collected."
Delineating sub-surface drainage using satellite imager,"The project focuses on mapping the extent of subsurface drainage (tile-drain) using satellite imagery to better understand its effects on landscape responses to precipitation and drying events. This data is crucial for evaluating how soil characteristics and land management practices affect streamflow and water quality in relation to climate variability. Outputs are currently undocumented, and updates will be provided once further data is collected."
Vegetation mapping on the Hawaiian island of Lanai,"The project focuses on developing a high-resolution vegetation mapping approach for the Hawaiian island of Lanai, utilizing satellite imagery, machine learning, and expert knowledge to classify plant species. The resulting detailed maps are intended to aid in conservation planning and monitor native and invasive species. Documentation of outputs is pending further data collection."
Machine Learning for automatic fracture mapping and rock identification,"Machine learning algorithms are employed to enhance the detection and characterization of faulting following significant surface rupturing earthquakes and to identify fragile geological features relevant to earthquake hazard assessment. Documentation of outputs is pending, with updates to use cases expected from the data submitter after further data collection."
Reinforcement Learning for Helmholtz Coil Operation and Simulation,"The USGS is leveraging artificial intelligence and machine learning, specifically reinforcement learning, to enhance the operation of Helmholtz coils for its magnetic observatories. This approach aims to optimize the generation of uniform magnetic fields. Future updates regarding use cases will be provided once further data is collected."
Deep-learning Integration into NEIC Operations,"The National Earthquake Information Center (NEIC) is enhancing its earthquake detection and processing capabilities through the integration of artificial intelligence and machine learning techniques. The project aims to improve operational efficiency, although outputs have not yet been documented, and the Department of the Interior (DOI) plans to update the use cases after further data collection."
Predictions of PFAS Concentrations in Groundwater,"A predictive model for PFAS concentrations in groundwater has been developed for public and private drinking water supplies across the continental United States. This model, which operates at a 1x1 km grid resolution, will provide concentration estimates rather than just occurrence predictions, enhancing its accuracy with a larger dataset. The updated model aims to improve resource allocation to areas projected to experience significant PFAS impacts."
NGWOS External R&D - Using advanced computing techniques for mobile monitoring platforms,"The NGWOS External R&D project focuses on developing a networking strategy for underwater robotic sensor platforms that enables them to autonomously adapt their monitoring activities in response to varying bathymetry and water conditions through artificial intelligence algorithms and underwater communication systems. Documentation of project outputs is pending, and the DOI will revise the use cases as more data is received from the submitters."
Population and critical habitat modeling of overwintering monarch butterflies,"This project focuses on modeling the population and critical habitat of overwintering monarch butterflies in coastal California, identifying the characteristics that make these groves suitable for their survival. The research aims to enhance understanding of land cover and climatic factors influencing site selection, thereby assisting land managers in preserving existing habitats and discovering new overwintering locations. Outputs are pending documentation, with updates expected once additional data is gathered."
Automating the Detection and Classification of Wildlife in Aerial Imagery,"The US Geological Survey, Bureau of Ocean Energy Management, and US Fish and Wildlife Service are collaborating on a multi-year project aimed at creating deep learning algorithms to automate the detection and classification of seabirds and other marine wildlife in aerial imagery. These tools will assist BOEM in evaluating wildlife populations for offshore energy development planning and monitoring. Outputs of the project are currently undocumented, with plans for updates once further data is acquired."
Machine Learning algorithm for stream velocity prediction,"The project focuses on developing a machine learning algorithm to predict stream velocity, which will enhance a web-based application for estimating travel times in spill response scenarios. This advanced application aims to provide users with greater accuracy in determining travel times. Documentation of outputs is pending, with the use cases to be updated once further data is obtained from the submitter."
Machine Learning for streamflow forecasting,"The project focuses on developing a predictive system for river flows in the Willamette River Basin to address increasing flood severity in the Pacific Northwest. In collaboration with Portland State University, the initiative utilizes advanced statistical and computational models alongside new hydrologic observations to enhance flood forecasting. Additionally, it seeks to improve the application of river flow data provided by USGS for more accurate predictions."
Automated otolith aging using image processing,"The project aims to automate the aging of fish otoliths using image processing and machine learning to enhance the accuracy and consistency of age estimates for fish populations. Traditionally a manual process prone to variability, the proposed system seeks to standardize ring counting in otoliths, potentially saving time for fisheries managers and researchers. Outputs will be documented when further data is collected, and use cases will be updated accordingly."
Automating blood smear cell counts using machine learning,"The project focuses on automating blood smear cell counts using machine learning techniques. After exposing largemouth bass to an immunogen and collecting blood smears, the slides were digitized and labeled to create training sets for a model designed to recognize and differentiate white blood cells. Currently, the team is validating the model's accuracy by comparing its automated counts against manual counts from human readers and new image tiles."
Machine learning for tsunami source zones,The project focuses on utilizing machine learning to enhance tsunami hazard analysis by efficiently selecting the most representative source zones from numerous offshore earthquake ruptures. This aims to reduce the computational demands associated with traditional hazard assessments for coastal communities and infrastructure. Documentation of outputs will be updated once further data is gathered from contributors.
Shoreline Modeling,"The Shoreline Modeling project seeks to evaluate the effectiveness of AI and machine learning models, such as LSTM, CNN, and Transformers, in predicting shoreline changes compared to conventional models. Current outputs are not documented, and a DOI will be assigned to update use cases once further data is gathered from the submitter."
Determining the resource potential of critical minerals in seafloor massive sulfide deposits,"This project focuses on assessing the resource potential of critical minerals found in seafloor massive sulfide deposits. Machine learning techniques are employed to analyze geochemical data and predict mineral composition. The outputs of the study have not yet been documented, as updates will occur following the collection of additional data from the submitter."
"Oceanographic, coastal, and geomorphic change analysis: data generation, QC/QA, and data management","The project focuses on analyzing oceanographic, coastal, and geomorphic changes using machine learning to quantify changes across extensive scales. It implements quality control and assurance (QC/QA) processes to ensure the robustness of the data, which will support United States Geological Survey (USGS) projects in forecasting trends related to shorelines and permafrost in various coastal and marine environments. Outputs are currently undocumented, and a Digital Object Identifier (DOI) will be updated with use cases as additional data becomes available."
Synthesizing mapping and monitoring data to inform prairie dog management in National Parks,The project focuses on enhancing prairie dog management in Theodore Roosevelt National Park by synthesizing mapping and monitoring data to understand variations in prairie dog colony size and density. It aims to develop cost-effective remote sensing techniques and models that can provide park staff with the necessary tools to assess habitat quality and predict population fluctuations based on colony area. This initiative addresses the challenges of resource limitations while maximizing the utility of existing data to improve wildlife management within the park.
"Quantifying the effects of land-use change and bioenergy crop production on pollinators, wildlife, a","The project aims to quantify the density of common and showy milkweed in grasslands of Minnesota and North Dakota using uncrewed aircraft systems (UAS) and artificial neural networks, addressing the decline of monarch butterfly populations. It involves developing a machine learning algorithm for detecting milkweed from UAS images, validating this algorithm against field counts, and determining the necessary spatial data collection for accurate monitoring. Progress has been impeded by a Department of the Interior ruling grounding UAS flights, with preliminary flights conducted but further actions on hold until the ruling is revisited."
Computationally efficient emulation of spheroidal elastic deformation sources using machine learning,"The project involves developing machine learning emulators to efficiently predict spheroidal elastic deformations caused by pressure changes in buried cavities, addressing shortcomings in both analytical and numerical models. By utilizing parallel partial Gaussian processes, the trained emulators serve as high-fidelity surrogates for finite element numerical models, facilitating faster and more accurate deformation calculations. Outputs and use cases will be updated as additional data becomes available."
Wildlife species recognition and distance from camera estimation,"The project focuses on recognizing wildlife species and estimating their distance from camera traps to provide reliable population density estimates. Documentation of the outputs is currently lacking, and a Data Object Identifier (DOI) will update the use cases once more data is obtained from the submitter."
Automating blood smear cell counts using machine learning,The project aims to automate blood smear cell counts by using machine learning techniques on blood samples collected from largemouth bass exposed to an immunogen. Blood smear slides were digitized and labeled to create training sets for a model designed to identify and differentiate various white blood cells (WBCs). The validation process involves comparing human manual cell counts with both the model's automated counts and counts from novel slide samples.
Machine Learning to evaluate water quality,"This project employs machine learning techniques to assess the impact of physicochemical and meteorological factors on water quality indicators related to harmful algal blooms in a shallow hypereutrophic lake. The outputs of the analysis are currently undocumented, and updates will be provided once further data is collected from the submitter."
Ecological niche models for bat species,"The project focuses on developing ecological niche models to analyze the environmental factors influencing the presence and absence of various bat species throughout their habitats. Currently, the outputs are not documented, and the DOI plans to update the use cases after additional data is collected from the submitter."
HotLINK: The volcanic hotspot learning and identification network,"HotLINK is a project focused on monitoring volcanic thermal emissions to identify processes that may signal impending eruptions. The project's outputs are currently undocumented, and the Department of Innovation (DOI) plans to update the use cases following the collection of additional data."
Development of a Strategic Framework for Use and Implementation of Machine Learning in Energy Resour,"The project aims to develop a strategic framework for integrating machine learning (ML) into Energy Resource Project (ERP) workflows and information technology systems. The framework will focus on adopting ML models tailored for ERP scientists, modernizing key data assets for improved accessibility, and providing targeted training for the geospatial ERP workforce. By implementing this framework, the ERP will enhance its ability to deliver data-driven information products and adapt to modern scientific needs."
"Quantifying Watershed Controls on Fine Sediment Flux to Lake Tahoe, California/Nevada","The project aims to quantify the impact of watershed controls on fine sediment flux to Lake Tahoe, influenced by variations in precipitation. Using supervised random forest regression models, researchers assessed key watershed parameters affecting sediment movement. Documentation of outputs is pending, with updates anticipated following additional data collection."
Seismology of Magmatic Injection,"USGS staff are collaborating with a Baylor University student to employ machine learning and network covariance techniques to analyze seismic sources linked to magmatic injection and transport, essential for understanding volcanic systems. Additionally, seismic studies are being conducted to explore magma plumbing dynamics. Documentation of outputs is pending, and the DOI will update use cases following further data collection."
Earthquake Catalog Development,"The Earthquake Catalog Development project utilizes AI and machine learning to create comprehensive and reliable earthquake catalogs, incorporating focal mechanisms and enhancing volcanic earthquake records. It employs integrated detection, matched-filtering, and relocation tools. Documentation of outputs is pending, with plans for updating use cases after further data collection from the submitter."
Seedling Identification and Percent Growth Analysis,"The project automates the extraction of alphanumeric labels from petri dish images using Optical Character Recognition (OCR) and applies k-means clustering to segment seedlings for growth analysis. This approach minimizes human error and improves efficiency in quantifying seedling growth over time, despite challenges like varied image conditions. Ultimately, it enhances data analysis accuracy and supports scalable research in environmental and toxicological fields."
Gulf Coast Geologic Energy Machine Learning,"The Gulf Coast Geologic Energy project employs machine learning to predict the expected ultimate recovery of shale oil wells using artificial neural networks and a comprehensive database of geological and well completion parameters. Researchers are also developing a model to estimate total organic carbon based on elemental data. Documentation of outputs is pending, with further updates planned as more data is collected."
Flow Photo Explorer to estimate flow,"The Flow Photo Explorer project aims to develop a cost-effective and low-maintenance method for estimating stream flow and volume, particularly for internment streams, as conventional USGS streamgages can be prohibitively expensive for cooperators. The project currently lacks documented outputs, with updates on use cases expected from the Department of the Interior once more data is gathered."
Predicting Sparse (Geothermal) Resources Availability by using Machine Learning,"This research project aims to create machine learning tools to predict the availability of sparse natural resources, such as geothermal energy, at regional levels while incorporating geoscience principles. It addresses challenges related to model performance metrics, mathematical sparsity, and the creation of new evidence layers to enhance modeling workflows. The project seeks to improve the explainability, reproducibility, and accessibility of the resource assessment modeling process."
National Wildlife Disease Database,"The National Wildlife Health Center has engaged the Pacific Northwest National Laboratory to develop a comprehensive National Wildlife Disease Database, funded by the American Rescue Plan Act of 2021. This database will compile diverse wildlife health data streams, enhancing situational awareness and analytics for natural resource authorities. The integration of PNNL's Canvas software will facilitate the visualization and contextualization of information from these data sources."
Landform Mapping GeoAI,"NASA and the USGS are collaborating on a project to create a national landform dataset using machine learning and active learning techniques to enhance the efficiency and accuracy of data labeling. The project employs advanced methods such as topological analysis and deep learning to analyze 3D shapes, while also developing a user-friendly interface to facilitate labeling and support future tools like natural language queries."
Using Machine Learning Methods for Automatic Discovery and Catalog of North Dakota Stock Ponds and Other Impoundments,"This project aims to develop a machine learning workflow that processes satellite imagery for the automatic discovery and cataloging of stock ponds and other impoundments in North Dakota. It will distinguish different types of stock ponds, stock dams, and dugouts while creating a comprehensive catalog that includes smaller ponds often neglected in existing databases, enhancing the understanding of their distribution and types."
Improved point cloud classification of 3DEP lidar data using Deep Learning models,"This project focuses on improving the classification of 3DEP lidar point cloud data, which represents various surface types such as buildings, trees, and roads. It employs deep learning models to enhance the accuracy and resolution of the surface type classifications, aiming to identify a broader range of surface types within the data."
Knowledge Graph development,The project focuses on the research and development of knowledge graph designs aimed at enhancing the interoperability of information by automatically identifying logical relationships from text. It incorporates AI and natural language processing techniques to facilitate the extraction and organization of data into a structured format.
Predicting inundation dynamics of small forested wetlands,"This project focuses on predicting the wetting and drying dynamics of small forested wetlands in the Upper Midwest to support land managers in their efforts to preserve amphibian habitats. It utilizes field observations of wetland water levels to train a random forest model, though outputs are yet to be documented as further data collection is ongoing."
Hydrograhy feature extraction from remotely sensed data,"This project focuses on extracting hydrography features from remotely sensed data using machine learning techniques. It aims to develop predictive models for surface water locations by analyzing elevation and image data, allowing for the mapping of hydrography in areas lacking existing data. The trained models can adapt to new remote sensing data to continuously update hydrography features and enhance environmental quality assessments."
Using machine learning to detect invasive bullfrogs,"The project employs machine learning techniques to identify invasive bullfrogs at their invasion front, aiming to support effective removal strategies. While outputs have yet to be documented, the DOI plans to update use cases as more data is gathered from the submitter."
"Deep Learning application for automated mapping of surficial landforms, surficial geological deposit","The Bascom Geoscience Center is employing deep learning within the ESRI ArcGIS Pro platform to automate the mapping of surficial landforms and geological deposits using lidar-derived topography. Additionally, they are developing models to identify abandoned mine sites using the same technology. Documentation of the project outputs is pending further data collection."
Zero shot segmentation to expedite Quaternary geologic mapping,"The project focuses on using a zero-shot segmentation approach to enhance the efficiency of Quaternary geologic mapping by adapting the Segment Anything Model. This innovation aims to reduce the extensive manual GIS data entry currently required to delineate geologic features. Outputs from the project will be documented, and the DOI plans to update use cases with additional data collected from participants."
Oil Spil Response for Ice-Covered Rivers,"The project employs backscatter data from the Sentinel-1 satellite's SAR to analyze ice phenology in large rivers and lakes using machine learning techniques, specifically a Random Forest Classifier. Funded by the DOI Inland Oil Spill Preparedness Program, it aims to deliver timely information to oil spill response teams about the safety of ice-covered regions between 2023 and 2025. Outputs are currently undocumented, with plans for updates once further data is obtained."
Modeling Sediment Abundance in the Eastern Snake River Plain Aquifer Using Supervised Learning,"The project focuses on modeling sediment abundance in the eastern Snake River Plain aquifer using supervised learning techniques and natural gamma ray readings. By predicting sediment presence at different depths in boreholes and training the model with sediment probability estimates, the initiative aims to improve understanding and management of sediment distribution in the aquifer."
Pacific Northwest Stream Flow Permanence,"The Pacific Northwest Stream Flow Permanence project utilizes machine learning, specifically random forest algorithms, to estimate the presence of year-round surface flow in streams across several U.S. states. The models employ flow/no flow observations as the response variable, alongside various physio-climatic factors, to aid in streamflow classification for management decisions by agencies such as the Bureau of Land Management and U.S. Forest Service. The project is funded by congressional allocations for fiscal years 2023-25, with outputs pending further documentation and data collection."
SAMPLE Toolbox,"The SAMPLE Toolbox is designed to assist land managers in creating plans for monitoring vegetation. Current outputs have not been documented, and the Department of the Interior (DOI) will update the use cases following the collection of additional data from users."
Mapping wildfire fuels in previously burned landscapes,"The project aims to analyze the impact of land management treatments on the likelihood of wildfires reburning in areas that have previously experienced fires. The outputs of the study are currently undocumented, and the Department of the Interior plans to update the use cases once more data is obtained from the contributors."
Inventorying landforms with convolutional neural networks,"The project focuses on using convolutional neural networks to inventory landforms from high-resolution LiDAR-derived topographic data, which provides detailed images of the Earth's surface. It aims to create efficient pipelines for training and deploying these neural networks to identify features relevant to scientific research and natural hazard assessment. Documentation of outputs is pending, with plans to update use cases as more data becomes available."
Lava lake thermal pattern classification using self organizing maps and relationships to eruption pr,"This project utilizes self-organizing maps (SOM) to classify thermal patterns in lava lakes by analyzing thermal infrared time-lapse images. The results are pending documentation, and a DOI will be updated with new use cases once additional data is acquired from the submitter."
Advancing image-based surveys to support sea duck conservation along the Pacific Flyway,"This project focuses on advancing image-based surveys to enhance sea duck conservation along the Pacific Flyway by transitioning from traditional observer-based aerial surveys to digital aerial surveys (DAS). The DAS utilizes convolutional neural network models to automate counts from aerial imagery, aiming to improve safety, data consistency, and accuracy of sea duck population estimates in coastal regions. The goal is to establish a standardized method that addresses current limitations in surveying techniques and supports better conservation efforts for these vulnerable species."
Probabilistic source classification of large tephra producing eruptions using supervised machine lea,"The USGS has developed a robust model that employs a voting ensemble classifier to identify large tephra-producing eruptions in the Alaska-Aleutian arc using in situ geochemistry. This model integrates six different machine learning algorithms, trained on approximately 2000 electron probe microanalysis measurements of glass major oxides from identified volcanic sources. The project aims to enhance the accuracy of volcanic source classification by leveraging data from proximal tephra deposits."
InSAR and other geodetic studies at Volcanoes,"The USGS employs InSAR technology to monitor ground deformation and volcanic activity worldwide, utilizing artificial intelligence to identify transient signals from combined InSAR and GPS data that may signal potential volcanic hazards. Documentation of project outputs is pending, with updates to use cases anticipated once more data is received from contributors."
Climate Futures for Lizards and Snakes in Western North America,"The project focuses on the climate futures of lizards and snakes in Western North America, identifying management challenges for reptiles stemming from changing environmental conditions. While outputs have not been documented yet, the DOI plans to update use cases as more data becomes available from the submitter."
Predicting inundation dynamics of small forested wetlands,"This project focuses on predicting the wetting and drying dynamics of small forested wetlands in the Upper Midwest to support land managers in their efforts to preserve amphibian habitats. It utilizes field observations of wetland water levels to train a random forest model, though outputs are yet to be documented as further data collection is ongoing."
Intelligent National Map project,"The Intelligent National Map project by the U.S. Geological Survey (USGS) aims to enhance mapping capabilities through advanced technologies such as artificial intelligence. This initiative seeks to develop self-updating maps that can automatically detect environmental changes and deliver improved information for decision-making regarding land, water, and natural resources."
Machine-learning model to delineate sub-surface agricultural drainage from satellite imagery,"A UNet machine-learning model was developed to identify sub-surface agricultural drainage systems from panchromatic satellite imagery, achieving accuracy comparable to human experts. The model was trained using images from the US Great Lakes basin and validated on different regions, demonstrating optimal performance during certain spring conditions. This approach enhances understanding of water, nutrient, and sediment movement in agricultural landscapes, which is crucial for managing environmental issues like harmful algal blooms."
Environmental streamflows in the United States: historical patterns and predictions,"The project analyzes historical patterns and variability of environmental streamflows across the United States, focusing on how changes in climate, land use, and water management affect these assessments. It also employs machine-learning methods to estimate streamflows for ungaged streams, providing essential data to water managers. Outputs will be documented and updated in the future as additional data is collected."
PROSPER,"PROSPER is a machine learning project focused on estimating the annual probability of streamflow permanence at a 10-meter sub-reach scale. The project has not yet documented its outputs, and a DOI will be updated with use cases once more data is collected."
[Un]supervised clustering of [non-]earthquake signals commonly recorded on regional seismic networks,"This project focuses on the automated classification of non-earthquake seismic signals, particularly those generated by surficial mass movements (SMMs) such as landslides and rockfalls. By employing machine learning techniques, the study aims to differentiate between seismic signals produced by vertical and horizontal SMM processes, as well as to categorize shallow earthquakes and blasts that share similarities with these signals. The classification leverages statistical metrics extracted from seismic waveforms, utilizing both unsupervised and supervised learning methods to enhance operational seismic monitoring."
"Extracting robust, searchable data from narrative geologic descriptions","The project focuses on extracting structured, searchable data from narrative geologic descriptions using natural language processing and large language models. By converting unstandardized text into easily queryable information, the initiative aims to enhance the usability of a national geology database. Future documentation and updates will be provided as additional data is gathered."
Classifying GPS data to understand flight behavior of birds.,This project involves classifying GPS data to analyze the flight behavior of eagles and identify the conditions that increase their risk of colliding with wind turbines. The findings aim to improve safety measures for both wildlife and renewable energy infrastructure. Output documentation will be updated once more data is gathered.
Whole-lake indexing of round goby abundances with photographic catch data,"The USGS project employs autonomous vehicles and artificial intelligence to monitor the abundance of the invasive Round Goby fish across three Great Lakes annually. This initiative incorporates photographic catch data and also examines surface geology factors affecting Round Goby populations. Output documentation is pending, awaiting further data collection."
Predicting PFAS in shallow soils in northern New England,"This project utilizes statewide shallow soil data and machine learning techniques, specifically boosted regression tree models, to predict the presence of PFAS in soils throughout Maine, New Hampshire, and Vermont. Outputs from the study have yet to be documented, and the Digital Object Identifier (DOI) will be updated with new use cases as more data is gathered from the submitter."
Improving accuracy and precision of sonar-based estimates of fish abundance,The USGS is enhancing the accuracy and precision of sonar-based fish abundance estimates used for managing fish populations in the Great Lakes. The initiative involves the development of new technologies and the integration of artificial intelligence to improve data processing capabilities. These advancements aim to reduce inaccuracies that currently limit the effectiveness of sonar estimates in fisheries management.
Classifying GPS data to understand flight behavior of birds.,This project involves classifying GPS data to analyze the flight behavior of eagles and identify the conditions that increase their risk of colliding with wind turbines. The findings aim to improve safety measures for both wildlife and renewable energy infrastructure. Output documentation will be updated once more data is gathered.
Machine learning-based landscape feature classification using satellite and airborne imagery,"This project utilizes machine learning classifiers to improve the accuracy of habitat and land cover classifications based on satellite and airborne imagery. The outputs of this research have not yet been documented, and the Digital Object Identifier (DOI) will be updated once more data is acquired from the submitter."
Predicting PFAS occurrence in groundwater using machine learning,"This project utilizes USGS groundwater data and machine learning techniques to predict the occurrence of PFAS in groundwater across the contiguous U.S. A paper detailing the initial findings was published in early FY25, and a subsequent phase has begun that will focus on predicting concentration ranges of PFAS rather than just occurrence. Documentation of outputs is pending further data collection for use case updates."
Machine Learning Image Classification,"The PLACE project aims to provide insights into historical and current environmental changes related to floods, droughts, and fires by employing machine learning, specifically random forest algorithms, for the classification of wetlands and soil moisture. This research seeks to quantify causal relationships related to wildfires, assisting land managers, planners, and researchers in their decision-making processes. Further documentation of outputs and DOI updates will occur as additional data becomes available."
Zero shot segmentation to expedite Quaternary geologic mapping,"The project aims to enhance the efficiency of Quaternary geologic mapping by applying zero-shot segmentation techniques, specifically through the adaptation of the Segment Anything Model for identifying geologic features. This approach seeks to reduce the reliance on manual GIS data input, thereby streamlining the creation of detailed geologic maps. Documentation of outputs is pending, with future updates planned once more data is collected from the submitter."
Inventorying landforms with convolutional neural networks,"The project focuses on utilizing convolutional neural networks to inventory landforms using high-resolution LiDAR-derived topographic data. This approach aims to enhance the identification of significant geological features, which are crucial for studying various scientific phenomena and natural hazards. Documentation of outputs is pending, with updates expected once further data is gathered."
Tracking wetlands and water movement across watersheds,"The project focuses on tracking wetlands and water movement across watersheds to improve predictions of flood and drought impacts by analyzing upstream surface water storage dynamics. It employs machine learning algorithms to classify satellite imagery and establish connections between daily river discharge, meteorology, and surface water dynamics. This initiative is funded by the USEPA, Office of Research and Development, with future outputs and use cases being updated as more data becomes available."
"Everglades-Flux, Digital Surveys","The Everglades-Flux project is developing a program that automatically processes Normalized Difference Vegetation Index images to provide accurate assessments of live vegetation. Additionally, it employs AI and machine learning techniques to fill in missing data. Documentation of outputs will be updated by the DOI once more data is received from the submitter."
Cooperative Agreement Oakridge National Lab-USGS Research:  Using Artificial Intelligence to Improve,"The project involves collaboration between Oakridge National Lab and USGS to enhance data management processes using artificial intelligence. Key objectives include developing algorithms for visualizing data in USGS and DOE ARM repositories, creating AI tools for standardized metadata generation, and automating FAIR data assessments to ensure long-term usability and accessibility of data. Overall, the aim is to reduce reliance on manual tasks and improve the efficiency of data management lifecycles."
Improved earthquake detection for research studies,"Deep learning techniques are being implemented to enhance earthquake detection, resulting in more comprehensive and high-resolution catalogs for research purposes. These catalogs will aid in understanding earthquake occurrences, rupture processes, and seismic hazards. Documentation of outputs is pending, with plans to update use cases after additional data collection."
Machine learning for tsunami source zones,"This project utilizes unsupervised machine learning to improve tsunami hazard analysis by accurately determining representative offshore earthquake ruptures based on tsunami wave heights. This approach aims to provide a transparent and consistent methodology for selecting tsunami source zones, addressing the computational demands of traditional methods. Further documentation of outputs will be updated once additional data is available."
Mendenhall postdoctoral fellow using machine learning,"A Mendenhall postdoctoral fellow is utilizing machine learning to predict the composition of seafloor massive sulfide deposits as part of the Global Marine Minerals Project. This work, funded following a successful proposal in 2023, is currently underway, with preparations for publications in progress. Documentation of outputs is pending until additional data is collected."
Critical Mineral Assessment with AI Support (CriticalMAAS),"The Critical Mineral Assessment with AI Support (CriticalMAAS) project aims to enhance the USGS's ability to produce high-quality assessments of critical minerals through an AI-assisted workflow. This approach is designed to mitigate exploration risk and aid in the strategic management of domestic resources. Documentation of outputs is pending, and the Department of the Interior plans to update use cases as more data becomes available."
Shoreline modeling,"The project aims to assess the effectiveness of AI/ML methods, such as LSTM, CNN, and Transformers, in predicting shoreline evolution and to compare their accuracy with traditional physics-based models. Documentation of outputs is pending further data collection, and the DOI will update the use cases accordingly."
Cell Phone Application for Oil Spill Detection,"The project aims to create a mobile application that utilizes image analysis to detect oil in environmental samples through cell phone photos. This tool is designed for quick deployment in the field by oil spill responders, enhancing their ability to assess contamination. Documentation of outputs will be updated once further data is gathered from users."
Wave runup and total water level observations from time series imagery at several sites with varying,"The project focuses on analyzing wave runup and total water levels through time series imagery at multiple sites using a segmentation tool to distinguish land from water. The generated masks facilitate the calculation of water levels, which will be compared against forecasted levels and may be featured on USGS webpages. Documentation of outputs is pending, and the DOI will revise use cases as further data is received from the submitter."
Development of a Ploidy Distinction Application: A Machine Learning Approach for Discriminating Trip,"A machine learning application is being developed to help fisheries personnel identify the ploidy of wild-caught invasive carp, specifically distinguishing between diploid and triploid Grass Carp. This approach utilizes digital imaging techniques, processing data from both a high-quality lab microscope and a portable field microscope, to enhance image resolution and improve accuracy. The computational model is trained on brightfield microscopic images of blood smears from known ploidy samples."
Storm Induced Erosion Response Network,"The Storm Induced Erosion Response Network aims to develop advanced forecasting models for Total Water Level and coastal changes caused by storms. This project will utilize innovative data analysis and predictive techniques to enhance understanding and response to coastal erosion and flooding events. Ultimately, it seeks to equip communities with better tools for managing and mitigating the impacts of extreme weather on coastal areas."
Coastal Ecosystem Prediction System,"The Coastal Ecosystem Prediction System is a collaborative project between USGS and NOAA designed to create a national framework for predicting the vulnerability of wetlands to sea level rise. By utilizing multi-model ensemble predictions, the project aims to provide insights into potential future conditions, ultimately aiding in the protection of coastal communities, economies, and natural resources."
National Wildlife Disease Database,"The National Wildlife Health Center has engaged the Pacific Northwest National Laboratory to develop a comprehensive National Wildlife Disease Database, funded by the American Rescue Plan Act of 2021. This database will compile diverse wildlife health data streams, enhancing situational awareness and analytics for natural resource authorities. The integration of PNNL's Canvas software will facilitate the visualization and contextualization of information from these data sources."
Sediment Transport in Coastal Environments (funded by San Francisco Bay-Delta PES),"The project on Sediment Transport in Coastal Environments, funded by San Francisco Bay-Delta PES, focuses on utilizing machine learning for time-series imputation of oceanographic data. Current outputs have not been documented, but a DOI will be updated with use cases as additional data becomes available from the submitter."
"Machine learning based shoreline time-series imputation, classification and forecasting (time-series","The project focuses on utilizing machine learning for shoreline time-series imputation, classification, and forecasting to enhance data generation and quality control processes. It aims to facilitate large-scale and short-term predictions of shoreline trends. Documentation of outputs is pending, and a DOI will be updated based on further data collection from the submitter."
National Oceanographic Partnership Program (NOPP),"The National Oceanographic Partnership Program (NOPP) focuses on using machine learning techniques to assess and predict coastal sediments. Although outputs have not yet been documented, the Digital Object Identifier (DOI) will be updated with relevant use cases following the collection of additional data from the submitter."
RSCC and TCA projects.,"The RSCC and TCA projects focus on utilizing machine learning methods to identify, assess, and quantify coastal features, habitats, and hazards related to coastal change. Outputs from these projects are currently undocumented, and the Digital Object Identifier (DOI) will be updated with relevant use cases once more data is acquired from the submitter."
Machinine Learning based shoreline detection and sea ice dynamics using coastal cameras,The project utilizes machine learning algorithms to detect shorelines and analyze sea ice dynamics through coastal cameras. It focuses on generating and ensuring quality control of data for forecasting shoreline trends and sea ice behavior in coastal areas. Future updates will document the outputs and use cases once more data is obtained.
Using Machine Learning in USGS StreamStats to make suspended sediment and bedload predictions,"The project utilizes machine learning within USGS StreamStats to predict suspended sediment and bedload in Minnesota rivers, serving as a resource for managers lacking sampling data. Current outputs are undocumented, and the Department of the Interior will revise usage cases once further data is obtained from the submitter."
Merbok Supplemental,"The Merbok Supplemental project focuses on using machine learning for shoreline detection and mapping while automating data suitability analyses from satellite imagery. Outputs from the project have yet to be documented, and the DOI plans to update the use cases once more data is gathered from the submitter."
Annual National Land Cover Database Deep Learning,"The project focuses on utilizing geospatial artificial intelligence techniques to create annual maps of land cover and surface characteristics across the nation. Outputs have not yet been documented, and a DOI will provide updates on use cases as more data is collected from the contributor."
"Event and sequence (life-stage, behavior, activity, movement modality) identification, segmentation,","The project focuses on identifying and segmenting events and sequences related to animal movements and behaviors, including life stages, activities, and movement modalities. By analyzing complex data streams, the project aims to uncover biological patterns and processes that are not easily observed in remotely tracked animals, requiring the integration of multiple tools to comprehensively represent these behaviors."
Data-driven approaches to filling missing time-series data within the San Francisco Bay-Delta,"The project focuses on developing data-driven techniques to address gaps in environmental time-series data collected from the San Francisco Bay-Delta, particularly in turbidity measurements. Utilizing various methods, including linear regression and machine learning, the aim is to fill these gaps while quantifying the uncertainty in the estimates. The project is crucial for improving the long-term observational records that inform water-quality assessments and ecological health in the estuary."
Seabird and Marine Mammal Surveys Near Potential Renewable Energy Sites Offshore Central and Souther,"The USGS WERC team is utilizing advanced machine learning techniques to automate the detection and counting of seabirds and marine mammals using digital imagery near potential offshore renewable energy sites. The project aims to enhance monitoring efforts, although specific outputs have yet to be documented and will be updated once more data is collected."
Data-driven approaches to filling missing time-series data within the San Francisco Bay-Delta,"The project focuses on developing data-driven techniques to address gaps in environmental time-series data collected from the San Francisco Bay-Delta, particularly in turbidity measurements. Utilizing various methods, including linear regression and machine learning, the aim is to fill these gaps while quantifying the uncertainty in the estimates. The project is crucial for improving the long-term observational records that inform water-quality assessments and ecological health in the estuary."
Image classification from images on robotic platforms,"The project focuses on image classification to identify different terrains using robotic platforms through a tool trained on labeled images. Originally developed for NASA Mars rovers, the application has potential uses in various other contexts. Documentation of the outputs is pending, and use cases will be updated once additional data is received from the submitter."
ChatGPT to write Python scripts for ArcGIS Pro Maps to be CVD-Friendly,"The project aims to automate the color adjustment of planetary geologic map units in ArcGIS Pro to make them friendly for individuals with color vision deficiencies. By utilizing ChatGPT, scripts will be generated to streamline this formerly tedious manual process. The outputs from this initiative are currently undocumented, and updates will follow once more data is gathered from participants."
Analytical Chemistry & Geologic Resources Identification from Laser Spectroscopy,"The project focuses on using laser spectroscopy to identify and analyze the composition of geological, mineral, and resource targets. Currently, the outputs of the research have not been documented, but a DOI will be updated with use cases once further data is gathered from the submitter."
Analytical Chemistry & Geologic Resources Identification from X-rays,"The project focuses on identifying chemical compositions and rock characteristics using X-ray-based analytical chemistry techniques. While outputs have not yet been documented, updates to the use cases will be provided once more data is gathered from contributors."
Retrieval-Augmented Generation Using USGS Documentation,"This project aims to develop a Retrieval-Augmented Generation (RAG) model utilizing USGS documentation to create an internal chatbot. The chatbot will be designed to access and provide information based on internal USGS resources, enhancing knowledge management within the organization. The project seeks to explore the effectiveness and accuracy of generative AI solutions in specialized documentation contexts."
Foundation Models to Advance Earth Science,"The project aims to enhance knowledge of Earth's conditions and processes through the creation and implementation of generalist AI models, known as Foundation Models, which are trained on Earth Observations from various sensors. These models will provide valuable insights for scientists and land management professionals, contributing to advancements in both Earth science and AI research. Documentation of outputs is pending, with updates expected once further data is collected."
Rangeland Condition Monitoring Assessment and Projection (RCMAP),"The Rangeland Condition Monitoring Assessment and Projection (RCMAP) project aims to track long-term vegetation changes in U.S. rangelands, which are vital for wildlife habitat, livestock forage, and water resources. Developed by the USGS and Bureau of Land Management, RCMAP generates annual maps detailing the percent cover of various rangeland components using field data, Landsat imagery, and machine learning techniques. This project provides crucial references for assessing landscape health and advancing ecological science within the BLM."
Global Food Security-Support Analysis Data (GFSAD) Project,"The Global Food Security-Support Analysis Data (GFSAD) Project aims to address the challenges of food and water security exacerbated by climate change, population growth, and recent global crises by producing accurate global cropland products at a fine spatial resolution of 30 meters. Utilizing machine learning algorithms, artificial intelligence, and satellite data analytics, the project will generate four distinct Landsat-derived cropland products, including assessments of crop extent, irrigation, cropping intensity, and crop types across specific regions. The GFSAD data will be made available through NASA's LP DAAC, enhancing research and decision-making related to agricultural sustainability."
Extracting analysis ready information from narrative geologic descriptions,"The project aims to extract analysis-ready information from the narrative descriptions of geologic maps in the USGS geologic mapping group. By utilizing a web interface with DOI-hosted ChatGPT, the team plans to systematically parse details such as rock unit thickness and associated analytical measurements from approximately 10,000 geologic descriptions. The extracted information will be evaluated for accuracy by comparing it against human-derived extractions, with a focus on improving accessibility and usability of the geologic map synthesis database."
21st Century Prospecting: AI-assisted Surveying of Critical Mineral Potential,"The project ""21st Century Prospecting: AI-assisted Surveying of Critical Mineral Potential"" is a collaboration between the USGS Mineral Resources Program and DARPA, aimed at enhancing the understanding and assessment of critical mineral resources in the United States. By utilizing large language models, the initiative focuses on extracting valuable information from scanned geological maps and mining reports to support national mineral security. Outputs are currently being documented, and updates will be provided as more data becomes available."
Articulate Training Develpment AI Add On,"The Office of Emergency Management's Interior Operations Center utilizes Articulate to develop online training courses for its staff. The introduction of an AI add-on will streamline the course creation and editing process, providing realistic text-to-speech capabilities and future assistance with course content development."
Machine Learning Applied to Geotechnical Engineering: Statistical Methods Applied to Seismic Analysis 1,"The project focuses on developing machine learning models to predict soil liquefaction during seismic events, using a geotechnical case history database for validation. This approach aims to provide geotechnical professionals with an additional tool for assessing liquefaction potential, thereby simplifying the evaluation process and reducing reliance on more complex methods."
Machine Learning Applied to Geotechnical Engineering: Statistical Methods Applied to Seismic Analysis 1,"The project develops machine learning models to predict the crest movement of embankment dams during seismic events. The primary goal is to create a screening-level tool that aids in the early assessment of potential deformation, allowing for more informed decisions before investing in extensive field exploration and testing."
Machine Learning Working Group,"The Machine Learning Working Group is focused on networking with Reclamation employees to assess their experience and interest in developing machine learning models, while also documenting potential applications for addressing daily challenges faced by the staff. This initiative aims to enhance understanding of existing in-house capabilities and explore how machine learning can effectively solve relevant problems. Currently, discussions and information gathering are ongoing, with outputs to be updated once additional data is collected."
Machine Learning for Chemical Savings at Reverse Osmosis Plants,"The project utilized machine learning techniques to optimize chemical usage for cleaning membranes in reverse osmosis (RO) water treatment plants, funded by Reclamation's Desalination and Water Purification Research Program. By analyzing water chemistry data, the project aimed to reduce chemical consumption per unit of water produced without compromising operational performance or membrane longevity. Implemented in full-scale facilities in Southern California, the project showcased the effectiveness of machine learning in enhancing cleaning frequency for RO systems."
Machine Learning Refines Quagga Habitat Suitability,The project focuses on refining habitat suitability models for quagga mussels by using machine learning techniques. Researchers collected and analyzed ecological data from 20 stations in Arizona between 2021 and 2023 to differentiate between invaded and uninvaded waterbodies based on water conditions and plankton taxa. The findings aim to enhance the understanding of quagga mussel invasiveness in pH- and calcium-suitable environments.
Generative AI to Improve Visitor Experience on NPS.gov,"This project leverages generative AI to enhance the visitor experience on NPS.gov by extracting relevant information from the NPS website and API based on user interests. The proof of concept aims to enrich existing structured data without necessitating the creation of new content by park services, ultimately reducing the time and labor costs associated with content reproduction."
Autonomous Drone Inspections,"BSEE has partnered with MIT Lincoln Laboratory to develop autonomous drone technologies for inspecting hard-to-reach areas on the Outer Continental Shelf. This research will enhance BSEE's inspection capabilities by leveraging NASA's corrosion models to assess corrosion levels, platform accessibility, and methane leaks during inspections. The project's goal is to improve safety and efficiency in offshore inspections through advanced sensor technologies."
Well Activity Report Classification,The project focuses on utilizing Masked Language Models and Convolutional Deep Neural Networks to classify significant well events derived from Well Activity Reports. It aims to develop a systematic approach for determining the classification of significant events that should be reported in these documents.
Level 1 Survey Report Corrosion Level Classification,"BSEE conducts annual Level 1 surveys for offshore platforms to assess structural integrity and corrosion, with reports submitted for manual review. To streamline this review process, BSEE is collaborating with NASA to develop a machine learning model that identifies potential mislabeling of corrosion levels in survey reports. The model has demonstrated promising accuracy, particularly in areas with severe corrosion, and will be further refined for integration into BSEE's operational workflows."
Well Risk Assessment,"NASA's Advanced Supercomputer Division is developing machine learning models to identify risk factors associated with wells, building on research into sustained casing pressure. This project aims to inform BSEE engineers about potential problems during the well's development stages by evaluating the precursors to sustained casing pressure and their contributions to overall well risk. The outcome will enhance the ability to assess well risk scores effectively."
Sustained Casing Pressure Identification,"The Sustained Casing Pressure Identification project aims to quickly identify wells experiencing sustained casing pressure (SCP) to mitigate safety risks associated with SCP, which can arise from gas migration or defects in well components. The Bureau of Safety and Environmental Enforcement (BSEE) partnered with NASA's Advanced Supercomputing Division to explore AI techniques for researching and predicting SCP issues in well platforms. This collaboration seeks to enhance the efficiency and accuracy of monitoring and addressing SCP problems."
ROV Smart Touch Subsea Pipeline Inspections,"The ""Smart Touch"" project, funded by BSEE and conducted by the University of Houston, is developing an advanced robotic system for subsea pipeline inspections. Utilizing Remote Operated Vehicles (ROVs) equipped with smart touch sensors, video cameras, and scanning sonars, the system autonomously detects flange loosening and pipeline leaks while enhancing efficiency and reducing human reliance. Collaborations with industry partners will aid in the system's development, testing, and commercialization."
Form Recognition model for Benefits Forms,The project involves the development of a custom machine learning model designed to extract data from complex benefits forms. The model processes input documents or scanned images and generates a JSON response containing key/value pairs that correspond to the field headers on the forms. The output of the AI system serves as a recommendation based on the extracted data.
Language Translation,"The project aims to develop an automated language translation system for unofficial documents, enabling quick and cost-effective translations. It leverages natural language processing models to facilitate the translation of published documents and websites into multiple languages."
Audio Transcription,The project focuses on converting speech into text for record-keeping purposes utilizing natural language processing models. It aims to provide accurate audio transcription to enhance data accessibility and organization.
Text to Speech Conversion,"The project focuses on developing a neural text-to-speech conversion system that utilizes natural language processing models to produce realistic, human-like audio output. This technology can be applied to enhance audio files for PowerPoint presentations, making them more engaging and easier to understand."
Claims Document Processing,The Claims Document Processing project focuses on developing custom natural language processing models to detect causal language in physician's notes. It includes ranking documents based on their relevance and highlighting sentences that may contain causal expressions. This approach aims to enhance the evaluation of claims documentation.
Website Chatbot Assistant,"The Website Chatbot Assistant provides users with basic information about the program, contact information, and updates on petition case statuses. It functions as a question and answer bot, relying on a predetermined set of questions and answers without utilizing AI for responses."
Data Ingestion of Payroll Forms,"The project involves developing a custom machine learning model for data ingestion from payroll forms. It extracts data from complex documents or scanned images, tagging entries to their corresponding field headers, and produces a JSON response containing key/value pairs."
Hololens,"The project utilizes Hololens technology to train inspectors in visually assessing unsafe areas from a secure location. AI assists in the training process by providing relevant images of these locations, enhancing the inspectors' ability to identify hazards effectively. This innovative approach prioritizes safety while maintaining inspection efficiency."
DOL Intranet Website Chatbot Assistant,The DOL Intranet Website Chatbot Assistant is a conversational AI tool designed to assist users with common procurement and specific contract inquiries. It leverages a knowledge base to provide accurate answers to user questions related to the Department of Labor's intranet resources.
Official Document Validation,The project focuses on utilizing AI technology to detect mismatched addresses and garbled text in official letters sent to benefits recipients. The outcome of this process is a recommendation for further review of the identified discrepancies.
Electronic Records Management,"The Electronic Records Management project aims to meet NARA metadata standards for permanent federal documents through the application of AI and NLP technologies. It focuses on identifying data within documents, classifying them, and summarizing their content to facilitate decision-making. The system ultimately enhances the management and accessibility of federal electronic records."
Call Recording Analysis,"The project involves the automatic transcription of recorded calls made to Benefits Advisors in the DOL Interactive Voice Response (IVR) center. While AI is utilized for transcribing the calls, it is not employed for any further analysis of the transcriptions. The primary output of the project is the transcribed text of the calls."
Automatic Document Processing,The project focuses on automating the processing of continuation of benefits forms by utilizing an AI tool. This tool is designed to extract data from pre-defined selection boxes in the forms for further analysis and processing.
Automatic Data Processing Workflow with Form Recognizer ,"The project focuses on automating the data processing workflow using Form Recognizer to efficiently extract required information. The AI system consolidates the extracted data for review, and a GPT model organizes this data into a spreadsheet for reconciliation."
Case Recording summarization,The project involves utilizing an open-source large language model to summarize publicly available case recording documents that do not contain personal identifiable information (PII) or sensitive data. The summaries generated by the model are reviewed by human note takers and are not hosted in the Department of Labor's technical environment.
OEWS Occupation Autocoder,"The OEWS Occupation Autocoder processes state-submitted response files containing occupation titles and job descriptions to assign up to two 6-digit Standard Occupational Classification (SOC) codes. It provides probability recommendations for human coders, and codes exceeding a specified threshold are added to the response files before being returned to the states to aid in SOC code assignment."
Scanner Data Product Classification,"The Bureau of Labor Statistics (BLS) is implementing a machine learning system to automate the classification of consumer goods data into Entry Level Item (ELI) codes, which were previously hand-coded by staff. This model uses word frequency counts from item descriptions and logistic regression to determine the most likely ELI category for each item. The automation is expected to enhance productivity, provide real-time results, and reduce costs, while still incorporating human review for classifications that do not meet a certain probability threshold."
Expenditure Classification Autocoder,"The Expenditure Classification Autocoder project aims to automate the assignment of expense descriptions reported by respondents of the Consumer Expenditure Diary Survey to specific item codes, or expenditure classification categories. This automation is expected to enhance productivity and achieve cost savings for the Bureau of Labor Statistics (BLS). The system will streamline the classification process, thereby improving overall efficiency in handling expenditure data."
Generative AI Assistant,"The Generative AI Assistant is a secure in-house solution designed to evaluate business use cases that leverage Generative AI models and semantic search. It addresses various problems through applications such as text summarization, text analysis, and document comparisons, while providing actionable recommendations."
Occupation Code Suggestion For Job Duties Data,"The project involves utilizing natural language processing and classification techniques to suggest appropriate occupation codes for job duties data. It aims to automate the process of assigning occupation codes, enhancing accuracy and efficiency in categorizing job roles."
Notice of Deficiency (NOD) Text Generation using Generative AI model,This project involves developing a custom Generative AI model to generate Notice of Deficiency (NOD) text tailored to specific input data. The focus is on utilizing natural language processing techniques to create accurate and relevant documentation efficiently.
PII Redaction,"The project involves using Amazon Web Services' Personal Identifying Information scrubber, along with Named Entity Recognition, to remove personal identifying information from ITA text fields. The output is a cleaned-up version of the input text with all sensitive information successfully redacted."
Website Chatbot Assistant,"The Website Chatbot Assistant provides users with essential information regarding the Workforce Recruitment Program, including relevant contacts for further inquiries. It generates content related to the WRP program to enhance user experience and facilitate communication."
Initial Determinations for incoming applications,"The project involves developing an AI tool to conduct an initial analysis of incoming 9141 and 9089 applications. This tool will determine if a Request for Information (RFI) is needed, either issuing the request automatically before case assignment or at the time of assignment, where an analyst can affirm the RFI. It will also identify cases that require an RFI."
AI Course Design Assistant,"The AI Course Design Assistant is a tool that recommends course structures, module titles, descriptions, and images using AI algorithms. It analyzes course content to quickly generate test questions and prompts for authentic assessments, streamlining the course design process. The product is designed for use with Blackboard and is offered as a commercial off-the-shelf solution without modifications."
Worker PLUS Microsimulation Program,"The Worker PLUS Microsimulation Program is an advanced version of the ACM model, used to simulate individual leave-taking behaviors and outcomes for workers, including the number of leaves, duration, benefit levels, and eligibility. It utilizes data from the five-year American Community Survey (ACS) Public Use Microdata Sample (PUMS) to create its simulations."
Computer-Assisted Coding: SOII Autocoder,"The SOII Autocoder is a transformer-based text classification model that automates the assignment of classification codes for the Survey of Occupational Injuries and Illnesses (SOII), handling narratives related to work-related injuries and illnesses. Since its inception in 2012 and expanded deployment, it achieved a 92% coding rate in 2022, with subsequent human validation. The model uses millions of labeled cases for training and operates internally via REST API within the BLS network, processing SOII and MSHA cases efficiently."
CFOI Record Matching,"The CFOI Record Matching program enhances the Census of Fatal Occupational Injuries (CFOI) by utilizing AI techniques, including natural language processing and record matching, to reconcile and enrich data from various sources like OSHA and QCEW. It employs random forest classifiers and TF-IDF vectors for effective data matching, producing periodic outputs for review by CFOI staff. This initiative aims to improve the completeness and accuracy of the data on work-related fatal injuries."
OIICS Coding,"The OIICS Coding project focuses on automating the assignment of Occupational Injury and Illness Classification codes to reduce the time required for manual coding. It aims to eliminate the estimated 65,500 labor hours needed for initial coding and the subsequent time for error correction, streamlining the process significantly."
AI Assisted coding -Microsoft GitHub Copilot,"Microsoft GitHub Copilot is an AI-assisted coding tool that automatically generates software code. This technology significantly reduces the time required for coding tasks, streamlining the development process for programmers."
CPS OTC Prediction,"The CPS OTC Prediction project utilizes Current Population Survey (CPS) data to estimate off-the-clock (OTC) hours worked by employees, enhancing the Bureau of Labor Statistics' productivity measures. A random forest model is employed to impute missing data regarding workers' compensation status to improve the accuracy of hours worked calculations. This innovative approach aims to refine the ratio of total hours worked to paid hours worked by leveraging various respondent characteristics for more precise predictions."
Sample Refinement: Frame API,"The Frame API enhances sample refinement for BLS establishment-based surveys by allowing fast retrieval and comparison of up-to-date Quarterly Census of Employment and Wages (QCEW) and Longitudinal Database (LDB) data. Utilizing TF-IDF vectors and cosine similarity, it checks for changes in company names, addresses, and unit descriptions, enabling efficient adjustments to survey samples. The SOII program uses this API to conduct over 20 refinement checks, producing reports to assist data collectors."
CE Interview Item Code Estimation,"The CE Interview Item Code Estimation project develops a custom machine learning model to predict expense classification categories for expenditures based on text descriptions from the Consumer Expenditure Interview Survey. The model aids economists by suggesting potential categories, thereby enhancing decision-making efficiency without directly assigning classifications. This approach aims to improve productivity in the review process."
CE Interview Imputations,"The project focuses on developing custom machine learning statistical models to replace missing expenditure values in the Consumer Expenditure Interview Survey, specifically when respondents indicate ""don't know"" or refuse to provide an amount. This modern approach enhances the statistical quality of imputed data compared to traditional methods, leading to more accurate expense reporting. The end goal is to produce reliable imputed expense amounts for analysis."
Note taking bot,The note-taking bot will summarize meeting transcripts by producing concise meeting notes. It will deliver both the full transcript and a summary that highlights key points and action items.
Determine Occupation Codes from Text (NIOCCS),The NIOCCS (Industry and Occupation Computerized Coding System) is a free tool provided by NIOSH that analyzes job descriptions to assign appropriate industry and occupation codes. This system streamlines the process of coding occupations based on text descriptions of job titles.
Camtasia,Camtasia is a software designed to enhance screen recordings and create video tutorials. It enables users to produce professional-quality videos efficiently and effectively.
Adobe Premier Pro,"Adobe Premiere Pro enhances the video editing process by automating complex tasks like scene detection, video reframing, and color grading through its integration with Adobe Sensei. This incorporation of AI components improves efficiency and provides creative tools that simplify editing tasks, ultimately assisting video editors in their work."
Audiate,"Audiate is an AI-driven platform specializing in speech-to-text transcription, text-based audio and video editing, and the creation of AI-generated scripts and audio. It also offers text-to-speech conversion and supports multilingual translation for text transcriptions from voice recordings."
SnagIT,"SnagIT offers tools for efficiently capturing, editing, and sharing visual content, including screenshots and screen recordings. Its features, such as Optional Character Recognition, SnagIT AI's Grab Text, and automatic captions and titles, enhance the ability to extract, reuse, and organize text from images."
Facebook Mobile App,"The Facebook Mobile App includes a feature that utilizes AI for enhanced user experience, specifically through MetaAI's search and chatbot capabilities. This feature assists with public relations and external communication from the Department, allowing users to interactively search for relevant topics and receive instant results. While AI is integrated, it is not the core technology of the app."
Google Authenticator Mobile App,"The Google Authenticator mobile app enhances online security by requiring a second verification step during sign-in, alongside the traditional password. It generates a unique code on the user's phone, which must be entered for secure login. This additional authentication method helps protect accounts from unauthorized access."
Google Maps Mobile App,"The Google Maps Mobile App enhances travel efficiency by providing real-time updates on traffic conditions, estimated travel times, and public transit information. It features automatic rerouting to avoid delays from incidents and closures. Additionally, the Live View function overlays navigational arrows on the user's surroundings to ensure accurate navigation."
Instagram Mobile App,"The Instagram mobile app allows users to share moments with friends through disappearing Stories and Notes, initiate group chats, and document memories in their Feed. Users can enhance their posts with customizable templates, music, stickers, and filters, while also discovering entertaining short videos through Reels. The platform emphasizes real-time communication and creative expression."
Microsoft Authenticator Mobile App,"The Microsoft Authenticator mobile app provides secure and convenient sign-in options for various online accounts through multi-factor authentication, passwordless access, and password autofill features. It also offers enhanced account management capabilities for Microsoft personal, work, or school accounts, along with authentication and random number generation functionalities."
Periscope Mobile App,"The Periscope mobile app will be discontinued on March 31, 2021, while the live video feature will be integrated into Twitter to maintain community engagement. This project emphasizes the importance of live video in enhancing communication and building vibrant communities."
X (formerly Twitter) Mobile App,"The X mobile app enables users to share content publicly, engage in conversations, and follow breaking news and personal interests. It offers features such as Community Notes for additional context, live audio and video streaming through Spaces, and private communication via Direct Messages. The app leverages natural language processing to enhance user communication and engagement."
Dragon Naturally Speaking,"Nuance Dragon Naturally Speaking is a speech recognition software that allows users to dictate documents, emails, and interact with various applications using their voice. It utilizes natural language processing (NLP) to convert spoken words into written text, enabling users to create content efficiently."
ZoomText and ZoomText Professional,"ZoomText Magnifier/Reader is a comprehensive software solution designed for individuals with low vision, offering both magnification and reading functionality. It incorporates text-to-speech capabilities to enhance accessibility and usability for users with visual impairments."
Visual Studio,"Visual Studio IDE is a versatile platform for writing, debugging, and building code, ultimately enabling users to publish applications. It offers a variety of outputs, including executable applications, libraries, and web applications, and features multiple versions to cater to different user needs. The integration of AI components enhances productivity, code quality, and collaboration for programmers and software engineers."
ABBYY FineReader,"ABBYY FineReader is an optical character recognition (OCR) system that converts scanned documents, PDF files, and image files into editable formats. The software extracts and recognizes text from input documents, outputting it as editable Word documents, Excel spreadsheets, searchable PDFs, or plain text files."
Google Earth Pro,"Google Earth Pro is a free desktop application that offers advanced GIS and mapping capabilities, allowing users to create maps, import and export GIS data, and access historical images. Users can explore a 3D representation of the Earth's surface, viewing high-resolution satellite imagery and 360 perspectives through Street View while collaborating on immersive, data-driven maps from anywhere."
Adobe Creative Cloud and Adobe Product Suite,"Adobe Creative Cloud and the Adobe Product Suite offer a diverse range of tools for creating and editing various forms of content, including motion graphics, audio, eLearning, and web development. Key software includes After Effects for visual effects, Audition for audio editing, Premiere Pro for video editing, and Photoshop for image creation, all enhanced by Adobe Sensei's AI capabilities. This comprehensive suite enables users to efficiently produce and manage high-quality creative assets across different media."
Autodesk,"Autodesk Civil 3D is a design software that enables civil engineers to tackle complex infrastructure challenges through detailed 3D modeling and visual simulations. It incorporates AI components that enhance the design and drafting processes, utilizing machine learning and automation to boost productivity, accuracy, and efficiency in land development, transportation, and infrastructure projects."
AI Course Design Assistant,"The AI Course Design Assistant is a tool that recommends course structures, module titles, descriptions, and images using AI algorithms. It analyzes course content to quickly generate test questions and prompts for authentic assessments, streamlining the course design process. The product is designed for use with Blackboard and is offered as a commercial off-the-shelf solution without modifications."
Webex Meeting Transcription,Webex offers an internal transcription feature that converts spoken words during meetings into written text. This feature is designed for webinars and includes a review process to ensure accuracy before the final transcript is published.
Omni Page Ultimate 19,"Omni Page Ultimate 19 is a software tool designed to convert physical documents and image-based text into editable digital formats. It offers features such as searchable and editable text extraction from scanned documents, along with advanced object recognition and optical character recognition (OCR) capabilities for effective document digitization and text recognition."
Tableau Public 2023,"Tableau Public 2023 enables users to create and share interactive data visualizations, including charts, graphs, and dashboards, which are designed for easy interpretation and dissemination. The platform supports data classification and predictive analytics, enhancing users' ability to derive insights from their data."
Adobe Acrobat Professional Latest Version,"The latest version of Adobe Acrobat Professional enhances document workflows through features such as text-searchable PDFs, fillable forms, and automated file structuring. It includes advanced capabilities like PDF Text Recognition (OCR) and Document Layout Analysis for effective document management."
Tableau Creator (Desktop and Prep),"The Tableau Creator project focuses on empowering analysts to connect, prepare, and visualize data effectively. It facilitates the creation of visual dashboards, reports, and predictive models through robust data analysis and predictive analytics capabilities. Additionally, it emphasizes data classification to enhance data insights and decision-making."
Grammarly 14,"Grammarly 14 is a writing enhancement tool that utilizes natural language processing to correct grammar, punctuation, and style errors. It provides suggestions for tone adjustments to ensure the text is grammatically correct, well-structured, and contextually appropriate."
Adobe Creative Cloud with Acrobat Pro Latest Version,"The project focuses on utilizing the latest version of Adobe Creative Cloud along with Acrobat Pro to enhance creative workflows. It aims to automate repetitive tasks, improve search accuracy, and enable advanced capabilities in image manipulation and video editing through features such as object recognition, image generation, and natural language processing (NLP). The integration targets the production and editing of images, videos, and other content."
Microsoft Project Office 365,"Microsoft Project Office 365 is a project management tool designed to assist project managers with planning, scheduling, and managing resources. It features task automation, resource allocation, optimized project timelines, and predictive alerts to enhance project efficiency."
Stata/MP 18,"Stata/MP 18 is a powerful statistical software designed for data scientists and researchers, enabling them to analyze large datasets effectively. It offers advanced tools for statistical modeling, data analysis, and predictive analytics, producing detailed reports and insights through regression models and statistical analyses."
Dragon Legal Individual (Speech Recognition) ,"Dragon Legal Individual is a speech recognition software designed for legal professionals to convert spoken language into written text. It effectively transcribes legal dictations and other spoken communications, enhancing efficiency and accuracy in legal documentation."
Speechify Text to Speech Voice Reader Chrome Extension 9,"The Speechify Text to Speech Voice Reader is a Chrome extension that converts written text into natural-sounding speech. It offers synthesized speech in multiple voices and languages, enhancing accessibility and convenience for users."
Adobe Creative Cloud / Adobe Express AI feature,"The Adobe Creative Cloud and Adobe Express AI feature enables users to efficiently create visual content, including graphics, posters, and social media materials, through AI-driven automation. This tool streamlines graphic design and content creation processes, allowing for rapid image generation and enhanced productivity."
Westlaw Precision & CoCounsel,"Westlaw Precision and CoCounsel are tools designed to assist legal professionals in identifying relevant case law, statutes, and legal precedents. They provide features for analyzing legal documents and predicting potential legal outcomes."
Kurzweil,"Kurzweil 1000 is a software program designed to make printed or electronic text accessible for people with blindness and visual impairments by converting text into spoken words. It utilizes natural language processing (NLP) for text-to-voice functionality, offering audio output that can be customized with various natural-sounding voices to suit individual preferences."
Microsoft Office Suite,"Microsoft Office Suite is a comprehensive collection of productivity software applications developed by Microsoft. It is commonly utilized for personal, educational, and business purposes, enabling users to create and edit text documents, as well as design slideshows that incorporate text, images, and multimedia elements."
GovChat,"GovChat is a generative AI chatbot tool designed for EPA staff, accessible via a web interface on the EPA network. It serves various internal purposes, including generating content and code, while adhering to a rules of behavior that prohibits using it for final decisions or recommendations. As usage patterns evolve, specific use cases may be identified if the system gains widespread adoption."
Transitioning historical help desk knowledge to new help desk software ,"The project aims to transition 20 years of historical help desk knowledge from a customized open source tool to Jira Service Desk. To facilitate this, the project team will utilize generative AI to categorize common questions and summarize responses, which will form the new knowledge base for the help desk system. This knowledge base will include common questions, categories, and corresponding answers to enhance the efficiency of the new help desk."
Emission monitoring program knowledge management system search and summary,"The project involves developing a chatbot that assists EPA monitoring system analysts by answering questions related to emission monitoring programs, including historical regulatory changes and their justifications. The system will leverage preambles and regulatory texts to provide accurate responses to inquiries about topics such as grace periods for quality assurance tests, updates to monitoring performance criteria, and monitoring options for oil-fired power plants."
Identification of lead service lines in drinking water distribution systems using bioindicators/biomarkers,"This project aims to identify lead service lines (LSLs) in drinking water distribution systems (DWDSs) using bioindicators and biomarkers derived from high-resolution microbiome profiles. By employing predictive tools, it seeks to determine the presence of LSLs without the need for excavation, yielding binary outcomes of either LSL or non-LSL."
Generative AI for Study Evaluation and Document Chat,The project utilizes generative AI to streamline the study evaluation process and enhance information retrieval from documents. It generates text responses based on user prompts to facilitate answering questions about the quality of reported information. This approach aims to reduce the time spent on evaluations while improving accessibility to relevant details.
Natural Gas STAR Videos ,"The Natural Gas STAR project utilized an AI tool to generate realistic audio narration files from text scripts, streamlining the production process and reducing costs associated with hiring voice actors. The AI tool solely facilitated the conversion of text to speech, without making any decisions or predictions."
Agency Records Management System (ARMS),"The Agency Records Management System (ARMS) is designed to enhance the accuracy of predicting records schedules for the Environmental Protection Agency (EPA). By leveraging machine learning, the system aims to reduce the administrative burden on EPA staff, streamlining the records management process."
Use of Microsoft CoPilot within the M365 Purview Security Suite,"The project involves integrating Microsoft CoPilot into the M365 Purview Security Suite to enhance the Agencys ability to protect Microsoft cloud data and endpoint devices. By utilizing CoPilot, security and infrastructure analysts can quickly access and analyze information regarding existing vulnerabilities, installed software, and Data Loss Prevention (DLP) alerts, leading to faster decision-making and improved security responses. This integration is expected to streamline reporting processes and enhance the Agency's capability to mitigate security risks."
Use of AI tools within the Agencys instance of ServiceNow,"The project aims to integrate AI tools within the Agency's ServiceNow platform to enhance service desk operations by allowing employees and IT professionals to interact with an AI agent for technical support and information retrieval. This initiative is expected to reduce the number of service tickets and calls, leading to direct cost reductions by providing efficient access to knowledge articles and inventory data. Use cases include responding to password reset queries, troubleshooting technical issues, and retrieving asset management data to streamline IT processes across the Agency."
Machine learning-assisted literature screening,"The project focuses on developing machine learning tools to assist scientists in efficiently screening literature by ranking references based on their relevance, as determined by predefined ""on topic"" and ""off topic"" criteria. This process enables researchers to quickly identify pertinent studies for scientific assessments, leveraging a model that adapts based on user input for inclusion and exclusion. Additionally, these tools offer estimates of recall, indicating the percentage of relevant references identified."
Data Management and Analytics Platform (DMAP) Operations and Governance AI Use Cases,"The Data Management and Analytics Platform (DMAP) aims to enhance data quality, operational efficiency, and support mission outcomes through AI and ML applications. Key features include automated data quality assessments, AI-driven documentation generation, intelligent onboarding processes, and predictive data governance. Additionally, the platform focuses on workflow automation, feature engineering for machine learning, and semantic data discovery to streamline data management and enhance usability."
Intelligent Superfund Search & Chatbot capabilities,"The Intelligent Superfund Search & Chatbot project aims to modernize the EPA's Superfund Enterprise Management System (SEMS) by implementing intelligent automation to enhance document search and processing capabilities. It will significantly improve operational efficiency, accuracy in document retrieval, and user experience, while reducing costs and improving compliance related to environmental site management. The AI system will produce outputs such as key entity extractions, relevant document recommendations, and risk assessment summaries to support better decision-making for EPA staff managing contaminated sites."
Resource Conservation and Recovery Act (RCRA) Predictive Analytics,"The project involves developing predictive analytics for the Resource Conservation and Recovery Act (RCRA) by assigning risk scores to Large Quantity Generators (LQGs) to enhance inspection processes. The risk scores range from 0 to 4, with the aim of identifying priority LQGs for inspection based on their potential risk levels. This approach supports more efficient resource allocation for regulatory oversight."
Clean Water Act (CWA)Predictive Analytics,The Clean Water Act (CWA) Predictive Analytics project focuses on identifying high-risk National Pollution Discharge Elimination System (NPDES) facilities that fail to submit Discharge Monitoring Reports (DMRs). The project involves creating a risk scoring system to rank these facilities from lowest to highest risk based on their DMR submission status.
Clean Air Act (CAA) Predictive Analytics,"The Clean Air Act (CAA) Predictive Analytics project involves developing a risk scoring system for Major and Synthetic Minor Facilities to enhance CAA inspections. Facilities receive a decimal score ranging from 0 to 1, indicating their level of risk for compliance violations. This scoring system aims to streamline inspection processes and prioritize resources effectively."
Extracting references from technical documents,"The National Center for Environmental Economics (NCEE) is exploring methods to document citations from regulatory documents in response to the OMB's interest in enhancing visibility for researchers. The project involves using GovChat to extract unique references from these documents, resulting in comprehensive lists that acknowledge the contributions of researchers cited in EPA analyses."
Streamflow Duration Assessment Modeling,"The Streamflow Duration Assessment Modeling project utilizes random forest modeling to predict streamflow duration classificationsspecifically whether streams are ""perennial,"" ""intermittent,"" or ""ephemeral."" This classification aids in informed water resource management decisions by reflecting the hydrologic regime's influence on stream and riparian characteristics. The model provides valuable insights across various geographical regions."
Solicitation Review Tool (SRT),"The Solicitation Review Tool (SRT) processes ICT solicitations from SAM.gov, compiling the data into a database for analysis by machine learning algorithms. The primary focus is a Natural Language Processing model that identifies compliance language in solicitations; those lacking this language are flagged as non-compliant. Agencies are tasked with validating the SRT's predictions, while the GSA performs random manual reviews on a monthly basis."
Acquisition Analytics,Acquisition Analytics involves analyzing detailed transaction data and categorizing each transaction according to the Government-wide Category Management Taxonomy. This process enhances the understanding of procurement trends and aids in effective decision-making for efficient resource allocation.
City Pairs Program Ticket Forecast and Scenario Analysis Tools,"The City Pairs Program Ticket Forecast and Scenario Analysis Tools analyze segment-level air travel purchase data to generate near-term forecasts for the current and upcoming fiscal year. These forecasts are produced monthly and segmented by different categories, including Department of Defense versus civilian travelers, specific agencies, and regions."
Category Taxonomy Classifier,"The Category Taxonomy Classifier is designed to categorize obligation transactions into specific GWAS subcategories. This is necessary when the existing FPDS coding scheme, including PSC and NAICS, does not provide adequate classification for a transaction. The classifier enhances the accuracy of transaction categorization by filling gaps in the current coding framework."
CPRM Contract Breach Forecast,"The CPRM Contract Breach Forecast project utilizes obligation forecasting to analyze ITC contracts, aiming to enhance awareness of potential risks related to contract ceiling breaches. This initiative seeks to proactively identify and manage contractual obligations to mitigate potential impacts on project delivery."
Category Taxonomy Refinement Using NLP,The project focuses on refining category taxonomy by utilizing natural language processing (NLP) for token extraction from product descriptions. This approach aims to more accurately define and shape the intended markets for product service combinations (PSCs). The outcome is expected to enhance market alignment and improve product categorization.
Key KPI Forecasts for GWCM,"The project involves using monthly historical data to create near-term forecasts for key performance indicators (KPIs) related to total agency/category spending. This pilot effort aims to establish a reliable methodology that, if successful, can be applied to additional KPIs in the future."
Enterprise Brain,Enterprise Brain is an AI-powered document repository developed by Tanjo that enhances the discovery of documents. It utilizes advanced technology to streamline the process of finding relevant information within a vast collection of documents.
AWS Captcha Solver,"The AWS Captcha Solver project involves the development of an AI model that solves AWS captchas to facilitate automated actions in the AWS console using Selenium. This model, trained from scratch with TensorFlow, operates within an AWS Lambda environment utilizing a headless Selenium driver. Future considerations include extending this solution to address a broader range of AI/ML challenges."
ServiceNow Generic Ticket Classification,"The project involves developing a model to automatically classify generic ServiceNow tickets, enabling their re-routing to the appropriate handling teams. Currently, this re-routing process is performed manually, and the initial model aims to target the top five most common ticket types, determining the most suitable group for assignment. This automation will streamline ticket management and improve efficiency."
ServiceNow Virtual Agent (Curie),"The ServiceNow Virtual Agent, named Curie, employs machine learning to deliver predictive responses for chat entries related to IT service requests. This natural language chatbot enhances the customer service experience for employees by utilizing knowledge-based articles to generate accurate text responses based on user input."
GREX AI Document Classification,"The GREX AI Document Classification project was a pilot program initiated by the Office of Leasing and IT Modernization to assess the use of AI and machine learning for classifying PDF documents in G-REX. The successful pilot demonstrated significant time savings and improved accuracy in document classification, although additional funding will be needed for continued implementation using AWS services. Appian plans to offer similar functionality as a standard feature in late 2024 to early 2025, contingent on G-REX transitioning to the cloud, with ongoing assessments being conducted."
Contract Acquisition Lifecycle Intelligence (CALI),"The Contract Acquisition Lifecycle Intelligence (CALI) tool is an automated machine learning solution designed to enhance the evaluation of vendor proposals during the Source Selection process. Provided by Octo Consulting as Infrastructure as a Service, CALI operates within AWS's public cloud and analyzes vendor submissions based on format compliance, forms validation, representations and certifications, and requirements compliance. Once the evaluation process is initiated by the Contracting Officer, the results can be reviewed and finalized within the CALI system before submission back to the Source Selection module in Bizagi."
Survey Comment Ham / Spam Tester,The Survey Comment Ham/Spam Tester project aims to evaluate and categorize comments on the USA.gov website to identify which ones are valuable for analysts to read. The tool will distinguish between useful feedback (ham) and irrelevant or spammy responses. This classification will streamline the analytical process and improve efficiency in handling survey comments.
Classifying Qualitative Data with Medallia,"USA.gov is working on classifying a diverse range of qualitative data, including survey comments, chat transcripts, and case notes, into identifiable topics like passports and tax refunds. The project emphasizes using Medallia's natural language processing capabilities to create rules for tagging data, while also exploring its AI classification features, which, despite their potential value, remain unused. The primary challenge lies in effectively categorizing the vast variety of content present in USA.gov's datasets."
Elastic Machine Learning Threat Detection,"The Elastic Machine Learning Threat Detection project employs AI to analyze security logs, identifying anomalous data patterns for review by human SOC analysts. This initiative aims to enhance the efficiency and speed of data searches by fostering a collaborative human/AI partnership. Detected anomalies are logged in a Security Information and Event Management (SIEM) tool, triggering alerts for the Security Operations Center (SOC) team."
Elastic Machine Learning Threat Detection - Phase 2,"The Elastic Machine Learning Threat Detection project aims to enhance the search and discovery capabilities of SOC analysts by utilizing a large language model (LLM) with access to security logs. This tool will expedite the discovery of relevant records and associated logs, while also automatically analyzing logs to suggest significant data points to the analysts. The implementation promises to increase efficiency in threat detection processes within security operations."
Chatbot for Federal Acquisition Community,"The GSA FAS NCSC is implementing a chatbot to enhance the customer experience by automating responses to frequently asked questions through knowledge articles. This initiative aims to reduce the staffing needs for live chat programs, allowing resources to focus on proactive customer service efforts. Customers will still have the option to speak with a live agent if they prefer."
Document Workflow / Intelligent Data Capture and Extraction,"The GSA is developing an advanced document workflow platform aimed at improving accuracy and scalability. This initiative focuses on the intelligent capture, classification, and transfer of essential data from both unstructured and structured documents, particularly PDF files, to appropriate processes, workflows, or decision engines."
OAS Kudos Chatbot,"The OAS Kudos Chatbot is designed to streamline the process of capturing employee peer-to-peer recognitions within the Office of Administrative Services. Utilizing Natural Language Processing from Google Dialogflow, the chatbot can engage in conversations, interpret user input, and implement branching logic to enhance user interactions."
NCMMS AI Chatbot,The NCMMS AI Chatbot is designed to offer inline technical support for NCMMS and IBM Maximo through a user-friendly chatbot interface. It utilizes natural language processing to provide contextual assistance by answering user queries based on existing training materials and support resources.
Login.gov,"Login.gov's identity verification service utilizes facial matching AI to securely establish and verify user identities, linking them to their created accounts. This service offers users a fast and convenient method for remote identity verification, safeguarding against identity theft. Additionally, it assists government partners in verifying identities during unattended sessions, enhancing protection against fraudulent access to government systems."
Gemini for Workspace,"The Gemini for Workspace pilot study aims to evaluate the impact of advanced AI capabilities on productivity, collaboration, and efficiency within the General Services Administration (GSA). Over 90 days, 200 users will test the Gemini system's features, which include intelligent assistance for drafting documents, smart communication tools, data analysis, and automation of routine tasks. The pilot will generate feedback to guide future AI investments and help modernize GSA's technology infrastructure while ensuring compliance with non-sensitive data usage."
Test Fit Layouts,The QBIQ pilot project aims to evaluate the use of AI in rapidly test-fitting spaces to meet specific requirements. It focuses on creating floor plans and 3D conceptual layouts to enhance communication with tenant agencies through visualizations. The goal is to determine if AI can expedite the vetting process for space utilization.
Design Your Facility,"The Design Your Facility tool streamlines the process of configuring facilities for unaccompanied children by utilizing large language models (LLMs). This interface allows users to describe their desired building, room, and bed layouts conversationally, generating a digital twin in the UC Bed Network Facility Mapper without extensive training or system administrator assistance. The AI model recommends optimal configurations based on user inputs and confirmations, enhancing efficiency in managing bed availability and assignments."
Discover Financial Business Intelligence System (FBIS) Report Analysis (Sub-CAN Line Items),"The Discover Financial Business Intelligence System (FBIS) Report Analysis project enables ACF Discover users to efficiently identify and aggregate related line items from various reports, creating a real-time spend plan. Utilizing a large-language model, the system retrieves and compiles information such as supplier name, document number, and total obligations associated with specific sub-CAN line items. This tool streamlines budget tracking and allows budget officers to maintain oversight of yearly budgets and budget health."
Grant Spend Health Analysis,"The Grant Spend Health Analysis project aims to enhance the fiscal stewardship of ACF-funded recipients by identifying active grants that are at risk of deobligating funds. The Office of Grants Management plans to utilize AI techniques to develop a predictive model that helps grant specialists recognize these potential issues early. Additionally, OGM intends to create tailored training and technical assistance materials to support recipients in effectively utilizing their awarded funds."
Structuring and Validating Completeness of Case Data Information,"The project involves structuring and validating data related to family separations, as stipulated by the Ms L vs ICE settlement. Beginning November 2024, the U.S. Customs and Border Protection (CBP) will provide relevant information, which the Office of Refugee Resettlement (ORR) will integrate into existing child profiles. AI will initially parse and evaluate this data for completeness before ORR's Intakes Team performs a final review and requests any missing information from CBP."
Triaging Notice of Concern Submissions,"The Office of Refugee Resettlement (ORR) is implementing an AI-powered triage tool to efficiently manage their backlog of Notice of Concern (NOC) submissions related to children's safety. The tool will structure data from NOCs and provide prioritization recommendations to assist ORR staff in reviewing the most urgent cases, ultimately reducing the backlog of submissions. AI will facilitate data parsing and validation while leaving decision-making to the ORR team."
Unaccompanied Children Program Policy & Procedure Research Tool,"The Unaccompanied Children Program Policy & Procedure Research Tool is designed to assist the Office of Refugee Resettlement (ORR) monitoring team in efficiently researching laws, standards, and policies related to the care of unaccompanied children. This tool aims to expedite compliance assessments, ensuring that care providers meet required standards and that any necessary corrective actions are identified and implemented promptly. The research tool does not suggest corrective actions but supports the monitoring process to protect the health and well-being of children being cared for."
Unaccompanied Children Process Model Digital Twins,"The Office of Refugee Resettlement (ORR) is developing a digital twin model to enhance its strategic and contingency planning for unaccompanied children in its custody. This model aims to enable ORR to simulate various scenarios, thereby improving decision-making and ensuring timely and safe releases of children to appropriate sponsors. The initiative focuses on optimizing the processes involved in the care and management of unaccompanied minors until they transition to custody or other legal statuses."
Analyzing Public Comments on Proposed Rule,"The project leveraged AI to analyze public comments on a proposed regulation for quality improvements in the Head Start program. It involved creating a comment analysis pipeline that produced tagged comment segments and topic-based summary drafts, which were refined by subject matter experts. The use of AI enhanced the review process, providing better information for more efficient final rule development."
Outreach List Segmentation,"The Office of External Affairs (OEA) utilized an AI tool to analyze a list of constituent email addresses, generating a structured spreadsheet that includes organization names, mission summaries, policy domains, and websites. This information enables OEA to effectively segment their outreach lists and send targeted communications to organizations based on their specific policy areas. The project enhances OEA's ability to connect with relevant stakeholders in various fields."
Ask HR Policy,"The Ask HR Policy project is a resource designed for ACF Executive Officers and Administrative Officers, offering an accessible way to navigate HR Policy documentation and obtain answers to management-related queries. By utilizing large language models (LLMs), the platform analyzes user questions, providing synthesized responses along with cited sources and links to relevant official HR documentation from HHS.gov. Access to the platform is secure and permissioned for specific users within the organization."
Child Welfare Information Gateway OneReach Application,"The Child Welfare Information Gateway, operated by the Children's Bureau, provides a hotline for inquiries related to child welfare resources. This hotline employs OneReach AI technology to automate routine questions and connect callers to local child abuse reporting hotlines based on their area code. Additionally, it features a limited FAQ texting service that uses natural language processing to assist users, with queries being used to improve the AI's capabilities and expand the FAQ database."
Collective Bargaining Compass,"The Collective Bargaining Compass is a resource designed for ACF managers to efficiently access and navigate Collective Bargaining Agreement documentation. Utilizing a secure Virtual Assistant interface, the tool allows managers to input questions and receive synthesized answers based on a comprehensive analysis of the official rulebook, complete with citations and links to relevant sections. The project leverages large language models to analyze user inquiries and summarize the information from the documentation."
Discover User Assistant,"The Discover User Assistant project serves as a resource for ACF Discover Staff Management Module users to facilitate easy navigation and access to information. It features a secure virtual assistant that answers specific inquiries about the module's capabilities and tools by leveraging user documentation through an AI model that synthesizes and summarizes relevant content. This solution enhances user support by providing quick, documented answers to questions related to the platform."
Policy Knowledge Base Data Migration,"The Office of Family Assistance (OFA) is consolidating over 1,100 TANF knowledge base articles into a unified platform to improve technical assistance for grantees. Large language models were employed to generate draft article topics and categorize them for better organization, facilitating the development of a minimum viable product for the knowledge base. This project aims to streamline access to TANF policy information, enhancing OFA's support capabilities."
Qualitative analysis,ACF staff analyze qualitative data from surveys and interviews to identify themes and trends. The project utilizes commercial software with AI capabilities to assist in identifying relevant passages and suggesting topic tags for the qualitative data. This streamlines the analysis process and enhances the insights gathered from the data.
AHRQ Search,"The AHRQ Search project implements advanced AI features to enhance organization-wide search capabilities. This includes techniques such as relevancy tailoring, auto-generation of synonyms, and automated suggestions to improve the user experience by optimizing search results and displaying the most pertinent information. The system also auto-completes queries, proposes relevant content tags, and offers spelling corrections based on user interaction data."
Chatbot,"The project implements a chatbot that allows users to interact with AHRQ content through natural language questions, providing a modern alternative to traditional public inquiry methods. This solution enhances user experience and minimizes resource use by delivering real-time responses to inquiries."
Chatbot,"The project involves developing a chatbot for the Patient Safety Organization Privacy Protection Center website, enabling users to ask questions in natural language. This initiative aims to enhance user experience and minimize the resources needed to address public inquiries by providing real-time responses through natural language processing."
Enhancing Diversity in Peer Review - Pilot,"The Division of Scientific Review (DSR) is implementing a pilot project to enhance diversity among peer reviewers by revising recruitment strategies to achieve 20% representation from underrepresented minorities in each study section. By leveraging AI to quickly and accurately identify diverse and qualified grant reviewers based on various demographic factors, the DSR aims to create a more efficient and equitable review process. This initiative seeks to improve healthcare accessibility and quality across the U.S. while enabling Scientific Review Officers to make informed recruitment decisions."
NLQuery- As Data or Pulse,"NLQuery enhances the clinical dashboards on the Patient Safety Organization Privacy Protection Center website by allowing users to pose questions in plain language and receive instant responses. These responses are delivered as automatic data visualizations, eliminating the need for users to manually manipulate data fields or comprehend complex data structures. This feature aims to improve user experience and potentially increase data reporting."
Quality and Safety Review System AI-enabled automated abstraction,"The Quality and Safety Review System (QSRS) project aims to automate the abstraction of patient records and subsequent data entry, thereby streamlining the process and reducing the reliance on manual efforts. This AI-enabled system is expected to increase the volume of abstracted cases while lowering government costs and improving accuracy, ultimately enhancing data quality for reliable reporting. By leveraging advanced AI and machine learning, the project aims to maintain or lower expenses while increasing efficiency in both national and local healthcare settings."
Document Q&A Interface ,The Document Q&A Interface enhances analysts' understanding of specific responses by enabling them to ask questions about associated SCCT media. It leverages Large Language Models to query existing documents and provide relevant answers based on user inquiries. This tool improves access to contextual information and streamlines the information retrieval process for analysts.
Emergency Inventory Redistribution Model,The Emergency Inventory Redistribution Model utilizes linear programming to develop optimization strategies for inventory management and distribution during emergencies. It aims to identify the most efficient interventions to meet the demand for medical supplies effectively. This model serves as a critical tool for enhancing preparedness and response efforts in emergency situations.
emPOWER AI,"emPOWER AI is an Amazon Alexa Skill designed to facilitate rapid access to publicly available emPOWER data, especially during disasters with unstable internet conditions. It enables first responders, public health authorities, and other emergency management partners to utilize critical information regarding electricity-dependent Medicare beneficiaries and other resources for effective planning and response to the needs of at-risk populations. This tool supports emergency preparedness, response, recovery, mitigation, and resilience efforts at various community levels."
Entity Resolution Tool,"The Entity Resolution Tool standardizes order information from thousands of manufacturers and customers to facilitate data aggregation for improved analysis of order and delivery patterns. It employs embedding models, hierarchical clustering, and large language models to detect duplicate entity names and assign them standardized names. This enhances the efficiency and accuracy of data processing within SCCT."
Executive Report Generation AI Copilot ,The Executive Report Generation AI Copilot automates the creation of executive summaries and commercial product awareness reports (CPARs) by leveraging data on supply chain disruptions and related events. This system reduces the time needed for SCCT analysts to generate reports by using large language models to summarize and compile existing data into cohesive texts.
Flow Model Edge Prioritization Estimation Tool,The Flow Model Edge Prioritization Estimation Tool is a critical component of a simulation tool designed to assess the impacts of supply chain disruptions on customers. It utilizes linear regression to analyze historical data on preferential order fulfillment and forecast future fill rates.
Generalized Demand Model Sensitivity Analyzer,"The Generalized Demand Model Sensitivity Analyzer is a diagnostic tool designed for SCCT to enhance demand projections for critical medical products. It utilizes a constrained regression model to identify key drivers of uncertainty in demand and quantifies their impact, helping analysts improve their models."
Google Search Model Alerts,The Google Search Model Alerts project utilizes publicly available information to identify supply chain disruptions through automated alerts. It employs a model based on exponentially weighted moving averages to detect rising trends in time series data related to Google search volume for specific keywords. This facilitates timely reviews by analysts of relevant data.
Google Search Model Rising Trend Entity Extraction,"The Google Search Model Rising Trend Entity Extraction project leverages publicly available information to enhance the identification of supply chain disruptions. This tool utilizes language models to analyze rising search terms and pinpoint products that may be in short supply, assisting analysts in recognizing potential shortages."
Manufacturer Name Standardization,"The project focuses on standardizing manufacturer names received from various distributors by consolidating and categorizing the name variants. An advanced grouping algorithm organizes similar names, while a Large Language Model suggests a standardized name for reporting purposes. This process enhances the consistency and accuracy of manufacturer data for analysts."
Model based open source reporting search and summarization,The project utilizes large language models to collect and summarize open source information related to supply chain events. It aids analysts by providing initial summaries that help them identify and focus on relevant topics of interest. The goal is to enhance monitoring and understanding of supply chain dynamics through effective information retrieval and summarization.
PPE Product Classification Model,"The PPE Product Classification Model analyzes data from distributors to categorize thousands of products into seven specific classifications, including gloves, needles, gowns, masks, eye/face shields, and test kits. By employing Bayesian anomaly detection and random forests, the model effectively classifies products, facilitating trend analysis and data aggregation."
Adverse Childhood Experiences (ACEs) Literature Review Dashboard,"The Adverse Childhood Experiences (ACEs) Literature Review Dashboard streamlines the process of conducting literature reviews by utilizing large language models to quickly identify relevant articles for an ACEs database. This automated system enhances the efficiency of ACEs researchers at the CDC's National Center for Injury Prevention and Control, allowing them to develop hypotheses and pinpoint gaps in the existing literature. The master dataset of relevant articles is integrated with PowerBI for easy reference."
Automated Analysis of Injury Control Research Center (ICRC) Annual Progress Reports (APRs) using Large Language Models,"The project involves the development of an AI system designed to automate the analysis of Annual Progress Reports (APRs) from Injury Control Research Centers (ICRCs), focusing on identifying challenges and extracting critical themes. This automation aims to enhance the efficiency and accuracy of the review process, allowing ICRC teams to concentrate on strategic planning and higher-level evaluations. Ultimately, the AI will facilitate timely responses to ICRC needs, supporting these centers in achieving their injury control goals and benefiting public health outcomes."
Detecting Stimulant and Opioid Misuse and Illicit Use,"The project focuses on developing machine learning models to detect stimulant and opioid misuse in electronic health records (EHR) data from the National Hospital Care Survey (NHCS). These models will analyze free-text clinical notes, allowing for the identification of non-therapeutic drug use that cannot be captured through traditional coding. One model will be for internal use while another will be publicly released, both designed to enhance statistical analysis and provide new insights into health statistics."
DHP Virtual Assistant,"The DHP Virtual Assistant is an AI tool designed to support HIV researchers by streamlining information retrieval related to HIV and its research. Utilizing retrieval augmented generation (RAG) technology, the assistant will enhance productivity by providing accurate information based on user queries and related documents."
Fuzzy matching tool,"The Fuzzy Matching Tool is designed to facilitate clearance and review management of CDC publications by ensuring compliance with the National Institutes of Health Manuscript Submission process and CDC's public access policy. It utilizes pre-trained, open-source language models to identify similar records between eClearance submissions and CDC-authored publications, aiding centers and divisions in prioritizing scientific output and conducting impact analyses. This tool is intended for internal use within the CDC's Office of Science."
Global (GIB) Initiative for Influenza Vaccine Equity (GIIVE): Ensuring Universal Access,"The Global Initiative for Influenza Vaccine Equity (GIIVE) aims to ensure universal access to influenza vaccines by conducting a literature review focused on vaccine inequity. The project utilizes large language models via APIs to analyze numerous abstracts, identifying marginalized groups at risk of low vaccine access, which will be further examined by epidemiologists. The output will include a list of relevant publications for in-depth review."
HIV Data Virtual Assistant,"The HIV Data Virtual Assistant is an AI solution designed to enhance the data retrieval and automation processes for HIV researchers by providing access to relevant datasets and generating code for analysis. It leverages retrieval augmented generation (RAG) to efficiently deliver information and facilitate the identification of datasets related to HIV, such as PrEP medication usage, while also generating code in languages like SAS, R, or Python for further analysis. This tool aims to streamline the research process, allowing scientists to focus on their inquiries and improving overall productivity in HIV-related research."
Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images,"The project aims to utilize machine learning technology to identify infrastructure that supports physical activity, such as sidewalks and bicycle lanes, through analysis of satellite and roadway images. This approach seeks to improve surveillance efficiency compared to traditional manual inspection methods, thereby enhancing data collection related to physical activity environments. The end goal is to provide accessible outputs like geocoded data tables and maps to better understand the effects of built environments on physical activity."
Immunization Information Systems Guidance Documentation Navigation and Management (IDAB EDAV Azure OpenAI Technology Use),"The Immunization Information Systems (IIS) Guidance Documentation Navigation and Management project utilizes a chatbot powered by AI to enhance the retrieval and updating of IIS guidance documentation. By leveraging natural language processing and content generation, it enables improved interactivity and discoverability of information related to HL7 electronic data exchange standards, clinical decision support, and operational best practices. This solution facilitates faster responses to inquiries, aids new employees in finding information, and supports the creation and validation of new guidance documents."
LaserAI,"The LaserAI project evaluates a software as a service systematic review project management tool that leverages machine learning and natural language processing to enhance the efficiency and accuracy of systematic reviews. It focuses on improving title and abstract screening, PDF retrieval, full text review, and data extraction, which will in turn inform evidence-based infection prevention and control recommendations for healthcare settings. This AI tool streamlines the systematic review process by identifying relevant articles, retrieving necessary documents, and suggesting key data for extraction."
NewsScape,"NewsScape is an AI-powered news aggregation and summarization tool designed to efficiently filter and summarize thousands of news articles daily, providing early warning indicators for public health events. It is integrated within the 1CDP platform and utilizes Large Language Models (LLMs) to deliver relevant insights tailored to the needs of various CDC program offices, thereby aiding in outbreak detection and monitoring of health-related news. The tool can be customized and deployed independently, allowing different program areas to maintain their own specialized versions of NewsScape."
RAPID Analysis of Policy and Program Documents (RAPID),"The RAPID analysis web application is designed to enhance efficiency in reviewing policy and program documents, ultimately saving time and reducing the need for specialized training. It offers clear, consistent answers to evaluation questions, minimizes variability in coding, and facilitates collaboration among CDC users by allowing them to import, search, and validate policy documents effectively. Additionally, it ensures secure storage and supports project teamwork in policy surveillance."
SewerScout: Automated on-site sewage facility detection from aerial imagery to identify failed systems,"SewerScout is an automated initiative designed to identify onsite wastewater systems using aerial imagery, focusing on recognizing failed sewage facilities that pose risks to soil and drinking water quality. By employing advanced object detection and image classification models, this project aims to assist state, tribal, local, and territorial health jurisdictions in assessing septic systems without the need for extensive on-site inspections. If successful, the project will enhance public health efforts by enabling efficient identification and management of failing systems, improving disaster response strategies through the utilization of satellite imaging."
Sidekick Comms bot Offering User-friendly Tips (SCOUT),"The SCOUT project aims to streamline content creation for CDC.GOV by utilizing Generative AI to simplify the process of developing new webpages and social media posts. This initiative seeks to enhance the accessibility and understanding of public health information for a broader audience while ensuring that all AI-generated content is thoroughly reviewed by experts for accuracy and quality. Ultimately, the project promotes the use of clear language and efficient communication in public health messaging."
Transcribing Cognitive Interviews with Whisper,"The project focuses on using AI, specifically Whisper, to transcribe cognitive interviews conducted in Federal Health Survey Research, a qualitative method to understand interviewees' perceptions of survey concepts. By automating transcription, researchers can significantly reduce the time required for qualitative analysis, thereby enhancing the efficiency of research publication and the quality of survey questions. This technology provides immediate access to important insights through easily accessible transcripts, streamlining the review process for researchers."
Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking,"The project employs Natural Language Processing and topic modeling to streamline the review of public comments on Notices of Proposed Rulemaking. By clustering similar comments, the methodology enhances the organization and insights gained from the reviews, making the manual process more efficient while complying with legal requirements. Utilizing open-source tools, this approach reduces the burden of labor-intensive reviews and ensures accurate reporting of public opinions."
Center for Forecasting and Outbreak Analytics Disease Modeling,"The Center for Forecasting and Outbreak Analytics develops models to predict the behavior of disease outbreaks and assess the impact of various response strategies, including vaccinations. By utilizing mathematical modeling and analyzing diverse data sources, the project provides crucial insights that inform Federal and State, Tribal, Local, and Territorial health decision makers in effectively directing resources and implementing measures during public health emergencies. This initiative ultimately aims to enhance the preparedness and efficacy of disease response efforts."
ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Data Analysis),"The ChatCDC project is a pilot program for an advanced AI chatbot that enhances the existing GenAI model by incorporating enterprise data to facilitate data analysis. It utilizes retrieval augmented generation (RAG) to extract key information from various document formats, enabling users to access critical insights efficiently while providing citations for accuracy verification. This technology primarily assists teams in streamlining literature reviews and improving data retrieval processes, ultimately leading to more accurate analysis and informed decision-making."
ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Summarization),"The ChatCDC is an enterprise-specific AI chatbot designed to enhance the GenAI system by allowing access to internal data for a select group of pilot testers as of November 5, 2024. Utilizing retrieval augmented generation (RAG), it summarizes enterprise documentation, such as documents and spreadsheets, enabling staff to easily access information for decision-making and onboarding processes. Each response includes citations for accuracy validation, improving the efficiency of information retrieval within the organization."
Leveraging AI for Metadata Tagging for Enterprise Data Catalog of CDC,"The project aims to enhance the CDC's Enterprise Data Catalog by utilizing AI for automated metadata tagging, addressing previous shortcomings in manual tagging that led to inconsistencies and gaps. By generating suggested metadata fields based on existing information, the initiative will improve the usability, relevance, and completeness of dataset descriptions, facilitating easier discovery and connectivity for CDC staff. This approach significantly reduces the time and effort required for manual metadata entry, thereby streamlining the data cataloging process."
Malaria parasites DNA barcode geography classification,"The project focuses on using genetic barcoding of malaria parasites to classify their geographic origins, aiding epidemiological investigations into domestically acquired malaria cases in the US. An algorithm is developed to analyze genetic sequences and assign the malaria genotype to specific geographic regions, enhancing the understanding of the strain's entry into the country. This methodology could potentially be adapted to analyze other pathogens if appropriate training datasets are available."
The School Closure Awareness System,"The School Closure Awareness System utilizes AI to efficiently identify unplanned school closures by analyzing publicly available Facebook posts from around 40,000 school or district accounts. This system, which categorizes closures related to various events and monitors status changes, has yielded significant cost savings of nearly 2 million dollars and reduced manual labor by 200 hours compared to previous methods. Regular data validation ensures accuracy and relevancy in capturing closure information."
Using Generative AI for Stance Analysis of Public Comments on CDCs Proposed Rules,"The project aims to enhance the review process of public comments on CDC's proposed rules by utilizing Generative AI for stance analysis, which streamlines the labor-intensive task through topic modeling and sentiment analysis. By employing open-source LLM-based tools, manual reviewers can efficiently categorize and analyze public feedback, making it easier to derive insights and report findings. This approach not only improves the speed and accuracy of the review process but also ensures adaptability for future regulatory analyses."
A reusable NLP pipeline for clinical narratives preprocessing and characterization,"This project aims to develop a reusable NLP pipeline for preprocessing and characterizing clinical narratives from health records. By cleaning and structuring data marked in various formats and utilizing pre-trained Named Entity Recognition (NER) models, the pipeline will facilitate the identification of signs and symptoms in electronic health records. The end goal is to enhance the extraction of insights from unstructured data, improving efficiency and consistency in analyzing clinical information."
Autocoding to Support Adverse Drug Event Surveillance,"The project involves developing a model to assist CDC surveillance epidemiologists in evaluating reported adverse drug events from the National Electronic Injury Surveillance System. This model will expedite the coding of drug event reports, enabling quicker production of prevalence estimates for the surveillance system, and will analyze de-identified free-text descriptions of patient encounters to output the likelihood of meeting surveillance criteria."
Automating LIMS Bioinformatics Workflow Configuration and Enhancing Lab Quality Management with AI,"The proposed tool will enhance laboratory bioinformatics workflow configuration in the Core Laboratory's Genomics Sequencing Lab by automating the creation and customization of workflows in Clarity LIMS. Utilizing a Retrieval-Augmented Generation framework, it will expedite the conversion of natural language lab protocols into XML workflows, while also serving as an interactive knowledge base for quality management and regulatory documentation. This innovation aims to improve efficiency in handling Next Generation Sequencing samples and facilitate training for laboratory personnel."
DGMH AI Chatbot,"The DGMH AI Chatbot will assist staff by generating initial draft responses to inquiries based on information from CDC's website, streamlining the response process and allowing for quicker turnaround times. By using Retrieval-Augmentation Generation (RAG), the chatbot will provide consistent and relevant answers that can be edited for clarity before being sent out. This project aims to enhance efficiency and free up staff to focus on higher-priority tasks while maintaining the integrity of the information provided."
Distiller SR: AI to screen research articles for Community Guide reviews,"Distiller SR is an AI-powered tool designed to screen research articles for reviews by the Community Preventive Services Task Force, which provides independent guidelines on public health. By employing machine learning, the tool aims to enhance the efficiency of systematic reviews, potentially accelerating the evaluation process for public health program effectiveness and subsequent recommendations."
Evaluating Generative AI for polio containment.,"The project focuses on evaluating Generative AI tools to enhance polio containment by improving data extraction from scientific publications, thereby identifying poliovirus in areas previously considered polio-free. Additionally, the AI assistant aims to assist HIV researchers by providing efficient data retrieval and generating analytical code, streamlining their research processes. This initiative will broaden the Polio and Picornavirus Branchs surveillance capabilities and potentially support CDCs polio containment efforts."
Respiratory Virus Response (RVR) Data Analysis Concept,"The Respiratory Virus Response (RVR) Data Analysis Concept aims to enhance the efficiency of knowledge dissemination during public health responses by utilizing AI to summarize subject matter expert (SME) interpretations. This project will facilitate quicker review and clearance of key takeaways for public communication, while also addressing the limitations and uncertainties associated with AI methods. The approach will involve generating summaries from SME-provided information through the ChatGPT interface, with an emphasis on refining prompts for improved output in future iterations."
School LLM initial abstract review process ,"The project utilizes a large language model (LLM) to streamline the process of reviewing and categorizing research related to school readiness science, specifically concerning school closures. By extracting data from abstracts and organizing it into a user-friendly dashboard, the AI significantly reduces the time and effort required for human review. Future goals include transforming this static tool into a dynamic resource for continuous article abstraction across various settings and populations if funding permits."
ChatCDC - CDC Enterprise Generative AI Chatbot (Content Editing),"ChatCDC is an internal generative AI chatbot designed to assist CDC staff with content editing tasks, such as refining emails, reviewing documents, and correcting formatting errors. By leveraging Azure OpenAI's capabilities, the chatbot provides recommendations for text improvements while ensuring no data security risks arise from uploads. The tool aims to enhance productivity and communication quality among CDC employees, all while adhering to established accuracy and review protocols."
ChatCDC - CDC Enterprise Generative AI Chatbot (Data Extraction),"ChatCDC is a generative AI chatbot developed for CDC staff to efficiently extract key information from large documents, significantly reducing the time and effort required to find specific data. It operates under existing internal AI guidelines, allowing for tailored policies by individual CDC centers or offices to ensure safe usage. The chatbot utilizes Azure OpenAI large language models to generate relevant responses based on user inquiries, facilitating easier access to important action items and discussions."
ChatCDC - CDC Enterprise Generative AI Chatbot (Ideation),"ChatCDC is a generative AI chatbot designed for CDC staff to assist with idea development and overcome writer's block by generating responses to user queries. It leverages Azure OpenAI Large Language Models and offers a secure alternative to third-party chatbots, incorporating CDC-specific guidelines to ensure responsible AI use. The chatbot allows staff to organize their thoughts and actions efficiently while providing a platform for exploring and refining their ideas."
ChatCDC - CDC Enterprise Generative AI Chatbot (Software Development),"ChatCDC is a generative AI chatbot developed for CDC staff to assist in software development and coding tasks, enhancing productivity and efficiency across various roles such as data analysts, software engineers, and scientific researchers. The chatbot, powered by Azure OpenAI, provides coding guidance, serves as a learning tool for novice programmers, and helps streamline complex analytical tasks, ultimately improving agency operations and workflows. It operates within the framework of existing internal AI guidelines, ensuring safe and responsible usage."
ChatCDC - CDC Enterprise Generative AI Chatbot (Summarization),"ChatCDC is an internal generative AI chatbot designed for CDC staff to efficiently summarize and synthesize information from extensive documents like meeting transcripts and research articles. This tool allows users to create concise summaries while ensuring data security by avoiding uploads to third-party platforms. Utilizing Azure OpenAI Large Language Models, ChatCDC enhances productivity by providing quick, digestible content that staff can easily integrate into their workflows."
DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (AI Summarization),"DCIPHER (SEDRIC) is an AI-powered platform designed to enhance the investigation of foodborne disease outbreaks by streamlining data analysis for CDC epidemiologists. By utilizing a centralized data platform, SEDRIC enables faster access to essential information from grocery receipts and other records, significantly reducing the time required for data parsing and enhancing the ability to track common food item names. This improvement allows public health officials to respond more efficiently to outbreaks and informs decision-making through automated summarization of investigation data."
DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (Receipt Reading),"DCIPHER (SEDRIC) is an AI solution designed to enhance the investigation of foodborne disease outbreaks by streamlining data processing through the System for Enteric Disease Response, Investigation, and Coordination (SEDRIC). The platform allows CDC epidemiologists to efficiently extract structured data from grocery receipts, shopper card records, and free-text responses, facilitating faster identification of outbreak sources and improving collaboration among agencies. This AI system reduces manual data entry errors, saves time for investigators, and standardizes reporting across involved organizations."
DFWED Food Vehicle Investigation Module,"The DFWED Food Vehicle Investigation Module (FVIM) enhances foodborne outbreak investigations by utilizing NLP and text classification tools to identify potential food vehicles and generate hypotheses quickly. By analyzing historical outbreaks with similar demographics and temporal characteristics, FVIM streamlines the response efforts and reduces operational burdens in tracking foodborne illnesses. The module categorizes reported food exposures and compares them statistically to population survey data, improving the accuracy of outbreak identification."
Genetic distance computation method for comparing complex multi-locus parasite (Cyclospora) genotypes,"The project develops an AI-driven method for computing genetic distances among complex multi-locus genotypes of the parasite Cyclospora, facilitating the comparison of infections during epidemiological investigations of cyclosporiasis outbreaks. This method enables the clustering of large datasets, identifying closely related infections and supporting public health efforts in tracking and analyzing outbreaks. While primarily focused on Cyclospora, the approach has also been applied to other parasites like malaria and certain parasitic worms."
MedCoder - Coding literal text cause of death information reported on death certificates to ICD-10,"MedCoder is a subsystem of the CDC's National Vital Statistics System that automates the coding of causes of death on death certificates to ICD-10 codes. It has improved the coding accuracy from 70-75% to over 85%, resulting in significant cost savings and enhancing the timeliness of public health data. By employing natural language processing, MedCoder effectively standardizes cause of death statements, streamlining the coding process and aiding in the identification of urgent health trends."
NCIRD SmartFind ChatBots - Public and Internal ,"The NCIRD SmartFind ChatBots project focuses on managing internal email communications and developing a knowledge base for program staff's efficient use. It involves the creation of internal and public-facing conversational ChatBots, which analyze text questions and provide agency-approved answers. The project utilizes Microsoft tools and technologies to enhance information retrieval and communication with healthcare providers and partners."
NIOSH Industry and Occupation Computerized Coding System (NIOCCS),"The NIOSH Industry and Occupation Computerized Coding System (NIOCCS) automates the coding of industry and occupation text into standardized codes, enhancing speed, accuracy, and consistency. By leveraging machine learning models, it reduces the costs associated with manual coding, facilitating improved research and analysis capabilities."
Nowcasting Injury Trends ,"The Nowcasting Injury Trends project aims to predict current injury rates and provide real-time estimates of injuries and deaths through an internal dashboard. This initiative will enhance the understanding of injury trends, improve the speed of identifying and investigating emerging issues, and offer timely situational awareness for injury surveillance, even when standard data processing takes time. The dashboard will utilize a multi-stage machine learning pipeline to analyze various datasets and deliver weekly updates on national injury death trends."
Risk Assessment Module (RAM) for the National Diabetes Prevention Program (National DPP) Operations Center.,"The Risk Assessment Module (RAM) for the National Diabetes Prevention Program (National DPP) Operations Center is an AI-driven tool designed to evaluate and enhance the performance of organizations within the program. By analyzing large datasets, including participant enrollment and demographics, RAM identifies organizations at risk of underperformance, thereby assisting program managers in decision-making to improve participation and health outcomes. Future developments aim to extend access to RAM outputs for State Quality Specialist users outside the CDC, facilitating broader support for organizational success."
Semi-Automated Nonresponse Detection for Surveys (SANDS),"SANDS is a specialized large language model designed to assist with the review of open-ended survey responses by automatically detecting nonresponses, thus reducing the manual labor involved in data curation. By filtering out unproductive responses, SANDS enables researchers to efficiently compile high-quality datasets, improving both data quality and the design of survey questions. The model is available on HuggingFace and facilitates more streamlined examination of survey outputs through scoring and flagging mechanisms."
Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage,"The CDC's National Center for Health Statistics (NCHS) Data Linkage Program has integrated machine learning techniques, specifically the Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation, to enhance the accuracy and efficiency of their record linkage process. These methods reduce manual processing, automate the development of blocking groups, and enable the program to adaptively refine their algorithms based on new data. As a result, this advancement significantly improves the scalability and scientific value of linked health data for research on various health factors."
TowerScout: Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation,"TowerScout is an AI-based tool designed to automate the detection of cooling towers from aerial imagery to aid in investigating Legionnaires' Disease outbreaks. It significantly enhances the speed of identification, achieving detection approximately 600 times faster than manual methods, thereby allowing researchers to respond more efficiently during such public health crises. The system utilizes advanced object detection and image classification models to accurately locate cooling towers in aerial images."
Creation of synthetic Survey-like Insurance Names for use coding NHIS private insurance responses,"The project involves the creation of synthetic survey-like insurance names to improve the coding process of private insurance responses in the National Health Interview Survey (NHIS). By generating known acronyms and standardized names for various insurance plans, the initiative aims to significantly reduce the time spent on manual coding and error review, potentially saving over 100 hours of staff labor annually. This solution works alongside existing efforts to enhance manual coding with AI and Machine Learning, ultimately increasing overall efficiency and accuracy in reporting insurance coverage rates."
Development of in-silico genomic and patient datasets using generative ML algorithms,"The project involves the development of in-silico genomic and patient datasets using generative machine learning algorithms, which aims to streamline the process of finding reference genomes. By utilizing NLP generative AI tools, such as ChatGPT, the initiative seeks to reduce the development time and administrative burdens associated with creating custom tools and bioinformatic pipelines, while validating the generated code against established benchmarks for factors like data accuracy and licensing. Ultimately, this solution will facilitate testing of bioinformatic workflows and enhance the efficiency of genomic research."
Mastering Metadata: AI-Powered Governance for Data Insights,"The ""Mastering Metadata"" project aims to enhance data quality and governance on the data.cdc.gov platform by utilizing AI to automate the management of the CDC's National Center for Immunization and Respiratory Diseases data. This initiative will ensure that accurate, reliable, and timely public health data is readily available for researchers, policymakers, and the general public, thereby maximizing its impact across diverse audiences. Through automated tasks such as metadata validation and monitoring, the project seeks to significantly improve the magnitude and quality of datasets accessible via the platform."
PII detection using Private AI ,"The project focuses on implementing a PII detection system using the tool Private AI to identify and mask personally identifiable information (PII) within sensitive data sources at the CDC, such as electronic health records and survey responses. The goal is to automate the detection and redaction process to reduce the time needed for human review, thereby facilitating faster access to critical public health information. However, the contract for Private AI has expired and there are no current plans for renewal, complicating the projects continuity."
Reddit Post Analysis for Sexual Health Using Large Language Models,"The project utilizes large language models to analyze Reddit posts related to sexual health, aiming to understand users' online advice-seeking behavior. By automating data extraction and analysis, the initiative seeks to identify gaps in sexual health resources, highlight underserved populations, and track changes in sexual health behavior over time. This approach not only enhances public health insights but also reduces administrative burdens associated with traditional analysis methods."
Retrieval Augmented Generation (RAG) with Q-Bank,"The project focuses on enhancing the accessibility and visibility of CCQDER's Q-Bank research publications related to question evaluation for surveys through a Retrieval Augmented Generation (RAG) approach. By implementing an LLM-based search tool, it aims to streamline the process of finding relevant reports, alleviating administrative tasks like tagging and organizing. The initiative leverages the already publicly available and manageable size of the reports to create a prototype AI tool for improved research navigation."
Using generative AI to gain insight of older adult falls,"This project aims to enhance the extraction of insights related to older adult falls by employing generative AI, transitioning from traditional manual and rule-based methods. By analyzing medical narratives from Emergency Departments using the National Electronic Injury Surveillance System (NEISS) data, the solution seeks to provide a deeper understanding of fall circumstances, which can inform targeted public health interventions."
AI-assisted comment triaging tool,"The AI-assisted comment triaging tool streamlines the review process of public comments submitted for the annual Physician Fee Schedule rulemaking. By leveraging AI technology, the tool aids the PFS team in efficiently sorting and categorizing comments, including the identification of form letters, thereby reducing their workload."
Bankruptcy BOT,"The Bankruptcy BOT is a proactive system designed to identify bankruptcy cases that affect Medicare's debt recoupment efforts. It ensures timely identification of filed provider bankruptcies, enabling Medicare to secure recovery rights before the deadlines for filing claims expire. This initiative enhances the oversight capabilities of the Bankruptcy/Overpayment Division of IFM."
Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool,"The Central Data Abstraction Tool-Modernized (Modernized-CDAT) Intake Process Automation (PA) Tool automates and modernizes the medical record review functions in the MA RADV audit process using advanced technologies like NLP, OCR, AI, and ML. This tool eliminates the manual review of medical record submissions, expedites the intake process, and generates cost savings in both time and resources by replacing manual functions for steps 2 and 3 of the RADV audit process. The PA-BOT ensures that the MAO Medical Record submissions meet RADV audit intake requirements before moving on to MR abstraction and coding."
CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot),"The CMS Enterprise Portal Services project leverages an AI-powered chatbot to enhance process efficiency and knowledge management for users. By automating customer support and troubleshooting, it reduces the burden on help desks while providing valuable insights into user inquiries. The chatbot utilizes machine learning technology to accurately respond to user questions and streamline task processing."
Enhanced Direct Enrollment Outlier Detection,"The Enhanced Direct Enrollment Outlier Detection project aims to ensure the integrity of the Enhanced Direct Enrollment program by using machine learning to identify anomalies and quality issues in data submitted by partners. As partners gain more control over their application processes, this initiative focuses on maintaining a reliable interface between these partners and the FFE APIs. Overall, the project enhances data quality and safeguards the enrollment process."
Exchange Complaints Review Categorization  ML/AI ,"The Exchange Complaints Review Contractor (ECRC) employs machine learning and artificial intelligence to automate the categorization of consumer complaints received from the Federally-facilitated Exchange call center. By training the AI model on thousands of complaints, the process reduces the categorization time from approximately ten minutes per complaint to mere minutes, enabling faster routing to the appropriate CMS caseworker or Issuer for resolution. This innovation enhances efficiency in addressing consumer issues related to medical treatment access."
Feedback Analysis Solution (FAS),"The Feedback Analysis Solution (FAS) is a system that leverages Natural Language Processing (NLP) and machine learning (ML) tools to analyze public comments and stakeholder feedback from various sources, including CMS and Regulations.Gov. By aggregating and sorting data, FAS creates efficiencies in the review process while identifying key topics, themes, and sentiments that influence program and policy decisions. Different groups within CCSQ utilize FAS to process unstructured data, ensuring effective interpretation and structuring for further analysis."
IT System Utilization Optimization,"The IT System Utilization Optimization project aims to improve the FFE application's performance by automating resource scaling through Machine Learning. This will enable the system to adapt to varying usage patterns more efficiently, eliminating the need for manual scaling and ensuring immediate responsiveness to changes in system volume."
Knowledge Management Platform,"The Knowledge Management Platform enhances data-driven decision-making by efficiently accessing and utilizing both structured and unstructured data sources. It employs advanced technologies like natural language processing and knowledge graphs to simplify knowledge accessibility, ultimately supporting CMS's mission and improving return on investment."
Risk Adjustment Outlier Analysis,"The Risk Adjustment Outlier Analysis project aims to maintain the integrity of the Risk Adjustment (RA) program by utilizing Machine Learning to identify outliers in issuer data and behavior that could adversely affect risk adjustment payments. The project focuses on managing financial risk for issuers by ensuring that RA payments are accurately calculated based on population risk levels. By monitoring and analyzing data patterns, this initiative seeks to prevent undue influence on annual calculations."
Agent/Broker Fraud Analysis,"The Agent/Broker Fraud Analysis project aims to enhance the oversight and integrity of Marketplace applications and enrollments facilitated by Agents and Brokers by leveraging machine learning to detect suspicious behaviors. This initiative assists CCIIO in identifying potential fraud, allowing for referrals to the Consumer Protection Initiative (CPI). Ultimately, the project seeks to safeguard the consumer enrollment process in the Marketplace."
CCSQ ServiceNow AI Search,"CCSQ ServiceNow AI Search enhances the search capabilities within ServiceNow by replacing the traditional Zing search tool with a more versatile and relevant search function. It promotes self-service by allowing users to find information independently, potentially reducing the number of support cases. The AI Search includes features like result prioritization, synonym support, auto-corrections, and analytics to improve overall search experiences."
MSP Assignment Bot,"The MSP Assignment Bot automates the retrieval of records from a contractor's system and imports them into an internal OPOLE Access database for review by staff. This automation increases efficiency by allowing the bot to pull and assign cases from BCRC faster than human analysts, thereby maximizing the time available for staff to process cases and reducing response times. The Medicare Secondary Payer Operations Group (MSPOG) utilizes this bot for handling compromise cases within their Management Information System (MIS)."
"Relationships, Events, Contacts, and Outreach Network (RECON)","The Relationships, Events, Contacts, and Outreach Network (RECON) project utilizes AI for recommender systems and sentiment analysis, allowing for faster data analysis. Currently, it relies on native Salesforce AI capabilities, which are not being fully utilized within the RECON framework."
Complaint Analysis POC,"The Complaint Analysis POC utilizes data science techniques and a language model to analyze complaint data for the OPOLE team. This AI solution aims to identify key issues and root causes of complaints, enabling the team to address them more efficiently and effectively."
Data Lake/Load-Extract-Transform-Load (L-ETL),"CMS is modernizing its Load-Extract-Transform-Load (L-ETL) pipelines and data tools using a Security Data Lake, setting the foundation for future machine learning and AI applications. This initiative will enhance agency security by consolidating system, telemetry, and program data under a unified governance model, enabling better decision-making over time series data. The groundwork laid today is expected to facilitate machine learning model development in the next 1-2 years."
FOIA Document Review/Redaction Automation,"The FOIA Document Review/Redaction Automation project is a collaboration between OIT and OSORA aimed at streamlining the internal review and redaction process for CMS business documents subject to FOIA requests. By employing GenAI technology, the project automates the review and redaction tasks, significantly reducing the manual workload for FOIA staff."
Help Desk Responses,"The Division of Issuer Management and Operations is working with their contractor, LMI, to implement an AI tool for the Help Desk contract. This AI feature will streamline the process of generating responses to common questions from Qualified Health Plan (QHP) issuers and external entities, reducing the time staff contractors need for review and approval. The tool will leverage previously cleared material to enhance response efficiency."
508 Accessibility Automation for Documents,"The project focuses on automating the review and correction of 508 accessibility issues in documents for individual CMS employees. By leveraging GenAI technology, it significantly reduces the burden of ensuring compliance with 508 accessibility rules, streamlining the document correction process."
Brand vs Generic Market Share,"The project aims to analyze the market share trends between brand and generic drugs within the context of Medicare Part D to enhance financial forecasting accuracy. By examining the shift of beneficiaries from brand to generic medications, the Drug Data Processing System (DDPS) will provide insights to predict changes in related costs. Forecasting future market shares based on Part D claims volume will help optimize financial estimates."
Chat Client - Resource Library,"The Chat Client project aims to enhance user experience for the QPP community by refining the content in the Resource Library and improving accessibility to information through innovative technology. Utilizing Amazon Bedrock, the Chat Client will create a comprehensive knowledge base that enables efficient communication and multilingual support, allowing users to receive accurate responses to their inquiries based on available program documentation."
Chatbot within Hub,"The project aims to develop a chatbot within Hub to automate various help support activities currently managed by personnel, such as answering personalized FAQs, clarifying onboarding questions, and handling inquiries about file or request statuses. The chatbot will access an internal knowledge base, enable interaction with a live agent, and offer features like a chat and talk interface, along with the ability to query custom data sources. This initiative is designed to enhance support efficiency and improve communication with external partners."
Drug cost anomaly detection,"The Drug Cost Anomaly Detection project focuses on monitoring Prescription Drug Event (PDE) data to identify outliers and inaccuracies. It allows the CMS Division of Payment Reconciliation to correct these anomalies through outreach to Part D plans, ultimately preventing overpayments related to drug costs. The initiative enhances the integrity of Part D claims by highlighting and addressing discrepancies in drug pricing."
Drug Cost Increase Predictions,The Drug Data Processing System (DDPS) is developing a machine learning model to forecast changes in Medicare Part D costs by analyzing historical drug cost increases and current market conditions. This predictive system aims to enhance decision-making regarding drug pricing and budget forecasting for Medicare Part D.
Medicare Part C/D Marketing Material Review,"The project focuses on improving the review process of Medicare Part C/D marketing materials, which are currently time-consuming and resource-intensive for the Drug and Health Plan Operations (DHPO) staff. By integrating AI into the review process, the project aims to enhance efficiency and quality, while ensuring compliance with Medicare Marketing Guidelines and reducing marketing misrepresentation complaints. A proof of concept for the AI tool is still in development, with the goal of allowing the AI to learn the requirements for marketing materials effectively."
Medicare Part C/D Plan Oversight of AI Used for Prior Authorization and Utilization Management,"The project focuses on the oversight of AI applications used for prior authorization and utilization management within Medicare Part C and D plans to ensure beneficiary access to necessary services and prescriptions. It aims to leverage AI tools to analyze extensive datasets for compliance monitoring, program auditing, and protecting the integrity of the Medicare program. Additionally, it seeks to evaluate claims and payment data to identify potential biases and ensure compliance with CMS rules, ultimately safeguarding beneficiary health outcomes."
Negotiated Drug Predictions,"The project focuses on assisting in the negotiation of drug prices for select high-expenditure, single-source Medicare Part B or Part D drugs as authorized by the Inflation Reduction Act. It involves utilizing historical drug data to forecast costs and claim volumes for the drugs chosen for negotiation by the Secretary."
QPP Admin Bot,"The QPP Admin Bot enhances reporting and analysis by addressing the analytics needs in the QPP cycle, including providing feedback to providers and calculating scores. Utilizing Amazon Bedrock, it ensures easy access to data from QPP's Universal Data Set, empowering users to make informed decisions through a user-friendly communication platform."
Operational Efficiency Analytics,"The Operational Efficiency Analytics project by OHI/MAG aims to enhance the appeals adjudication process for Marketplace consumers by utilizing predictive analytics. This involves identifying operational trends, forecasting the volume of appeals during open enrollment, and analyzing regional or demographic trends related to appeal complexity and outcomes. The project includes training a predictive model using data from a forthcoming data lake within the Eligibility Appeals Case Management System (EACMS)."
ICPG Governance Tool,"The ICPG Governance Tool automates the processing and analysis of acquisition plans, classifying them as IT-related or non-IT. By streamlining manual validation and classification steps, it reduces the time and effort required for these tasks. This project aims to enhance efficiency in the business process of acquisition plan analysis."
Innovation Center Investment Proposal (ICIP) Model Analysis POC,"The Innovation Center Investment Proposal (ICIP) Model Analysis Proof of Concept (POC) focuses on enhancing the process of analyzing ICIP documents. By utilizing a RAG-based architecture, the project aims to extract relevant insights and recommendations, which will be presented through a user-friendly natural language interface for easier access and interaction."
OAGM Rate Card,"The OAGM Rate Card project aims to analyze historical price trends for labor categories in business proposals to improve decision-making on future contracts. By providing a standardized view of historical price data, it will help normalize labor categories and enable the OAGM team to identify relevant labor categories despite naming variations."
CCSQ Now Assist for CSM ,"CCSQ Now Assist for CSM is a ServiceNow product that integrates generative AI with Customer Service Management to enhance agent productivity and efficiency. It uses a ServiceNow native Large Language Model to provide features such as case and chat summarization and auto-generated resolution notes, enabling agents to respond faster and resolve cases more effectively."
AI Workspace,"The AI Workspace project facilitates AI experimentation by offering a safe and secure environment that reduces barriers and supports strategic AI infrastructure. It provides teams with hands-on experience to understand the risks and benefits of AI, utilizing data science tools and approved AWS services like Sage Maker and Bedrock for prototype development."
Citation Analysis and Survey Assistant (CASA - Nursing Home Survey CMS 2567),"The Citation Analysis and Survey Assistant (CASA) enhances the monitoring and review of nursing home surveys in the U.S. by utilizing advanced natural language processing and machine learning to analyze deficiencies reported on CMS Form 2567. This system enables real-time interaction with survey data, allowing the Quality, Safety, and Oversight Group to identify discrepancies and follow up on citation cases, ultimately supporting CMSs mission to maintain high standards of care in nursing homes."
Hazards & Threats Awareness Data Processing Automation,"The Hazards & Threats Awareness Data Processing Automation project aims to enhance the efficiency of situation report generation for EPRO by automating the processing of open web and email materials. The implementation of an AI system will reduce the manual processing time from 2-3 hours per day to approximately 30 minutes by scraping relevant websites, monitoring resource mailboxes, and summarizing significant events. This automation will facilitate faster delivery of actionable insights to decision-makers across the agency."
Independent Dispute Resolution (IDR) Eligibility Rules Engine,"The Independent Dispute Resolution (IDR) Eligibility Rules Engine project aims to automate the current manual and time-consuming IDR Technical Assistance process to enhance efficiency and throughput. By leveraging artificial intelligence, the tool will quickly identify essential data points within documentation, resulting in greater consistency in outcomes and a more predictable review timeline. This automation will streamline the eligibility review process and reduce reliance on manual operations."
Medicare Fee for Service Requirements Modernization (MFRM),"The Medicare Fee for Service Requirements Modernization (MFRM) project focuses on leveraging AI large language models (LLMs) to parse, curate, and simplify Medicare coverage and coding requirements by medical condition. Following extensive accuracy testing, the AI-generated information will be integrated into the MFRM application to improve operational efficiencies for CMS and healthcare providers by organizing guidance documents and identifying complexities. The project specifically utilizes Anthropics Claude 3.5 LLM to ensure the information is current and reliable."
Review Regulatory Comments,"The Division of Issuer Management and Operations is exploring the use of an AI tool by contractor AIR to analyze comments on the Letter to Issuers (LTI) and Notice of Benefits and Payment Parameters (NBPP). This implementation aims to streamline the review process, reducing the time and resources required by CCIIO and contracting staff by 25%, while also identifying trends in stakeholder responses related to CMS policy and operational issues."
Improved Data Quality Checks,"The project focuses on enhancing data quality checks to improve consumer experience by implementing an asynchronous feedback system that enables near real-time outreach, thereby reducing return cycle times without necessitating UI changes. Additionally, a proof-of-concept classifier model will be developed to identify incorrect document uploads and low-quality images using Optical Character Recognition (OCR) technology."
Plan Certification Recommendation Model,"The project aims to enhance the efficiency of the plan certification review process by employing natural language processing (NLP) and classification techniques to analyze trends in certification justification templates. A supervised machine learning model will be developed using historical data on justification and certification outcomes, providing recommendations to the Centers for Medicare & Medicaid Services (CMS) for improved review efficiency."
AI-Assisted Data Entry,The AI-Assisted Data Entry project aims to enhance the efficiency of data entry by utilizing AI technology to convert paper forms into digital datasets. This process reduces human error and streamlines the overall data intake workflow.
Transcription in Zoom and Teams,"The project focuses on providing transcription services for meetings held on Zoom and Teams, either live or from recorded sessions. This feature enhances communication by generating accurate transcribed text, facilitating better information accessibility and follow-up."
Email Prioritization in Outlook,The Email Prioritization project for Outlook in the Office365 suite enables users to categorize incoming emails according to their own criteria. This functionality assists users in managing their inbox more efficiently by providing categorized emails as the output.
AI-assisted Pattern Detection,The AI-assisted Pattern Detection project utilizes AI technologies to enhance existing log systems by identifying unusual patterns. This integration enables the detection of system log issues and facilitates the generation of alerts and reports for human intervention.
Report Summarization by commercial GenAI platform,Commercial GenAI platforms like ChatGPT and Google Gemini are capable of summarizing non-sensitive documents. They produce concise summaries based on the content of the provided paragraphs or documents.
Information Search from Google,Google's search engine utilizes AI-assisted techniques to efficiently process search queries. The result is a collection of relevant search results tailored to the user's request.
Document Digitization by AdobePro,"Adobe Pro specializes in converting scanned documents into digital formats, enabling enhanced accessibility and functionality. The resulting digital data is searchable, allowing for efficient information retrieval."
Autocorrect in MS Word,MS Word's autocorrect feature employs AI to enhance written communications by suggesting corrections. This results in improved accuracy and clarity in documents.
AI-Assisted Real-time Collaboration,"The AI-assisted real-time collaboration tool utilizes natural language processing to analyze inputs from team members and deliver real-time statistics and feedback. It generates summaries and statistical data based on the contributions of multiple users, enhancing collaborative efforts."
Presentation Design by MS PowerPoint,"The project focuses on enhancing presentation design using MS PowerPoint, which offers improved design suggestions tailored to the content. Users receive multiple visual design options to choose from, allowing for more engaging presentations."
Data modeling and visualization by MS Excel,"The project focuses on utilizing MS Excel's data analysis toolkits for data modeling and visualization. It leverages AI-powered features to enhance data understanding and presentation, ultimately producing machine learning models and statistical analyses along with visual representations of the data."
News from commercial publisher such as Google News,"Major news publishers like Google News curate news content tailored to users' preferences and browsing history. This results in more personalized news feeds for each user, enhancing their news consumption experience."
Travel Route Optimization by Google Maps and Apple Maps,"This project focuses on the optimization of travel routes using major commercial map services like Google Maps and Apple Maps. By leveraging algorithms and live traffic data, these services automate route selection to save time and provide optimal travel paths tailored to user preferences. The result is a more efficient and user-friendly navigation experience."
AI-Powered Travel Booking,"The AI-Powered Travel Booking project utilizes algorithms to enhance major travel booking platforms by providing personalized accommodation options based on customer preferences. This technology optimizes the selection process, saving time and offering better deals. Ultimately, it generates a curated list of travel accommodations for customers to choose from when making their booking decisions."
Facial Recognition Unlock,The Face ID feature in iPhones utilizes AI technology to securely unlock the device through facial recognition. This advanced security measure enhances user convenience by allowing access to the phone without requiring passwords or other authentication methods.
AI to Improve Public Access to the Administrative Appeals Process,"The project aims to implement an AI-driven chatbot on the DAB's website to enhance public access to the administrative appeals process by helping appellants identify the appropriate division for their appeals. This chatbot will provide immediate assistance and accurate information, particularly benefiting deaf and hard-of-hearing individuals and those with limited English proficiency. Ultimately, the initiative seeks to improve efficiency in adjudication, increase the DAB's productivity, and optimize resource allocation."
AI Use Policy Tool,The AI Use Policy Tool aims to enhance the integrity and efficiency of the Determinations and Appeals Board (DAB) by ensuring compliance with quality review standards and protecting sensitive information. It will facilitate quicker identification of data trends requiring further analysis while preventing the unauthorized use of generative AI in DAB decisions. This tool supports public confidence in the fairness and legality of DAB determinations.
Resources to Assist the Advisory Board In Identifying AI Tools for Use In An Adjudication Environment,"The project aims to support the Advisory Board in selecting AI tools suitable for the adjudication process, which involves comprehensive data analysis during docket management, case processing, decision issuance, and post-adjudication quality review. By leveraging AI and machine learning technologies, the Advisory Board intends to enhance efficiency and identify trends within the large volumes of data received from appellants and interested parties. Ultimately, this initiative seeks to improve the overall effectiveness of the adjudication environment."
356H ML Facility Supply Chain Role Classification,"The 356H ML Facility Supply Chain Role Classification project automates the extraction of supply chain roles from unstructured text submissions related to facilities. By improving the efficiency of evaluating these submissions, it reduces processing time and provides data stewards with a streamlined interface for verifying and determining the identified roles."
AI Tool for Risk-based FAR Review & Decision Support,"The AI Tool for Risk-based FAR Review & Decision Support enhances the Field Alert Report review process by delivering risk-based intelligence and insights, incorporating a Human-in-the-Loop approach. It streamlines reviews by summarizing risk profiles and utilizing machine learning to classify FAR risks into low, medium, and high categories, while highlighting problem clusters, rare events, and source variables."
Analytics-Driven Supplement Evaluation (ASE),"The Analytics-Driven Supplement Evaluation (ASE) project utilizes AI to enhance the triage and staff assignment process for reviewing post-market Change Being Effected (CBE) supplement submissions. By employing a Convolutional Neural Network alongside a rules-based approach, the AI system effectively summarizes submitted information to assist reviewers in making informed decisions on CBE 30/0 supplemental submissions."
Augmenting death and cause of death ascertainment in observational data sources,"The project aims to enhance the assessment of mortality in electronic health records by employing Natural Language Processing (NLP) techniques to extract and improve the quality of mortality data, including the date and cause of death. This augmentation supports research efforts within the Sentinel system to develop probabilistic estimates for causes of death, thereby enhancing the reliability of mortality as a study endpoint."
CLAT (Computerized Labeling Assessment Tool) ,"CLAT (Computerized Labeling Assessment Tool) employs computer programming, image processing, and AI to enhance the human review process of drug labeling by identifying potential deviations from FDA regulations and standards. The tool improves the efficiency and accuracy of labeling reviews by flagging errors such as missing barcodes and incorrect strength statements, ultimately helping to mitigate medication errors and standardize labeling practices. By facilitating a thorough visual comparison against established guidelines, CLAT supports reviewers in ensuring compliance and consistency across various drug types."
Empirical evaluation of EHR-based signal detection approaches,"The project focuses on enhancing Electronic Health Record (EHR) signal detection through Natural Language Processing (NLP) and advanced tree-based scan statistic (TBSS) methods. By extracting data from unstructured clinical notes, it aims to improve the identification of health outcomes and streamline the manual detection process."
FAR-based Facility Signal Detection Tool ,"The FAR-based Facility Signal Detection Tool objectively identifies problem clusters associated with flagged signals. This tool aids in the triage and review process, enabling further actions to be taken and, if necessary, opening up CMS inspection work activities."
MedWatch Dashboard ,"The MedWatch Dashboard project aims to enhance the monitoring and identification of product risks through the analysis of MedWatch reporting patterns. It utilizes time series analysis to flag potential product risks and topic modeling to summarize relevant comments, facilitating efficient and objective risk-based assessments for review staff."
Quality Surveillance Dashboard (QSD),"The Quality Surveillance Dashboard (QSD) analyzes unstructured text from documents and integrates it with existing data to create a comprehensive dashboard for assessing CDER regulated manufacturing facilities. It facilitates efficient, objective, and risk-based evaluations by identifying and presenting relevant keywords and phrases in context."
Scalable automated NLP-assisted chart abstraction and feature extraction tool,"This project focuses on developing a scalable automated tool for chart abstraction and feature extraction using natural language processing (NLP) to enhance the usability of electronic medical records in pharmacoepidemiology studies. Through a case study examining montelukast use among asthma patients and associated neuropsychiatric events, the project aims to implement a comprehensive approach for accurately identifying outcomes and covariates from unstructured EHR data. The tool will facilitate large-scale data analysis by leveraging advanced analytic methods to extract relevant health information efficiently."
Annual Report CMC,"The project aims to extract Chemistry, Manufacturing, and Controls (CMC) changes from unstructured annual report submissions to create a comprehensive repository for further analysis. The extracted data is visualized in a dashboard, facilitating downstream human analysis and supporting information extraction from unstructured documents."
Application-DMF Reference,"The project focuses on extracting references to Drug Master Files (DMFs) from marketing application submissions, both structured and unstructured. It involves parsing content from various forms such as the 356H form and eCTD modules to identify and present DMF references in a structured format for analysis. The extracted data, displayed on a dashboard, aims to create a comprehensive inventory of application to DMF references, assisting the Office of Pharmaceutical Quality (OPQ) in reviewing applications that previously lacked these references."
Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS) ,"The project develops an Artificial Intelligence-based deduplication algorithm to identify and eliminate duplicate reports in the FDA Adverse Event Reporting System (FAERS). It employs Natural Language Processing (NLP) to analyze unstructured data from case safety report narratives, extracting relevant clinical features for use in a probabilistic record linkage approach. This enhances the efficiency of processing the FAERS database and supports data mining analytics."
Development of automation tools and data warehouse to facilitate BE assessments,"The project focuses on developing automation tools and a data warehouse to streamline the bioequivalence assessment process for Abbreviated New Drug Application (ANDA) submissions. By reducing manual data entry efforts, the tools will prepare, format, and export pharmacokinetic data for analysis, enabling reviewers to efficiently conduct evaluations using pre-written SAS codes while generating draft documents alongside firm-submitted eCTD tables. This initiative aims to enhance data collection and information retrieval without impacting the reviewer's evaluative responsibilities."
DMF (Drug Master File) Facilites,"The DMF Facilities project focuses on extracting facility references and supply chain roles from Type II Drug Master File submissions, which may contain both structured and unstructured documents. The parsed data is organized into a structured format for analysis, helping OPQ identify discrepancies between facilities reported in marketing applications and those disclosed in DMFs. The end goal is to create a comprehensive inventory of facilities linked to DMF submissions and their corresponding applications, supported by a user-friendly dashboard for further analysis."
Four Part Harmony Identification,"The Four Part Harmony Identification project aims to enhance the accuracy of language in deficiency reports submitted by staff. By streamlining this process, the project will decrease verification time and alleviate staff workload, ensuring compliance with MDUFA requirements."
Information Visualization Platform (InfoViP) to Support Analysis of adverse event reports,"The Information Visualization Platform (InfoViP) enhances post-market surveillance by utilizing AI to prioritize and analyze adverse event reports. It employs Natural Language Processing (NLP) and Machine Learning (ML) algorithms to extract relevant data from unstructured narratives and integrate it with structured data, thereby improving the efficiency of preparing and analyzing such reports. This tool also facilitates case series analyses, data visualization, and classifications based on information quality."
LLM-Assisted VAERS Analyses,The project aims to enhance the efficiency of Vaccine Adverse Events Reporting System (VAERS) analyses by utilizing a large language model (LLM) to generate customized query outputs. It focuses on building the capacity to enable reviewers to perform ad-hoc VAERS queries effectively.
Pharmacovigilance machine learning to detect excess safety signal,"The project utilizes machine learning algorithms to enhance pharmacovigilance by detecting excess safety signals in post-market adverse event reporting. The technology aids the FDA in identifying rare adverse events that manual reviews might overlook, generating potential safety signals for further investigation through statistical analysis."
Module 3 Facilties,"The objective of Module 3 Facilities was to identify and extract information about drug manufacturing facilities from unstructured data in marketing application submissions. This process aimed to create a comprehensive inventory of drug facilities, with the extracted data visualized in a dashboard for further human analysis. The project facilitates information extraction from unstructured documents."
OPPQ Policy Bot (AKA Policy and Guidance Documents Search) ,"The OPPQ Policy Bot is an AI-enabled tool designed to assist policy staff in efficiently searching for and identifying relevant regulations and policy documents. It enables users to quickly access previously published materials, ensuring consistency in policy development and responses to inquiries by providing direct links to the documents for further human review."
Packaging Materials and Suppliers,"The project focuses on extracting data from unstructured sources to create an inventory of drug packaging materials and their suppliers, aiding staff in drug supply chain analysis. The gathered information will be displayed on a dashboard for further analysis. This initiative enhances the efficiency of information extraction from unstructured documents."
Process Large Amount of Submitted Docket Comments,"The project involves the development of an AI/ML tool within CBER/HIVE that streamlines the downloading and processing of large volumes of docket comments, thereby enhancing the efficiency and accuracy of regulatory reviews. Additionally, it generates customized outputs for VAERS queries to facilitate the work of reviewers."
Real World Data/Evidence ,"The project involves identifying unstructured submissions in the industry that contain Real World Data/Evidence (RWD/E) by analyzing parsed content for indicators of RWD/E. The extracted data is then visualized in a dashboard to facilitate human analysis, with a focus on tagging documents that contain relevant evidence and data. This process supports congressional reporting efforts."
Regulatory Starting Material ,The project involves extracting Regulatory Starting Materials (RSMs) and their suppliers from unstructured Module 3 industry submissions to develop an inventory that clarifies the upstream supply chain. The extracted data is then visualized in a dashboard for further downstream analysis. This initiative aids in the effective information extraction from unstructured documents.
Resource Capacity Planning,"The Resource Capacity Planning project aims to enhance the forecasting of expected workloads in the human drug review program to better align fee revenue with required resources. It analyzes submissions across major user fee programs to support fee-setting processes, ensuring adequate funding to efficiently manage the anticipated workload. This improvement will help the FDA effectively allocate resources needed for drug review activities."
Supply Chain Resilience Program,"The Supply Chain Resilience Program focuses on forecasting the demand for medical devices and supplies under various scenarios, such as natural disasters and public health emergencies. This initiative aids in preparing for critical device requirements by providing accurate demand predictions."
AI Audit Resolution Assistant,"The AI Audit Resolution Assistant (AIARA) aims to expedite the review and resolution of Single audits for HRSA, which have surged due to COVID-related funding. By leveraging generative AI and advanced technological capabilities, the project seeks to enhance the efficiency of auditors, increase the number of audits processed, and automate the creation of Management Decision Letters. The solution includes a vector database for audit documents and a chatbot to assist auditors with specific inquiries, ultimately reducing their cognitive workload."
Knowledge Navigator,"The Knowledge Navigator project aims to create an AI model that provides detailed answers to complex inquiries regarding the Application and Program Guidance (APG) documents for 10 loan repayment and scholarship programs. This initiative is designed to enhance the efficiency of loan repayment and scholarship analysts and call center agents by improving their ability to respond to public inquiries, potentially reducing call volume and the need for additional call center staff. A proof of concept Generative AI Large Language Model has already been implemented to support National Health Service Corps (NHSC) and Nurse Corps programs."
Policy Assistant,"The Policy Assistant (PA) is a Generative AI tool developed by HRSA to efficiently create first drafts of essential policy documents such as APGs, NOFOs, and budget documents. By utilizing large language models and advanced editing features, PA aims to streamline the drafting process, reduce time spent on document creation, and enhance the quality of the final outputs through critical analysis and refinement. The project incorporates cloud-based services and natural language generation technologies to improve the overall policy-making workflow."
Scholar Match,"Scholar Match (SM) is an AI-driven platform designed to streamline the candidate evaluation and placement process for NHSC and Nurse Corps scholars in underserved communities. By analyzing candidate profiles and regional health care needs, SM optimizes placements to enhance workforce distribution and candidate satisfaction. The project utilizes machine learning, recommendation systems, cloud-based platforms, and data analytics to achieve its goals."
Scholarship Insight,"Scholarship Insight is a project aimed at enhancing the evaluation process of scholarship essays for the NHSC and Nurse Corps programs by developing a Generative AI program to assist human reviewers. This AI will analyze previous essays and scoring rubrics to conduct an initial assessment, improving both fairness and efficiency in the application process. The system will provide detailed insights into essay strengths and weaknesses while ensuring that human graders adhere to appropriate scoring standards through a combination of advanced technologies."
Site Application Analysis,"The Site Application Analysis (SA) project aims to enhance the review process for NHSC, STAR, and Nurse Corps Site Applications by integrating AI and machine learning technologies. This initiative will streamline the evaluation of complex documents, enabling faster and more accurate reviews while freeing BHW Regional Analysts to concentrate on more strategic tasks. The implementation will utilize cloud-based services, recommendation systems, natural language understanding, and text analysis."
A Cluster-Based Machine Learning Approach for Evaluating Factors Associated with Plasma Neurodegenerative Biomarkers,"The project aimed to enhance the prediction of incident dementia by incorporating health-related risk factors alongside plasma biomarkers associated with neurodegeneration and inflammation. Utilizing data from the Age, Gene/Environment Susceptibility  Reykjavik Study, which spanned over 20 years and included around 450 health-related risk factors, the study sought to improve outcomes in a diverse population. However, this AI use case has been retired and is no longer in use."
AccessGUDID Data Validation,"The AccessGUDID Data Validation project utilizes an AI system designed to enhance data quality assurance for medical device metrics by detecting anomalies in both structured and unstructured data. By identifying issues such as inconsistent units of measurement and unusual device dimensions, the AI flags potential problems for human review without directly altering the data. This integration within the FDA's workflow aims to streamline the data validation process, reduce manual effort, and improve the integrity of the AccessGUDID database, ultimately fostering better decision-making and enhancing public health and safety regarding medical devices."
AI Solution for Image Duplication Detection,"The project focuses on developing an AI solution for detecting image duplications in microscopic images generated by NIA researchers. With each publication producing 100 to 200 TIFF files, the manual verification process currently in use is inefficient and error-prone, necessitating an automated system to enhance research quality and credibility. This AI solution aims to streamline the identification of duplicate images across multiple publications."
AI Solution for Research Funding Gap Analysis (RF-GAP),"The AI Solution for Research Funding Gap Analysis (RF-GAP) aims to identify and address funding and publication gaps in NIH-funded research by utilizing text-mining and AI techniques on data from various sources. This initiative will enable NIA leadership to make informed decisions and refine funding strategies, while program officers will leverage customized dashboards for efficient monitoring and management of research portfolios. Ultimately, the project seeks to improve the allocation of NIH funding, enhance data integration for a comprehensive view of research trends, and maximize operational efficiency across NIA."
AI/ML for Study Section Prediction in NICHD,"The AI/ML for Study Section Prediction project aims to classify NIH grant applications into appropriate Study Sections within the NICHD's Scientific Review Branch. Utilizing human-in-the-loop development, it allows for human evaluation and modification of model outputs, enhancing the accuracy and efficiency of grant application alignment. The project leverages data from the NIH IMPAC II system and aims to improve the review process, thereby furthering NIH's mission in scientific discovery and health advancement."
AI-enabled landscape analysis of New Approach Methodologies (NAMs) in biomedical research literature,"The project employs AI-enabled landscape analysis to evaluate New Approach Methodologies (NAMs) in biomedical research, aiding the NIH Common Fund's strategic planning for resource investment. By utilizing generative AI for literature searching and extraction, the study identifies trends, gaps, and opportunities related to NAMs, with methods applicable to other systematic literature reviews."
Applying for Grants Chat Bot,"The Applying for Grants Chat Bot is designed to assist prospective grantees by providing instant and comprehensive information about various grants, including eligibility, deadlines, and documentation requirements. It guides users through the application process, recommends grant writing resources, and helps track application status while addressing common questions. Overall, the chatbot simplifies and enhances the grant application experience, making it more efficient for users seeking funding."
Assessment of DTT/NTP research effectiveness,"The project involves the modification of the DEXTR automated extraction tool to identify citations related to the Division of Translational Toxicology (DTT) and the National Toxicology Program (NTP) in various published sources. This tool, which adheres to data privacy regulations and is certified with FEDRAMP, facilitates an evidence-based assessment of the impact and effectiveness of DTT and NTP research. Ultimately, the goal is to provide valuable insights for research prioritization by evaluating how this research has influenced publications."
Assisted Referral Tool,"The Assisted Referral Tool (ART) aids in the assignment of grant applications to appropriate scientific areas by recommending study sections based on the application's content. Users input their application text, and ART provides a list of relevant study sections categorized as ""Strong"" or ""Possible"" matches. The tool does not store user information and focuses solely on facilitating the user's application process."
Autism Spectrum Disorder (ASD) Classification Model for Children using Deep Neural Network,The Autism Spectrum Disorder (ASD) Classification Model for Children was a deep learning-based AI tool designed to improve the accuracy of ASD diagnosis in children around the age of 10 using hand tracking data from an Inertial Measurement Unit (IMU). It classified children as either exhibiting ASD or typical development based on their performance in cognitive and motor tasks. This AI use case has since been retired and is no longer in use.
Automated annotation of study data using knowledge organization systems,"The project focuses on automating the annotation of study data in environmental health research using knowledge organization systems. This automation aims to facilitate the systematic review processes and enhance the integration of extracted information with other structured datasets, thereby supporting predictive model development and improving analyses of chemical effects on biological systems."
Automated approaches for table extraction,"The Division of Translational Toxicology (DTT) at NIEHS is focused on enhancing public health through innovative data and knowledge development. The project aims to create automated, model-based processes for extracting data from published tables, thereby saving time and effort for teams involved in evaluating studies, such as epidemiology reviews and hazard assessments, ultimately improving health effect conclusions."
Automated Basic-Applied Categorization of extramural grants,"The project involves the development of a machine-learning algorithm to categorize NIMH-funded extramural research projects as basic or applied research. The algorithm uses data from past grant applications and will suggest categorizations for new grants, which can be reviewed and edited by NIMH staff. The categorization will be used for internal analysis and annual reporting, without influencing funding decisions or utilizing personally identifiable information."
Automated extraction of study methods and assessment of reliability,"This project aims to automate the extraction of study methods and the assessment of their reliability in environmental health research. It utilizes supervised and unsupervised techniques to identify studies that meet established reliability criteria, facilitating a more efficient systematic review process. Ultimately, the project supports evidence-based conclusions and informs policy decisions by streamlining the evaluation of research quality."
Automation of Receipt & Referral Process of NIDDK grant applications,"The project focuses on automating the receipt and referral process for NIDDK grant applications, which currently involves a labor-intensive manual review of 100 to 500 applications each week. By implementing AI and Natural Language Processing tools, the automation aims to efficiently stratify applications according to specific business rules, significantly reducing the time required for program and referral staff by over 3000 hours annually. The system will provide real-time tracking and recommendations for program class codes, thereby enhancing the referral process."
Best Match: New relevance search for PubMed,"Best Match is a relevance search algorithm designed for NLM's PubMed, enhancing the search effectiveness for over 37 million biomedical literature citations. Utilizing advanced machine-learning technology and insights from user interactions, it offers improved retrieval performance compared to traditional date-sorted search methods, enabling users to find the most relevant and high-quality information efficiently. This algorithm significantly elevates the overall user experience on the PubMed platform."
Biomedical Citation Selector (BmCS),"The Biomedical Citation Selector (BmCS) project automates the selection of articles for the MEDLINE database, which is maintained by the National Library of Medicine (NLM). This automation standardizes the article selection process, significantly reducing the time required to process MEDLINE articles and improving the efficiency of indexing relevant information in biomedicine and life sciences. The end result is a collection of citation records that are curated for public access."
Chatbot for researchers to find data sets for environmental health research efforts,"This project aims to develop a chatbot that utilizes large language models to help researchers efficiently locate relevant data sets for environmental health research. It will source descriptions from NIH and federal data catalogs, producing periodically updated recommendations ranked by relevance. The tool is designed to enhance research efforts by streamlining the process of finding high-quality data sets."
Clinical Trial Predictor,"The Clinical Trial Predictor is an AI tool developed to assist NIGMS extramural officers in identifying grant applications that may contain clinical trials based on the analysis of their textual elements, such as titles and abstracts. Utilizing a combination of natural language processing (NLP) and machine learning (ML) algorithms, the tool highlights potentially relevant applications for further evaluation, but does not make decisions or serve as the primary basis for any evaluations. Its purpose is to enhance the efficiency of the review process regarding grant applications related to clinical trials."
ClinicalTrials.gov Protocol Registration and Results System Review Assistant,The ClinicalTrials.gov project seeks to assess the potential of AI to enhance the efficiency and effectiveness of reviewing clinical study records. It utilizes a classifier that analyzes free-text descriptions of study endpoints to identify and predict the presence of issues. The overall goal is to improve the quality and accessibility of information regarding clinical research studies.
Collections Summarization Chatbot,"The Collections Summarization Chatbot is an AI application designed to provide contextual answers and summaries regarding collection objects in the NLM Digital Collections. Using the Retrieval-Augmented Generation framework on AWS, the chatbot activates when users spend extended time on a resource page, offering them concise summaries based on the content and metadata of the collection objects. This initiative aims to enhance accessibility and user interaction within NLM's digital services."
Computed Author: author name disambiguation for PubMed,"The National Library of Medicine (NLM) developed a machine-learning method for author name disambiguation in PubMed, which contains over 37 million citations for biomedical literature. By scoring features to distinguish between papers with similar author names and using agglomerative clustering, the method effectively groups papers by the same authors. This tool, now integrated into PubMed, improves the accuracy of author name searches, addressing the common issue of name ambiguity that can result in irrelevant search results."
COVID-19 Pandemic Vulnerability Index Dashboard,"The COVID-19 Pandemic Vulnerability Index Dashboard generates risk profiles, known as PVI scorecards, for each U.S. county, providing continuously updated visualizations of disease risk based on various data inputs. Its primary goal is to assist in equitable resource allocation and decision-making to better support vulnerable populations during the pandemic. The dashboard features metrics such as current infection rates, population concentrations, and health and environmental vulnerabilities, and is accessible at https://covid19pvi.niehs.nih.gov/."
CSR Public Chatbot (CPC),"The CSR Public Chatbot (CPC) is designed to assist potential applicants and reviewers by providing direct answers to questions regarding NIH peer review policies and procedures. It sources information exclusively from official government web pages, includes links for verification, and includes a disclaimer urging users to confirm the accuracy of the provided information."
DAIT AIDS-Related Research Solution,"The DAIT AIDS-Related Research Solution (DAIT ARR) utilizes natural language processing to categorize and prioritize incoming HIV/AIDS grant applications, predicting their relevance and research areas. After grants are awarded, DAIT reviews the projects to identify those that are AIDS-related, enabling the NIH's Office of AIDS Research to provide additional funding where applicable. This systematic approach improves the efficiency of grant reviews and enhances the alignment of research funding with AIDS-related initiatives."
Detecting Overlapping Science (DOS),The Detecting Overlapping Science (DOS) tool identifies potential duplicate funding by analyzing grant applications submitted to the NIH. It provides real-time reports highlighting pairs of applications that may represent overlapping research funding. This tool aims to prevent the allocation of duplicate resources to similar projects.
Detection of Implementation Science focus within incoming grant applications,The project aims to streamline the grants management process by utilizing natural language processing and machine learning to evaluate incoming grant applications. It calculates an Implementation Science score to predict whether a proposal involves Implementation Science and assigns applications to the appropriate division for oversight and administration. This technology enhances the efficiency of grants management and ensures proper categorization of applications.
DEXTR - automated data extraction tool,"DEXTR is an automated data extraction tool designed to streamline the literature review process by efficiently extracting data from published studies. It utilizes natural language processing, regular expressions, and large language models to enhance accuracy and efficiency while reducing the manual burden of data extraction. The tool is continuously optimized to support various use cases, ultimately improving the speed and comprehensiveness of scientific data processing."
Division of International Services Customer Service Chatbot,"The Division of International Services has developed a customer service chatbot that provides accurate responses to general immigration policy questions for both foreign nationals and administrative officers. Utilizing a local database of frequently asked questions and relevant policy information, the chatbot aims to reduce the volume of manual inquiries to the division, enhancing efficiency and accuracy in information dissemination."
Enhance NLM Website Accessibility,"The NLM is pilot testing the use of artificial intelligence to enhance the accessibility of its website in compliance with Section 508 standards. The AI tool will identify and resolve accessibility errors, integrate with existing content management systems, and provide reports and suggestions for code fixes, ultimately aiming to improve user experience and mitigate risks related to non-compliance. This project expects to reduce costs and time for manual evaluations while increasing the quality of accessibility features on the site."
Enhancing Responses to Customer Questions about NLM Products,"NLM is developing an application utilizing OpenAI's GPT models to automatically respond to technical questions about its products, based on data from NIH/NLM web domains. This AI-driven tool aims to enhance customer service by providing accurate and timely responses, thereby improving efficiency and user satisfaction. The application will operate behind NIH's firewall and integrate with existing knowledge bases to deliver real-time answers without direct customer interaction."
Environmental health research annotation for model development,"The project focuses on creating annotated datasets to facilitate the development of AI and machine-learning models for environmental health research, specifically targeting toxicology. By addressing the lack of relevant training data and accommodating diverse study designs, the project aims to streamline literature assessments and improve efficiency in identifying critical data from published studies. The output will be an annotated corpus formatted to support model development."
Expansion of Generative AI (GenAI) Caption Generation for all Collections Videos,"The project aims to enhance the Generative AI (GenAI) captioning system for all videos in the NLM Digital Collections, standardizing and automating the captioning process. It utilizes existing video files and metadata, focusing solely on videos without pre-existing captions. The expansion is designed to reduce costs by minimizing reliance on third-party services while ensuring accuracy and consistency across the collections."
Federal IT Acquisition Reform Act (FITARA) Tool,"The Federal IT Acquisition Reform Act (FITARA) Tool, managed by NIAID, classifies contract statement of work (SOW) documents to determine their relevance to IT initiatives. This classification aids in clarifying and revising SOWs in accordance with FITARA requirements."
Generative AI (GenAI) Still Image Tagging,"The Generative AI project focuses on tagging still images in the NLM Digital Collections that currently lack descriptions using tools like AWS Rekognition and Bedrock. This initiative aims to enhance metadata generation for approximately 75,000 untagged images, thereby improving their searchability and accessibility for research and public health efforts. The AI-generated metadata will integrate with existing NLM systems to facilitate better management and retrieval of these digital resources."
Grant Application Subject-Matter Classification Tool,"The Grant Application Subject-Matter Classification Tool utilizes natural language processing to automatically classify grant applications based on the content of their abstracts, thereby improving the efficiency of the NIEHS grant administration process. It analyzes keywords to assign appropriate scientific categories and route applications to program officers with relevant expertise. The tool is trained on historical human-classified data and operates independently without integration with other datasets."
HIV-related grant classifier tool,"The HIV-related grant classifier tool is a front-end application designed for scientific staff to input grant information, which it then processes using an automated algorithm to classify HIV-related grants. Utilizing natural language processing, the tool assigns scientific topics and routes applications to the appropriate Program Officer based on the content of their abstracts. This system enhances the efficiency of the grant administration process by providing a predictive categorization, improving the allocation of applications to experts in relevant fields."
Improving Customer Response,"NLM is pilot testing an AI system to assist Customer Service Representatives in drafting responses to inquiries. The AI will generate draft responses based on customer inquiries and publicly accessible biomedical information, without making final decisions or communicating directly with customers. The project aims to improve response metrics, customer satisfaction, and the efficiency of the customer service department."
Improving Metadata Retrieval and Transformation for Metadata Management,"The project focuses on enhancing the efficiency and accuracy of metadata retrieval and transformation for the Dataset Catalog, which facilitates access to biomedical datasets. By developing an interface that automates the collection and formatting of metadata from external repositories through AI, the National Library of Medicine aims to streamline internal metadata management processes. The anticipated outcomes include resource savings, improved data quality, and better management of the Dataset Catalog, while maintaining human oversight for critical curation tasks."
Internal Referral Module ,"The Internal Referral Module for the NIH Extramural Research Program automates the assignment of grant applications to program officials, transitioning from a manual spreadsheet process to an efficient AI-driven system. By utilizing AI and natural language processing, it streamlines the referral process, improving the accuracy and speed of assigning applications to appropriate NIH Institute and Center Program Officers. The inputs consist of grant applications, while the outputs include referrals, program class codes, and organizational units within the NIH."
IT System Outage Alerts,"The project utilizes Generative AI to create and distribute maintenance and IT system outage alerts for NIDCD staff. This tool aims to streamline the communication process, reducing the time staff spend crafting email alerts by automatically providing details such as the affected system, building, day, and time of the outage."
JIT Automated Calculator (JAC),"The JIT Automated Calculator (JAC) is a tool developed to help NIGMS evaluate the total funding support of Principal Investigators (PIs) to ensure they are not financially over-resourced while applying for additional grants. By utilizing natural language processing (NLP), JAC analyzes Just-In-Time (JIT) Other Support forms, enabling accurate determination of outside funding received by PIs. This ensures NIGMS can make informed funding decisions based on the financial landscape of investigators."
Large Language Automation,"The Large Language Automation project aims to streamline various processes by automating tasks such as extracting Resource Sharing Plans from grant applications, generating summaries for published papers and internal documents, and creating training materials. It involves integrating Microsoft Azure AI with UiPath to enhance compliance assessment and automate templated emails using existing MS Excel worksheets. The project will ultimately improve efficiency and reduce manual workload in handling grant-related documentation and communications."
Leveraging User-Generated Content for Digital Behavioral Interventions,"The project aims to utilize AI-driven text classification technology to categorize smoking-related tweets into six specific categories, such as quitting strategies, while assessing their sentiment and the presence of sarcasm, irony, and emojis. By employing the BERT pre-trained language model and ChatGPT for classification, the project will analyze a large volume of publicly available tweets to identify effective messaging for smoking cessation interventions. The ultimate goal is to evaluate tweets that are positive and devoid of irony or sarcasm for their potential impact on target audiences."
LLM Support for Admin Services,"The LLM Support for Admin Services project seeks to integrate large language models (LLMs) into administrative operations to improve efficiency, accuracy, and productivity. By automating repetitive tasks such as data analysis and documentation drafting, the project aims to reduce the administrative workload and enable personnel to focus on strategic initiatives. Additionally, LLMs will enhance communication consistency and facilitate faster response times to inquiries, ultimately optimizing administrative workflows and organizational performance."
Mapping Sequence Data to Research Outcomes,"The project involves a proof-of-principle analysis aimed at mapping sequence records from NLM-managed repositories to relevant downstream research products. By examining sequence records and associated citations indexed in PubMed, the analysis seeks to inform operations and prioritize resources, resulting in text summaries that indicate the presence or absence of identified research products."
Medical Text Indexer-NeXt Generation (MTIX) MEDLINE Indexing,"The Medical Text Indexer-NeXt Generation (MTIX) is a machine learning-based system designed to automate the indexing of MEDLINE citation records using Medical Subject Headings (MeSH) terms. By implementing a multi-stage neural text ranking approach, MTIX enhances information retrieval in PubMed while addressing the challenges posed by the increasing volume of biomedical literature, thereby providing cost-effective and timely indexing solutions. The system takes PubMed citation data as input and outputs relevant MeSH terms for the articles."
MetaMap,"MetaMap is a program that connects biomedical text to concepts in the Unified Medical Language System Metathesaurus, utilizing natural language processing (NLP). It serves as a tool for mapping biomedical literature to relevant Metathesaurus concepts, facilitating access to comprehensive biomedical knowledge."
MicroStrategy Evaluation,"The MicroStrategy Evaluation project aims to assess software that delivers a business intelligence interface for Azure DevOps and OneStream systems. The software must feature robust development capabilities for creating manual reports and AI functionalities enabling end-users to independently generate reports, with inputs coming from financial data in OneStream and project management data in Azure DevOps. The expected output includes data-driven business intelligence dashboards."
MTIX,"MTIX is a machine learning system designed for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. It employs a multi-stage neural text ranking approach to achieve cost-effective and timely indexing, improving efficiency for the world's largest biomedical library."
NanCI: Connecting Scientists,"NanCI is a mobile application designed for biomedical scientists, facilitating the discovery of scientific papers, career networking, and event exploration. Utilizing machine learning algorithms, it matches users' interests to deliver personalized content and enhance their professional experience."
NBS Virtual Assistant,"The NBS Virtual Assistant is an AI-powered chatbot designed to enhance user engagement and provide personalized support for the NIH Business System (NBS), which is NIH's financial system. By streamlining service desk operations, the assistant effectively manages routine inquiries and offers self-service options, alleviating the workload on IT support."
"NCI-DOE Collaboration, MOSSAIC project (Modeling Outcomes using Surveillance Data and Scalable AI for Cancer)","The MOSSAIC project, a collaboration between the NCI and DOE, utilizes deep learning and natural language processing to analyze population-based cancer data from the SEER program, improving the efficiency and accuracy of cancer data collection. Through tools such as the pathology-coding API implemented in 22 SEER registries, MOSSAIC aims to provide near real-time cancer incidence reporting by automating the extraction of relevant data from unstructured clinical texts. This initiative addresses the challenges posed by manual data review, ultimately enhancing the understanding of cancer trends in the US."
NHLBI Chat,"NHLBI Chat is a secure tool that allows NHLBI staff to access the Azure OpenAI API for generative AI applications in their daily activities. The platform enables users to input text via a chat interface on a website, receiving text-based responses in return."
NIAID GenAI Toolkit,"The NIAID GenAI Toolkit consists of Azure-hosted applications designed to enhance employee efficiency through the use of large language models from the Azure OpenAI Service. These tools assist with various administrative tasks, including content generation, document summarization, and email drafting, by processing natural text inputs and generating relevant text outputs."
NIAMS AI Chatbot Pilot,"The NIAMS AI Chatbot Pilot aims to create a secure environment for NIAMS staff to enhance their research capabilities, assist with writing, generate scientific and IT code, summarize meeting minutes, and learn about AI applications in their workflows. This pilot will also evaluate the cost-effectiveness of developing an in-house chatbot compared to existing NIH Enterprise solutions like MS Copilot and OpenAI ChatGPT, and serve to establish a tiered business case for chatbot usage among staff. User interactions will generate text-based outputs, including summaries and recommendations, tailored to frequency of use."
NICHD RPAB AI/ML Application Referral System,"The NICHD RPAB AI/ML Application Referral System utilizes advanced AI/ML technologies to predict the appropriate extramural branch for new NICHD grant applications, enhancing efficiency and accuracy in the referral assignment process. It incorporates a human-in-the-loop framework, allowing for human oversight and adjustments to model outputs. The system aims to reduce the workload on Subject Matter Experts by streamlining internal referral processes without impacting existing NIH systems."
NLM-Chem: towards automatic chemical indexing in PubMed articles,"NLM-Chem is an automatic tool developed by the National Library of Medicine to enhance the process of chemical indexing in PubMed articles using advanced natural language processing and deep learning techniques. This initiative aims to streamline the time-consuming task of manually indexing chemicals in the MEDLINE database, thereby improving literature retrieval and information access in the biomedical field."
NLM-Gene: towards automatic gene indexing in PubMed articles,"NLM-Gene is an automatic tool developed by the National Library of Medicine to enhance the gene indexing process in PubMed articles, utilizing advanced natural language processing and deep learning methods. This initiative aims to streamline the labor-intensive manual indexing performed by expert indexers, ultimately improving literature retrieval and access to biomedical information in the MEDLINE database."
NLP Automated Referral,"The NLP Automated Referral project integrates natural language processing and machine learning into NIGMS's Internal Referral Module to streamline the assignment of research applications to program officers. By leveraging historical data, the system reduces referral delays and minimizes staff workload, allowing more focus on high-value tasks. The automated process analyzes application data to identify the three most relevant NIH institutions for each application, enhancing program officer efficiency and institutional knowledge retention."
OCIO GenAI Advisor,"The OCIO GenAI Advisor is a pilot productivity enhancement tool that utilizes Retrieval Augmented Generation (RAG) to answer questions based on user-provided data. It aims to streamline the information retrieval process and provide comprehensive responses to complex inquiries, particularly in areas like security and policy. The project also seeks to identify specific use cases while addressing data needs and security concerns."
OIT Help Desk Chatbot,"The OIT Help Desk Chatbot is a proof of concept tool designed to enhance productivity by answering questions related to publicly available help desk data and NIST policy documents through a Retrieval Augmented Generation (RAG) framework. This project aims to explore specific use cases, data requirements, and security and privacy issues while potentially reducing ticket resolution time and delivering detailed responses in natural language on complex topics."
Person-level disambiguation for PubMed authors and NIH grant applicants,"The NIH Office of Portfolio Analysis developed an AI-based solution for person-level disambiguation to accurately link researchers to their grants and outputs, such as articles and patents. This system processed 24.5 million unique papers from the PubMed database, matching them to 16 million unique author names using a novel neural network model to identify variant representations of the same individual. This high-quality disambiguation is essential for informing data-driven decision-making in biomedical research."
Portfolio Analysis Summarization Tool (PAST),"The Portfolio Analysis Summarization Tool (PAST) utilizes Power BI to create an interactive interface for program staff to effectively manage their grant portfolios. By leveraging AI-generated summaries of extensive grant narratives, including Titles, Abstracts, Specific Aims, and Research Strategies, PAST aims to simplify data navigation and enhance understanding, enabling staff to quickly grasp key information from grants data sourced from QVR."
Program Classification Coding,"A machine learning model has been created to assist NIA Division Staff in assigning Program Classification Codes (PCC) by providing the top three PCC suggestions for applications based on IMPAC II data. The model allows users to customize their data views by filtering results according to IC/OrgCode and Program Officer names. This solution streamlines the processing of applications during council rounds, enhancing efficiency in PCC assignment."
RCDC AI Validation Tool,"The RCDC AI Validation Tool is designed to enhance the accuracy and completeness of NIH's reporting on research funding across various categories. By utilizing this tool, the NIH aims to improve public transparency regarding its funded research through grants, contracts, and other funding mechanisms."
Remediate Adobe .pdf documents to be more accessible,"The project aims to enhance the accessibility of Adobe PDF documents by ensuring they conform to Section 508 accessibility standards. Manual remediation of these documents can be labor-intensive and requires specialized knowledge, so NLM is utilizing AI technology to streamline the process. The improved PDFs will provide better access for readers using assistive technology."
Research Performance Progress Report (RPPR) Report Comparison,"The National Institute on Aging (NIA) aims to streamline its grant application review process, which currently involves a time-consuming and error-prone manual comparison of grant documents. By utilizing grants data from the QVR, the project will enable the identification of duplications and overlaps in grants across different years, thereby improving efficiency and resource allocation. Each Program Officer manages a substantial number of grants, necessitating a more effective solution for oversight of approximately $4 billion in funding."
Scientific summaries tool,"The Scientific Summaries Tool is designed to assist the NIAID DIR team in generating justifications for personnel actions related to physicians, scientists, and veterinarians. By utilizing inputs such as scientific publications and prior justifications, the tool will facilitate the quick preparation of tailored justifications for investigators in specific research fields. The final output will be a comprehensive scientific summary that supports various personnel decisions."
Semantic group prediction in the UMLS Metathesaurus,"The project focuses on developing AI methodologies, specifically neural networks and heuristics, to predict the semantic groups of new terms for integration into the Unified Medical Language System (UMLS) Metathesaurus. This hybrid system aims to enhance the editing process and quality assurance of the Metathesaurus, significantly reducing the time required to implement new concepts while improving consistency. The system processes new concepts, represented as text phrases, to classify them into appropriate semantic groups."
Similarity-based Application and Investigator Matching (SAIM),"The Similarity-based Application and Investigator Matching (SAIM) system utilizes natural language processing (NLP) to identify non-NIH grants awarded to NIGMS Principal Investigators, helping NIGMS assess the total support received by these investigators. This tool is designed to ensure that funding is allocated to those who require additional resources, thereby preventing oversaturation of funding for already well-supported researchers."
SingleCite: Improving single citation search in PubMed,"SingleCite is an advanced search algorithm aimed at enhancing single citation searches in the PubMed database, which is managed by the National Library of Medicine (NLM). By predicting the likelihood of a retrieved document being relevant to a user's query, SingleCite significantly improves the effectiveness and success rate of locating specific documents in this extensive biomedical library."
SRDMS NLP COI,"The SRDMS NLP COI project developed a tool for the NIAID to identify potential conflicts of interest during the grant review process. Utilizing natural language processing methods, the tool assists the Scientific Review Program team in recognizing COIs between grant reviewers and applicants more efficiently. This enhances the integrity of the grant review process in extramural research program areas."
Stem Cell Auto Coder,"The Stem Cell Auto Coder automates the classification of Stem Cell Research subcategories, significantly reducing the time and effort involved in manual coding. Utilizing natural language processing (NLP) and machine learning (ML), it accurately predicts categories such as human embryonic, non-human embryonic, and various induced pluripotent stem cells. This innovation enhances the efficiency of NIGMS-funded research efforts."
Study Section Clustering Tool (SSCT),"The Study Section Clustering Tool (SSCT) organizes grant applications into groups of similar scientific fields, aiding in the formation of new study sections. It processes the text of grant applications and outputs recommendations for study section groupings, which are finalized by subject matter experts. This tool ensures that the grouping aligns with the current trends and developments in the field of science."
Synonymy prediction in the UMLS Metathesaurus,"The project focuses on developing AI approaches, specifically neural networks, to predict synonymy among biomedical concepts in the UMLS Metathesaurus, facilitating the integration of new concepts. This system aims to reduce the time required for adding new terms and improve consistency in the Metathesaurus. Preliminary results suggest that the performance of the AI system will adequately support the insertion of new concepts and enhance the overall editing process."
TB Case Browser Image Text Detection,"The TB Case Browser Image Text Detection tool utilizes AWS Recognition to identify and count instances of text in images as part of the NIAID TB Portals Program, which focuses on global tuberculosis data sharing and research. If the text detected potentially includes Personally Identifiable Information (PII) or Protected Health Information (PHI), the tool alerts the user, requiring them to confirm their intention to upload the image."
Tech Support Chatbot,"The Tech Support Chatbot is designed to serve the ORS/ORF community by offering an interactive customer service interface for inquiries about OIIT technology services and for OIIT staff to receive technical assistance while troubleshooting. By enhancing the efficiency of information delivery and addressing administrative questions, the AI improves support for both users and internal teams. The chatbot utilizes a local database for data input and provides responses in various formats, including text, images, and data."
Tool for PO Lookup Assignment (TPAL),"The Tool for PO Assignment Lookup (TPAL) automates the process of identifying appropriate Program Officers (POs) and NIH Institute and Center (IC) assignments for project proposals using natural language processing and machine learning. By analyzing the project description entered by users, TPAL predicts the top three relevant POs along with their corresponding Program Area Codes and NIH ICs, even when NIGMS is not the top-recommended IC. This tool facilitates efficient proposal assignment and provides decision support for NIH program staff."
Transformative Research Award Anonymization Check (TRAAC),"The Transformative Research Award Anonymization Check (TRAAC) is a tool designed to assess whether NIH grant applications for Transformative Research Awards are appropriately anonymized. It automatically screens application documents for identifying information in the Specific Aims and Research Strategy sections, highlighting potential exposure for review by experts. The tool enhances the efficiency of content screening, aiding NIH staff and the scientific community in ensuring applicant anonymity."
Machine learning pipeline for mining citations from full-text scientific articles,"The NIH Office of Portfolio Analysis has developed a machine learning pipeline that identifies freely accessible scientific articles by harvesting full-text PDFs and converting them to XML. It utilizes a Long Short-Term Memory (LSTM) recurrent neural network model to distinguish between reference text and other content, with the recognized citations subsequently processed through a Citation Resolution Service. This system enhances access to scientific literature without requiring institutional library subscriptions."
Machine learning system to predict translational progress in biomedical research,The project involves a machine learning system designed to predict translational progress in biomedical research by identifying research papers likely to be cited in future clinical trials or guidelines. This innovative approach enables real-time assessment of the impact of biomedical research based on early reactions from the scientific community. Further details can be found in the publication by Hutchins et al. 2019.
"Assessing developing possible version of ""HHSGPT"" for OIDP-specific internal use","The project involves developing a customized, internal version of ""Chat GPT""termed Ask ABE!for OIDP to enhance operational efficiency in HIV-related work. This AI-driven tool functions as a digital librarian, providing secure and equitable access to resources from HIV.gov, while addressing security, privacy, and risk management through a tailored infrastructure. The initiative aims to support OIDP staff in developing and revising content using a specialized dataset, including NIH HIV guidelines."
Informal generative AI research for OIDP's HIV.gov,"The informal generative AI research for OIDP's HIV.gov focuses on monitoring new AI tools and policies, as well as their impact on HIV-related content delivery. Conducted by an ORISE fellow in collaboration with the HIV.gov communications team, the findings are reviewed weekly to explore potential applications that could enhance outreach, such as synthesizing content into narrated videos. This initiative aims to inform and guide strategic planning for improved communication efforts."
Presenting/providing technical assistance on HIV.gov's cautious & transparent use of generative AI,"OIDP's HIV.gov provides technical assistance through workshops, one-on-one training, and limited labs focused on the cautious and transparent use of generative AI for creating communications content. These activities emphasize federal guidance and best practices, with AI-generated content clearly marked as ""Created by AI, Reviewed By Humans."" Over 500 individuals have been trained through these initiatives, enhancing understanding of both generative AI and related HIV programs."
Utilizing HHSGPT Pilot for writing/editing ,"The project involves a limited group of OIDP staff utilizing the HHSGPT Pilot, an internal generative AI tool, for various tasks such as editing, brainstorming, and drafting text. The tool has been specifically used to assess national strategies related to vaccination and viral hepatitis, with the goal of reducing labor burdens and documenting findings through Excel reports. Team members leverage HHSGPT to enhance their efficiency in tasks related to infectious diseases and HIV policies."
HHSGPT,"HHSGPT is an AI-powered chatbot integrated with Azure, designed to enhance productivity for data scientists and policy analysts within the HHS organization. It automates repetitive tasks, allowing human agents to concentrate on more complex activities while providing instant insights and assisting in the creation of policy documents. Currently, it is in the pilot phase across the entire HHS organization."
DECIDE,"The DECIDE project aims to streamline the review process of grantee organizations' progress in reducing health disparities for SAMHSA's Office of Behavioral Health Equity by developing an AI-based tool. This tool will automate the extraction and comparison of data from various sources, enhancing the accuracy of grantee reports and significantly reducing the administrative burden on staff. Ultimately, DECIDE will enable faster feedback to grantees regarding their demographic data reporting and progress towards health equity goals."
Document drafting and editing,"The document drafting and editing tool developed for SAMHSA employees aims to enhance productivity and improve the quality of internal and public-facing documents. By functioning as a writing assistant, it will help users structure their thoughts, create outlines, and proofread text, ultimately facilitating clearer and more effective communication. This tool operates similarly to a standard large language model chatbot, allowing employees to perform specific writing tasks efficiently."
Document summarization,"The document summarization tool is designed to help SAMHSA employees quickly ingest and summarize large volumes of information, improving efficiency in grantmaking and management. It allows users to upload documents for automatic summarization while incorporating enhanced data privacy measures to protect sensitive information. The tool will not utilize any SAMHSA-provided input as training data, ensuring confidentiality remains intact."
Smart Search,"The SAMHSA.gov team plans to implement ""Kendra"" to enhance the search functionality on store.samhsa.gov, addressing current limitations that hinder user access to behavioral health information. Kendra will improve search accuracy and speed by scanning all documents in the store, functioning within strict guidelines to protect sensitive data like Personally Identifiable Information (PII). This initiative aims to eliminate existing barriers and provide a more efficient resource for users seeking materials."
Counterparty Risk Anomaly Detection ,"Ginnie Mae utilizes machine learning algorithms, including clustering and genetic techniques, to analyze counterparty risk profiles of mortgage issuers in its program. This approach enhances the identification of data patterns, allowing Ginnie Mae to detect potential risk areas and focus subsequent analyses effectively."
Subledger Data Quality Machine Learning,"Ginnie Mae employs machine learning models to analyze Master Sub-Servicer transaction data monthly, significantly enhancing its capacity to detect inconsistencies and exceptions. This automation improves the efficiency and accuracy of reporting processes by identifying data anomalies in a large volume of transactions."
Automating Draft Counterparty Credit Narrative Reports,"Ginnie Mae automates the generation of draft counterparty credit narrative reports using Natural Language Generation (NLG) technology, which processes written analyses and financial data. This application improves efficiency and minimizes errors associated with manual reviews of mortgage issuers participating in Ginnie Maes program. The automation represents an essential initial step in the counterparty credit review process."
Voice of the Customer,"The Voice of the Customer application, developed by the Office of the Chief Financial Officer's Customer Experience Team, leverages advanced voice transcription and text analytics to analyze customer feedback from surveys, calls, and chats. This tool enables HUD to extract valuable insights to enhance program and service delivery, ultimately improving customer experiences. Additionally, a data analytics dashboard presents this information in clear metrics, such as customer satisfaction rates across various interaction topics."
Quantitative Text Analysis,"The project involves conducting quantitative text analysis to identify patterns in large volumes of text. It generates outputs such as charts and graphs that display the frequency of commonly appearing words, word clusters, and the overall sentiment of the text."
Translation of Digital Media,"OPA is utilizing Google Translate to enhance language access on HUD's public-facing websites by adding an ""Espaol"" button for Spanish translations and allowing users to select other languages. This free and uncustomized solution serves as a temporary measure while HUD works on a permanent solution aligned with its Language Access Plan per Executive Order 13166."
NextGen Advanced Methods: Air Traffic Control System Command Center (ATCSCC) Webinar Speech2Text and Analysis,"The NextGen Advanced Methods project focuses on leveraging innovative technologies like machine learning, artificial intelligence, and advanced data analytics to enhance the FAA's air traffic flow management. Specifically, it aims to convert live conversations from the Air Traffic Control System Command Center webinars into text using deep learning, followed by natural language processing for analysis and review of air traffic management content."
NextGen Data Analytics: Letters of Agreement,"The NextGen Data Analytics project aims to enhance the accessibility and standardization of Standard Operating Procedures (SOP) and Letters of Agreement (LOA) within air traffic control. By employing modern data analytics and machine learning, the project seeks to digitize and streamline these documents, making them readily available to stakeholders such as flight planners. This initiative will facilitate more efficient flight planning and support advancements in noise abatement procedures and time-based flow management in the National Airspace System (NAS)."
AEGIS: Autonomous Exploration for Gathering Increased Science,"AEGIS is an autonomous system designed for planetary rovers that enhances targeting and data collection through advanced computer vision. It identifies scientifically relevant targets in the environment and autonomously measures them using remote sensing instruments. Initially implemented in the MER Mission, AEGIS is currently utilized in the MSL Mission and is set to be deployed in the M2020 Mission."
ASPEN Mission Planner,"ASPEN Mission Planner is a modular application framework leveraging AI techniques to support diverse planning and scheduling tasks. It includes reusable components such as a modeling language, resource management, temporal reasoning, and a graphical interface. ASPEN has been utilized in various space missions, including the Modified Antarctic Mapping Mission and ESA's Rosetta Orbiter, to enhance science optimization from scientific sensors."
CLASP Coverage Planning & Scheduling,"The Compressed Large-scale Activity Scheduling and Planning (CLASP) project is a sophisticated long-range scheduler designed for optimizing the orientation and operational timings of pushbroom instruments in space-based and aerial missions. It enhances the scheduling process by maximizing the coverage of target points while managing memory and energy usage through advanced geometric computations using the SPICE ephemeris toolkit. CLASP supports mission planning across various projects, including the NISAR and ECOSTRESS missions, by enabling simulations that inform multiple aspects of mission design and expected scientific outcomes."
Enhanced AutoNav for Perseverance Rover on Mars,"The Enhanced AutoNav system for the Perseverance Rover autonomously plans safe navigation paths on Mars using advanced technologies, including tree search decision-making, Dijkstra algorithm for global path planning, stereo processing for 3D terrain reconstruction, and Approximate Clearance Evaluation (ACE) for safety checks. This system enables the rover to drive autonomously across the Martian landscape, ensuring safe and efficient exploration."
Mars2020 Rover (Perseverance),"The Mars2020 Rover, named Perseverance, is designed to enhance future rovers with onboard autonomy and advanced scheduling capabilities, including path planning, onboard science, image processing, terrain classification, fault diagnosis, and location estimation. The rover utilizes a non-backtracking scheduler that incrementally constructs feasible activity schedules while accounting for necessary maintenance and operational constraints. To improve the scheduler's robustness, a Copilot system employs Monte Carlo stochastic analysis to adjust scheduling parameters based on mission priorities."
MLNav (Machine Learning Navigation),"MLNav is a project that enhances the path planning capabilities of rovers by employing machine learning-based heuristics, while ensuring safety through traditional collision checking methods. It is integrated with the Mars 2020 mission's Enhanced AutoNav system and has been tested using real Martian terrain data in a simulator. The system utilizes a U-net architecture trained on simulation-generated terrain data to provide optimized path planning recommendations for the Mars 2020 Rover."
Perseverance Rover on Mars - Terrain Relative Navigation,"The Perseverance Rover utilizes Terrain Relative Navigation (TRN) through dual cameras and machine vision to enhance its path planning capabilities. This system employs convolutional neural networks, physics-based evaluations, and advanced techniques like random forests and Approximate Clearance Evaluation (ACE) to navigate the Martian terrain effectively. The TRN also contributed to the precision landing of the rover during its entry, descent, and landing on Mars, with plans for even more sophisticated artificial intelligence and machine learning methods for future missions."
SPOC (Soil Property and Object Classification),"SPOC (Soil Property and Object Classification) is a convolutional neural network that classifies terrain types from rover images to enhance driving safety. It is trained on labeled images gathered from various Mars rovers, with annotations provided by citizen scientists through the AI4Mars project. The system is deployed in MSL's ground operations and is being considered for onboard testing on the Mars 2020 rover."
Volcano SensorWeb,"The Volcano SensorWeb project employs a network of sensors interconnected via software and the internet to monitor and respond to volcanic activity and other environmental phenomena. Using a flexible, modular architecture, it enables automated satellite observations triggered by low-resolution sensors for improved data collection. The system is currently focused on monitoring the Earth's 50 most active volcanoes, as well as conducting experiments related to flooding, wildfires, and cryospheric events."
NASA OCIO STI Concept Tagging Service,The NASA OCIO STI Concept Tagging Service is an API designed to provide access to topic models generated from the Scientific & Technical Information concept training repository. It adheres to established API standards to facilitate the integration and utilization of these models. This service aims to enhance the accessibility of scientific and technical information through effective tagging.
Autonomous WAiting Room Evaluation (AWARE),"The Autonomous WAiting Room Evaluation (AWARE) project utilizes a security camera and YOLO Machine Learning model to monitor and count individuals waiting for service at Langley's Badge & Pass Office. When the number of people exceeds a set threshold, automated alerts via text and email are generated to request additional assistance at the service counters. The project aims to improve service efficiency by providing real-time data on customer counts in the waiting area."
Onboard Planner for Mars2020 Rover (Perseverance),"The Mars2020 onboard planner for the Perseverance rover constructs a feasible activity schedule in a priority-first manner, utilizing a non-backtracking approach that determines valid placement intervals while accounting for the rover's operational needs. To address potential brittleness from its non-backtracking nature, a Monte Carlo-based stochastic analysis is employed for setting meta parameters, such as activity priority and temporal constraints. Additionally, the project encompasses broader research and engineering initiatives aimed at enhancing onboard autonomy for future rovers through various applications, including path planning and terrain classification."
"SensorWeb: Volcano, Flood, Wildfire, and others.","The SensorWeb Project utilizes a network of sensors and satellite observations to create a flexible and modular system for monitoring natural disasters such as volcanoes, floods, and wildfires. By integrating low resolution, high coverage sensors with high resolution instruments, the project enhances global surveillance and response capabilities for environmental phenomena. This innovative approach facilitates customized monitoring and data collection, significantly improving temporal resolution and offering comprehensive insights into the Earth's most active geological and climatic events."
"Global, Seasonal Mars Frost Maps","The Global Seasonal Mars Frost Maps project generates comprehensive frost maps of Mars using five remote sensing datasets, processed through various data science techniques, including CNNs. These maps provide valuable insights into the seasonal distribution of frost on the Martian surface. The resulting frost maps are publicly accessible on the JMARS platform."
Purchase Card Management System (PCMS),The Purchase Card Management System (PCMS) utilizes a machine learning model to evaluate purchases and determine if they should be classified as taggable assets or chemicals. It provides metadata tagging recommendations to streamline asset tracking and compliance.
New Technology and Software Reporting (NTR),"The New Technology and Software Reporting (NTR) application utilizes a machine learning model to classify reported new technologies into specific categories, such as Aerospace or Robotics. This automated categorization streamlines the reporting process and enhances the organization of technology classifications."
"ServiceNow GenAI ""Now Assist""","ServiceNow GenAI ""Now Assist"" is a FedRAMP High certified platform designed to enhance digital transformation in customer service. It automatically generates content such as responses and work notes, while offering intelligent recommendations to boost productivity and expedite delivery. Additionally, it features chatbots that comprehend human language to facilitate quick issue resolution."
Budget Area Topic Classification Tool,"The Budget Area Topic Classification Tool employs a pre-trained BERT model to categorize proposals into one of eight specified budget areas, utilizing a semi-supervised training method with previously tagged data. Following training, the model's performance is evaluated on a hold-out sample to ensure accuracy, generating a numerical vector of probabilities that indicates each proposal's likelihood of belonging to multiple categories. A cut-off value is applied to establish definitive classifications for the proposals."
AI voice over,"The project utilizes a commercially available AI voice-over system, Wellsaid, to generate temporary voice recordings that will eventually be replaced by real voice-overs. This approach enables the agency to bypass the design and development processes typically carried out by federal personnel or contractors, minimizing potential AI policy concerns."
Adobe Photoshop,"OLPA's Creative Services team will utilize Adobe Photoshop's AI-powered tools to enhance photo and graphic edits, focusing specifically on the retouching of portraits. This project aims to improve the quality and efficiency of visual media creation through advanced technology."
Resubmit Checker ,"The Resubmit Checker analyzes a list of proposal IDs and identifies similar past proposals submitted to NSF, scoring them based on similarity. This tool assists in decision-making regarding the resubmission process by evaluating proposal revisions, ensuring continuity in merit reviews, and analyzing resubmit trends."
AWS Assisted Software Development,"The AWS Assisted Software Development project aims to enhance developer productivity and code quality by integrating AI-driven tools, such as AWS CodeWhisperer, Amazon Q, and Bedrock, into DIS Developers' IDEs, Jenkins automation, and Bitbucket. This pilot serves as a foundation for implementing Secure AI Assisted Development at NSF."
Mine Potential Reviewer's Area of Expertise,"The project utilizes Airtable, a low-code platform that integrates Open AI services, to evaluate its AI capabilities in matching potential reviewers to relevant areas of expertise. Data security is ensured, as Airtable's services are private and have been certified secure by the NSF OCIO Security Team. TIP has received approval to implement Airtable for various use cases, including this trial."
Finding the State,"TIP utilizes Airtable for managing project-related tasks, including the recruitment and organization of reviewer volunteers. The platform's database includes only public PII, such as names and professional details. Additionally, Airtable AI is employed to analyze potential reviewers' LinkedIn profiles for expertise updates and to search the existing potential submitters database for institutional state information."
Enhancing TIP Awards: Efficient Tagging for the 10 Key Technology Areas (KTA),"The project focuses on improving the tagging process for TIP Awards to align with the 10 Key Technology Areas (KTA) mandated by the CHIPS and Science Act. This enhancement aims to provide better insights into TIP's investment portfolio, ensuring efficient categorization and tracking of awards within these critical technology domains."
Data Access Alternatives: Artificial Intelligence Supported Interfaces,"The project aims to develop and test AI-supported interfaces to enhance user experiences with federal statistical data. By creating an AI chatbot, users will be able to submit text queries and receive answers derived from public data provided by federal statistical agencies, improving upon current methods of obtaining information."
FOIA processing,"The project involves processing Freedom of Information Act (FOIA) requests, with an emphasis on selecting tools that can assist in sorting these requests efficiently. Currently, no specific tool has been chosen, and the team is in the exploratory phase to identify suitable options."
Alt text Generator for Images in NSF's Media Hub,"The Alt Text Generator project aims to integrate ChatGPT with NSFs Digital Asset Management system to automatically create alt text for images hosted on the platform. This initiative is designed to enhance accessibility in digital communication products, ensuring that users with assistive technology can effectively engage with the content on NSFs website."
Exploring the use of BERTopic Modeling for a portfolio analysis,"This project investigates the applicability of BERTopic modeling, a natural language processing technique, for portfolio analysis. The goal is to determine if this method can enhance insights and understanding within the context of evaluating investment portfolios."
Open-source topic identification for the Public Engagement with Science Initiative data analysis.,"The project involves using unsupervised natural language processing (NLP) techniques to identify topical themes in responses to the NSF public engagement questionnaire for the Public Engagement with Science Initiative. An AI system will be developed to create a clustering model that can analyze all responses, while RTI STEM education experts will manually align the research topics with NSF research programs when applicable."
Hand-written text extraction using Textract for the Public Engagement with Science Initiative,"The project utilizes AWS Textract as a character recognition tool to extract handwritten text from open-format questions related to science and engineering on postcards. This technology will also be used to capture demographic and optional data through checkboxes, effectively converting handwritten responses into machine-encoded text."
Ask NSF Initial Pilot,"The ""Ask NSF Initial Pilot"" project aims to evaluate the feasibility of developing a chatbot using an AI platform to quickly address general inquiries based on existing documents. This pilot will test the hypothesis of rapid chatbot creation and its effectiveness in providing information."
USA Class,"The USA Class project aims to develop an application that streamlines the creation of position descriptions (PDs) for managers and HR specialists, reducing the lengthy and complex process often associated with PD development. By using large language models and a curated library of PD content, the application will suggest draft duties and evaluation statements, which can be customized by users, ultimately decreasing the time to hire, improving the quality of PDs, and facilitating better workforce management in federal agencies. The project is expected to enhance recruitment efforts, lead to cost savings, and ensure that organizations are effectively structured to achieve their missions."
Copilot for Microsoft 365,"Copilot for Microsoft 365 is an AI-powered tool designed to enhance productivity and creativity within the Microsoft 365 suite. It utilizes large language models and integrates with user data to assist in summarizing content, drafting emails, analyzing data, and automating tasks, among other features. While it aids users by generating initial drafts and insights, the responsibility for validation and editing remains with the user."
Insight,"Insight is an AI-based decision support software designed for disability program adjudicators, enhancing decision quality and consistency by analyzing the free text of disability decisions and case data. It offers real-time alerts on potential quality issues and provides case-specific reference information through a web application, along with 43 Quality flags that highlight inconsistencies or non-compliance with policy. This technology aims to maximize efficiency and minimize human error in the adjudication process."
Intelligent Medical Language Analysis Generation (IMAGEN),"The Intelligent Medical Language Analysis Generation (IMAGEN) project utilizes AI to enhance the visualization and search capabilities of clinical content in medical records for employees. By providing document annotations that highlight key information such as patient encounters, tests, and relevant dates, IMAGEN improves the efficiency and accuracy of disability determinations and decisions. Additionally, the system identifies potential impairments and SSA Medical Listing Codes to aid in the assessment process."
Duplicate Identification Process,"The Duplicate Identification Process utilizes AI to identify, flag, and mark duplicate cases, streamlining the review process for hearings. This technology significantly reduces the time needed for case review by minimizing redundancy."
Handwriting Recognition of Forms; Intelligent Document Processing Platform - Forms Classification and Data Extraction ,"The project focuses on an intelligent document processing platform that utilizes AI to classify, identify, and extract data from structured and semi-structured forms with printed and handwritten fields. By automating this process, it aims to minimize clerical errors and decrease customer wait times. Extracted data is formatted in JSON for easy integration with downstream systems through APIs and other methods."
Modernized Development Worksheet (MDW),"The Modernized Development Worksheet (MDW) project utilizes AI to analyze data during case development, enhancing the categorization process. This improvement leads to reduced processing and customer wait times by efficiently labeling and organizing new or updated MDW requests."
Anomalous iClaim Predictive Model,The Anomalous iClaim Predictive Model utilizes AI to identify high-risk claims that require further review by Operations. It generates risk scores for recently submitted iClaims to facilitate the adjudication process.
Pre-Effectuation Review / Targeted Denial Review Models,"The Pre-Effectuation Review and Targeted Denial Review Models utilize AI to identify claims with a high likelihood of error, ensuring they are referred for further review. This approach effectively reduces the occurrence of incorrect benefits payments by assigning probability scores through an integrated mainframe process."
Representative Payee Misuse Model,"The Representative Payee Misuse Model utilizes AI to detect potential fraud by representative payees, effectively reducing instances of misuse. It generates numerical scores that indicate the likelihood of representative payee fraud, allowing for targeted reviews."
Continuing Disability Review Model,"The Continuing Disability Review Model utilizes AI to analyze disability cases and identify those with the highest potential for medical improvement. It generates numerical scores that categorize each case into low, medium, or high likelihood of improvement, thereby enhancing the accuracy of continuing disability reviews."
Social Security Income Redetermination Model,"The Social Security Income Redetermination Model uses AI to identify and prioritize cases of overpayment for review, focusing on those with the highest expected amounts. The system generates numerical scores for individuals based on the likelihood and extent of overpayment, enabling technicians to efficiently target cases."
Proactive Triage and Analysis of Hearings (PATH),The PATH project utilizes AI to identify and flag claims with a high likelihood of favorable outcomes for human adjudicators to review. It provides sorted case listings that prioritize claims based on their chances of success in on-the-record hearings. The goal is to streamline the adjudication process and enhance decision-making efficiency.
Quick Disability Determinations Model,"The Quick Disability Determinations Model is designed to streamline the screening of initial disability applications by identifying cases likely to receive favorable determinations and where medical evidence is readily available. It generates probability scores for each scoring service, including Allowance, Processing Time, and an overarching QDD Score, to prioritize and expedite case processing."
Mobile Wage Reporting (MOBWR) ,"Mobile Wage Reporting (MOBWR) leverages AI technology to swiftly extract text and data from scanned images of pay stubs or payroll documents. The system specifically identifies key information such as gross pay and pay dates, facilitating faster processing of wage reports."
SSA 800# Public Question & Answer Bot,"The SSA 800# Public Question & Answer Bot provides responses to callers' inquiries using approved FAQs from SSA.GOV, available in both English and Spanish. By addressing questions directly, the bot reduces wait times for callers needing agent assistance and delivers answers that mirror the language found on the SSA FAQs webpage."
Generative AI for Analytic Insights,"The project involves developing a generative AI model to analyze transcripts from the Social Security Administration's National 800 Number. This model will provide insights into caller intent, call resolution, and topics discussed, helping to identify policy and process pain points. Ultimately, the goal is to enhance customer service, reduce unnecessary calls, and decrease wait times."
PolicyNet Plain Language Search Engine,"The PolicyNet Plain Language Search Engine is designed to enhance information retrieval for Social Security Administration (SSA) staff by utilizing a learning to rank functionality that will be implemented in FY25. This system will rank search results based on user feedback in the form of thumbs up/thumbs down ratings, improving access to relevant policies, procedures, and instructions, thereby facilitating better customer service."
Speech to Text Video Transcription,The project involves creating transcripts from recorded audio of disability hearings through speech-to-text technology. This process aims to accurately convert spoken language into written form for documentation and accessibility purposes. The final output is a comprehensive transcript of the hearings.
Customer Insight Tool,"The Customer Insight Tool is a survey analysis platform that evaluates sentiment and categorization within feedback. Its features include machine translation for text conversion, sentiment analysis for classification into negative, positive, and neutral categories, and automated categorization of related terms. Additionally, it identifies explicit suggestions and mentions of customer effort from feedback text."
Benefit and Earnings Public Use File,The Benefit and Earnings Public Use File project creates high fidelity synthetic benefits and earnings data to support policy research and decision-making while ensuring participant privacy. This synthetic microdata file is designed for public use by policy researchers.
Therapy Chatbot - Text-Based Mental Health Support for SSA Employees,"The Therapy Chatbot is a text-based mental health support tool designed for SSA employees, providing accessible, AI-driven conversations on their personal devices. It generates synthetic text responses to engage users in therapeutic dialogue and support."
Agency Support Companion (ASC) chatbot,"The Agency Support Companion (ASC) chatbot utilizes a generative AI model to provide content creation, summarization, and research capabilities. It delivers responses to user inquiries while also generating management information reports for executives."
Intelligent generation of modernized code.,"The project involves the intelligent generation of modernized code by transforming legacy code into a new target language using advanced AI techniques such as cluster analysis, pattern matching, and programming language models. This approach ensures efficient data processing and yields structured, standardized code that is highly maintainable. The use of AI enhances the overall quality and adaptability of the generated code."
Data Governance Product (DGP) -  Data cataloging and predictive analysis of data assets. ,"The Data Governance Product (DGP) automates data cataloging and predictive analysis of data assets using a vendor-built AI engine. It employs Natural Language Processing (NLP) to enable non-technical users to contribute to rule creation and efficiently convert plain text into regular expressions, enhancing data asset analytics and search capabilities."
Product Service Code Automation ML Model,"The Product Service Code Automation ML Model was a proof-of-concept project designed to utilize machine learning to analyze unstructured procurement data and automatically identify commodity and service types. However, the project has been retired and is no longer active."
Tailored Integration Logistics Management System (ILMS) User Analytics,"The Tailored Integration Logistics Management System (ILMS) User Analytics project aimed to create customized user experiences and analytics by leveraging transactional data and planned transactions. It focused on extracting meaningful insights from actual user actions and clicks. However, the project was ultimately retired and is not in production."
Property and Procurement Analytics,The project aims to enhance analytics within the Integrated Logistics Management System (ILMS) by creating a machine learning model to identify patterns of potentially anomalous activity in property and procurement. This initiative will involve collecting and analyzing data related to such activities.
AI input in Translation,"The project focuses on enhancing translation workflows by integrating machine-based tools for initial outputs, which are then meticulously post-edited by professional human translators. This process ensures a high-quality final product, balancing efficiency with human expertise in language accuracy and nuance."
FOIA Web ML Document Indexer,"The FOIA Web ML Document Indexer is a project aimed at developing a machine learning algorithm that creates index metadata for documents in the Department's online FOIA Library. This initiative will enhance document classification and improve the accuracy of search results, featuring a series of prepopulated metadata entries."
BudgetChat AI Tool,"BudgetChat AI Tool aims to consolidate budget documents to enhance the ease of searching and summarizing financial information. This tool will streamline access and analysis of initiatives spanning multiple years and programs, with all summarized data being verified and reviewed by humans for accuracy."
Travel.state.gov (TSG) Content Refinement with AI Text Editor,"The project focuses on using an AI text editor to refine public-facing content on International Travel Safety & Security for Travel.state.gov. The aim is to enhance readability by simplifying the text, which will subsequently be reviewed and edited by human editors."
Predictive Analytics Platform,"The Predictive Analytics Platform is designed to support AI research and development by incorporating various Azure services such as Azure AI, Azure Machine Learning, and Azure Databricks. It will enable the modeling of multiple AI use cases and provide the necessary infrastructure for effective R&D in this domain. Individual AI use cases will be developed and integrated into the platform."
Consular Affairs Photo Quality Service (PQS) / FaceVACS,"The Consular Affairs Photo Quality Service (PQS) utilizes FaceVACS technology to automatically assess the quality of passport photos during the Online Passport Renewal process. This system provides instant feedback to applicants, prompting them to retake or upload new photos when necessary to ensure compliance with requirements. If an acceptable digital photo cannot be obtained, applicants may submit a physical photo through standard procedures, leading to improved outcomes for the renewal process."
Innovation and Transformation Measurement and Prediction,"The project focuses on measuring and predicting the impacts of changes in consular services on various outcomes, including efficiency and customer experiences, through machine learning and statistical modeling. By understanding these causal relationships, Consular Affairs aims to foresee the effects of service changes on customers and employees, ultimately leading to improved outcomes."
Evaluating Customer Feedback and Sentiments with AI,"The project focuses on utilizing Natural Language Processing (NLP) and Large Language Models (LLM) to analyze unstructured customer feedback data. It aims to extract actionable insights through sentiment analysis, categorization, and summarization, thereby informing customer improvement initiatives."
Translation of Consular Content using AI,The project focuses on using AI translation models to enhance the capacity of the Consular Affairs (CA) department to deliver website content in customers' preferred languages. It aims to ensure accurate and comprehensible translations while reducing the resources required for traditional translation methods.
Travel.State.Gov (TSG) Enhanced Search and Chatbot  ,"The Travel.State.Gov (TSG) project introduces a new chatbot and enhanced search functionality on the TSG website. This system processes existing FAQs and resources, offering predefined responses to users. The implementation aims to improve user outcomes when seeking information."
CodeGen - AI-assisted IT Application Development,"CodeGen is an AI-assisted application that integrates with Large Language Models (LLMs) to streamline IT application development. It offers a secure API suite that accelerates the processes of code generation, translation, analysis, optimization, and debugging for developers, ultimately leading to improved software development outcomes."
Violence Against Civilians Model,"The Violence Against Civilians Model is a machine learning tool designed to predict mass civilian killings worldwide by analyzing open-source political, social, and economic datasets. It generates quarterly and yearly forecasts of these incidents, providing critical insights for conflict prevention efforts."
Automated Damage Assessments,The Automated Damage Assessments project utilized AI and machine learning to analyze commercial satellite imagery for damage evaluation. It has since been retired.
Automated Burning Detection ,The Automated Burning Detection project involved daily scanning of moderate resolution commercial satellite imagery to identify anomalies through the near-infrared band. This project has since been retired.
Senturion Alpha,Senturion Alpha is a simulation tool designed to analyze political dynamics by mapping key decision makers according to their positions on an issue spectrum and identifying their influences. It estimates how the policy positions of competing interests will evolve over time based on stakeholder interactions. This model aids in understanding complex decision-making processes within various contexts.
Mass Mobilization Model,"The Mass Mobilization Model is a machine learning forecasting tool designed to predict mass mobilizations, such as protests and riots, using open-source political, social, and economic datasets from around the world. It provides yearly estimates for each country, helping to identify potential social unrest on a global scale."
Apptio,The Apptio project involved using the Working Capital Fund (IRM/WCF) to bill bureaus for consolidated services and develop cost models to assist them in budgeting for future fiscal years. Apptio's capabilities included extrapolating future values through various formulas. This project has now been retired.
DT Data Analytics and Assessment (DAA) AI Use Case ITCP data harvest,The DT Data Analytics and Assessment (DAA) project focuses on utilizing AI to analyze unstructured text from essential DT documents. The goal is to create structured data that indicates compliance with DT data governance and FAM-related policies. This initiative aims to enhance the organizations data management capabilities.
ServiceNow AI-Powered Virtual Agent (Chatbot),The ServiceNow AI-Powered Virtual Agent project aimed to integrate a chatbot into existing applications for improved user support and data access. The AI technology was sourced from ServiceNow's Platform as a Service (PaaS). This project has since been retired.
POA&M Orchestration,The POA&M Orchestration project aims to automate the opening and closing of Plan of Action and Milestones (POA&Ms) in response to log and vulnerability data from each Federal Information Security Modernization Act (FISMA) system. This orchestration will enhance efficiency and ensure timely updates to compliance documentation.
NLP for Foreign Assistance Appropriations Analysis,"This project utilizes Natural Language Processing (NLP) to enhance the analysis of Foreign Assistance Appropriations by automating the extraction of earmarks and directives from the annual appropriations bill. Previously, this extraction process was conducted manually, making it time-consuming and inefficient. The implementation of NLP streamlines data extraction, improving efficiency and accuracy."
ForeignAssistance.gov Processing for Mismatched Data,The project involved developing a custom Natural Language Processing (NLP) model to enhance data processing for ForeignAssistance.gov by identifying mismatched data. The model provides recommendations for tagging and highlights potential discrepancies in the information.
Creating Persistent Virtual Reality Personas for dynamic training,The EdTech Innovation Lab team is developing a system that integrates various AI tools to create persistent virtual reality personas for use in training exercises. These personas will be stored and allow for interaction during dynamic VR training scenarios. The goal is to enhance the training experience by providing consistent and engaging virtual characters.
FSI Enterprise Operations - Gaming and Simulations,"In FY 2024, the bureau initiated a pilot program focused on enhancing experiential learning using gaming and simulations. This program will utilize complex scenarios presented in multiple target languages to facilitate a more effective learning experience. The plan includes the development and implementation of these simulations."
FSI Continuous Learning Solutions,"FSI is implementing a continuous learning strategy focused on enhancing content generation, analytical tasks, and overall efficiency in content development. This initiative is part of an AI action plan approved by the Front Office, aimed at achieving improved outcomes in productivity."
Enhancing Training Effectiveness in FSILearn Using AI,"The project aims to enhance employee learning experiences in FSILearn by utilizing AI within the Cornerstone Learning Management System. The AI will analyze key data related to learning behaviors, such as course completions, quiz scores, and engagement levels, to create personalized learning paths for users. This approach is designed to improve overall training effectiveness."
J Reports Data Collection & Management Tool (DCT),"The J Reports Data Collection & Management Tool (DCT) is an AI-driven research assistant designed to enhance the quality and integrity of Congressional reports while minimizing the labor required for their generation. It automates tasks such as summarization, translation, and categorization of user-submitted content to create a searchable database, allowing users to easily upload and retrieve materials throughout the year. Additionally, the DCT employs optical character recognition (OCR) to digitize images and documents, facilitating efficient research management."
TIP Report Research Translation,"The TIP Report Translation AI system delivers informal, unofficial translations of materials associated with the annual Trafficking in Persons report, streamlining the research process for staff. Each translated document, whether in PDF or Microsoft Word format, contains a watermark indicating its unofficial status and requires human verification, review, and editing before final use. This tool allows researchers to concentrate on addressing critical report needs, such as identifying and resolving data gaps."
FOIA 360 AI Matching Tool,"The FOIA 360 AI Matching Tool is designed to enhance the Department of State's Freedom of Information Act (FOIA) process by identifying similar requests and documents to reduce duplication. Additionally, it analyzes current and new requests to identify patterns, ultimately improving response times for the public."
StateChat,StateChat is an enterprise chatbot developed by the Department that utilizes Generative AI technology. It provides textual responses in a chat interface to facilitate user interactions.
Crisis Campaign Cable Analytics,"The Crisis Campaign Cable Analytics project utilized optical character recognition and Natural Language Processing to analyze Department cables, aiming to identify gaps and trends in crisis training and enhance post-crisis preparedness. The project has since been retired."
NLP to pull key information from unstructured text,"The project utilizes natural language processing (NLP) to extract key information, such as country names and agreement dates, from unstructured text in PDF documents. It aims to create a dataset containing this crucial information to facilitate data analysis and retrieval."
ECA Program Management and Outreach - Summarization,The ECA Program Management and Outreach project involves utilizing approved Large Language Models to generate artifacts for leadership and visiting delegations based on accurate datasets. Draft summaries will be created and subsequently reviewed by human experts to ensure quality and relevance.
Storyzy,"Storyzy focuses on enhancing the accuracy of detecting synthetic content, which is computer-generated data that resembles real-world data. The project aims to improve the outcomes related to the identification and management of such content."
Optical Character Recognition - Text Extraction,"The Optical Character Recognition project involved extracting text from images by utilizing standard Python libraries, with websites serving as data sources. The project has since been retired."
Topic Modeling,"The project involved analyzing text through topic modeling, which clustered documents based on the frequency of word usage. It was applied to digital media articles and social media posts, utilizing Python libraries for implementation. This project has now been retired."
Forecasting,"The project involved using statistical models to forecast expected outcomes, specifically focusing on COVID case projections and the analysis of violent events linked to tweets. This initiative has since been retired."
Deepfake Detector,"The Deepfake Detector is a deep learning model designed to classify images of faces as either real or fake, identifying synthetically generated faces created by Generative Adversarial Networks. This project has been retired."
SentiBERTIQ,"SentiBERTIQ was a sentiment analysis project that utilized a fine-tuned multilingual BERT model to identify and extract subjective information from text. The model was trained on 2.2 million labeled tweets in English, Spanish, Arabic, and traditional Chinese. The project has since been retired."
TOPIQ,The TOPIQ project utilized Latent Dirichlet Allocation (LDA) to automatically categorize text documents into topics for analytical review. It extracted topics from documents and assigned probabilities indicating the likelihood of each document belonging to a specific topic. The project has since been retired.
Text Similarity,The Text Similarity project involved calculating cosine similarity scores to identify and group identical or nearly identical texts for analysts to review. The project has since been retired and is no longer active.
Image Clustering,"The Image Clustering project utilized a pretrained deep learning model to create image embeddings, followed by hierarchical clustering to group similar images. The project has been retired."
Louvain Community Detection,The Louvain Community Detection project focused on clustering nodes within a social network into communities based on similarities. This project has since been retired and is no longer active.
Fast Text Word Builder,"Fast Text Word Builder was an AI-based tool designed to identify similar terms and phrases derived from a root word, enhancing A&R's ability to construct effective search queries for data collection. The project has since been retired."
Digital Media Analytics Platform,The Digital Media Analytics Platform utilizes open-source neural machine translation models to convert global media articles and various foreign social media posts into English. It also includes trend analysis capabilities to identify and analyze emerging patterns in the translated content.
Geospatial Mapping of Historical Survey Data,"The project involved creating an interactive geospatial map using PowerBI, based on cleaned and collected historical survey data from Pollfish, which included all statistically significant results. The project has since been retired."
AI Tools to Enhance PD Workflows,"The project aims to enhance Public Diplomacy workflows by integrating AI tools, specifically ChatGPT licenses, in accordance with Department policy. The initiative seeks to streamline processes and improve efficiency within the department's operations."
LEO - Budget Office Inquiries,LEO is a project designed to address frequently asked questions related to budget inquiries. It provides clear and concise answers to common budgeting concerns. The goal is to streamline budget-related communications and enhance understanding among users.
Collections Chatbot,"The Collections Chatbot project developed a self-service FAQ chatbot for taxpayers, focusing on payments and financial relief topics, with additional topics in development for future incorporation. The chatbot utilizes a natural language processing (NLP) intent engine to classify user inquiries into specific intents, providing predetermined responses based on a set of trained models, ensuring accuracy and consistency. The system is designed to maintain reliability in controlled environments by only delivering responses tied to predefined topics, avoiding the generation of new or ad-hoc answers."
Systran Translation Software,"Systran Translation Software is a commercial product that offers language translation services using a neural network-based engine. Users, primarily IRS staff, can input documents in English or Non-English, which Systran translates into a target language without storing any documents. The software can be enhanced with domain-specific dictionaries and translation memories to improve accuracy, allowing users to review translations via a graphical user interface or export them."
Automated Underreporter (AUR) Voicebot,"The Automated Underreporter (AUR) Voicebot enhances taxpayer interaction by authenticating users through ""Shared Secrets"" and providing account-related information after authentication. It offers confirmations of responses, case statuses, and facilitates requests for additional response time when eligible. Additionally, the system can route inquiries to the appropriate service areas or escalate to live agents as needed."
Employee Resource Center (ERC) Chatbot,"The Employee Resource Center (ERC) Chatbot project provides IRS employees with self-service access to frequently asked questions about various administrative topics through a natural language processing (NLP) and AI-driven Intent Engine. This tool classifies user inquiries into predefined categories and delivers accurate, consistent responses based on predetermined content without generating new responses. It ensures precision in a controlled environment by only pulling answers from established topics."
Robotic Process Automation for Form 941-X Extraction,"The Robotic Process Automation project aims to intelligently extract data from scanned Form 941-X documents using Artificial Intelligence and Intelligent Document Processing. It enhances character recognition and involves human verification when confidence scores are low, ultimately increasing the speed, volume, and accuracy of data extraction while clearing backlogs. By automating this process, data transcribers can process forms more efficiently than manual methods."
Taxpayer Services Chatbot,"The Taxpayer Services Chatbot project developed a self-service tool that provides taxpayers with answers to FAQs about refunds and the Advanced Child Tax Credit. Utilizing Natural Language Processing (NLP) and AI algorithms, the chatbot classifies user questions into predefined intents and delivers predetermined responses to ensure accuracy and consistency. This approach relies on established topics and does not generate new responses, making it a reliable solution for taxpayer inquiries within a controlled environment."
Winnie Chatbot for Employee IT FAQs,"The Winnie chatbot project provides IRS staff with a self-service tool for answering IT-related FAQs using Natural Language Processing (NLP) and AI algorithms to classify user inquiries. The chatbot's responses are predetermined by content owners and do not involve Generative AI, ensuring that only accurate and consistent information is delivered based on predefined topics. This system is designed for controlled environments, prioritizing precision and reliability in the provided answers."
DATA Act Bot for Procurement Data Matching,"The DATA Act Bot automates the verification of IRS Federal Procurement Data System (FPDS) reporting against contract documents using supervised learning and natural language processing. It enhances operational efficiency by ensuring the consistency and accuracy of contract metadata, such as dollar amounts and contract dates, by validating that the reported contract spending information aligns with official documents. The performance of the validation models is measured using F1 accuracy scores for each specific data element."
Taxpayer Services Form 1040 Voicebot,"The Taxpayer Services Form 1040 Voicebot project implements an interactive voice response system that allows taxpayers to check their individual tax information and is capable of directing them to appropriate customer service representatives. Utilizing natural language processing and AI algorithms, the voicebot classifies taxpayer inquiries into specific intents, providing predetermined responses based on established business logic. This AI tool enhances taxpayer access to information and support during both filing and non-filing seasons."
Where's My Refund and Where's My Amended Return Voicebot,"The Where's My Refund (WMR) and Where's My Amended Return (WMAR) voicebots are designed to assist taxpayers in obtaining status updates on their refunds and amended tax returns. Utilizing an Intent Engine powered by natural language processing and AI algorithms, the voicebots classify taxpayer inquiries and provide predetermined responses based on established business logic. This project aims to enhance taxpayer engagement by streamlining the process of accessing refund and amended return information."
Simulation of the Nation (SimoN) Synthetic Data Engine,"The Simulation of the Nation (SimoN) Synthetic Data Engine is an IRS initiative that generates large volumes of synthetic tax data for diverse testing scenarios while ensuring no use of Federal Tax Information (FTI). It produces over 700,000 unique Individual Master File (IMF) tax returns and 50,000 Business Master File (BMF) returns, utilizing artificial intelligence and machine learning to simulate various socioeconomic factors and scenarios. SimoN also features an aging model for the population and supports automated testing and validations to ensure the synthesized data is accurate and usable for IRS testing purposes."
Machine Translation,"The IRS is implementing a cloud-based Machine Translation (MT) solution leveraging AWS Neural Translate to enhance and automate its content translation efforts. The Linguistic, Policy, Tools, and Services (LPTS) Team is assessing the application by integrating it into their existing processes, initially focusing on translating text and labels into Spanish, with plans for expansion into other non-English languages as an enterprise solution."
Economic Impact Payment (EIP) FAQ Voicebot,"The Economic Impact Payment (EIP) FAQ Voicebot is a self-service tool designed to answer taxpayer inquiries about the EIP and can connect users to live assistance during business hours. Utilizing an Intent Engine and AI algorithms, the voicebot classifies questions into predefined intents and provides accurate responses based on predetermined content, rather than generating answers with AI. This project aims to enhance taxpayer support and streamline information access regarding economic impact payments."
One-Time Payment Voicebot,"The One-Time Payment Voicebot project created a self-service application that assists taxpayers with inquiries related to One-Time Payments and can direct calls to live agents during business hours. Utilizing an Intent Engine powered by NLP and AI algorithms, the voicebot classifies questions into specific intents and provides predetermined responses crafted by content owners rather than generated by AI. The tool aims to efficiently guide taxpayers to the appropriate information or support based on their needs."
FAQs / Notice Clarifications Voicebot,"The FAQs / Notice Clarifications Voicebot project is a self-service application that addresses general taxpayer inquiries regarding notice clarifications and offers the option to connect with a live assistant during business hours. Utilizing an Intent Engine powered by NLP and AI algorithms, the system classifies taxpayer questions into predefined intents to provide accurate, predetermined responses created by content owners. If the voicebot cannot resolve a question, it escalates the issue to a live agent or requests more clarification from the taxpayer."
Advance Child Tax Credit (AdvCTC) Voicebot,"The Advance Child Tax Credit (AdvCTC) Voicebot is a self-service application designed to answer common taxpayer inquiries regarding the Advance Child Care Tax Credit using an Intent Engine that applies NLP and AI algorithms to classify questions. The responses are predefined by content owners, ensuring accurate information delivery, and the system can route users to live agents during business hours for issues that cannot be resolved by the voicebot."
Small Business/Self Employed (SBSE) FAQ Voicebot,"The Small Business/Self Employed (SBSE) FAQ Voicebot project creates a self-service application on the ACI platform to assist taxpayers with inquiries about One Time Payments (OTP) and Notice Clarifications. Utilizing an Intent Engine that employs NLP and AI algorithms, the voicebot classifies taxpayer questions into specific intents and delivers predetermined responses. Additionally, it can route calls to live agents during business hours when needed."
Insolvency and Offer in Compromise Voicebot,"The Insolvency and Offer in Compromise Voicebot project created a self-service application that assists taxpayers with inquiries related to the Offer in Compromise (OIC) program and insolvency issues. Utilizing an Intent Engine powered by NLP and AI algorithms, the voicebot classifies taxpayer questions into predefined intents and provides predetermined responses created by content owners. If the voicebot is unable to answer a question, it either asks for clarification or transfers the call to a live assistant during business hours."
Financial Relief Voicebot,"The Financial Relief Voicebot project developed a self-service application that assists taxpayers by answering inquiries about financial relief options. Utilizing an Intent Engine powered by NLP and AI algorithms, the system classifies questions and provides predetermined responses created by content owners. It also offers the ability to route calls to live agents during business hours for more complex issues."
Generative AI Toolbox for Contract Document Assistance,"The project aims to develop a Generative AI Toolbox that assists users in contract document tasks, including drafting statements of work, reviewing contracts for compliance, and providing proposal writing support to small businesses. The AI system produces accurate and contextually relevant text outputs based on user inputs, delivering document summaries, draft responses, rewrites, and analytical recommendations. Overall, it seeks to streamline contract-related processes and enhance accessibility for new entrants in bidding for Treasury contracts."
Integrate Google Doc AI for Digitalization,"The project aims to integrate Google Document AI with the Digital Enablement Platform (DEP) to enhance data extraction, reduce reliance on paper, and automate manual processes using artificial intelligence and Robotic Process Automation (RPA). By implementing an extraction engine alongside human validation processes, the DEP AI will improve efficiency, accuracy, and customer service for IRS operations, while also promoting environmental sustainability through reduced paper usage. The initiative ultimately seeks to provide a modern, digitally-capable experience for taxpayers and streamline operational workflows."
Modernization Accelerator - Legacy Applications Chatbot & Code Conversion,"The Modernization Accelerator project aims to modernize legacy applications within the IRS by utilizing a Large Language Model (LLM) to convert outdated coding languages into modern formats, specifically focusing on translating Assembler Language Code (ALC) to Java. The initiative involves creating a Generative AI (GenAI) Sandbox to facilitate knowledge discovery and improve understanding of legacy code through a Retrieval Augmented Generation (RAG) Chatbot, which will provide insights and documentation on the functionality and structure of the code. This project is restricted to IRS use, primarily for internal analysis and not intended for production deployment."
Modernization Accelerator - International Business Machines (IBM) Cognitive Data Mapper (CDM) and AWS SageMaker+LLAMA,"The Business Masterfile Modernization (BMF Mod) project aims to transform the outdated legacy BMF system, originally built on 60-year-old technology, into a modern cloud-based platform while incorporating additional features enabled by new technology. Utilizing IBM Cognitive Data Mapper and AWS SageMaker with LLAMA, the project will leverage AI/ML tools to analyze existing code and produce business logic, modern Java code, and microservice recommendations for developers to improve maintainability. This initiative, conducted in a sandbox environment, is designed to accelerate the modernization process and enhance documentation for better understanding of the BMF system, benefiting all stakeholders involved."
Joint Committee on Taxation Research Aide,"The Joint Committee on Taxation Review (JCTR) Research Aide is a generative AI system that employs Retrieval Augmented Generation (RAG) to answer inquiries related to JCTR policies and procedures. Utilizing a specific user interface and integrating with the Certara platform via API, the system incorporates an embedding model for contextual searching and a Large Language Model to generate responses. Outputs include both the AI-generated responses and relevant document excerpts used in the answer formulation."
Technical Demo of Large Language Models for Code Development,"This project presents a technical demo showcasing the application of Large Language Models (LLMs) to enhance code development for IRS developers, who currently face time-consuming manual coding processes. By integrating llamafile and collama IDE plugins within VS Code, the solution offers features such as code completion, generation, refactoring, documentation, debugging, and unit testing, aimed at improving the overall developer experience and ensuring the delivery of high-quality code. The initiative responds to the immediate need for Generative AI capabilities while a more comprehensive long-term enterprise solution is in progress."
Internal Revenue Manual Research Aid (IRMA),"IRMA is a generative AI system designed to assist users in understanding Internal Revenue Manual (IRM) policies and procedures by utilizing Retrieval Augmented Generation (RAG) search. It features a specialized user interface that integrates with the Certara platform via API to perform contextual searches and generate responses to user inquiries. The system employs an embedding model for text representation and a Large Language Model to provide comprehensive answers, complete with relevant document excerpts."
Tax Payer Notice Modernization,"The Tax Payer Notice Modernization project aims to enhance taxpayer comprehension by transforming complex tax language into clear, accessible content using AI. The initiative automates the generation of revised notices, which are then reviewed for accuracy before distribution. Expected outcomes include reduced errors, higher taxpayer satisfaction, and improved efficiency in tax administration."
Enable Face ID to unlock M365 apps on Government iPhone and iPad,"The project aims to enable Face ID on government-issued iPhones and iPads to facilitate easier access to M365 apps and Microsoft Teams. By implementing Face ID, users will no longer need to repeatedly enter passwords, enhancing the overall user experience when accessing organizational data. The technology relies on complex algorithms that analyze facial geometry to securely unlock devices and applications."
Data Integration using Informatica Data Management Cloud,"Informatica Intelligent Cloud Services (IICS) is a cloud-native platform for data integration and management that facilitates seamless access, transformation, and governance of data across hybrid and multi-cloud environments. It utilizes artificial intelligence, specifically through its AI component named Claire, to optimize data integration workflows and enhance data quality by making intelligent recommendations during mapping design. The platform supports various integration patterns and directly loads on-premises data to the cloud, addressing gaps in native support for Databricks and simplifying the data management process."
Answering Employee Questions with Natural Language Processing in IRWorks,"The AI component of the IRWorks platform is designed to utilize natural language processing to provide automated responses to common employee inquiries regarding knowledge base articles and service catalog items. By training the Virtual Agent in ServiceNow, the system aims to streamline Tier 1 support, ultimately reducing costs and enhancing the user experience for over 90,000 IRS employees. Human review is incorporated to ensure the accuracy of responses and links generated for user queries."
Compliance Data Warehouse Data Access Log Monitoring,"The Compliance Data Warehouse Data Access Log Monitoring project aims to enhance understanding of data usage and PII exposure risks by analyzing user activity patterns and identifying anomalies. It utilizes an AI model to automate the analysis of log data, generating scores that indicate how far a user's activity deviates from expected behavior, which aids the RAAS Infrastructure Security Team in investigating potential security risks. The findings are presented through a Tableau Dashboard and automated reports, allowing human reviewers to make informed decisions based on the model's outputs."
Volunteer Income Tax Assistance (VITA) Generative AI Chatbot Proof of Concept,"The VITA Generative AI Chatbot Proof of Concept aims to streamline the process of locating IRS information for Volunteer Income Tax Assistance (VITA) personnel by consolidating data into an accessible question-and-answer format. The chatbot, which utilizes retrieval-augmented generation AI technology, has been tested with a 99.5% accuracy rate and aims to enhance the efficiency of tax preparation by providing reliable, IRS-sourced answers. This proof of concept will conclude at the end of the upcoming tax season in April 2025 with a limited group of 30 certified VITA volunteers participating in the testing phase."
Ask-CFO Research Aide,"The Ask-CFO Research Aide is an advanced tool developed on the Certara Composer platform, designed to enhance CFO-specific document retrieval and analysis. It utilizes Retrieval Augmented Generation (RAG) to provide contextual searches and responses, incorporating AI agents for tasks like document summarization and data extraction. The system combines an embedding model for text vectorization and a Large Language Model for generating informative responses based on retrieved documents."
Redaction Studio - Redaction Assistant,"Redaction Studio is a Commercial Off The Shelf (COTS) application designed to assist Criminal Investigation Special Agents in redacting body worn camera footage efficiently and securely. Its key feature, the Redaction Assistant, employs AI to automatically identify and mask sensitive items, such as faces, while allowing agents to review and modify the proposed masks. This tool helps agencies comply with Executive Order 14047, which mandates the quick public release of body worn camera footage following serious incidents."
Intelligent Document Management System (IDMS),"The Intelligent Document Management System (IDMS) is a cloud-based platform that enhances document processing, storage, and sharing by employing artificial intelligence and machine learning for automation. It minimizes manual document handling, efficiently manages large data volumes, and integrates with existing business platforms to improve user experience. The system outputs information in JSON format, facilitating improved decision-making for clients, starting with the Office of Chief Counsel."
Taxpayer 90 (Palantir prototype),"The Taxpayer 90 project utilizes the Palantir AIP to efficiently summarize and parse synthetic data and public information, such as the Internal Revenue Manual and tax forms. This feature operates exclusively within a Software as a Service (SaaS) platform and requires specific user permissions through the Taxpayer 90 Business Entitlement Access Request System (BEARS). All data is securely housed within the SaaS environment without the need for firewall changes or proxy exceptions."
Expanded Systran Translation Software,"The Internal Revenue Service-Criminal Investigation (IRS-CI) is seeking to acquire an expanded enterprise license for Systran Translation Software to enable high-volume processing of translated documents using multiple Graphic Processing Units (GPUs). This expansion will facilitate the translation of large quantities of seized foreign language data, with the final output being a PDF document containing the translations."
Transcription -- Evidence.com,Evidence.com offers an AI-based transcription tool specifically designed for law enforcement recordings. The platform generates accurate transcriptions and delivers them in a Word document format.
Digital Forensics Chatbot for IRS Employees,"The Digital Forensics Chatbot is an application designed for IRS employees to provide instant access to information and assistance related to digital forensics. It offers support for examiners dealing with new technologies by answering questions, aiding in script writing for data management, and supplying detailed information on code sequences, data storage locations, and known security exploits. This tool aims to enhance efficiency and accuracy in digital forensics efforts, reducing reliance on external search engines."
Generative AI for Form 1040X: Tax Examiner Assistant,"The Generative AI for Form 1040X: Tax Examiner Assistant project aims to develop a workflow assistant that utilizes generative AI to analyze and consolidate tax policy information for Tax Examiners handling amended returns. The tool will provide real-time guidance and will include features for generating taxpayer correspondence, with collaboration from key stakeholders to enhance its capabilities. Ultimately, it aims to improve operational efficiency, reduce processing times, and ensure the accuracy of information provided to Tax Examiners."
ServiceNow Generative AI Pilot,"The ServiceNow Generative AI Pilot aims to enhance the IT Service Desk's efficiency by implementing AI for incident summarization, resolution notes generation, and knowledge article creation. This initiative, supported by the CTO, seeks to reduce time spent on warm handoffs, lower the mean time to restore incidents, and improve the quality of resolution notes, ultimately facilitating better self-service capabilities and faster closure of incidents. The pilot will leverage concise case summaries and accurate documentation to streamline operations and knowledge management."
Circular Dependencies (Individual Master File Modernization),"The AI project aims to expedite the resolution of circular dependencies within the Individual Tax Processing Engine (ITPE) by utilizing a Large Language Model (LLM) to propose solutions based on the identified classes. While human review is required for any proposed changes, the anticipated outcome is a significant reduction in resolution time from months to hours, benefiting ITPE architects and developers. Ultimately, the project enhances the efficiency of the ITPE codebase management."
Synthetic Test Data Generation (Individual Master File Modernization),"The Synthetic Test Data Generation project aims to produce rich synthetic data for testing purposes by generating scripts from data model schemas. This automated process enhances the quality of testing scenarios, ensuring the data mimics real-world datasets while undergoing human review to meet standards. The project ultimately benefits ITPE and Individual Master File (IMF) stakeholders by providing comprehensive test data, leading to more reliable testing outcomes."
Auto Tech Debt Remedy (Individual Master File Modernization),"The Auto Tech Debt Remedy project focuses on automating the resolution of technical debt in source code using AI and industry-standard scanning tools such as SonarQube. By leveraging a large language model to generate modified code based on identified issues, the project aims to streamline this process while ensuring human review of the AI-generated output before implementation. The anticipated outcome is a reduction in technical debt, leading to more maintainable and efficient codebases that will ultimately benefit both software developers and end users."
M365 Copilot,"The project involves a designated group of participants from various business areas who will test AI-driven features within M365 applications through M365 Copilot. This testing aims to validate the security, benefits, and functionality of these features in relation to the existing architectural constraints of M365."
Copilot for Power Platform,"The Copilot for Power Platform project involves a small group of participants from various business areas who will test AI-based features within the Power Platform applications. The testing aims to validate the security, benefits, and capabilities of these AI features, ensuring they adhere to the existing architectural boundaries of the platform. This initiative will enhance development activities by leveraging an AI assistant."
Copilot for M365 (Criminal Investigation Unit),"The Copilot for M365 project aims to enhance productivity within the Criminal Investigation Unit by leveraging AI tools across various Microsoft applications. It assists users in creating and refining documents in Word, analyzing data and generating charts in Excel, designing presentations in PowerPoint, managing collaboration in SharePoint, streamlining email communication in Outlook, and optimizing meeting processes in Teams. Overall, Copilot enhances efficiency and organization across multiple tasks and platforms."
Automated Collection System (ACS) Voicebot,"The Automated Collection System (ACS) Voicebot project developed a self-service application to assist taxpayers with various issues related to their tax accounts in four phases. Each phase enhances the Voicebot's capabilities, including payment plan management, information retrieval based on zip codes, outstanding balance inquiries, and access to account history. The system utilizes natural language processing (NLP) and AI algorithms to interpret taxpayer requests and provide tailored responses, while also offering escalation to a live agent when necessary."
Customer Experience Analytics,The Customer Experience Analytics project focuses on analyzing data from the customer service sector to derive insights aimed at enhancing service interactions. It specifically involves summarizing call transcripts between the IRS and taxpayers to identify areas for improving the overall customer experience. The goal is to leverage this analysis to create new opportunities for better service delivery.
Exercise Design,"The project aims to enhance the exercise development process by utilizing a Large Language Model (LLM) for rapid event design and efficient post-event reporting. The LLM will generate realistic and complex scenarios, particularly in cybersecurity, that expose participants to various threats, improving their preparedness and response capabilities. Additionally, it will streamline the creation of detailed event descriptions and facilitate thorough post-event analysis."
Incident Coordination and Reporting Support,"The project focuses on using a large language model (LLM) to enhance incident coordination and reporting by rapidly generating draft products from both public and private data sources. This technology aims to significantly reduce development time, especially during the early stages of an incident, allowing Incident Coordinators to efficiently manage diverse inputs and create quick-turn reports for key partners. This streamlined process will facilitate timely updates and research as incidents evolve."
EFTPS Fraud Monitoring,"The EFTPS Fraud Initiative enables near-real-time detection of fraudulent activity in Direct Pay and EFTPS Online payment channels by profiling and scoring transactions. It generates risk scores based on comparisons with historical data, which trigger alerts for fraud analysts to review and potentially take action, such as blocking accounts or escalating cases to law enforcement."
Digitization of Microfilm,"The Digitization of Microfilm project involves Iron Mountain's use of AI and deep learning machine learning to enhance the efficiency and accuracy of converting Mature Undredeemed Debt/Savings Bonds. This initiative has successfully digitized 175,000 reels of film, yielding approximately 2.1 billion images stored in the Azure cloud, while enabling Fiscal Service to effectively search for and identify bond owners."
Check Fraud Pipeline,"The Check Fraud Pipeline project addresses the increase in U.S. Treasury check fraud driven by Economic Impact Payments and Advance Child Tax Credit checks, where fraudsters steal and alter checks. By streaming check images into a payment analytics environment and utilizing AI and machine learning, the pilot has analyzed 30 million check images and settlement transactions, identifying 12,000 fraudulent items valued at over $100 million. This technology aims to enhance identification and risk assessment of potentially fraudulent checks."
Gender differentiated credit scoring,"The University of California, Berkeley is developing a machine learning model for gender differentiated credit scoring targeted at Rappicard customers in Mexico. This model will be evaluated against Rappi's existing credit scoring method to assess its effectiveness in improving credit access for women. The project aims to identify potential benefits of incorporating gender differences into credit scoring practices."
Using ML for predicting treatment interruption among PLHIV in Nigeria,"The project developed and implemented a machine learning algorithm to predict treatment interruptions among people living with HIV in Nigeria, using data from the USAID-funded SIDHAS project. The algorithm was integrated into the Lafiya Management Information System (LAMIS), allowing health facility staff to receive weekly risk assessments for new patients and provide targeted support to those at high risk. Additionally, a qualitative assessment was conducted to gather healthcare workers' perceptions of machine learning and identify necessary support for its integration into routine practice."
Machine Learning for Peace,"The Machine Learning for Peace project involves a collaboration between DRG and a consortium of researchers, including those from Duke University's DevLab, to develop an AI tool that predicts the closing of civic spaces. This tool aims to analyze patterns of events that lead to restricted freedoms and weakened democratic processes by utilizing event labels and forecasts."
Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswanas reservoirs using satellite data and artificial intelligence methods: Case study of the Botswanas Limpopo River Basin (1984-2019),"The project investigates the long-term impacts of land-use and land-cover dynamics on water quality in Botswana's reservoirs, focusing on the Limpopo River Basin from 1984 to 2019. By employing satellite data and artificial intelligence, the study aims to establish quantitative relationships between land-use changes, socioeconomic factors, and climate change effects on water quality and availability, while also predicting future scenarios until 2050. The research will develop models for real-time monitoring of water quality using a combination of in-situ measurements, drone-borne spectrometers, and optical satellite imagery."
Morogoro youth empowerment through establishment of social innovation (YEESI) lab for problem-centered training in machine vision,"The YEESI project established a social innovation lab at Sokoine University of Agriculture to enhance ICT education in Tanzania, focusing on training students in Machine Learning, Machine Vision, and Natural Language Processing. Over 650 students participated in the program, which created the first comprehensive open-source machine vision dataset for Tanzania's central regions and collaborated with agriculture start-ups and NGOs to promote sustainable agricultural practices and economic growth."
Breakthrough RESEARCHs Social Media Listening,"Breakthrough RESEARCH conducted a social media listening project utilizing machine learning to analyze 12,301 posts from Nigeria, focusing on gender-related discussions over the past five years. By employing Crimson Hexagon's ""Brightview"" algorithm, the study categorized content related to reproductive health, family planning, and youth, revealing key trends in conversation volume, misinformation, and social norms. The findings provide valuable insights that surpass traditional public health research methods, enhancing the understanding of online conversations around these critical topics."
Serbia: AI predictions for the utilization of hospital beds,"The project utilized AI technology to predict hospital bed occupancy in Serbia using Ministry of Health data from 2019, achieving a median prediction error of around 20% per department. Developed at the request of the Institute of Public Health, this proof-of-concept model has led to a new focus on waiting list optimization for scheduled imaging diagnostics, specifically CT and MRI, which will be prioritized in alignment with the national AI strategy in 2023-2024."
Qure.AI integrated in mobile X-ray screening to improve community TB case finding,The USAID Support to End TB project utilizes Qure.AI technology in mobile X-ray vans to enhance TB case detection and screening quality in Vietnam. This AI integration not only accelerates the screening process but also increases the accuracy of TB detection.
AI for Predictive Analysis of patients on HIV treatment,"The JHU ACCELERATE project utilizes Artificial Intelligence and Machine Learning to identify People Living with HIV (PLHIV) on treatment who are at risk of becoming lost to follow-up. By assessing patient risk scores, the project aims to enable pre-emptive counseling and tailored interventions to retain at-risk patients in care."
Private Sector Engagement Evidence Gap Map Analytical Pilot,The Private Sector Engagement Evidence Gap Map Analytical Pilot explored the application of natural language processing for large-scale analysis of the EGM documents. This pilot serves as an exploratory initiative to enhance understanding and accessibility of private sector engagement data. Reports and visualizations were produced as part of the analysis.
Risk-based modeling of poacher movements in protected areas,"The risk-based modeling project aims to predict poaching activity in protected areas to assist managers in resource allocation. The model generates outputs that indicate the risk level through historical predictions, risk categories, or specific poaching activity types. Data inputs include animal tracking, terrain and habitat information, historical conservation records, and spatial-temporal data, with the results presented on annotated maps."
CARI/El Salvador: Risk factors at community level that cause Internal Displacement,The USAID/CPS/OTI's CARI program in El Salvador is collaborating with Cristosal to investigate the impact of extortion on internal displacement. A specialized research team will conduct interviews with 60 affected families in Panchimalco to explore the violence and social norms driving internal migration. The study aims to develop data-driven recommendations for implementing early warning systems and community responses to mitigate extortion-related violence.
"Chemonics International Inc.'s ""Disinformation Monitoring and Sentiment Analysis""","Chemonics International Inc. implements the ""Disinformation Monitoring and Sentiment Analysis"" project under the Transition to New Sudan program, utilizing AI technology to track social media for disinformation and assess public sentiment. The project produces reports and visualizations to present insights derived from the monitored data."
PEER 8-161: A wood species identification tool to aid in compliance and enforcement of Peruvian timber regulations,"The Xylotron is an artificial intelligence tool developed by the U.S. Forest Service's Forest Products Laboratory to identify wood species, aiding in compliance with Peruvian timber regulations and CITES. By matching scanned images with a comprehensive DNA database, the Xylotron can quickly determine whether timber is legally sourced, and the project expanded its database to include 35 additional Peruvian wood species."
PEER 9-452: Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswanas reservoirs using satellite data and artificial intelligence methods: Case study of the Botswanas Limpopo River Basin (1984-2019),"The PEER 9-452 project analyzed the long-term impacts of land-use and land-cover dynamics on water quality in Botswana's Limpopo River Basin from 1984 to 2019 using satellite data and artificial intelligence. Researchers developed machine-learning models to map and quantify changes in land use, while also assessing the effects of socioeconomic and climate variables on water quality and availability within the reservoir catchments."
BA Cote d'Ivoire Public Social Media Data,"The project for Breakthrough ACTION Cte d'Ivoire utilizes Meltwater software to extract and organize public social media data from various sources, including Facebook and Twitter, in real-time. Additionally, a CrowdTangle account and a custom Python application are employed to pull Facebook data and apply machine learning techniques for optimizing topic identification. This process incorporates artificial intelligence through natural language processing and image recognition to analyze sentiment and key terms, ultimately leading to the generation of reports and visualizations."
USING PREDICTIVE ANALYTICS TO IMPROVE CARE,"The project employs predictive analytics to identify high-risk patients, specifically focusing on children at risk of malnutrition, for targeted intervention. Additionally, it aims to identify frontline health workers or caregivers who require further support from community health facilitators. The approach is designed to be adaptable for broader applications beyond the healthcare sector."
Smart Supervision Platform - Superintendencia Financiera de Colombia (Colombian Financial Regulator),The Smart Supervision Platform developed by the Superintendencia Financiera de Colombia is designed to gather and analyze data related to financial product complaints from customers and financial intermediaries. This system employs statistical analysis and control panels to identify trends and facilitate decision-making for regulatory supervision. It enhances the oversight of financial institutions by classifying information across various dimensions and improving complaint resolution processes through predictive analytics and visualizations.
Feed the Future Innovation Lab for Applied Wheat Genomics,"The Feed the Future Innovation Lab for Applied Wheat Genomics employed multi-modal deep learning to integrate genotype and phenotype data, utilizing unmanned aerial systems to forecast wheat yield across various environments. The project has concluded without any reported outputs or results."
Market segmentation,"The project employs analytical techniques to enhance understanding of the market for private HIV treatment and services by profiling people living with HIV/AIDS (PLHIV) based on their willingness to pay. Utilizing various data sources, including geospatial, market, and micro-economic data, it generates patient profiles at different scales to estimate the market size and characteristics. This country-agnostic approach facilitates the identification of specific PLHIV population segments across PEPFAR-priority countries, supported by reports and visualizations."
Climate-based malaria forecast,The climate-based malaria forecast model utilizes confirmed malaria cases alongside eco-climatic data to predict malaria incidences for up to two months in advance. It employs time series predictions to enhance the accuracy of its forecasts.
Covid Decision Support,"The Covid Decision Support project, led by the Wadhwani Institute for Artificial Intelligence and supported by USAID, provided predictive modeling and analytics to the Municipal Corporation of Greater Mumbai and Jharkhand's six districts from June 2020 to January 2021. This initiative resulted in the establishment of over 2,500 ICU beds and more than 50,000 quarantine beds ahead of the second COVID-19 wave, along with recommendations to increase case discovery in under-tested areas. The project received recognition from state governments in both Jharkhand and Maharashtra for its contributions."
Artificial Intelligence for observing Hand Hygiene,"The Momentum Country and Global Leadership (MCGL) project, supported by USAID and led by Jhpiego, has developed SafeHands, an AI tool designed to enhance compliance with WHO-recommended hand hygiene techniques. SafeHands utilizes AI algorithms to monitor handwashing practices in real-time, ensuring proper execution of the ""Nine steps for correct handwashing"" and measuring the duration of soap application. This innovative digital solution aims to improve facility-level hand hygiene through precise observation and feedback."
Cough Against Covid,"The ""Cough Against Covid"" project, supported by USAID and led by TRACE TB and the Wadhwani Institute of Artificial Intelligence, developed an AI-based technology that analyzes cough sounds to identify at-risk Covid-19 patients prior to RT-PCR testing. This innovative application utilizes machine learning and deep learning algorithms for sound classification, allowing for early detection even in asymptomatic individuals."
Automated interpretation of Line Probe Assay strips using computer vision,"The project focuses on using AI to automate the interpretation of Line Probe Assay strips for drug-resistant TB, improving accuracy, efficiency, and consistency in test results. By detecting bands on the strips and classifying them as resistant or susceptible, the system reduces manual errors and speeds up diagnosis. It generates comprehensive diagnostic reports that aid clinicians in making timely treatment decisions integrated with the Ni-kshay platform."
Prediction of risk for Loss to Follow Up (LFU) among TB patients using AI,"The project utilizes AI to assess the risk of Loss to Follow Up (LFU) among TB patients by predicting adverse treatment outcomes like treatment failure or mortality. It generates a risk score for each patient, categorizing them as HIGH-RISK or LOW-RISK, which allows for prioritized interventions. This approach aims to improve patient outcomes, optimize resource allocation, and enhance the overall effectiveness of TB treatment programs."
Leveraging Artificial Intelligence for TB screening,"The Closing the Gaps in TB Care Cascade project, funded by USAID and led by World Health Partners, aims to improve TB diagnostics by partnering with Deeptek.ai to deploy the Genki AI tool, which automates chest X-ray readings to detect 20 abnormalities. This initiative addresses delays in TB diagnosis caused by patients seeking care from informal providers and multiple healthcare professionals, thereby facilitating earlier probable diagnoses. Ultimately, the project supports the Government of India's vision for a 'TB-Free India' by enhancing the TB care cascade process."
"Social listening to inform youth programming in Colombia (previously ""Communications Strategy"")","The project focuses on utilizing social listening to inform youth programming in Colombia by understanding dynamic conversations among young people, defined by various socio-demographic factors. It employs Artificial Intelligence tools developed by Audience Insights in partnership with Twitter and Facebook to ethically collect and analyze data, enabling the design of targeted and engaging communication strategies. By leveraging insights on audience affinity and interests, the Youth Resilience Activity aims to enhance the effectiveness and relevance of campaigns aimed at youth."
AI Pilot- Detection of data exfiltration,"The AI Pilot Project was initiated by USAID to utilize artificial intelligence for detecting security events and anomalies in network data, aiming to identify previously undetected data exfiltration attempts. By reverse engineering known attacks and developing machine learning algorithms, the project successfully detected penetration attacks on specific protocols like ICMP, HTTP, and HTTPS. However, the project was discontinued before testing on a second dataset."
Global Antimicrobial Resistance Surveillance System,"The Global Antimicrobial Resistance Surveillance System (GLASS), established by WHO, aims to enhance global surveillance and research on antimicrobial resistance (AMR) to inform decision-making at various levels. The USAID Infectious Disease Detection and Surveillance (IDDS) project provided support to Ministries of Health in Kenya, Cameroon, and Liberia by training surveillance sites on AMR data collection, analysis, interpretation, and reporting. This initiative included regular supportive supervision to improve the quality of AMR data submitted to GLASS."
GXAlert,"GXAlert is a software platform developed by System One that integrates diagnostic devices, providing clinicians and program staff with secure access to test results through flexible reporting options. The implementation of GXAlert is supported by USAID's IDDS project in Zimbabwe, Tanzania, and Vietnam. This collaboration aims to enhance communication within health systems and improve patient care."
DataToCare,DataToCare is a customizable suite of integrated applications that links national laboratory networks by gathering diagnostic and patient data at healthcare facilities. It provides real-time information on a dashboard for central decision-making and alerts medical teams and patients of test results. The implementation of DataToCare is supported by USAID's IDDS project in the Democratic Republic of Congo and Cambodia.
CAD4TB: AI-Powered Tuberculosis Detection Software,"The CAD4TB software, developed by Delft, leverages AI to enhance the detection of tuberculosis through improved chest x-ray analysis. Supported by USAID's Infectious Disease Detection and Surveillance (IDDS) project, it is being introduced in countries including DR Congo, Kenya, Nigeria, Philippines, Uganda, and Vietnam to facilitate more accurate tuberculosis diagnoses."
DeepGreen Ukraine,"DeepGreen Ukraine is a project focused on creating an Illegal Logging and Deforestation Alert System in Ukraine, building upon the previously established DeepForest Project. This IT-based service will analyze satellite data on forest cover changes and compare it with publicly available information to monitor illegal logging activities and assess compliance with government permits. The system aims to provide near real-time updates on deforestation, detailing the extent and timing of forest loss across Ukraine."
"National Park information classification using AI, Garamba National Park, DRC","The project involves using AI to classify information related to Garamba National Park in the Democratic Republic of Congo. It utilizes Python scripting to train the J2/intelligence office workflow, focusing on the classification, separation, and sharing of sensitive data gathered from park ranger patrols. Text classification techniques are employed to streamline the handling of confidential information."
"Wildlife identification using computer vision (Mbaza), DRC","Mbaza is a machine learning program designed to identify wildlife species captured by camera traps, facilitating the inventory process for biodiversity surveys in a designated protected area in the Democratic Republic of the Congo. This computer vision initiative enhances efficiency and accuracy in assessing local biodiversity."
AI-enabled presentation design,The project focuses on utilizing AI technology to enhance the design of PowerPoint presentations. It aims to save staff time while improving the quality of presentation materials. This initiative will streamline the presentation creation process and elevate the overall effectiveness of communications.
"AI tools for learning, evaluation, and research","The project focuses on developing AI tools to enhance learning, evaluation, and research for a USAID implementing partner. These tools aim to improve the effectiveness of research and reporting processes, ultimately synthesizing data into comprehensive reports for USAID activity managers."
AI-enabled classification for Standardized Program Structure and Definitions,"The project focuses on implementing AI-enabled classification to automate the categorization of U.S. foreign assistance information using the Standardized Program Structure and Definitions (SPSD). This system establishes a common language for foreign assistance programs, facilitating the aggregation, comparison, and analysis of budget and performance data across various programs at different geographic levels. By sorting indicators into the SPSD, the project aims to streamline the process and enhance the usability of foreign assistance data."
MENA Assessment Chatbot,The MENA Assessment Chatbot is designed to search a specific repository of USAID-funded assessments and provide relevant information in response to user inquiries. It utilizes a chatbot interface to facilitate easy access to reports and assessments.
Generating reports for program monitoring and evaluation and literature reviews and syntheses to inform activity design and contribute to learning and knowledge management,"This project focuses on creating reports for program monitoring, evaluation, and literature synthesis to enhance activity design and promote learning and knowledge management. It aims to minimize staff time costs in report generation for USAID while improving the thoroughness and efficiency of evaluations conducted by contractors. The initiative includes producing written reports for both internal use and external sharing."
AI tools for grant application application review,"The project focuses on enhancing the grant application review process for humanitarian assistance by implementing three machine learning tools. These tools are designed to facilitate the review of emergency applications, assess Resilience and Food Security (RFSA) applications, and analyze trends in issues letters related to the RFSA application review process. This initiative aims to streamline the grantmaking process and improve efficiency."
Natural Language Processing to detect gender-based violence in Kenya,"The project aims to develop a tool utilizing Natural Language Processing (NLP) and machine learning algorithms to detect and analyze technology-facilitated gender-based violence (TFGBV) in Kenya. It will enable early identification of potential threats and support automatic, anonymous reporting while providing reports and visualizations to enhance understanding of the patterns related to this form of violence."
Identifying harmful social media content in Sinhala and Tamil,"The project aims to create AI tools to detect hate speech on social media platforms in Sinhala and Tamil. It includes developing systems for reporting harmful content and formulating counter-narratives to reduce the impact on affected communities. Overall, this initiative seeks to promote a safer online environment by addressing and mitigating harmful interactions."
Value4Her Connect Digital Platform,"The Value4Her Connect Digital Platform leverages AI to create personalized learning experiences for women in agriculture, offering tailored tutorials, courses, and resources to enhance their skills. It fosters collaboration among women entrepreneurs by connecting them and providing insights into market trends, demand forecasts, and pricing strategies, ultimately empowering them to make informed decisions and improve productivity. Additional features include networking tools, mentorship connections, business performance alerts, and assessments of farm carbon footprints, all aimed at driving economic growth in the agricultural sector."
"SERVIR Agriculture and Food Security: SERVIR is using machine learning techniques to interpret satellite data to improve crop area, crop type, crop condition, and yield estimates at the scale of 10s of meters, aggregated to country, district, province, or country.","SERVIR Agriculture and Food Security employs machine learning to analyze satellite data for enhanced assessments of crop area, type, condition, and yield at a high resolution. This project aims to provide accurate geospatial information that supports food security evaluations and agricultural decision-making across various administrative levels."
"SERVIR Water Security: SERVIR is applying deep learning on in situ and global/regional hydrologic forecasts to fill gaps in historic and recent streamflow and river elevation estimates, and improve streamflow forecasts, to a vertical precision of meters to centimeters, potentially for thousands to millions or river reaches worldwide.","SERVIR Water Security utilizes deep learning techniques to enhance the accuracy of streamflow and river elevation estimates by addressing gaps in historical and recent data. This project aims to improve forecasts with a precision of meters to centimeters for thousands to millions of river reaches globally, thereby informing water security decisions for ungauged rivers."
"SERVIR Ecosystem and Carbon Management: Automation of land cover and change mapping, including forest disturbance due to roads and mining. SERVIR is applying machine learning and deep learning techniques on satellite data to automate the classification and identification of land surface activities at the scale of 10s of meters.","The SERVIR Ecosystem and Carbon Management project focuses on automating land cover and change mapping by utilizing machine learning and deep learning techniques applied to satellite data. This initiative aims to enhance the detection of land cover changes, particularly related to forest disturbances caused by roads and mining, thereby improving resource management and estimating carbon and greenhouse gas emissions. The project provides vital geospatial information for monitoring ecosystems and informing carbon management decisions."
"SERVIR Weather & Climate Resilience: Short-term and seasonal weather prediction and hazard mapping. SERVIR is mapping floods and landslides with machine learning classification techniques, on the order of 10m to 10km. SERVIR is exploring the performance of weather foundational models versus numerical weather predictions on the 4-10km scale.","SERVIR is focused on enhancing short-term and seasonal weather predictions, along with hazard mapping, using machine learning techniques to identify floods and landslides. The project investigates the effectiveness of foundational weather models compared to traditional numerical predictions on scales of 4-10 kilometers. Ultimately, SERVIR aims to improve hazard detection and prediction to mitigate the impacts of climate and weather-related disasters."
"SERVIR Air Quality and Health: Processing modeled air quality forecasts and assimilating large volumes of data from satellite instruments. SERVIR is downscaling satellite- and model-derived air quality predictions with neural networks, down to 5km spatial resolution.","The SERVIR Air Quality and Health project aims to enhance the tracking and monitoring of air quality events by processing modeled forecasts and assimilating satellite data. It utilizes neural networks to downscale air quality predictions to a 5km spatial resolution, thereby providing precise geospatial information to inform health-related decision-making. "
Amazona Mia - AI for environmental law enforcement in Colombia,"The Amazona Mia project aims to enhance the Colombian Attorney General's Office's ability to investigate and prosecute environmental crimes, particularly focusing on deforestation in the Amazon. It seeks to improve technical, technological, and human resources to effectively address criminal activities and identify key perpetrators involved in environmental degradation. The project will utilize reports and visualizations to support law enforcement efforts."
Knowledge management and situational awareness for civil society in Colombia,"The project involves the development of an application designed for social organizations in Colombia to manage and utilize knowledge generated from their activities and projects. It aims to enhance access to information on security and violence through an intuitive natural language interface, while also providing tools for monitoring security conditions that support effective decision-making. The application will include features such as reports, visualizations, and a chat interface to facilitate the efficient use of crucial information."
Virtual host for attendees of the Invest for Climate activity,The project involves creating a virtual host to engage and interact with attendees of the Invest for Climate activity. The primary objectives are to enhance project visibility and facilitate attendee interaction through an interactive avatar. This innovative approach aims to improve the overall experience during the event.
Farmer support chatbot in Colombia,The Farmer Support Chatbot in Colombia utilizes AI to analyze agroclimatic data and provide tailored recommendations to farming families. It helps producers make informed decisions by interpreting climate information relevant to their agricultural practices. The project includes generating reports to enhance understanding and application of the provided recommendations.
"LIDA: Instant Messaging System in the Family Commissioner's Office of Montera - Crdoba, Colombia","The LIDA instant messaging system implemented in the Family Commissioner's Office of Montera, Crdoba, Colombia, aims to enhance communication between citizens and the office. It focuses on promoting awareness and knowledge of gender-based violence (GBV) referral pathways, thereby strengthening the protection of rights within the community."
AI assistant for Colombia Partners for Transparency,"The AI assistant for Colombia Partners for Transparency leverages Large Language Models and Retrieval-Augmented Generation to facilitate user interaction with PfT documentation. By allowing users to upload Word and PDF documents and pose natural language inquiries, the tool delivers accurate and contextually relevant responses based on the document content through a chatbot interface."
Twitter trend analysis in Colombia,"The Twitter trend analysis project in Colombia employs artificial intelligence to create a control dashboard that tracks retweets in real-time while categorizing tweets by gender, topic, geolocation, sentiment, and emotions. Its purpose is to counter misinformation and enhance transparency on social media, contributing to the fight against corruption. The system utilizes various Machine Learning algorithms to identify trending posts, analyze user demographics, and detect fake news, providing valuable reports and visualizations."
Project Data Machine: Open governance data in Colombia,"Project Data Machine aims to enhance transparency in Colombia's Congress by integrating governance information into a standardized, easily downloadable format. The initiative provides open data suitable for reuse, utilizes agreed-upon schemas for accurate interpretation, offers an inventory of datasets for consultation, and ensures accessibility through user-friendly web addresses. Ultimately, it acts as a catalyst for further open data initiatives in both public and private sectors."
Mibanco: Equitable Finance Activity in Colombia,"The Micomunidad Ecosystem project in Colombia aims to create a relational framework that fosters collaboration among various stakeholders to enhance community development and financial inclusion. The initiative focuses on reducing poverty sustainably while building long-term relationships in vulnerable areas. A key component of this project is a ChatBot for Financial Education, designed to improve users' personal and family financial management skills."
Remote sensing for land cover identificiation in Colombia,"The project focuses on using remote sensing techniques to identify land cover in Colombia, specifically targeting water body identification. It utilizes a training dataset derived from Landsat and Sentinel imagery to create annotated maps that enhance the accuracy of land cover classification."
AI to support road construction in rural Colombia,"The project involves the development of an AI-based chatbot to support the ""Caminos Comunitarios para la Paz Total"" Program in rural Colombia. This AI solution aims to improve outreach and operational efficiency by providing communities with quick access to vital information about technical and legal requirements for road construction. The initiative seeks to scale the Program's impact across the region."
Mobile application for reading rapid cryptococcosis tests,"The project focuses on developing a mobile application designed to assist healthcare workers in accurately reading cryptococcosis test results. The app serves to validate the initial readings by providing confirmation of whether the test result is positive or negative, thereby minimizing human error in the diagnostic process."
Chatbot to respond to teachers' questions about how to prevent student dropout,The project involves developing a chatbot designed to assist teachers by providing tailored recommendations on interventions to prevent student dropout. It aims to facilitate smoother interactions and guide educators through a pre-established protocol of steps to effectively address dropout prevention strategies.
Predictive analytics model to predict HIV Treatment Interruption Risk,"The project aims to develop a predictive analytics model for assessing the risk of HIV treatment interruption in patients. This model will identify individuals at potential risk of discontinuing their care, allowing for timely intervention and support."
Anti-Money Laundering and Shareholders Transparency IT System,"The Anti-Money Laundering (AML) and Shareholders Transparency IT System implemented by the National Bank of Moldova (NBM) enhances detection of suspicious banking activities through a combination of a rule-based framework and machine learning (ML) and artificial intelligence (AI) capabilities. The system enables comprehensive monitoring of banking operations, supporting a risk-based approach to identify potential money laundering and terrorist financing risks while strengthening the bank's oversight role. A proof of concept using ML/AI has been developed to improve detection ratios through a K-means clustering algorithm that segments entities by their money laundering risk levels."
AI analysis of Moldova's media content and social media landscape,"This project employs AI to analyze the media landscape of Moldova, emphasizing narrative framing in Romanian and Russian-language media and social platforms. It aims to enhance situational awareness and support strategic communications planning, with findings compiled into monthly reports. The focus is on analysis rather than content removal or blocking."
"""Bu Mira"" financial inclusion chatbot","Bu Mira is a financial inclusion chatbot created for women entrepreneurs to engage with on WhatsApp. The chatbot provides access to educational modules, financial tools, and loan applications to support their business endeavors."
Machine translation for communication with country teams,The project focuses on implementing machine translation to facilitate communication between English-speaking colleagues and an in-country team that operates entirely in Spanish. This technology will enhance collaboration and ensure effective understanding of written text between the two language groups.
E-Audit system for the tax department in Jordan,"The E-Audit system for the tax department in Jordan aims to enhance voluntary tax compliance, identify high-risk cases for follow-up, and expedite refunds, thereby supporting fiscal responsibility and economic growth. By automating routine checks, the system saves time and resources, fostering public trust in the tax system, and aligns with Jordan's macro fiscal policy objectives for cost-effective revenue generation. It utilizes a scoring system to rank taxpayers based on their returns, prioritizing audits on those with higher perceived risk."
Crop2Cash National Hotline for Agriculture,"The Crop2Cash National Hotline for Agriculture is an AI-powered advisory platform available 24/7 in four major Nigerian languages, providing personalized guidance on crop management, pest control, soil health, and market trends. It integrates real-time weather data and climate predictions, helping smallholder farmers develop adaptive strategies to mitigate the impacts of climate change. This telephone-based technology enhances access to essential extension services and market information for farmers."
FarmerChart,"FarmerChart is an AI-driven application designed to assist smallholder farmers in Nigeria by offering agricultural advisory services and real-time weather predictions. Accessible on Android devices and available in Hausa and Yoruba, the platform aims to enhance farmers' resilience to climate change by providing access to vital extension services and market trend information."
Automated due diligence for corruption risks,"The project aims to create a platform that automates due diligence for corruption risks by processing and standardizing data from published reports, making it accessible for public use. Compliance teams in financial institutions and corporations will be able to screen their customers, transactions, and supply chains against this NGO data, similar to their existing practices with sanctions and other watchlists. The platform will also provide reports and visualizations to enhance understanding and analysis of corruption risks."
AI-powered portal for the Development Experience Clearinghouse,"The project focuses on creating an AI-powered portal for the Development Experience Clearinghouse, aimed at simplifying access to its information. It includes the integration of Excel tables that will supply data to a Tableau dashboard, which will feature various tables and visualizations for enhanced usability."
ARTS - Automated Indirect Cost and Tracking System,"The Automated Indirect Cost and Tracking System (ARTS) aims to enhance efficiency and productivity through the use of chatbots and generative AI. It provides 24/7 support for inquiries, automates repetitive tasks, and tailors trend analysis for improved engagement with implementing partners (IPs), ultimately saving time and resources. Additionally, ARTS utilizes AI to generate data-driven insights and forecasts, aiding decision-makers in indirect rate negotiations."
Crop pest identification and advisory,"The project focuses on developing an AI system for the efficient identification of crop pests and diseases. It provides personalized recommendations for pest control and offers plant health advice in local languages, enhancing accessibility for farmers."
AI-enabled agricultural logistics in Mozambique,"Appload is enhancing agricultural logistics in Mozambique by providing a digital marketplace that connects small agricultural aggregators and transporters in Nampula, Zambezi, and the Beira Corridor. The initiative aims to serve 1,588 shippers and 740 transporters, facilitating over $675,000 in cargo movement through numerous trips, while also offering subsidized goods in transit insurance in collaboration with Hollard Insurance. The platform includes an app interface and supply chain predictions to streamline operations."
Using AI to detect information manipulation,"The project focuses on employing AI technologies to identify and analyze manipulated images and videos on social media, aiming to uncover misleading narratives and trends. It produces reports and visualizations to enhance understanding of information distortion."
HelloTask: multichannel job platform for blue-collar workers,"HelloTask is a multichannel job platform funded by USAID/Asia, designed to connect blue-collar workers with clients for care services through a smartphone application. To enhance accessibility for lower-income users without smartphones, the platform is developing an AI-based interactive voice response (IVR) system that allows users to verbally interact with job placement functions via feature phones. This technology will enable domestic workers to accept or decline jobs and provide feedback by speaking into their phones."
Georgian speech-to-text transcription,The Georgian speech-to-text transcription tool utilizes automatic speech recognition (ASR) technology to convert spoken language into written text. It aims to provide users with an efficient solution for transcribing large volumes of audio data with high accuracy and speed.
Skhivi: AI tools for Georgian journalists,"Skhivi is an AI tool tailored for Georgian journalists, providing features such as a news aggregator, trend analysis, and polarization metrics. It is currently being utilized by local media outlets like Tabula and Aprili and offers an online dashboard with visualizations and reports. The team is now welcoming subscription requests for access to more advanced features."
Intelligent forecasting for Family Planning products (Cote d'Ivoire),The project focuses on optimizing health supply chains for family planning products in Cote d'Ivoire by implementing intelligent forecasting methods. This approach aims to reduce costs and improve the quality of care by preventing stock-outs of essential products. The initiative leverages supply chain predictions to enhance overall efficiency and effectiveness in healthcare delivery.
Intelligent forecasting for Malaria products (Cote d'Ivoire),"The project focuses on enhancing health supply chains in Cote d'Ivoire to optimize the availability of malaria products. By implementing intelligent forecasting methods, it aims to reduce costs and improve the quality of care by minimizing stock-outs of essential supplies. Supply chain predictions are central to this initiative."
Intelligent forecasting for Routine Vaccines (Serbia),The project focuses on optimizing health supply chains for routine vaccines in Serbia through intelligent forecasting. It aims to reduce costs and enhance quality of care by preventing stock-outs. Utilizing advanced supply chain predictions will improve the efficiency of vaccine distribution.
Intelligent forecasting for COVID-19 vaccines (Mali),The project focuses on intelligent forecasting for COVID-19 vaccine distribution in Mali by optimizing health supply chains. It aims to reduce costs and enhance the quality of care by preventing stock-outs of vaccines through accurate supply chain predictions.
Intelligent forecasting for TB products (Indonesia),The project focuses on optimizing health supply chains for tuberculosis (TB) products in Indonesia. It aims to reduce costs and enhance the quality of care by preventing stock-outs through intelligent forecasting based on supply chain predictions. The initiative seeks to improve overall health outcomes by ensuring consistent availability of TB medications and resources.
Drip irrigation system with AI control,"The GEAR Center has developed a smart drip irrigation system that utilizes artificial intelligence to optimize water and energy use for smallholder farmers in water-stressed regions. By providing hyper-local weather predictions and tailoring irrigation needs to specific locations, the system enhances agricultural efficiency and addresses issues of soil degradation and water scarcity. The AI model leverages historical data and local weather sensor inputs to forecast conditions for the next 24 hours."
Streamlining recruitment with AI-powered online testing,TestGorilla is an AI-powered pre-employment testing platform designed to streamline recruitment by assessing candidates' skills and aptitudes through various objective tests. The platform focuses on minimizing biases associated with traditional resumes and improving hiring efficiency by providing detailed candidate scores and rankings.
Qualitative Analysis of Countering Violent Extremism (CVE) Community Perception Data,The project involves a qualitative analysis of community perceptions regarding countering violent extremism (CVE) using AI-assisted coding to analyze long-form survey responses. It focuses on text classification to categorize and interpret the collected data effectively. The goal is to derive insights that can enhance CVE strategies based on community feedback.
AI-based translation for key Global Health documents,"This project utilizes AI-based translation to efficiently and cost-effectively translate key USAID global health documents into the diverse languages spoken in the countries where USAID operates. By producing two documents for each translationa translated material document and a translation reportit aims to enhance the availability of essential health information for international partners and local populations. The process seeks to improve the speed and accuracy of translations, ensuring broader access to critical health resources."
Retrieval-augmented generation for government-to-government due diligence,"The project focuses on enhancing due diligence for government-to-government agreements through retrieval-augmented generation, employing AI tools to streamline the initial desk review process of the G2G Country Context Report. It involves querying authoritative documents with a standardized list of due-diligence questions, while utilizing an Excel spreadsheet for organizing questions, answers, and source citations. This approach aims to facilitate USAID's assessment of partner countries' fiscal management and budgetary systems efficiently."
ESDB/IDEA Series Classification,"The ESDB/IDEA Series Classification project aims to decrease the labor hours needed for categorizing new economic and social data indicators within the ESDB/IDEA system. It will achieve this by offering automatically suggested categories to data curation staff, facilitating more efficient classification of data series."
CDR Document Data Improvement with AI,"The project focuses on enhancing the quality and coverage of CDR documents through AI automation to overcome current staffing limitations. It aims to fill gaps in summary data, provide audio and video transcripts with summaries, and add descriptions to images. These improvements will enhance user experience, search result quality, and overall accessibility."
Evaluation Registry Abstracts Generator,The Evaluation Registry Abstracts Generator automates the creation of USAID evaluation report abstracts for the Evaluation Registry Dashboard using data from existing survey fields. This automation streamlines the process and significantly reduces the labor hours required for manual content creation.
FADB QA Support Automation,The FADB QA Support Automation project aims to enhance data quality assurance and curation efficiency by automating the initial evaluation process. This includes classifying activities based on DAC purpose codes and identifying relevant countries and regions in activity descriptions. The automation will provide suggested DAC purpose codes and geographical identifiers for a list of activities.
TOSSD Data Curation Automation,"The TOSSD Data Curation Automation project aims to streamline the data curation process by automating initial classifications of activities related to research and development, alignment with international public good definitions, and scoring for benefits and compliance with TOSSD guidance. It also includes automated classification of activities according to applicable Sustainable Development Goals (SDGs) and provides suggestions for activity category classifications and scoring. This automation seeks to significantly reduce the effort required for data curation."
BHA/DMEAL: Application Review Processes Automation,"The BHA/DMEAL project automates the review processes for partner-submitted RFSA applications using AI and ML algorithms, reducing the burden on BHA staff. It provides support for M&E Plan reviews by flagging missing components and summarizing narratives, while also offering initial scoring and identifying issues in RFSA applications. Additionally, the project analyzes trends and issues in solicitation and application reviews through data from Issues Letters, aiming to enhance the efficiency and transparency of the review process."
BHA/DDAIM: Decision Support via CHOPP,"The BHA/DDAIM project aims to enhance decision support through the implementation of the ""Ask CHOPP"" feature, which offers on-demand generative AI insights, and by improving emergency application processing to align with USAID/BHA guidelines. It also focuses on increasing situational awareness by analyzing programming trends and enriching contextual understanding through data integration. Finally, the project seeks to generate comprehensive reports from both structured and unstructured data for better reporting and analysis."
GenDev Key Issue Narrative Generation,"The GenDev Key Issue Narrative Generation project utilizes AI to process, validate, and summarize narratives from USAID's Gender Development sector. The project involves parsing Implementing Mechanism (IM) data, reviewing narratives for compliance with reporting criteria, synthesizing review notes into concise summaries, and creating keyword-based harmonized summaries. The output includes lists of extracted IM names and compliance data along with summarized narrative reviews."
USAID CDM-XDR (Extended Detection and Response),"The USAID CDM-XDR project enhances cybersecurity by deploying advanced detection, hunting, and response tools to identify and address vulnerabilities within the Agency's IT infrastructure. Security telemetry data is transmitted via software agents to a USAID proxy and directed to a cloud-based management console, offering a centralized platform for security analysts to monitor and manage threats effectively."
Boomitra: Accelerating soil carbon removal on a planetary scale.,"Boomitra is a project focused on accelerating soil carbon removal globally by employing satellites and AI technology to monitor soil moisture, nutrients, and carbon levels. It assists farmers in decreasing water and nutrient consumption by 30% while simultaneously improving soil fertility. The initiative is supported by the WFP Innovation Accelerator and produces reports and visualizations to track its progress."
"DARTS: Accurate, accountable cash transfer data and reconciliation","DARTS is a user-friendly web application developed for WFP country offices that leverages advanced machine learning to ensure the accuracy and accountability of cash transfer data and reconciliation. This tool allows for the implementation of controls on large cash transfer datasets and the generation of reconciliation reports, which are essential for effective cash assistance programs. Funded by the WFP Innovation Accelerator, DARTS enhances efficiency, builds trust, and guarantees accurate fund distribution."
EYouth: Learning and training opportunities for refugees and host communities,EYouth is an AI-driven learning platform that offers training and educational opportunities for refugees and host communities. It provides various online learning paths designed to equip young people with essential skills for employment. The initiative is supported by the WFP Innovation Accelerator and focuses on customizing learning content to meet diverse needs.
Ignitia: AI-powered weather forceasts for smallholder farmers,"Ignitia delivers AI-powered, localized weather forecasts to smallholder farmers in the tropics via SMS, utilizing a predictive model that is twice as accurate as global forecasts. The platform has served 2.7 million farmers, with around 700,000 as repeat users, enhancing agricultural productivity. This initiative is supported by the WFP through grant funding to bolster its agribusiness models."
SKAI: Large-scale assessment of building damage,"SKAI is an open-source tool leveraging satellite imagery and AI to automatically assess building damage on a large scale during disaster response. It provides real-time insights and actionable intelligence, facilitating data-driven decision-making for organizations and expediting humanitarian assistance to affected households. The project is funded by the WFP Innovation Accelerator and combines advanced machine learning algorithms with extensive satellite data."
NEMO: Real-time categorization of hotline calls,"NEMO is a project designed to enhance the quality and efficiency of feedback and complaint collection from hotline calls by utilizing AI for real-time categorization. It incorporates customized open-source algorithms and existing AI services, offering automated speech-to-text transcriptions, real-time categorization support for operators, and error identification. The initiative is funded by the WFP Innovation Accelerator."
"WFP AI Sandbox: Platform to innovate, pilot, and scale AI models and use cases","The WFP AI Sandbox is a collaborative platform designed to enable WFP colleagues and partners to experiment with and scale AI models and use cases. It aims to enhance efficiency and impact by fostering innovation, while also investing in talent, establishing ethical governance, and creating a responsible-use roadmap. The initiative is funded by the WFP Innovation Accelerator and focuses on piloting use cases with the potential for scalability."
Enhancing Smart Agriculture in Rural Africa,"The project ""Enhancing Smart Agriculture in Rural Africa"" aims to reduce post-harvest loss by utilizing real-time data collection powered by TinyML and AI technology. It focuses on early detection of pests and diseases to minimize crop losses and improve agricultural practices. The initiative is supported by the WFP Innovation Accelerator East Africa Regional Hub, providing valuable reports and visualizations to farmers."
Emata: Affordable digital finance for farmers,"Emata is a Ugandan fintech and licensed microfinance institution that provides affordable digital financing to farmers by utilizing technology and partnerships with agricultural cooperatives. The company forgoes traditional collateral requirements by employing AI-powered alternative credit scores based on farmers' delivery histories. Emata aims to empower farmers to transform their farms into profitable businesses and invest in sustainable futures, with support from the WFP Innovation Accelerator East Africa Regional Hub."
SoilPro 2.0: Advancing impact monitoring & monetization,"SoilPro 2.0 is a project in collaboration with SoilWatch that enhances impact monitoring and monetization by integrating advanced environmental monitoring techniques using satellite imagery, machine learning, and in-field testing. The project leverages robust data from AIMS to assess the effectiveness of Nature-Based Solutions (NBS) and develop a toolkit for funding and carbon financing in the region. It is funded by the WFP Innovation Accelerator East Africa Regional Hub."
RAG system for FEWS NET food security reports,"The FEWS NET Data, Learning and Communications Hub is creating a Retrieval-Augmented Generation (RAG) model using 40 years of historical food security reports, supported by AWS SageMaker. This model enables analysts to quickly search for and retrieve relevant information using natural language, providing links to the original reports. Ultimately, it enhances access to historical data and supports informed, data-driven decision-making for future projects."
Generating SQL queries from natural language,"The FEWS NET Data, Learning and Communications Hub is creating an application that enables users to generate SQL queries from natural language, utilizing a secure database schema. This tool facilitates access for analysts with limited SQL knowledge, allowing for efficient data extraction from the FEWS NET Data Warehouse. As a result, it improves accessibility and streamlines data retrieval, enhancing the availability of critical insights for informed decision-making."
API queries from natural language prompts,"The FEWS NET Data, Learning and Communications Hub is creating an application that allows a large language model (LLM) to convert natural language prompts into API queries by interpreting OpenAPI specifications. This application enables users to easily extract data or receive answers based on API responses, streamlining data interaction for those without extensive API expertise."
Interactive exploration of FEWS NET food security reports,"The FEWS NET Data, Learning and Communications Hub is launching a dashboard application developed by CIAT, leveraging natural language processing (NLP) to facilitate interactive exploration of 40 years of food security reports. This tool enables users to analyze the evolution of food security trends and drivers across the countries covered by FEWS NET, providing valuable insights through reports and visualizations."
Media synthesis for food security,"The FEWS NET Data, Learning and Communications Hub is developing a dashboard application that utilizes natural language processing and machine learning to analyze social and formal media for insights on food security. This application, created by the International Center for Tropical Agriculture, assesses media content for relevance based on a comprehensive taxonomy pertaining to food insecurity drivers, providing reports and visualizations to enhance understanding of the issue."
"AI translation of water, sanitation, and hygiene learning materials","CAWST, a partner funded by BHA WASH, utilizes AI technology to translate online learning materials related to water, sanitation, and hygiene (WASH). This project aims to enhance accessibility and understanding of crucial WASH information across diverse populations. Reports detailing the project's progress are also provided."
Labeling and classifying food security activities,"The project utilized AI and machine learning models to analyze and label 3,000 BHA files related to resilience food security activities from 2015 onwards. This classification was based on a taxonomy developed specifically for the Food Assistance and Food Security Assessment (FAFSA-3). The initiative was funded by ALT through a buy-in to IPI's Technical Assistance Project for Economic Growth (TAP-EG) award."
SOPHIA: Solutions Platform for Humanitarian analysis,"SOPHIA is a tool developed by ACAPS, part of the Norwegian Refugee Council, designed to enhance humanitarian analysis. It utilizes natural language processing (NLP) to sift through hundreds of data sources in over 70 languages, providing users with targeted information on specific indicators."
DEEP: Data Entry and Exploration Platform,"DEEP is an online platform designed for the storage, sharing, and analysis of humanitarian data, with a focus on unstructured and qualitative information. It incorporates an AI component that utilizes natural language processing (NLP) to efficiently filter, annotate, and categorize content, streamlining data summarization for decision-makers. The platform also provides reports and visualizations to enhance data exploration and insights within the humanitarian community."
AI for humanitarian logistics,"Handicap International is developing an AI-based operational decision support tool that automates the analysis of field data to aid humanitarian logistics in the Cabo Delgado and Nampula regions. This tool models a complex logistical environment by mapping interactions among various entities like warehouses, airports, and hospitals, thereby enhancing understanding of their interconnectedness. The project is funded by the Humanitarian Grand Challenge and includes reports and visualizations to assist aid providers in optimizing their strategies."
"SMARTplus: digital system for fast, reliable malnutrition data tackling the health-crisis in Somalia","SMARTplus is a digital system developed by Action Against Hunger to address malnutrition in Somalia through rapid and reliable data collection. It employs 3D scanning technology to streamline the gathering of nutrition and mortality statistics, analyzing and verifying the data before visualizing it on a public dashboard. This innovative approach minimizes delays and reduces the risk of using inaccurate information, supporting more effective responses to the health crisis."
HOPE and HELP: Modeling for complex humanitarian engagement,HOPE and HELP is a project developed by Lensinsight and AllSource Analytics that utilizes advanced technologies such as Machine Learning and Complex Event Processing to streamline the collection of community feedback in humanitarian efforts. The initiative also supports project and stakeholder management and is funded by the Humanitarian Grand Challenge. Results include reports and visualizations to enhance understanding and engagement.
Advanced language technology in marginalized languages for efficient information gathering,"Translators Without Borders US Inc. is developing advanced language technology specifically for marginalized languages to enhance data quality and engagement in humanitarian contexts. This initiative aims to facilitate efficient information gathering, thereby improving the understanding of humanitarian needs in remote regions. The project is funded through the Humanitarian Grand Challenge and includes the creation of an app interface."
Camp forecast: AI-driven supply chain forecasting to reach 7% more refugees without spending more,"Camp Forecast (CF) is an AI-driven tool designed to enhance supply chain forecasting for humanitarian camps. By accurately predicting resident numbers and necessary supplies, CF aims to increase assistance to 7% more refugees while maintaining current expenses. The project is supported by the Humanitarian Grand Challenge and provides valuable reports and visualizations to camp managers."
Humanitarian language toolkit: AI-enabled qualitative engagement with conflict populations,"The Humanitarian Language Toolkit project, developed by Kobo, Inc., aims to utilize AI-enabled natural language processing (NLP) to facilitate qualitative engagement with populations affected by conflict. The toolkit will enable field workers to automatically record, transcribe, and translate interviews using standard data collection platforms, enhancing their efficiency and accuracy in humanitarian settings. This initiative is funded through the Humanitarian Grand Challenge."
Chatbot photo diagnosis for malnutrition,"The ""Chatbot Photo Diagnosis"" project, developed by Fundacin Accin Contra el Hambre in collaboration with the World Food Programme, aims to enhance the diagnosis and monitoring of malnutrition through a smart communication platform. This innovative chatbot interface enables effective engagement and assessment of nutritional status, supported by funding from the Humanitarian Grand Challenge."
PathVis: A water monitoring device for Vibrio cholerae detection,"PathVis is an innovative water monitoring device designed for the rapid detection of Vibrio cholerae, delivering results in under 30 minutes. The device automatically logs data to a cloud server and can upload information via a Wi-Fi hotspot in remote areas, offering automated, time-stamped, and location-specific records. It represents the first technology of its kind for water-based V. cholerae detection, supported by funding from the Humanitarian Grand Challenge."
NeedsBot - Aggregating real-time needs from anywhere via chatbot,"NeedsBot is a chatbot-based platform that allows vetted frontline responders to text urgent resource needs into the NeedsList, which aggregates this information in real-time. This secure data collection enables quick responses from various stakeholders, including individuals, corporations, and governments, in the humanitarian aid sector. The project is funded by the Humanitarian Grand Challenge and includes features for reporting and data visualization."
Using technology to combat violence against female refugees,"ActionAid in London is implementing a low-cost mobile platform designed to support female refugees by providing crucial information on rights, services, and safe spaces, as well as allowing for incident reporting and risk mapping in urban environments. The initial pilot will be launched in partnership with a Mobile Network Operator and Women's Protection Action Groups, with funding from the Humanitarian Grand Challenge. The project aims to combat gender-based violence by enhancing access to resources for at-risk women and girls."
AutoAnthro: 3D scanning for improved malnutrition assessment in conflict areas,"AutoAnthro is a 3D scanning system developed by Body Surface Translations, Inc. that enhances the assessment of malnutrition in conflict areas by providing accurate digital measurements of children's anthropometric data. The system efficiently captures essential metrics such as length/height, mid-upper arm circumference (MUAC), and head circumference for children aged 0-5 years, ultimately improving health outcomes in both individual and population contexts. This initiative is supported by the Humanitarian Grand Challenge."
Machine learning enabled safe water optimization tool for humanitarian response,"The project at York University develops a cloud-based tool that employs machine learning to optimize safe water practices for humanitarian responses. By analyzing water quality data, it generates tailored chlorination instructions for various field sites globally, ensuring safe drinking water according to specific conditions. This initiative is funded by the Humanitarian Grand Challenge."
Combatting health misinformation in Yemen,"The SecDev Foundation collaborates with local partners in Yemen to combat health misinformation in conflict-affected communities. By utilizing trusted local networks and various communication channels such as emergency alerts, online campaigns, and radio bulletins, the initiative ensures that accurate health information reaches those in need. This project is funded by the Humanitarian Grand Challenge."
AI-enabled air raid sirens and war crime documentation,"Hala Systems Inc. is developing AI-enabled air raid sirens that leverage predictive algorithms and community engagement to monitor various forms of violence, such as artillery and mortars. The project will also utilize blockchain technology to create immutable evidence of war crimes, and it is funded through the Humanitarian Grand Challenge initiative."
AI tools for volunteer mapping,"The Missing Maps project, supported by the Humanitarian OpenStreetMap Team in the United States, engages volunteers to map uncharted regions using user-friendly, open-source tools. Remote volunteers utilize satellite imagery to create base maps, which are then refined and verified by local volunteers and agencies. This collaborative mapping effort provides critical hyper-local data to enhance life-saving crisis response initiatives."
Chatbot to provide accurate COVID-19 information,"The project is a chatbot developed by Translators without Borders US Inc. that delivers accurate COVID-19 information in users' native languages to combat misinformation. Currently deployed in the Democratic Republic of the Congo, it aims to expand to additional languages and countries, making reliable pandemic information accessible via platforms like WhatsApp and Messenger. The initiative is funded by the Humanitarian Grand Challenge, targeting vulnerable communities with critical health information."
Imagery authentication from conflict zones,"Sealr is an innovative mobile app that utilizes AI and blockchain technology to authenticate imagery from conflict zones, enabling vulnerable populations to securely report their needs. As the first verified image-capture app for humanitarian crises, Sealr aims to enhance efficiency in feedback systems within the sector. The project is funded through the Humanitarian Grand Challenge."
Tracking COVID-19 misinformation on social media,"Murmurate is a project that tracks the spread of COVID-19 misinformation on social media, particularly in conflict-affected areas. Utilizing Computer Vision and Natural Language Processing, it analyzes online conversations to identify harmful public health misinformation, which informs the creation and dissemination of corrective messaging. The project is funded by the Humanitarian Grand Challenge and produces various reports and visualizations to support its findings."
Bambara language processing tool,"The Bambara language processing tool aims to enhance the tracking of narratives in Bambara, which is spoken by 90% of Mali's population. It addresses the current technological gap in monitoring unverified messages that often stem from French sources. The tool will provide reports and visualizations to analyze the spread of social media narratives in Bambara."
Repair Spend,"The Repair Spend model classifies financial expenses as either ""facility repairs"" or ""not facility repairs."" This automation aims to reduce manual labor in identifying transaction types and provides recommendations on categorizing repair-related expenses."
ARS Project Mapping,"The ARS Project Mapping model analyzes research plans from the Agricultural Research Service to identify patterns and opportunities among different projects. It aims to reduce the time spent on manual project evaluation by grouping similar projects and extracting key terms, while also uncovering patterns that may be overlooked by human reviewers. The model provides output metrics, such as silhouette scores and importance scores, to evaluate the relevance and similarity of the grouped projects."
NAL Automated Indexing,NAL Automated Indexing is a system that assigns relevant word tags to agricultural research articles using a controlled list from the National Agricultural Library Thesaurus (NALT). These tags enhance user experience by simplifying the search and retrieval of articles pertinent to their needs. The model generates specific search tags based on the content of each analyzed article.
Predictive Modeling of Invasive Pest Species,"The project develops a predictive model to assess the likelihood of imported agricultural products carrying invasive pest species. It aims to enhance the discovery and quarantine processes for these pests, thereby preventing invasions and improving trade safety. The model predicts both the presence of invasive species in the products and categorizes the specific type of pest."
Detection of Pre-symptomatic HLB Infected Citrus,"The project aims to develop a model that identifies citrus trees infected with Huanglongbing (HLB) disease by analyzing images captured by a camera sensor on a drone. This automated detection system improves efficiency by reducing the time and costs involved in manually searching for infected trees, providing GPS coordinates of potential HLB-affected areas."
High Throughput Phenotyping in Citrus Orchards,"The project focuses on using drone imagery for high throughput phenotyping in citrus orchards, enabling the identification, counting, and categorization of citrus trees. This system significantly reduces the labor required to detect plant damage and disease, as it efficiently flags images indicative of issues within the orchard."
Detection of Aquatic Weeds,"The project aims to develop a system that utilizes drone imagery to detect and identify aquatic weed species. By automating this process, the system is designed to significantly reduce the time required for manual image review, providing efficient and accurate species identification."
Automated Detection & Mapping of Host Plants from Ground Level Imagery,The project focuses on the automated detection and mapping of specific tree species using ground-level imagery from streetview images. It aims to reduce the time and costs involved in manual data collection by providing GPS coordinates for flagged locations of host plants.
Democratizing Data,"The ""Democratizing Data"" system analyzes published documents to assess the use of publicly-funded data in science and society. It supports the National Agricultural Statistics Service and the Economic Research Service in understanding user engagement with their data, enhancing customer service, program evaluation, and informing planning decisions. The model generates text that includes references to the identified datasets."
Land Change Analysis Tool (LCAT),"The Land Change Analysis Tool (LCAT) generates high-resolution maps to facilitate informed land use decisions. It has been employed for nearly 40 years to monitor eastern redcedar in South Dakota and assist with wildlife hazard assessments at airports, significantly decreasing labor hours needed by the Farm Service Agency in Georgia for land data accuracy reviews. LCAT produces detailed land cover maps as part of its outputs."
OCIO/CDO Council Comment Analysis Tool,"The OCIO/CDO Council Comment Analysis Tool is a prototype designed to enhance the efficiency of comment reviews by identifying and grouping similar comments based on their main topics and themes. This tool streamlines the review process, reduces redundant development efforts across government agencies, and helps in cost savings by providing valuable insights. The model categorizes comments into groups, facilitating quicker and more organized analysis."
Retailer Receipt Analysis,"The Retailer Receipt Analysis system utilizes optical character recognition (OCR) to convert physical inventory documents into digital text, enhancing the efficiency and consistency of document review. It also categorizes and identifies food items within the outputted digital text."
Ecosystem Management Decision Support System (EMDS),"The Ecosystem Management Decision Support System (EMDS) utilizes AI-powered tools within ArcGIS and QGIS to facilitate environmental analysis and planning. This system aids stakeholders in making informed decisions regarding natural resource management by identifying landscapes that require attention and recommending appropriate management actions based on cost, effectiveness, and policy considerations."
Cross-Laminated Timber (CLT) Knowledge Database,"The Cross-Laminated Timber (CLT) Knowledge Database provides a specialized resource for researchers, practitioners, and the public to access information about timber products efficiently. The system facilitates faster information sharing and reduces the time required for manual searches, presenting outputs in the form of webpage links."
Raster Tools,"Raster Tools is a system that leverages machine learning techniques for geospatial applications, offering standardized methods that enhance work quality and user productivity. Its API delivers various AI outputs, primarily in raster images and data tables, facilitating easier access to advanced analytical capabilities in geospatial projects."
TreeMap and FuelMap (all versions),"TreeMap is a comprehensive tool designed to model US forests, assisting in carbon measurement, fuel treatment planning, landscape vegetation modeling, and fire effects assessment. It creates detailed forest maps along with a database of individual tree records and fuel characteristics, serving users such as the US Forest Service, private companies, and state governments."
Landscape Change Monitoring System (LCMS),"The Landscape Change Monitoring System (LCMS) is designed to track changes in land cover and land use across extensive areas over time. It provides a consistent methodology for monitoring landscape alterations and generates predictions on vegetation gain, vegetation loss, and different land uses."
Forest Health Detection Monitoring,"The Forest Health Detection Monitoring project utilizes satellite data to detect tree damage by analyzing changes in light patterns. This method enables the Forest Health Protection program to monitor inaccessible areas and provides outputs that indicate the stage of forest health, along with mapped polygons for targeted monitoring."
Cropland Data Layer,The Cropland Data Layer project generates supplemental estimates of crop acreage and provides geospatial data products for users. It produces output that includes acreage estimates and agriculture-specific land cover products.
List Frame Deadwood Identification,"The List Frame Deadwood Identification model accurately identifies farms that may no longer be operational, enhancing the National Agricultural Statistics Service's data. By establishing clear rules for identification, the model generates a probability score indicating the likelihood of a farm being out of business, allowing for smaller sample sizes and reducing the respondent burden."
Climate Change Classification NLP,"The Climate Change Classification NLP model analyzes the National Institute of Food and Agriculture's funding portfolio to identify projects related to climate change. This model aims to streamline reporting processes by reducing labor hours and enhancing the accuracy and repeatability of identifying and classifying climate-related projects for internal review. The output categorizes projects as either ""climate change related"" or ""not climate change related."""
Video Surveillance System,"The Video Surveillance System utilizes facial recognition technology to enhance security and streamline operations. It reduces the need for technician labor while improving surveillance capabilities by delivering positive identification matches to the security control center, along with alarm notifications to alert security personnel."
Aquisition Approval Request Compliance Tool,The Acquisition Approval Request Compliance Tool identifies potential IT purchases lacking an Acquisition Approval Request to reduce unauthorized purchases and enhance compliance with IT procurement procedures. The tool generates a score reflecting the likelihood that a purchase is related to IT.
Operational Water Supply Forecasting for Western US Rivers,"The National Water and Climate Center has developed a multi-model machine-learning metasystem (M4) to improve water supply forecasting for rivers in the Western US. By leveraging AI and data science technologies, the system reduces forecast errors, enabling stakeholders to make more informed decisions about water supply availability. The M4 model produces accurate water supply forecasts to aid in resource management."
Standardization of Cut Flower Business Names for Message Set Data,"This project employs Natural Language Processing (NLP) to standardize and match producer names with varietal information for the cut flower business, facilitating the transition from manual to automated inspection systems. The automation significantly enhances efficiency by enabling the management of thousands of entities simultaneously. The model provides comparative lists of producer names and cut flower varieties before and after standardization."
Intelligent Ticket Routing,"The Intelligent Ticket Routing system automates the process of directing help desk tickets to the correct group, eliminating the need for manual re-routing. This enhancement increases customer satisfaction by reducing transfers and hold times while also decreasing average handle time (AHT) for issue resolution. The system predicts the appropriate group for ticket management, thereby expediting the overall resolution process."
Predictive Maintenance Impacts,"The Predictive Maintenance Impacts project utilizes a natural language processing (NLP) model to evaluate the potential impact of infrastructure maintenance changes at the Digital Infrastructure Services Center (DISC). By scoring proposed changes on a scale from 0 to 1 based on their likelihood of causing incidents, the system aims to enhance the review process and address specific needs, ultimately leading to improved productivity, performance, job satisfaction, client satisfaction, and achievement of key performance indicators (KPIs)."
Artificial Intelligence SPAM Mitigation Project,"The Artificial Intelligence SPAM Mitigation Project involves an AI/ML model that classifies and removes spam and marketing emails from civil rights complaints email channels. This project streamlines email management, minimizes the load on email systems, and reduces exposure to malicious emails by flagging and filtering unwanted communications."
Approximate String Matching (aka fuzzy matching) to Standardize Data,"The project utilizes a fuzzy matching model to automatically correct typos in Plant Protection and Quarantine (PPQ) program data by replacing them with standardized producer and commodity names. This automation leads to clean, standardized data, significantly reducing labor hours for manual cleaning and enabling near-real-time reporting. The improved accuracy of the data enhances program managers' ability to enforce policies and monitor programs effectively."
Automated PDF Document Processing and Information Extraction,"The project focuses on automating the processing of thousands of PDF documents to extract program and workforce-related information. It converts the extracted data into structured database tables, enabling real-time analytics and dashboard creation, thus facilitating decision-making and significantly reducing time investment compared to previous methods."
Census Propensity Scores via ML,"The Census Propensity Scores model utilizes machine learning to predict the likelihood that individuals or operations will complete the Census of Agriculture. These predictions enable data collectors to strategically focus their efforts on areas with lower response rates, ultimately improving the completeness of census responses. The model provides probability scores ranging from 0 to 1 for each individual or operation."
Ecological Site Descriptions (Machine Learning),"The project utilizes machine learning to analyze over 20 million soil data records and 20,000 ecological text documents, generating comprehensive soil-based ecological information for the country. It significantly reduces labor hours required for manual analysis and allows stakeholders to access and interpret records in innovative ways for better decision-making. The AI model produces ecological soil classifications and mappings."
Conservation Effects Assessment Project,"The Conservation Effects Assessment Project aims to provide real-time predictions of the impact of cropland practices on sediment and nutrient levels, without requiring technical expertise. The model outputs specific changes in sediment and nutrient values based on various conservation methods, assisting field conservation planners in their decision-making."
Digital Imagery (no-change) for NRI Program,"The Digital Imagery project for the National Resources Inventory (NRI) program utilizes AI algorithms to analyze approximately 72,000 aerial images annually, identifying changes in landscapes over time. By automating the detection of ""no-changes,"" the project aims to significantly reduce the labor hours required for technicians to manually interpret these images. This enhancement will improve efficiency and accuracy in data collection for the NRI program."
Nutrition Education & Local Access Dashboard,"The Nutrition Education & Local Access Dashboard aims to deliver county-level insights regarding nutrition education, food access, and related metrics on hunger and nutritional health. This interactive tool enables users to analyze specific characteristics such as farm to school intensity and program participation, facilitating the discovery of comparable states for potential partnerships. The dashboard enhances stakeholder awareness and supports informed decision-making and collaboration across counties and states."
Survey Text Remarks Value Scoring,"This project aims to analyze a substantial volume of text from survey responses and assign priority scores to individual comments. High-scoring text snippets are prioritized for human review, allowing for more efficient responses to valuable feedback. The model effectively ranks the text, ensuring that significant comments are addressed promptly."
Survey Outlier Detection Model,The Survey Outlier Detection Model identifies abnormal values in surveys to enhance data quality and reduce manual labor. It generates recommendations for which specific values in a dataset should be edited.
Multilingual Translation of Recalls and Public Health Alerts,"The project aims to enhance the multilingual dissemination of food safety information, including recalls and public health alerts, by utilizing a translation system. This initiative offers cost savings on translation services, accelerates the distribution of messages, and increases accessibility to various languages for the public. The model generates translations from original English text, facilitating broader communication of important health information."
Genomic Analyses of Pathogen Subtypes,"The project uses machine learning techniques to categorize foodborne pathogens based on genetic patterns and correlates this data with health information to assess their risk to public health. It aims to enhance the understanding of significant genetic markers, identify critical germs, and recognize emerging trends in foodborne illness. The model provides predictions of high-risk pathogen subtypes and ranks key genetic markers by their significance."
Foodborne Illness Source Attribution,"The Interagency Food Safety Analytics Collaboration (IFSAC) combines efforts from the CDC, FDA, and FSIS to utilize computer-based methods for predicting the sources of foodborne illnesses in humans caused by various germs. This initiative aims to enhance understanding of germ origins and transmission, leading to effective prevention measures and policies. The model provides predictions of illness sources along with confidence scores regarding their accuracy."
Public Comments Analysis,"The Public Comments Analysis project aims to automate the examination of comments from regulations.gov, streamlining the review and response processes for personnel. The model provides text analysis and categorization of public comments, significantly reducing the labor hours required for these tasks."
Rangeland Analysis Platform,"The Rangeland Analysis Platform (RAP) is a tool designed to monitor changes in plant growth and coverage in agricultural ecosystems over time. It provides data on fractional plant cover and net primary productivity to assist in guiding conservation practices, wildlife habitat management, and carbon assessments. This system ultimately aids in evaluating the effectiveness of conservation efforts."
Predictive Cropland Data Layer,The Predictive Cropland Data Layer system predicts crop rotations to enhance the quality of area-based surveys. It provides forecasts of the types of crops grown in specific locations throughout the Conterminous United States (CONUS).
Dam Inspection Report Document Processing,"The Dam Inspection Report Document Processing AI is designed to extract and organize data from thousands of dam inspection documents, streamlining the analysis of over 2,100 USDA Watershed program dams in Oklahoma. This solution enables users to visualize dam conditions and identify key issues and trends through Microsoft Power BI, while significantly reducing the manual labor required for data processing. The AI produces outputs that include dam metadata, inspection issue tracking, and detailed remarks regarding repairs or actions needed."
Portfolio Approval and Management (PAM) Bot,"The Portfolio Approval and Management (PAM) Bot is designed to enhance the research approval process at the Economic Research Service (ERS) by streamlining information submission and approval requests. It improves efficiency, accuracy, and transparency in tracking approval status across divisions, delivering three key outputs: approval status, summary recommendations, and generated citations."
GIS Invasive Tree Extraction for Field Level Users,"The project aims to create a model for estimating the spread of Eastern redcedar, an invasive tree species, to assist field level users. By automating data collection, the model reduces inaccuracies caused by time constraints and heavy workloads. It generates polygons that represent the geographical extent of the tree infestation in the landscape."
DISTRIB-II: Habitat Suitability of Eastern United States Tree,"The DISTRIB-II project focuses on assessing habitat suitability for various tree species in the eastern United States in the context of climate change. It provides valuable information for forest managers and landowners by predicting how different tree species may adapt to changing climates, supported by GIS-generated maps, graphs, and reports. This helps inform forest management decisions regarding current and future tree habitats."
FSA FLP Chatbot,The FSA FLP Chatbot project aims to improve customer service by enabling employees to quickly access loan handbooks and provide accurate information. It also seeks to offer specialized responses for Veterans regarding their services. The primary output will consist of text responses to user inquiries.
ROE Document Recognition - RoeDR,"The ROE Document Recognition (RoeDR) model automates the analysis of documents from producers and Authorized Insurance Providers by extracting the producer's signature name and signature date. This data is converted to text and loaded into an application, significantly reducing manual data entry. The extracted information can then be utilized for reporting purposes."
IRIS,"IRIS is a system designed to enhance the efficiency of literature searches for Biotechnology Regulatory Services, thus improving regulatory work tasks. It provides scientists with a curated list of recommended literature to facilitate their research."
Ticket Resolution Categorization (Incident/Change),"The Ticket Resolution Categorization model classifies closed support desk tickets based on their resolution type and tier. This automation enables the support team to focus on identifying process inefficiencies and developing solutions, resulting in improved processes, increased productivity, and enhanced performance. The model ultimately provides a streamlined output of categorized support ticket resolutions."
Ticket Templatization,"The Ticket Templatization model is an exploratory tool that analyzes service and change requests to identify trends and insights for data-driven decision making. It aims to uncover subcategories in the dataset that may benefit from standardization and automation, which could enhance operational efficiency, reduce costs, and improve customer satisfaction. The model focuses on outputting trends to support effective decision-making processes."
File Rename Automation,"The File Rename Automation tool streamlines the process of renaming thousands of digital documents that have generic file names. By extracting text from the first page of each document, it generates appropriate file names automatically, significantly reducing the time and effort required by employees. The tool outputs newly renamed files, enhancing organizational efficiency."
Rapid Drafting of ARS Research Summaries,"The Rapid Drafting of ARS Research Summaries tool is designed to efficiently summarize ongoing research within the Agricultural Research Service (ARS), enabling program staff to quickly produce accurate summary documents. By streamlining this process, staff can allocate more time to other tasks, while leadership receives the necessary materials to address inquiries and support budget requests effectively. The tool generates talking points and concise briefing papers to enhance communication and promote the relevance of ARS research."
DS Hub Geo-metadata generation,"The DS Hub Geo-metadata generation project utilizes generative AI to produce consistent and compliant metadata for NRCS datasets. This initiative aims to enhance data accessibility, streamline workflows by reducing manual tasks, and improve the understanding and retrieval of geospatial data for stakeholders. The resulting metadata ensures accuracy and adherence to established standards."
Dynamic Soils Hub ,"The Dynamic Soils Hub (DS Hub) is a tool developed by the Natural Resources Conservation Service (NRCS) to facilitate the understanding and analysis of soil information for both government employees and the public. By linking various soil and conservation databases, it allows for a comprehensive evaluation of the environmental benefits of conservation programs and improves the USDA's capability to study changes in soil properties resulting from conservation efforts. The DS Hub also provides classifications of soil based on input information."
Cover Crop Mapping,"The Cover Crop Mapping project develops annual state-level maps of cover crop use in the U.S. Midwest by utilizing satellite imagery and plant growth models to identify cover crops in the fall and spring. This mapping provides data that allows agencies to monitor and verify farmers' cover crop practices remotely, reducing the necessity for on-site inspections."
Planting Date Detection,"The Planting Date Detection project analyzes satellite images and plant growth models to determine the planting dates of corn, soybean, and winter wheat in the U.S. Midwest. The resulting annual maps for crop years 2016-2023 enable agencies to verify farmers' reported planting dates independently, decreasing the necessity for on-site field visits. This enhances the integrity of agricultural programs."
Acreage and Crop Type Validation,"The project employs satellite imagery and plant growth models to validate the reported sizes of farm fields and the types of crops grown in the U.S. Midwest. The resulting data supports the independent verification of reported field sizes and crop types, specifically for corn, soybean, and winter wheat, thus enhancing the integrity of agricultural programs."
U.S. Poultry Operations and Populations Dataset,The U.S. Poultry Operations and Populations Dataset aims to provide comprehensive information on the locations of poultry farms and their bird populations. This dataset is crucial for planning animal health emergencies and predicting disease spread. The final output will be a national-level dataset detailing domestic poultry operations and estimated populations.
Equine Operations and Populations Dataset for the U.S.,The project aims to create a comprehensive dataset that maps horse farm locations and population counts across the United States. This dataset addresses the issue of incomplete information that is crucial for emergency planning and disease management in equine operations. The final output will include national-level data on domestic horse farms and their estimated horse populations.
NASS - Naggle 2.0 Automated Editing Tool,"The NASS - Naggle 2.0 Automated Editing Tool is designed to enhance the accuracy of survey responses by classifying answers as valid or invalid. For invalid answers, a regression model suggests corrected values, streamlining the editing process and reducing labor hours. The outputs include a classification report on the validity of variables and a regression output detailing corrections for invalid records."
County-level remotely-sensed corn and soybean yield estimation,"The project provides a tool for estimating annual corn and soybean yields at the county level using satellite imagery. The model outputs yield estimates in bushels per acre, offering stakeholders valuable data for informed planning and decision-making. This approach enhances forecasting accuracy for agricultural productivity in the United States."
NASSportal Intranet Bot,The NASSportal Intranet Bot is designed to assist National Agricultural Statistics Service (NASS) staff by providing quick answers to questions related to program administration. This implementation aims to reduce labor hours and enhance the efficiency of NASS staff in managing their programs through automated text responses.
XyloTron/XyloPhone Wood Identification System,"The XyloTron/XyloPhone Wood Identification System is designed to identify various types of wood by analyzing their cross-sections. These tools assist industries in compliance with national and international regulations, such as the Lacey Act and CITES, by providing predictions about wood types."
Incident Invoice Document Understanding,"The Incident Invoice Document Understanding tool analyzes incident invoices to extract necessary data for database entry, streamlining the invoice processing workflow. This approach enhances efficiency by decreasing processing time and minimizing data entry errors. The resulting output is an Excel document with the identified values from the invoices."
Forest disease detection and screening,"The project aims to enhance the diagnosis and screening of tree diseases, supporting disease management efforts within and outside the Forest Service. It utilizes a model that predicts whether a tree is diseased and assesses its resistance or susceptibility to specific diseases."
Use of LLMs for data extraction,"The project aims to utilize large language models (LLMs) for efficient data extraction from scientific papers related to plant diseases. This approach significantly reduces the time and potential errors associated with manual information collection. The model produces a structured table containing key data variables such as country, pathogen name, and host name."
IPWG Application Survey Analysis,"The IPWG Application Survey Analysis project involves analyzing over 5,000 employee survey responses regarding IT applications to provide summarized feedback and sentiment analysis for each application. This tool streamlines the review process, enabling the team to make quicker, informed investment decisions. Additionally, the project will feature a dashboard that visualizes relevant attributes across various levels, such as agency and individual responses."
Fire Resilent Landscapes,"Fire Resilient Landscapes is a tool designed to quantify the costs associated with forest treatments. It enables users to accurately map treatment costs, facilitating more informed decision-making through the generation of raster surfaces and maps."
PC Rasterize,"PC Rasterize is a tool designed to enhance the efficiency of processing point cloud data, thereby reducing associated costs. It generates both point clouds and raster surfaces/maps as outputs."
Spread and Balance Sample Design,"The Spread and Balance Sample Design tool generates well-distributed and balanced samples, minimizing the number of samples required and lowering field data collection costs. It provides output in the form of data frames and geospatial data frames."
"Regression, Classification, Clustering with Hilbert Curves","This project aims to enhance regression, classification, and clustering techniques using Hilbert curves, which will improve the accuracy of estimates while minimizing costs and errors. The output will consist of data frames and raster surfaces/maps, providing valuable insights for various applications."
"The Big Data, Mapping, and Analytics Platform (BIGMAP) Project","The BIGMAP Project aims to enhance the accuracy of forest characteristic estimations by leveraging geospatial predictions derived from Forest Inventory and Analysis samples. By producing predictions as raster maps, the project facilitates more informed decision-making regarding US forest resources."
BirdNET to detect bird vocalizations for research and species monitoring,"BirdNET is a tool designed to efficiently analyze extensive forest audio recordings to identify bird vocalizations, focusing on key species for forest monitoring. This automated system significantly reduces the time and cost of manual audio analysis by producing text files that document the species and timing of detected bird calls."
Hurricane impact descriptions,"The AI model is designed to transform data on a tropical cyclone's path and its estimated impact on forests into clear narrative reports for rapid assessments following a cyclone. This tool automates the storytelling process, producing concise, easy-to-read summaries that enhance the quality of reports provided to stakeholders."
Predictive flood modeling,The predictive flood modeling tool is designed to forecast water flow during floods and evaluate the vulnerability of drains beneath roads. It provides the U.S. Department of Transportation and USDA Forest Service with essential data to guide decisions regarding drain restoration and flood protection. The model outputs include predictions of water flow during flood events and assessments of drain vulnerability.
FuelCast,"FuelCast is a predictive system designed to enhance fuel management by forecasting future fuel conditions and providing early warnings for US firefighting teams. It improves preparedness for potential large wildfires and alleviates the workload of fire behavior analysts by delivering accurate fuel estimates, reducing the reliance on trial and error methods for assessing fire behavior patterns. The model outputs predictions regarding the future availability of wood and plants that may fuel wildfires."
R1 Forest Vegetation Modeling,R1 Forest Vegetation Modeling utilizes satellite imagery and LiDAR technology combined with machine learning to model forest vegetation and generate estimates. This approach enhances the accuracy of the models while reducing both time and costs. The project produces predictions in the form of raster and vector geospatial maps.
ESRI Support Chat Bot,"The ESRI Support Chat Bot is designed to streamline support requests related to geospatial software by facilitating communication between users and the software vendor. It saves time and minimizes the volume of support tickets sent to the Forest Service Geospatial Helpdesk and ESRI. The chatbot provides users with support ticket entries, code snippets for queries, and relevant text and links for assistance."
Wildlife deterrent system,"The wildlife deterrent system uses AI for video object detection to identify coyotes and activate an electrical barrier, preventing their entry through gaps in a fence while allowing other wildlife to pass. This technology facilitates ecological research that would otherwise be hindered and reduces the time spent monitoring camera footage and manually controlling the fence."
The Lost Meadows Model,"The Lost Meadows Model aims to identify historical meadow locations and their frequency to assess their potential for restoration. By predicting areas with meadow-like environmental conditions, the model enhances opportunities for biodiversity, wildfire management, carbon storage, and water storage. The outputs include a combination of undocumented meadows, former meadow lands, and potential meadow-like areas."
Markov random fields,"The Markov random fields tool aims to enhance the accuracy of estimates in machine learning models, particularly for managing mixed forests. It provides predicted counts of tree species in a specific area and assesses the competition among different species, enabling stakeholders to make informed and effective management decisions."
AI for regional forest mapping and monitoring,"The project aims to develop an AI model that utilizes satellite images and USDA Forest Service survey data to produce detailed maps of forest structures. The resulting GeoTiffs provide valuable information on attributes like tree density and species, enhancing the planning capabilities of land managers."
IOL Focus Group and Survey Sensemaking,"The IOL Focus Group and Survey Sensemaking model efficiently processes large volumes of focus group transcripts and survey results, significantly reducing the labor hours required for manual analysis. It produces concise text summaries of comments and survey feedback, streamlining the synthesis of qualitative data."
Esri ArcGIS Pro Deep Learning Modules,"The Esri ArcGIS Pro Deep Learning Modules are designed to standardize Geographic Information System (GIS) workflows for scientific modeling and analysis. This tool will produce image classifications, enhancing the capabilities of GIS analytics."
EMC Comment Parsing and Analysis,"The EMC Comment Parsing and Analysis project focuses on extracting, categorizing, and responding to public comments using past responses to create a standardized handling process. It aims to improve accessibility of public comment data for AI, reduce processing time and costs, minimize human errors, and enhance responsiveness, public trust, and accountability. Additionally, the project will build a database of common themes and response strategies to support team training."
QUIC-Fire processing and analysis,"The QUIC-Fire project leverages AI to analyze data from fire-atmosphere models, aiming to enhance understanding of fire behavior and its impacts. The outcome will be a set of metrics that aid fire and smoke managers in using the QUIC-Fire model for planning controlled burns and evaluating wildfire behavior effectively."
Analysis of prescribed fire turbulence data,"This project focuses on analyzing the relationship between heat generated by wildfires and the resulting air turbulence. By utilizing AI, it aims to enhance the accuracy of tools used by fire and smoke managers for effective smoke management. The model produces correlation analyses that link temperature changes to air turbulence measurements above prescribed fires."
Complaint Summarization,"The Complaint Summarization project aims to assist support staff in efficiently analyzing and reviewing consumer complaint narratives and company responses amid rising complaint volumes. It involves creating brief narrative summaries that encapsulate the key concepts within these complaints, thereby facilitating internal reviews and avoiding costs associated with prolonged analysis."
Ask Complaints,"The project focuses on supporting staff in analyzing complaints by generating quantitative data to address user inquiries. It aims to enhance production scalability while facilitating cost avoidance. Additionally, it provides summary data points for different cohorts of complaints."
Complaint Narrative Redaction,"The Complaint Narrative Redaction project aims to redact personally identifiable information (PII) and other identifying details from consumers' complaint narratives to facilitate large-scale data sharing. This initiative focuses on cost containment, privacy protection, and enhancing informed consumer consent, ultimately allowing consumers to make educated decisions about the publication of their narratives."
Document Review Tool,"The Document Review Tool is designed to aid investigations by providing support for reviewing key documents. It streamlines the process of analyzing essential information, enhancing the overall efficiency of investigations."
Anomaly Detection for Data Quality,"The project involves creating an anomaly detection model to identify erroneous data loads in TCR data. It employs an isolation forest model that operates automatically on a daily basis, generating an anomaly score for the complete dataset of a single exchange."
Spoofing Detection AI/ML Project,"The Spoofing Detection AI/ML project utilized advanced AI and machine learning techniques to analyze order message data for identifying spoofing patterns. It combined various supervised and unsupervised methods with existing expert-based spoofing detection algorithms, resulting in a model that estimates the probability of spoofing behavior for each trader in a given market on a specific day."
Stress Testing Scenarios with Deep Learning,The project focuses on employing deep learning techniques to develop stress testing scenarios for Futures and Options portfolios. It utilizes neural networks to estimate profit and loss by predicting price movements based on current and recent market conditions. The AI generates these predictions using specified input probabilities.
MPD Entity Risk Modeling,"The MPD Entity Risk Modeling project aims to develop statistical and probabilistic models to predict capital level changes for firms. This early-stage R&D effort will generate a daily now-cast score for each registrant, indicating the probability or risk category for potential near-future capital adjustments."
Microsoft Copilot Integration,"The Microsoft Copilot Integration project aims to enhance efficiency and streamline administrative tasks through the use of text-based summaries and AI-generated content. By leveraging advanced AI capabilities, it focuses on automating routine processes to save time and improve productivity."
Clearinghouse Network ,"The Clearinghouse Network is a collection of exclusive online communities designed for state and local election officials, hosted on the Roundtable platform. It features AI tools that summarize lengthy text and video content to assist election officials in accessing and understanding relevant information efficiently."
Language Translation,"This project focuses on enhancing language translation services by improving the quality, efficiency, and accessibility of these services. It incorporates advancements in text-to-speech and speech-to-text technologies to streamline communication in multiple languages. The overall goal is to facilitate better understanding and interaction in diverse linguistic settings."
Reasonable Accommodation,"The Reasonable Accommodation project aims to enhance the quality, efficiency, and accessibility of services through the implementation of text-to-speech and speech-to-text technologies. By integrating these tools, the project seeks to better support individuals with varying communication needs. Ultimately, it focuses on fostering inclusive environments for improved service delivery."
Virtual Assistants,"The Virtual Assistants project aims to enhance the quality, efficiency, and accessibility of services through advanced text-to-speech and speech-to-text technologies. By leveraging these capabilities, the project seeks to improve user interactions and streamline communication. The focus is on delivering a more effective and user-friendly experience across various applications."
Employee Training and Professional Development,"The project focuses on enhancing employee training and professional development to improve the quality, efficiency, and accessibility of services. It aims to foster a skilled workforce capable of adapting to evolving industry demands. Ultimately, this initiative seeks to generate better overall service outcomes."
Legal Research & Discovery,"The project focuses on enhancing the quality, efficiency, and accessibility of legal research and discovery services. It aims to generate pertinent legal information that supports enforcement actions and litigation processes."
Records Management,"The Records Management project focuses on ensuring the integrity of electronic data by implementing systematic processes for creating, organizing, indexing, and accessing digital documents. It prioritizes compliance with established standards for effective data management."
FOIA,"The project aims to enhance the Freedom of Information Act (FOIA) process by developing a system for the generation, categorization, and classification of public comments based on priority or topic. This improvement will streamline the handling of policy and legal comments, facilitating more efficient responses and better organization of information."
Cybersecurity,The project focuses on enhancing cybersecurity practices by identifying and classifying anomalies within systems. It aims to improve threat detection and response mechanisms to safeguard data integrity and protect against cyber threats.
Invoice and Contract Data Extraction,"The project focuses on extracting data from invoices and contracts in PDF format to enhance the accuracy and efficiency of reconciliation processes. It aims to reduce the time Oversight Managers (OMs) spend on these tasks by generating an Excel output that highlights discrepancies and errors, which is then emailed to them. This automation improves overall operational efficiency in managing financial documents."
Server Failure Prediction,"The Server Failure Prediction project aims to use predictive intelligence to identify servers at risk of failure, thereby preventing work stoppages for the FDIC. It employs natural language processing to automatically generate help desk tickets for these at-risk servers. The project will produce a list of servers predicted to fail and corresponding system-generated help desk tickets."
Plain Language Policy Assistant,"The Plain Language Policy Assistant is an AI tool designed to help FDIC policy writers comply with the Plain Language Writing Act. It evaluates drafts for clarity, simplicity, active voice, conciseness, and the use of jargon and acronyms, offering feedback and redrafting sections to align with PLWA principles."
Knowledge Article Generation,"The Knowledge Article Generation project aims to automate the creation of draft Knowledge Articles following server outage incidents, thereby saving staff time and improving service efficiency. This initiative will enable the Infrastructure Operations Systems Branch (IOSB) to leverage self-service solutions, reduce support caseloads, and decrease average handle times for server-related issues. Ultimately, the project enhances the overall service experience by allowing IOSB team members to access valuable information around the clock."
AI Coding Assistant,"The AI Coding Assistant is designed to improve coding efficiency and precision by providing real-time code suggestions, generating unit tests, debugging code, and translating code between languages. It also offers explanations and comments to clarify code functionality. This tool aims to streamline the coding process for developers."
Content Creation,"The project focuses on creating generative content to reduce the time needed for content creation and increase the overall volume of materials available. It aims to provide interactive resources that assist students who struggle with note-taking and classroom engagement, ultimately enhancing their learning experience."
Immersive Learning,"Immersive learning utilizes Generative AI to create realistic training environments, allowing learners to practice and improve their skills in controlled, interactive scenarios. This innovative approach enhances employee engagement, retention, performance management, and various HR processes such as onboarding and recruiting. Additionally, it provides predictive analytics on learner progress and completion rates relative to set objectives."
Course Recommendation ,"The project aims to develop a course recommendation system that suggests personalized learning paths based on employees' historical data and needs. This system is designed to enhance employee engagement, retention, performance management, and onboarding by providing industry-specific training recommendations. Ultimately, it supports workforce planning and facilitates achievement of learning and development milestones."
Student Monitoring ,"The Student Monitoring project aims to enhance course engagement and success by tracking progress and comprehension. It utilizes predictive analytics to adapt learning experiences for individuals, offering insights on completion rates and course milestones. The initiative also supports performance management and employee onboarding through continuous learning and development."
Plagiarism Detection ,"The project focuses on detecting and preventing plagiarism to promote the FDIC's values of fairness, accountability, and integrity. It aims to reduce the time spent on manual plagiarism inspections by providing automated reports that flag suspected instances of plagiarism along with their sources."
Student Outcome Projection ,"The Student Outcome Projection project focuses on early intervention in student academic growth by accommodating diverse learning styles and levels, thereby personalizing the educational experience. It aims to improve employee onboarding and retention through tailored learning and development programs that align with industry-specific tasks, leading to customized training reports for each user."
Facilitating Status ,"The project involves overseeing activities and conducting evaluations in both supervised and unsupervised settings to ensure compliance with industry standards and facilitate the accreditation of Corporate University courses, such as Accounting Continuing Education Units (CEUs). It includes generating reports to confirm physical attendance for both in-person and virtual sessions."
AI Assisted Data Collection,"The AI Assisted Data Collection project automates the extraction of data from PDF form documents to improve the efficiency of fair lending and compliance functions. This automation significantly reduces the time required for data collection, enhances accuracy, and enables FDIC examiners to concentrate on examination activities. The extracted data is provided in Excel-readable formats for easier analysis and accessibility."
AI Assisted Time Management,The AI Assisted Time Management project aims to enhance the efficiencies of Process HQ by utilizing the FOCUS framework to analyze the Examination process. It will generate a report detailing time allocation and pinpoint specific bottlenecks that hinder progress in compliance and CRA activities.
Compliance Risk Monitoring,"The Compliance Risk Monitoring project aims to improve off-site risk monitoring across various regulatory areas. It includes a report from Division of Consumer Protection (DCP) Analytics that assesses the relative compliance violation risk of financial institutions, which examiners utilize to define the scope of their examinations."
Analysis of Consumer Complaints,"The project focuses on analyzing consumer complaint trends by utilizing AI for pre-processing complaints to improve their adjudication. It involves cleaning and categorizing consumer complaints, which are then stored in a data lake for further post-processing analysis. This approach aims to enhance the efficiency of understanding consumer issues and deriving actionable insights."
Pre-Examination Planning Monitoring,"The Pre-Examination Planning Monitoring project focuses on assisting examiners in effectively planning for exams by identifying misaligned pre-exam questions that do not contribute to risk assessments. It involves generating a report from the Division of Consumer Protection Analytics to the DCP Compliance and UDAP section, ensuring that pre-exam questions align with risk identification objectives."
Einstein Call Center Assistance,"The Einstein Call Center Assistance project aims to enhance the categorization and routing of consumer cases within the Epic system for Enterprise Public Inquiries and Complaints. This improvement will enable call agents to handle cases more effectively and efficiently by ensuring better tagging and organization of calls. Overall, the project seeks to streamline the call center operations and improve customer service."
HMDA (Home Mortgage Disclosure Act) Outlier Screen,"The HMDA Outlier program analyzes off-site mortgage data to detect potential fair lending risks concerning pricing, underwriting, and redlining. It generates reports from statistical analyses to assist in examination supervisory actions."
FDIC Deposit Insurance Misrepresentation ,The Division of Consumer Protection Analytics is utilizing AI technology to analyze social media posts for potential misrepresentations of FDIC deposit insurance. The project aims to compile a spreadsheet report that highlights specific posts related to banks and their associated deposit insurance claims. This initiative seeks to enhance consumer awareness and protect against misinformation.
Aggregating Complaint Data,The DCP Exams aims to enhance the efficiency of analyzing complaint data to better identify trends and concerns within complex banks. The project will focus on developing methods for aggregating this data to facilitate clearer insights and decision-making. Further details regarding implementation are to be determined.
Financial Well-Being Project,"The Financial Well-Being Project created the first comprehensive census of non-profit organizations offering various financial well-being services. This initiative supports the FDIC's goal of enhancing economic inclusion by facilitating better connections between banks and local non-profits that provide essential financial services. Additionally, the project includes a classification system for the types of financial well-being services offered by these organizations."
Generative Artificial Intelligence (AI) for Legal Research,"The project focuses on implementing generative artificial intelligence to enhance legal research capabilities, enabling users to obtain information more quickly and efficiently. It aims to improve the research process for attorneys by integrating commercially available legal research tools equipped with generative AI features. This development aligns with the mission of providing superior research support to users in the legal field."
Outlook Unstructured Text Extraction ,The Corporate Services Branch (CSB) is conducting a pilot project to test the extraction of unstructured text from emails in group mailboxes using a custom AI prompt. This initiative aims to condition the extracted data for reporting and tracking Key Performance Measures. The project will also assess the feasibility of automating this process and provide training for CSB Citizen Developers.
Public-Facing ChatBot,The Public-Facing ChatBot is an initiative by the Enterprise Information and Records Management Section (EIRMS) aimed at reducing inquiries to the FDIC Contact Center. It will utilize the RASA open-source platform and Natural Language Processing (NLP) to deliver standardized responses regarding deposit insurance and coverage. The project is currently pending a vendor platform to implement the chatbot technology in a government cloud environment.
Purchase Card Activity Monitoring,"The Purchase Card Activity Monitoring project aims to automate the detection of prohibited and restricted purchase card transactions using a Machine Learning (M/L) algorithm, reducing the manual effort currently required. It will involve creating a training and test dataset from actual purchase card activity to establish the algorithm's accuracy, which will then be visualized in a dashboard or report. The M/L system will generate data extracts highlighting non-compliant purchase card activity across the FDIC."
AI-driven Workflow Automations to Improve Business Operations,"The project focuses on leveraging AI-driven workflow automation to enhance business operations, specifically within Human Resources. It involves collaborating with vendor software to integrate various AI capabilities, such as generative AI and intelligent chatbots. The expected outcomes include decision trees that provide real-time insights and aid in identifying trends to boost performance."
Automatically-Scored Writing Assessment (AWA),"The Automatically-Scored Writing Assessment (AWA) is designed to enhance the efficiency and affordability of essay scoring in employment decisions. It provides a total score on a scale from 1 to 5, along with three subscale scores that evaluate grammar and mechanics, analysis and reasoning, and organization and structure."
Structured Interview (SI) tool,"The FDIC is developing an online Structured Interview (SI) tool to enhance the personnel selection process through automation. This tool will manage the scheduling, creation, administration, scoring, and maintenance of structured interview materials while securely storing a vast array of internally developed, competency-based interview questions."
FDIC Predictive Budget Analysis,"The FDIC Predictive Budget Analysis project involves analyzing budget data to compare reported figures with actuals, helping to identify discrepancies. This process streamlines report generation, enhances responsiveness, and facilitates in-depth data exploration. The final output provides detailed explanations of the identified gaps in data and the reasons for these discrepancies."
CFOO Assessment Chatbot,"The CFOO Assessment Chatbot compiles data from the FDIC website and specific documents to provide users with searchable and accessible information regarding Bank Assessments. It offers text-based responses to inquiries, enhancing public access to relevant data about bank assessments available on the FDIC.gov site."
Goals and Workload Assumptions,"The project aims to compile and narrate divisional efforts, factoring in staff numbers and competencies, to enhance response times for data-driven inquiries. It will include a visualization to assess the effectiveness of divisional projects and provide recommendations to address any gaps in missing elements or competencies."
CFOO Admin Chatbot,"The CFOO Admin Chatbot aggregates information from the internal FDIC website and relevant documents to provide users with text-based answers regarding CFOO administration. This project enhances public access to information, making it more searchable and user-friendly."
CFOO Travel Chatbot,"The CFOO Travel Chatbot leverages data from the internal FDIC website and relevant documents to provide users with quick, searchable answers about FDIC travel inquiries. It enhances accessibility and readability of travel information for users."
CFOO Transactional Data Analysis,"The CFOO Transactional Data Analysis project utilizes AI to enhance financial monitoring by identifying issues such as improper invoice submissions and duplicate payments. This initiative has significantly decreased the time needed for error detection, reviews, and the creation of data visualizations. It also provides recommendations for addressing identified gaps, including explanations and potential causes."
FDIC Staffing Model,"The FDIC Staffing Model focuses on monitoring retention rates, retirement planning, and knowledge retention to improve succession strategies. It aims to reduce response times for inquiries, enabling staff to concentrate on essential mission-driven tasks. Additionally, it offers predictions on future staffing needs and recommendations for achieving diverse organizational goals."
FDIC Financial Audit Report,"The FDIC Financial Audit Report involves monitoring employee transactions to ensure compliance with regulations and policies. The initiative aims to reduce the time required to obtain responses, enabling employees to concentrate on more critical mission-driven tasks. Additionally, the report identifies inconsistencies with outside policies and makes recommendations on whether emerging trends require attention."
Risk Identification and Response,"The project focuses on applying a risk model to identify risks and analyze them using additional data sets to uncover correlations. The goal is to enhance the corporation's ability to quickly and accurately assess and report on risks, ultimately reducing overall risk exposure. The outcome will include recommendations based on identified correlations and a report detailing potential solutions."
FDIC Narrative Reports Generation,"The FDIC project involves analyzing quarterly narrative and table data to produce internal narrative reports. This initiative streamlines the reporting process, significantly reducing response times and enabling staff to concentrate on essential mission-driven activities. The outcome includes a report or table summarizing the quarterly data points, enhanced with visualizations for clarity."
FDIC Investment Portfolio Management ,"The FDIC Investment Portfolio Management project involves analyzing historical investment data and conducting predictive analyses to enhance investment decision-making. The initiative aims to decrease response times for investment inquiries, enabling staff to concentrate on more essential mission-driven tasks while providing an additional layer of investment analysis for comparison. Additionally, it offers predictions on the likely outcomes of potential investment choices and recommendations for optimizing the current portfolio."
Analytics on Loan Data,"The project focuses on analyzing a portfolio of failed bank loans to streamline the process, which is typically time-consuming and labor-intensive. It involves formatting unstructured data into a structured dataset, providing data-supported strategies for effective portfolio disposition."
Analytics on Securities Data,"The project focuses on analyzing securities data to streamline the evaluation of failed bank loan portfolios, significantly reducing the time and labor involved in this complex process. It involves formatting unstructured data into a structured dataset, which facilitates the development of data-driven strategies for effectively managing and disposing of the portfolios."
Business Data Extraction from Loan Files,"The project involves extracting and formatting data from unstructured loan documents into a structured format, optimizing this process to reduce costs and effort. This enables efficient analysis of failed bank loans, leading to data-supported strategies for managing the portfolio. Ultimately, it produces a structured dataset from previously unstructured files."
Data Extraction from Security Prospectus,"The project focuses on transforming unstructured data from security prospectus documents into a structured format efficiently and at scale, resulting in reduced costs and efforts. This process enhances the analysis of failed bank loans and facilitates data-driven strategies for managing the portfolio. A formatted dataset containing essential elements extracted from the original documents will be produced."
Deposit Insurance Determination,"The Deposit Insurance Determination project focuses on extracting and formatting data from unstructured documents to streamline the management of provisional holds on bank accounts exceeding $250 million. This initiative aims to reduce the costs and efforts involved in releasing or retaining these holds, while providing structured data sets for analysis by Claims Specialists."
Initial Deposit File Analysis,The Initial Deposit File Analysis project involves evaluating various data files in different formats to extract and normalize key input data into a cohesive dataset. This dataset will include a list of accounts and assets with essential data elements necessary for insurance determination and asset valuation for analysis by other functional areas within the FDIC.
Owned Real Estate (ORE) Property Appraisal,"The Owned Real Estate (ORE) Property Appraisal project focuses on validating and enriching loan data by extracting information from Loan Underwriting, Title, and Property Appraisal Documents. This process aims to expedite the valuation of loan portfolios and enhance valuation quality. Additionally, it generates a comprehensive list of property records that includes current and historical appraised values along with sale transaction details."
Trust Document Entity Extraction,"The Trust Document Entity Extraction project focuses on extracting key elements, such as grantor/settler and beneficiaries, from Trust Agreements to decrease the time and cost associated with transcribing this information. The extracted data, combined with the original Trust Agreement, will be made accessible to users via an application user interface."
Trust Document Entity Extraction - LLM,"The Trust Document Entity Extraction project aims to automate the review process for monetary claims related to Trust Accounts, significantly reducing processing time. It utilizes a Gen AI-powered function to extract and validate data from Trust Documents against customer inputs, minimizing the need for manual intervention and legal reviews. The extracted information, along with the original Trust Agreement, will be accessible through a user-friendly application interface."
Post Examination Survey Comment Analysis,"The Post Examination Survey Comment Analysis project aims to categorize a diverse range of comments from survey participants to improve comprehension and analysis of their feedback. The approach may involve organizing entire comments or segments of them into a structured format, potentially utilizing a table with comments in one column and corresponding categories in the rows. This systematic classification will facilitate better understanding of the survey results."
Extracting IT information,"The AlphaREx algorithm performs horizontal analysis of unstructured narrative content in IT examination workpapers and Reports of Examination (ROE), providing actionable insights to support the FDICs supervision modernization initiative. It automates the collection, analysis, and visualization of both structured and unstructured data from various sources to identify IT and cyber risks for insured deposit institutions. This information is essential for trend analysis, pattern recognition, and improving FDIC IT examination processes."
Transcribing Structured Interviews,"RMS Atlanta is initiating a pilot project to implement transcription technology for structured interviews, enabling panel members to focus on the applicant rather than note-taking. The goal is to enhance the interview process by allowing easy access to recorded structured answers while AI assists rather than replaces traditional note-taking methods. The end product will be a transcription of the interview audio."
New Offsite Models,"The New Offsite Models project focuses on developing a machine learning model to predict banks that are likely to be downgraded from 1- and 2-rated to 3-rated or worse. The initiative aims to enhance the accuracy of bank downgrade predictions by utilizing advanced ML techniques, resulting in a ranked list of banks based on their likelihood of receiving a downgrade."
Document Indexing,"The Regional Automated Document Distribution and Imaging System (RADD) is an electronic document management system that facilitates the indexing of supervisory correspondences between the FDIC, financial institutions, and other regulators. Currently, indexing is a manual process conducted by approximately 24 individuals, using a table-driven schema to ensure accurate indexing of nearly two million documents. The project aims to implement AI/ML technologies to automate and enhance the indexing process, thereby reducing labor costs and improving the accuracy of document classification."
eDiscovery Organize & Search,"The eDiscovery Organize & Search project utilizes commercially available software to manage the vast amounts of electronically stored information by employing machine learning techniques. This AI-driven software organizes and identifies relevant documents from large datasets based on user-defined searches, while human users are tasked with verifying the AI's suggestions. This approach streamlines the eDiscovery process, making it more efficient and manageable."
Leverage AI in the Rulemaking Process Use Case ,"The AI solution aims to enhance the efficiency and accuracy of FERC's rulemaking process by automating the review of public feedback. It will analyze sentiment and identify key themes, enabling FERC analysts to save costs, reduce regulatory timelines, and implement energy policies more effectively for the benefit of the industry and the public."
Improve Safety Inspections Use Case ,"The AI solution aims to improve the safety inspections of dams and LNG pipeline structures conducted by FERC inspectors by analyzing historical and real-time visual data. It enhances both the efficiency and accuracy of inspections, identifying potential safety defects and trends while reducing the manual workload for inspectors. This innovative approach is set to streamline inspection timelines significantly."
Enhance Market Surveillance and Fraud Detection Use Case ,"The AI solution is designed to enhance market surveillance and fraud detection by analyzing large and complex datasets for market integrity and compliance. It processes trading data swiftly to identify anomalies and potential regulatory violations, thereby supporting staff in maintaining fair markets and improving compliance. This tool aims to save time, increase efficiency, and uphold public trust in market operations."
Support Interconnection Request Responses Use Case ,"The AI solution aims to streamline the processing of project interconnection requests, significantly reducing the average three-year wait time. By addressing the backlog of requests, the system will enable FERC to achieve cost savings and enhance efficiency in proposal management. The use of AI will facilitate thorough analysis of interconnection requests, optimizing response times."
LexisNexis,LexisNexis has developed a generative AI-assisted legal research tool that enhances the efficiency of legal work for the Federal Housing Finance Agency (FHFA) by streamlining the search for and summarization of legal information. This advanced technology aims to improve the accuracy and speed of legal research tasks.
Neural Networks for FHFA Modeling Analytics Platform (FMAP),"The FHFA Modeling Analytics Platform (FMAP) project aims to enhance the production framework and specifications for the Single-Family FMAP by utilizing neural networks. This tool is designed to detect nonlinearities, anomalies, and significant variables in loan-level mortgage data, thereby assisting FHFA staff in improving forecasting accuracy for Single-Family models."
Phishing Email Identification,"Knowbe4 PhishER is a machine learning and artificial intelligence-based tool designed to identify and manage suspicious emails by categorizing them as spam, phishing, or malicious. This automation allows for faster responses to end user concerns regarding email threats, eliminating the need for cybersecurity specialists to manually analyze each report. The tool enhances efficiency in handling suspicious emails while safeguarding users from potential cyber threats."
WestLaw,"WestLaw is a generative AI-assisted legal research tool that enhances the efficiency of legal work for FHFA. It utilizes AI technology to search for and summarize legal information, streamlining the research process."
Public Comments Summarization and Topic Classifications Pilot Project,"The Public Comments Summarization and Topic Classifications Pilot Project aims to efficiently summarize and classify public comments received by the FHFA during comment processes. By utilizing natural language processing, the project enhances staff productivity by rapidly processing comments."
Virtual Acquisition Office (VAO) Ally ,"VAO Ally is an integrated feature of the Virtual Acquisition Office subscription that streamlines the process of researching acquisition-related policy and guidance questions. By analyzing various information resources, VAO Ally delivers concise responses to user inquiries and cites the source materials that informed its answers, enhancing efficiency in information retrieval."
"Analytics,, Search, Queries and LLM integration for data management on Oracle","Oracle Enterprise 23AI leverages built-in AI capabilities for predictive analytics, AI Vector search, and natural language queries. It also integrates seamlessly with Large Language Models to enhance data management functionalities. This project aims to optimize data handling and analytics within the Oracle ecosystem."
Python modules to support AI/ML,Several Python modules have been installed to facilitate artificial intelligence and machine learning projects. These modules provide essential tools and libraries for developing and implementing AI/ML solutions.
R modules to support AI/ML,The project involves the installation of various R modules that enhance capabilities for artificial intelligence (AI) and machine learning (ML). These modules provide essential tools and functions to facilitate the development and implementation of AI and ML solutions.
Security and network monitoring using Cisco Identify Services engine,"The project focuses on enhancing security and network monitoring through the Cisco Identity Services Engine (ISE), which utilizes AI to analyze network traffic and user behavior in real-time. This capability facilitates improved security visibility, segmentation, and threat response, allowing for the automatic detection, isolation, and resolution of potential security risks."
Desktop productivity using Microsoft 365,"The project focuses on enhancing desktop productivity through the Microsoft 365 suite, which includes Teams, SharePoint, Excel, PowerPoint, and Word. It leverages AI to provide functionalities such as language translation, smart recommendations, and data insights, ultimately fostering improved collaboration among users."
Virtual Desktop using Citrix ,The project focuses on leveraging Citrix technology to create virtual desktops that utilize AI for performance optimization and workload management. It also enhances security by implementing behavioral analysis and threat detection measures.
"Analytics, Indexing, and Anomaly Detection for Data Management on SQL Server ","The project focuses on enhancing data management in SQL Server through the integration of predictive analytics, automated indexing, and anomaly detection. It leverages AI technologies to improve query performance and streamline data handling processes."
Workflow automation and predictive analytics using ServiceNow,The project focuses on implementing workflow automation and predictive analytics using ServiceNow. It leverages AI to enhance service management solutions by automating processes and delivering actionable insights for improved efficiency.
Security and Compliance in file sharing and collaboration using Kiteworks,Kiteworks improves security and compliance in file sharing and collaboration through real-time detection of anomalies and potential threats. The platform leverages AI technology to enhance its capabilities in safeguarding sensitive information during collaborative processes.
"Network monitoring, anomaly detection through Whats Up Gold and Flowmon integration",The project focuses on network monitoring and anomaly detection by integrating Whats Up Gold with Flowmon. It utilizes AI to enhance network visibility and security by identifying anomalies within network traffic. This integration aims to improve overall network management and response to potential security threats.
Mathematical formula transcription using Commonlook Online,"Commonlook Online is a tool designed to convert complex mathematical formulas into plain language, ensuring accessibility in publicly released documents. This process facilitates better understanding and communication of mathematical content."
Mobile Worker Productivity using Apple iOS platform,"The project focuses on enhancing mobile worker productivity through the utilization of the Apple iOS platform's applications that incorporate Natural Language Processing (NLP). This technology predicts the next word a user intends to type in real time, offering a single tap selection for increased efficiency."
Economic Trend Modeling,"The Economic Trend Modeling project utilizes advanced data beyond traditional statistical approaches to predict economic events. It employs multiple methods to calculate the probability of such events occurring within the next twelve months, resulting in a consolidated probability score ranging from 0 to 1."
Document Organization Tool,The Document Organization Tool is designed to improve the efficiency and organization of reference materials for adversarial analysis. It utilizes labeled documents to enhance searchability and streamline information retrieval.
PDF Optical Character Recognition (Text),The project focuses on implementing Optical Character Recognition (OCR) to extract text from PDF reports. It aims to accurately identify and decide the appropriate column names from the extracted text based on a predefined list of valid column names.
PDF Optical Character Recognition (Images),"The project focuses on developing a system for Optical Character Recognition (OCR) to extract text from images embedded in PDF files. The AI system will convert the image content into a text format, facilitating further analysis of the extracted information."
Stock Market Analysis,The project focuses on analyzing media narratives related to stock market events. It employs time series analysis to examine the correlation between the frequencies of various news topics and market volatility. This research aims to uncover how news coverage impacts stock market behavior.
Earnings Calls Search Tool,The Earnings Calls Search Tool is a Natural Language Processing (NLP) application designed to summarize earnings calls and extract key takeaways. It features an interface that allows users to query different sections of public earnings reports efficiently.
Incident Reporting Pattern Detection,The project focuses on the automatic detection of network-based security risks through incident reporting pattern detection. It aims to identify potential security incidents and generate problem notifications for network administrators to enhance security measures.
Consumer Related Information Classification,"The project focuses on classifying consumer-related information in accordance with relevant regulations. It involves assigning one or more appropriate regulations to each piece of consumer information, ensuring compliance and proper handling of data."
Commercial Real Estate Index,"The project aims to develop a market index for commercial real estate by identifying a principal component through the analysis of various data points. This principal component will serve as the basis for the index, facilitating informed decision-making in the commercial real estate sector."
Variable Optimization,The project focuses on optimizing variable selection by exploring different lag structures to identify the most effective one for predicting call report metrics. This analysis aims to produce accurate forecasts for specific call report metrics.
Credit Fragment Analysis,The Credit Fragment Analysis project involves researching the various components of credit fragments and identifying key observations within the dataset. This analysis aims to enhance the understanding of credit fragmentation and its implications in the financial sector.
Cybersecurity Monitoring Tool,The Cybersecurity Monitoring Tool is designed to monitor emerging cyber risks specifically targeting the financial sector. It employs a risk ranking algorithm that utilizes a dictionary of weighted terms to assess and indicate potential threats to the financial system.
Proposals and Public Comments,"The Board of Governors of the Federal Reserve System is developing the Proposals and Public Comments (PPC) system to electronically manage and process public feedback on various regulatory proposals. The PPC system, expected to launch in mid-November 2024, will utilize artificial intelligence for efficient comment processing, including features like PII redaction and spam detection, with human verification for accuracy."
Graphic design improvements,The project focuses on improving graphic design to enhance the readability of presentations. It includes updates to slide layouts and visualizations for a more effective communication of information.
Bank Subsidiary Identification,The project focuses on identifying auto loans that are reported as subsidiaries of banks. It also aims to pinpoint loans issued by finance company subsidiaries affiliated with these banks. The overarching goal is to enhance the understanding of the banking ecosystem's subsidiary structures in relation to auto lending.
Manufacturer Sentiment Analysis,The Manufacturer Sentiment Analysis project quantifies survey responses about forecasts in industrial production. It utilizes time series data to measure the sentiment of the manufacturing sector based on feedback from survey respondents.
Supply Chain Estimations,The project focuses on estimating supply chain bottlenecks by analyzing time series data related to supply chain bottleneck sentiment. It aims to identify and quantify potential issues within the supply chain to enhance efficiency and decision-making.
Research And Development Analysis,The project focuses on quantifying the intensity of AI research and development within various industries. It aims to create a time series analysis that measures R&D investment levels over time. The findings will provide insights into trends and patterns in AI-related innovations across sectors.
Newsfeed Data Transformations,"The project involves transforming newsfeed data by applying labels that indicate the country of origin and specific topics for various articles. This includes tagging articles with labels for entities, topics, and sentiment analysis to enhance categorization and organization of the content."
Newsfeed Data Processing,"The project focuses on enhancing the processing of news articles through advanced data techniques. It utilizes a dataset that includes entity extraction, topic modeling, and sentiment analysis to facilitate better understanding and categorization of content."
Body Worn Cameras Data Management System,"The Body Worn Cameras Data Management System transcribes and redacts audio recordings, labeling them as ""unverified"" until reviewed and approved by an OIG member. It features automatic detection and redaction of sensitive information, such as computer screens, faces, and license plates, with final approval from a special agent required before sharing evidence. This system ensures the integrity and confidentiality of recorded materials."
Market Fund Portfolio,The Market Fund Portfolio project focuses on aiding the classification of issuers for money market funds. It provides a comprehensive list of potential issuers associated with specific securities to enhance investment decision-making.
Earnings Calls Analysis,"The Earnings Calls Analysis project examines company transcripts to extract key words, terms, and themes. It includes a suite of time series indicators that track the evolution of language and categorize topics over time."
Sentiment Analysis of Earnings Transcripts,"The project focuses on performing sentiment analysis on bank earnings call transcripts to identify and classify sentiments as positive, negative, or neutral. It provides additional insights into the sentiments associated with various topics discussed during these calls. This classification helps in understanding the overall tone and sentiment conveyed in the earnings communication."
Anomaly Detection,The project focuses on enhancing the iterative data quality process through anomaly detection. It aims to generate suggested messages related to the data quality of specific subsets of firm-submitted data by leveraging historical messages that address similar issues. This approach is intended to facilitate better data quality management and consistency.
Consumer Complaints Explorer,"The Consumer Complaints Explorer project aims to enhance the classification of consumer complaints by implementing topic modeling techniques. It analyzes the gamma value, assigns a topic number, and identifies the top five terms related to each narrative for improved categorization. This project facilitates better understanding and management of consumer complaints."
Graphic Design Improvements,The project focuses on enhancing graphic design processes to improve efficiency in image processing. It aims to streamline workflows and optimize the handling of images for better productivity and output quality.
Regulatory Data Analysis,The Regulatory Data Analysis project focuses on enhancing data quality for stakeholders by providing predicted percentile level values for comparison with current reported values. This allows analysts to accurately assess discrepancies and improve decision-making based on reliable data.
Decision Tree for Deposits Data,"The project involves implementing a decision tree analysis on deposits data to enhance process efficiency and improve data quality. Key variables are calculated and filtered to identify potential outliers in the reporting period data, ensuring more accurate insights."
Institutional Profile Dashboard,"The Institutional Profile Dashboard provides leadership with high-level information about district FR Y-9C reporters, facilitating informed discussions with business partners and stakeholders. It features interactive dashboards that allow for dynamic data exploration and analysis."
Novel Activities Call Report Classification,The project involves developing a random forest model to analyze call report data in order to determine which reported categories most effectively predict a bank's inclusion on novel banking activity lists. The model identifies relevant call report line items that correlate with banks on internal supervisory lists and classifies banks based on their statistical similarity to those engaged in novel activities.
Financial News Processing,The project focuses on processing financial news to extract relevant insights. It includes the development of interactive dashboards to visualize and analyze the data effectively. This initiative aims to enhance the understanding of financial trends and events through accessible and informative presentations.
Bank Exam Quality Control,The project develops a traditional machine learning natural language processing model to assess bank performance using data from news articles and other inputs. The outcomes of this model are incorporated into the bank's quality control processes.
Document Summarization Statistics,The project involves analyzing bank review letters by generating statistics based on their length and the frequency of common financial terms. The data includes insights extracted from letters housed in PDF format. This analysis aims to identify patterns and commonalities in financial communication.
Writing Quality Analysis Model,"The Writing Quality Analysis Model is a natural language processing (NLP) tool designed to assist leaders in evaluating the writing quality and consistency of documents. It generates an analysis score that reflects the consistency of the writing style, enabling users to improve their communication standards."
Comment Review System,"The Comment Review System (CRS) is an electronic platform developed by the Board of Governors of the Federal Reserve System to efficiently process and manage public comments on regulatory proposals. It utilizes artificial intelligence and traditional machine learning natural language processing techniques for tasks such as text summarization, entity identification, and duplicative comment identification. The system ensures comprehensive review of all public comments while enhancing the analysis process with advanced search and labeling functionalities."
Trading Desk Grouping,The Trading Desk Grouping project involves categorizing trading desks by their specific descriptions. Each desk is assigned an asset class type to facilitate organization and analysis. This classification aims to enhance the clarity and efficiency of trading operations.
Labor Market Analysis,"The project focuses on labor market analysis by estimating key factors influencing employment trends. It utilizes time series data to measure the frequency and quantity of layoffs, providing insights into workforce dynamics."
Entity Name Matching Tool,"The Entity Name Matching Tool is designed to enhance process efficiency by assisting analysts in comparing reported entity names against a comprehensive database of legal entity names. This tool streamlines the name matching process, ultimately facilitating better decision-making and analysis."
Time Reporting Tool,"The Time Reporting Tool automates the classification of individual work activities and generates a detailed classification report. It provides a categorized list of activities organized by time, enhancing the efficiency of time management and reporting processes."
Threshold Monitoring,"The Threshold Monitoring project aims to improve the monitoring of limit thresholds and actual values, facilitating quicker collaboration among analysts. It provides tools to enhance the efficiency and effectiveness of this monitoring process."
Supply and Demand Tool,The Supply and Demand Tool is designed to track and forecast resource and supply needs by utilizing established rule sets. It effectively monitors resources in accordance with the outcomes dictated by those rules.
Outlier Detection,The Outlier Detection project utilizes traditional AI techniques to identify and synthesize information from various firms. It focuses on delivering relevant insights and data to enhance decision-making processes. This approach aims to streamline the analysis of diverse data sources for improved information accessibility.
Earnings Call Topic Model,"The Earnings Call Topic Model is designed to classify various topics discussed during earnings calls. It systematically analyzes and organizes information, enhancing the understanding of key themes and insights shared in these calls."
Bank Performance Monitoring,The Bank Performance Monitoring project utilizes an econometric model to enhance off-site risk analysis by incorporating historical ratings. This model supports the evaluation of bank performance and assists in identifying potential risks effectively.
Network management platform,The project involves developing a network management platform that automatically detects network configuration issues. It provides real-time notifications to administrators to facilitate quick responses and resolutions. The goal is to enhance network reliability and performance.
Bank Exam Quality Control,The Bank Exam Quality Control project employs a traditional machine learning NLP model to analyze bank ratings by utilizing data from news articles among other inputs. The outcomes generated by the model serve as a component for ensuring quality control within the banking sector.
Recommendation Engine,"The Recommendation Engine connects users with relevant content by analyzing their view history and the viewing patterns of similar users. It offers two main features: recommending similar documents based on the currently viewed document, and suggesting new documents based on the user's past viewing history. This enhances user experience by providing personalized content suggestions."
Risk Rating Model- Community Banks,"The Risk Rating Model for Community Banks aims to enhance the risk classification framework used to categorize these banks based on their risk levels. It utilizes statistical methods for variable selection to inform the model, allowing for a more tailored examination intensity that aligns with the identified risks."
Risk Rating Model,"The Risk Rating Model aims to identify factors that predict the likelihood of adverse outcomes for banks, categorizing them into High-, Moderate-, and Low-risk tiers for further evaluation. It employs statistical methods for the selection of relevant variables to create an effective risk assessment model."
Automatic PSC Classification,"The Automatic PSC Classification project aims to streamline the processing of uncategorized complaints received by the FTC from various channels. It utilizes advanced data classification techniques to efficiently assign Product and Service Codes (PSCs) to the diverse content of these complaints, enhancing organization and response capabilities."
Group Duplicate Complaints,"The project focuses on grouping duplicate complaints submitted by consumers regarding the same issue across different channels. This initiative aims to streamline the process for Law Enforcement by enhancing their ability to efficiently search and identify leads amidst the multitude of complaints. Additionally, the project includes the incorporation of links to the identified duplicate complaints for easier access."
Chatbot,"The chatbot provides 24/7 unattended chat support for IdentityTheft.gov and ReportFraud.gov, ensuring assistance outside of business hours. During business hours, users can access assisted chat options for more personalized help."
Word Cloud,"The Word Cloud project employs natural language processing to create visual representations of complaints, enhancing the ability of law enforcement to analyze search results efficiently. By generating word clouds, the project aims to reduce the time needed for thorough investigation and understanding of prevalent issues."
Graph Analytics,The Graph Analytics project focuses on helping law enforcement agencies identify connections between various complaints using node diagrams. It leverages advanced data analysis techniques to visualize relationships and enhance investigative efforts. The goal is to improve the efficiency and effectiveness of crime-solving through better understanding of data interconnections.
Developer productivity,"FTC is enhancing developer productivity by integrating Generative AI, specifically Azure OpenAI GPT-4, into its workflow. This integration aims to improve efficiency in application code development."
AI Pilot Project to Screen and Flag for Personally Identifiable Information (PII) in Digitized Archival Records,"The AI Pilot Project at NARA aims to automate the screening and redaction of Personally Identifiable Information (PII) in digitized archival records, enhancing both speed and accuracy while safeguarding privacy. This initiative will generate redacted records, provide a prioritized list for further redaction, and create a tool for staff to manage unpublished records, facilitating increased public access to historical data. Additionally, the AI will support ongoing management of NARA's extensive collection in response to evolving privacy requirements."
Freedom of Information Act (FOIA) Discovery AI Pilot,"The Freedom of Information Act (FOIA) Discovery AI Pilot by NARA utilizes artificial intelligence to enhance the efficiency and accuracy of FOIA requests. The AI tools assist in identifying relevant records and automatically redacting sensitive information, thereby ensuring compliance with privacy laws while expediting the response process. The project aims to produce both the pertinent records and their redacted versions for improved public access."
Auto-fill of Descriptive Metadata for Archival Descriptions ,"NARA is implementing AI technology to automatically generate descriptive metadata for its digital archives. This initiative aims to enhance the completeness and clarity of archival descriptions, thereby improving the accessibility of records for both archivists and the public. Ultimately, it will facilitate easier navigation and comprehension of information within the National Archives Catalog."
AI based Semantic Search for National Archives Catalog,"NARA is developing an AI-based semantic search engine for its online catalog that interprets the meaning behind searches rather than relying solely on keywords. This advanced tool will reveal hidden connections between documents, making research faster, easier, and more insightful."
AI Pilot for National Declassification Center (NDC) at NARA,"NARA is implementing AI to automate the declassification of documents, enhancing speed, accuracy, and transparency in the process. This initiative aims to improve efficiency, ensure consistent application of declassification rules, and increase public access to information by producing declassified documents with sensitive information redacted."
Develop a Custom AI Model to Power Generative AI- Capabilities,"NARA is developing a custom AI model tailored to its own data to enhance the performance of its AI applications. This initiative aims to deliver more accurate results, improve user experience, and create new opportunities in record management and access. The model will be specifically designed to address NARA's unique requirements."
Develop a Natural Language Based Chat Interface (like ChatGPT) to Interact With the Archival Documents,"NARA is developing an AI-powered chat interface that allows users to interact with its digital archives using natural language, similar to ChatGPT. This interface will enhance accessibility to historical documents, facilitate more efficient research, and promote a deeper understanding of history."
"Topic Summarizer and Entity Extraction using AI
","NARA intends to utilize AI for automatic creation of descriptions for its digital objects, enhancing the accessibility and understanding of these materials. This initiative will enrich metadata, thereby improving the management of NARA's digital assets and allowing archivists to focus on other tasks."
Automated Data Discovery and Classification Pilot ,"The Automated Data Discovery and Classification Pilot by NARA aims to assess the effectiveness of AI in organizing and categorizing its data. This initiative is designed to enhance data understanding, expedite information retrieval, boost operational efficiency, and manage risks. Additionally, the pilot seeks to improve data categorization and search functions while training AI for the identification of new document types."
Voice to text transcription,The project involves creating draft voice-to-text transcriptions of investigation recordings to enhance the speed and efficiency of initial audio processing. This automated process will streamline the workflow before the recordings undergo manual transcription. The resulting draft transcriptions will facilitate quicker access to essential information from the audio files.
Semantic Similarity Text Search,"The Semantic Similarity Text Search project enhances the efficiency of researching transportation safety topics by utilizing semantic search techniques on an agency library of safety recommendation and report texts. It enables users to quickly identify relevant narratives in previously published documents, thereby streamlining access to critical safety information."
Synthetic Data Generation,"The project involves generating synthetic data that replicates the characteristics and statistical properties of real end user and pensioner data. This artificial data maintains privacy by avoiding sensitive or Personally Identifiable Information (PII), facilitating analysis, research, and software testing without compromising confidentiality."
IT Security Monitoring,The project focuses on IT security monitoring by analyzing extensive data sets of end user activity to identify anomalies and potential security threats. It aims to improve the detection and reporting of potential IT security events.
Lexis +AI,"Lexis +AI is a legal research tool designed to streamline the process of finding relevant legal information and case law. It utilizes advanced AI technology to enhance research efficiency and accuracy, enabling legal professionals to gain insights quickly. This tool aims to improve overall productivity in legal research tasks."
"Productivity and communications including the generation of insights, automation and workflow","The project focuses on enhancing productivity and communication through the generation of insights, automation, and improved workflows. It aims to foster collaboration and streamline information sharing, ultimately leading to better recommendations and enhanced organizational efficiency."
Ability to find information through search results and other methods,"The project aims to enhance information retrieval by optimizing search results and utilizing various methods for improved accessibility. It focuses on delivering accurate translations and providing answers to user queries efficiently. Overall, the initiative seeks to streamline the process of finding relevant information."
"Pattern identification, simulations, optimization and forecasting leading to alerts, notifications and reporting","The project focuses on pattern identification, simulations, optimization, and forecasting to enhance environmental awareness. It aims to improve future event predictions by generating insights, warnings, alerts, and recommendations. The ultimate goal is to provide timely notifications and reporting for better decision-making."
"Scheduling and managing social media posts using AI, including sentiment analysis","The project focuses on leveraging AI for scheduling and managing social media posts, incorporating sentiment analysis to enhance communication efforts. It aims to improve awareness and insights by providing detailed reports on social media performance and recommending effective communication strategies."
Optimized navigation for traffic and other purposes,"The project focuses on optimizing navigation to enhance traffic management and other functional purposes. It aims to improve navigation and routing systems for better travel efficiency and user experience. Overall, the initiative seeks to modernize how users navigate and route their journeys."
Comment Letter Review and Analysis ,The project focuses on improving the review process for public comment letters by providing enhanced analysis and summaries. It aims to facilitate a better understanding of the feedback received and streamline the evaluation of public input.
Forms Filed,"The project aims to automate the identification of incomplete filings by investment companies, enhancing staff efficiency in evaluating submitted information. Currently, it is in the planning phase with details yet to be determined."
Federal Acquisition Research Solution,"The Federal Acquisition Research Solution is a tool that aggregates and summarizes federal acquisition policy, best practices, and templates to address common issues faced by the federal acquisition workforce and stakeholders. It is designed to support operational activities, training, and policy formulation within the Office of Acquisition."
Human Resources Search,The Human Resources Search project delivers results to staff inquiries by identifying relevant knowledge articles and available services. It aims to streamline access to essential HR information for employees.
8-K Filing Solution,"The 8-K Filing Solution is designed to search and extract information from specific 8-K filings, including both HTML files and images. It provides organized extracts of filing data for efficient retrieval and analysis."
Training Conversation Tool ,"The Training Conversation Tool is designed to enhance the communication and collaboration skills of the SEC workforce. It provides feedback to employees on their collaborative and communication efforts, fostering a more effective work environment."
Mobile Phone Artificial Intelligence Features,"The project focuses on testing new artificial intelligence features for mobile phones. It is currently in the planning phase, with details yet to be determined."
Create Work-Related Videos,The project enables staff to produce and edit work-related videos. It focuses on the creation and modification of video content for professional use.
CF Staff Review Comments ,The project aims to classify staff comments to enhance the CF review process. It focuses on categorizing SEC staff comments for clearer and more efficient handling. This improvement will streamline the review process for CF staff.
EDGAR Filing Certification Review Solution ,The EDGAR Filing Certification Review Solution identifies potentially non-compliant 302 certifications associated with EDGAR filings. It includes tables that present data on these potentially non-compliant filings for further analysis.
Evaluating Cybersecurity Alerts,The project focuses on improving the identification of anomalous cybersecurity alerts for further review. It involves the creation of tables that organize and display these alerts for better analysis.
EDGAR Filing Audit Report Solution ,The EDGAR Filing Audit Report Solution uses a specialized tool to detect audit reports in EDGAR filings that may not comply with SEC Rules and Regulations. It generates tables that present potentially non-compliant filing data for review.
Public Filing Disclosure Review,The project focuses on reviewing public filing disclosures by summarizing their content and highlighting both differences and similarities between them. It also provides answers to user-selected questions related to the disclosures.
EDGAR Technical Support Public Chatbot,The EDGAR Technical Support Public Chatbot offers users prompt answers to technical inquiries related to accessing the EDGAR system. It provides direct responses or links to relevant technical documentation for efficient assistance.
EDGAR Filing Signature Review Solution ,The EDGAR Filing Signature Review Solution analyzes EDGAR filings to identify instances where required signatures may be missing. It generates tables that highlight potentially non-compliant filing data for further review.
EDGAR Filing Risk Disclosure Review Solution ,The EDGAR Filing Risk Disclosure Review Solution analyzes earnings call transcripts alongside EDGAR filings to evaluate risk factor disclosures. It provides a table that summarizes the comparison between earnings call data and EDGAR filings for clarity and insight.
Testing Developer Workflows,"The project involves testing developer workflows to gather insights that will inform the guidance for future AI use case development. It is currently in the planning phase, with specific details yet to be determined."
Exploring AI Products for Enterprise Use,"The project focuses on exploring web-based AI features for enterprise applications. Currently, it is in the planning phase, with details yet to be determined."
Name Matching,"The Name Matching project aims to identify similarities in names across various data sources to facilitate easier information comparison for staff. It provides a numerical output that quantifies the degree of similarity between names, enhancing data integration and analysis."
Parsing of Plain Language Descriptions to Machine-Readable Notations,"The project automates the conversion of plain-language descriptions into machine-readable standardized notations, facilitating easier analysis. It outputs standardized notations that enhance data accessibility and usability."
Identification of Potentially Manipulative Trading Activity in Registrant Data,The project focuses on identifying potentially manipulative trading activity within registrant data for further examination. It utilizes a system that highlights significant activities of interest for review by an examination team.
Testing of Various AI Algorithms and Models ,"The project focuses on testing various AI algorithms and models to assess their potential in improving examiner efficiency, productivity, and effectiveness. Currently, it is in the planning phase, with details yet to be determined."
Using Natural Language Processing Techniques to Search and Analyze Certain Filings ,The project utilizes Natural Language Processing techniques to enhance the search and analysis of unstructured filings. It provides staff with valuable insights that can inform their examination efforts. The system improves the efficiency and effectiveness of reviewing specific filings.
Using Machine Learning/Artificial Intelligence Techniques to Predict Entities With Certain Risk Characteristics,The project utilizes Machine Learning and Artificial Intelligence techniques to analyze data and predict entities that possess specific risk characteristics. The results generated by this system are intended to assist staff in their examination efforts by providing valuable predictive insights.
Developed Parsing Logic for Filings ,The project focused on developing parsing logic to improve the efficiency of searching and analyzing disclosure text in various filings. This enhancement will enable staff to more effectively process and interpret specific filings.
Identification of Potentially Manipulative Activity in Certain Accounts,The project involves creating a system that identifies accounts exhibiting potentially manipulative activity for further examination. It screens specific behaviors and flags accounts for review by an examination team.
Using AI to Help with Coding-Related Tasks/Questions,"This project utilizes AI to assist staff with coding-related tasks across a selected range of programming languages. It serves as both a practical tool for generating code and an educational resource, providing textual explanations about the coding logic and usage."
Optical Character Recognition (OCR) for Records Analysis,"The Optical Character Recognition (OCR) project assists ENF staff by extracting relevant information from digital image files, thereby speeding up ENF investigations. The output includes a text string that contains all recognized text from the associated images."
Microsoft Copilot for Internal Employees ,"USAGM is implementing Microsoft Copilot for its internal employees to boost productivity and collaboration. The tool utilizes generative AI within the Microsoft 365 suite to streamline workflows, allowing employees to focus on high-value tasks by automating processes like document drafting, content summarization, and meeting scheduling. This initiative aims to enhance operational efficiency through improved collaboration and task management."
Automated Transcription Generation ,"The Automated Transcription Generation project employs generative AI to improve the efficiency and accessibility of USAGMs media workflows. By integrating Latakoo and OpenAI's Whisper technology, the system accurately transcribes content during processing and incorporates it into USAGMs media asset management system, facilitating easy searchability and future access."
Content Enhancement for Articles ,"The project leverages AI technology to improve the quality of articles within the content management system (CMS) by generating multiple title options, automating SEO tag creation, and providing concise article summaries. These enhancements aim to boost user engagement and increase time spent on pages, particularly from search engine and social media traffic. Journalists can refine the AI-generated suggestions to align with their specific editorial goals."
Automated Translations ,"The Automated Translations initiative utilizes AI technology integrated with the content management system to enhance multilingual content production within USAGM's networks. It addresses the challenge of translating content into over 50 languages while ensuring accuracy and cultural sensitivity. This AI-driven approach facilitates draft translations for articles, promoting efficient content reuse among language teams and ensuring high-quality localized content delivery to global audiences."
AI-Powered CMS Guide Agent ,An AI-powered agent is being developed to improve user support for the CMS by providing responses to natural language inquiries. It will offer personalized guidance and solutions based on the CMS's internal help documentation.
Content Summarization and Audience Engagement ,"The project implements AI tools within the content management system (CMS) to produce multi-article summaries, smart search responses, and interactive highlights, focusing on mobile-first users. These innovations aim to enhance content discoverability, user engagement, and accessibility, while also improving comprehension for long-form articles through the use of interactive formats. Overall, the project seeks to create a seamless user experience across digital platforms."
Automated Text Narration ,The Automated Text Narration project aims to enhance accessibility and engagement for long-form articles through AI-generated audio narrations. An integrated audio player will be developed to provide users with a convenient and flexible way to consume content.
Automated Metadata Generation ,"The project focuses on utilizing AI to automate the generation of descriptive metadata, including content summaries and SEO tags. This innovation intends to streamline cataloging processes, enhance content discoverability, and minimize the manual workload involved in creating metadata."
Microsoft Copilot Integration,"The Microsoft Copilot Integration project aims to enhance efficiency and streamline administrative tasks through the use of text-based summaries and AI-generated content. By leveraging advanced AI capabilities, it focuses on automating routine processes to save time and improve productivity."
Relativity One ,Relativity One focuses on enhancing efficiency and streamlining administrative tasks. It utilizes text-based summaries and AI-generated content to improve workflow and productivity.
Lookout for mobile security,"Lookout for mobile security employs AI and machine learning to identify and mitigate cyberattacks in real-time. It offers threat intelligence services encompassing data forensics, incident response, and research, alongside a comprehensive dashboard for monitoring activities and reports."
Qualys Cloud Detection and Response,"Qualys Cloud Detection and Response employs AI to identify real-time threats, including malware, ransomware, and unauthorized access. It features a dashboard for monitoring activities and generating reports, providing real-time alerts for detected issues."
Crowdstrike Falcon Threat Detection and Response,"Crowdstrike Falcon employs AI to provide real-time detection and response to cybersecurity threats, including malware and ransomware. It features a monitoring dashboard that delivers real-time alerts and detailed reports on security activities."
Exiger Due Diligence IQ (DDIQ) Research Software,"Exiger's Due Diligence IQ (DDIQ) research software enhances the efficiency of analyzing individuals and companies for potential partnerships with USTDA. The AI reviews and consolidates relevant publicly available information, such as news reports, into a unified data set for Exiger's analysts to review and refine. This platform streamlines the due diligence process by providing an organized overview of research subjects."
Evolv WDS - OSSO,The Evolv WDS - OSSO project utilizes heat map technology to detect the heat signatures of known weapons. It focuses on identifying areas of interest that produce heat indicators matching the heat signatures associated with various types of weapons. This approach aims to enhance security measures by effectively pinpointing potential threats.
VA Chat Copilot Meta Pilot,"VA Chat Copilot is a generative AI tool designed to enhance administrative efficiency for VA employees. It enables users to upload documents and receive outputs such as draft emails, summaries, project templates, and responses to content-related inquiries. By streamlining document processing and communication tasks, it supports improved productivity within the VA."
Avigilon Camera/Search Function - OSSO,The Avigilon Camera/Search Function in the OSSO project enhances security video surveillance by enabling users to search for points of interest within the video footage. This feature allows users to efficiently retrieve specific video or images based on their search criteria.
CareCentra Next Level Personalized AI Health Coach,"The CareCentra Next Level Personalized AI Health Coach is an evidence-based AI solution designed to enhance the quality of care for veterans by utilizing precision nudging techniques. This randomized control trialed project aims to reduce alert fatigue by developing personalized behavioral change algorithms, tailored to each veteran's unique needs and preferences in terms of timing and communication channels."
SafePointe WDS - OSSO,"SafePointe WDS - OSSO is a weapon detection software project that utilizes heat map technology to identify objects that emit heat signatures associated with various types of weapons. The software is designed to pinpoint areas of interest based on these heat indicators, enhancing security measures and threat detection capabilities."
GE Xeleris ,"GE Xeleris V utilizes AI technology to enhance the accuracy of organ segmentation for quantitation and dosimetry calculations. The Q.Thera AI feature significantly improves efficiency, reducing processing and calculation times by an average of 58%. This system is designed to provide precise patient dosimetry calculations."
Genesys Cloud Contact Center,"The Genesys Cloud Contact Center project enhances staff efficiency by providing knowledge-based recommendations, conversation summarization, and automating quality assurance metrics. This allows employees to respond more swiftly to customer needs, reduces time spent on information retrieval and repetitive tasks, and enables a greater focus on customer interactions. The system primarily supports staff in managing customer engagements and streamlines processes like scoring quality forms and routing customers based on intents."
Verkada Camera - OSSO,The Verkada Camera - OSSO project enhances physical security camera solutions by incorporating an advanced video search function. This feature utilizes AI to search for and retrieve relevant video and image footage stored within the camera system.
MRI - GE Signa Artist,"The GE Signa Artist MRI system utilizes the AIR Recon DL deep-learning-based reconstruction algorithm to produce high-quality images with improved clarity. By effectively eliminating noise and ringing from raw images, this technology enables faster scan timesreducing them by up to 50%and enhances the overall workflow, positively impacting patient experiences."
Google Cloud Platform - CCAI / Dialogflow ,The project utilizes Google Cloud Platform's CCAI and Dialogflow to enhance self-service options for veterans through the implementation of virtual voice and chat agents. It incorporates text-to-speech (TTS) and speech-to-text (STT) capabilities to facilitate seamless communication.
Axon Body Camera and DMS - OSSO,"The Axon Body Camera and DMS - OSSO project aims to enhance the search capabilities within the data repository, improve redaction processes for files, evidence, and multimedia, and optimize license plate recognition specifically for the Fleet System. The project's goal is to enable better retrieval of case files and evidence while ensuring efficient handling and presentation of sensitive information."
Ultrasound - GE Logic E10,"The GE Logic E10 ultrasound system features several automated assistants designed to enhance imaging efficiency and accuracy. The Auto Preset Assistant optimally configures settings for specific anatomies, while the Auto Abdominal Color Assistant adjusts color flow parameters based on the detected organ. Additionally, the Auto Renal Measure Assistant automatically measures kidney dimensions, contributing to improved clinician decision support and reduced workflow errors."
Smart AI Bot Assistant,"The Smart AI Bot Assistant project aims to enhance the efficacy of crisis calls for the Veterans Crisis Line by employing machine learning and natural language processing to offer real-time resource prompts and streamline documentation for responders. By analyzing keywords and sentiments, the AI will facilitate improved communication between crisis responders and their supervisors, ultimately optimizing workflow and providing responders with necessary downtime. This initiative will be developed and refined in collaboration with VA experts and crisis line staff."
Radiology - Siemens YSIO Max,"The Siemens YSIO Max project focuses on enhancing radiology digital image quality through innovative technologies. It features bone suppression capabilities that eliminate the need for dual exposures and Diamond View technology that enhances image contrast and detail. Overall, the project aims to improve the clarity and quality of radiological images."
Enterprise Precision Scanning and Indexing (EPSI) Next: Enhancing Healthcare Services for Veterans,"The Enterprise Precision Scanning and Indexing (EPSI) Next project aims to enhance healthcare services for veterans by utilizing generative AI to summarize and create notes from patient health records. This AI-generated output will streamline the indexing workflow for the EPSI product, improving efficiency in healthcare documentation."
Nursing Proficiency Coach & Nurse Proficiency Evaluator...and beyond!,"Two custom GPTs, the Nurse Proficiency Writer and Nursing Proficiency Coach, have been developed to help nurses evaluate and report their performance against established standards. These tools assist over 90,000 RNs in understanding proficiency standards, generating performance reports, and improving their submissions for ePerformance. Ultimately, while the tools enhance the quality and accuracy of submissions, the responsibility for the content and evaluations rests with the nurses and their supervisors."
Parable 3D Wound Care Management System,"The Parable 3D Wound Care Management System automates wound measurement using computer vision to create 3D polygon mesh representations, eliminating the need for manual measurements. This contactless approach reduces the risk of infection and improves the accuracy and consistency of measurements, allowing clinicians to focus more on patient care and wound analysis. The system provides comprehensive volumetric data, including length, width, surface area, depth, and volume, enhancing the overall healing process for patients."
VEO Virtual Analyst Proof of Concept,The VEO Virtual Analyst Proof of Concept aims to demonstrate generative AI capabilities in customer experience insights and service delivery processes. It will offer a development environment where users can interact with dummy data to create and refine generative AI tools. The resulting Virtual Analyst tool will enhance services for veterans by delivering data-driven responses to inquiries about machine learning models and customer experience metrics.
GE Portable Critical Care Suite 2.x,The GE Portable Critical Care Suite 2.x is an FDA-cleared medical device designed to assist clinicians in managing critical care patients. It aims to improve healthcare outcomes through enhanced monitoring and support capabilities. Detailed information about the device is available in FDA documentation.
Patient Care Systems Integration Program (PCSIP),"The Patient Care Systems Integration Program (PCSIP) AI aims to enhance access to care for Veterans by increasing the capacity of Veterans Affairs Medical Centers (VAMCs) by up to 20% without adding staff or resources. Key benefits include significant reductions in charting time and cancellations, along with improved patient flow and scheduling across various medical services. The AI system integrates with existing patient records platforms to generate comprehensive notes and reports, streamline processes, and ensure instant availability of relevant patient information at the point of care."
Billing Claims Prediction,"The AI project aims to assist Revenue Operations Billing by generating a propensity to bill flag based on historical user activity in the Revenue Operations Workflow Tool. It utilizes data from Third Party Community Care Billing and Facility Revenue Activity Codes over a two-year period, having been trained on 1.2 million accounts from the Florida Caribbean Consolidated Patient Account Center (FCCPAC). The model helps users make informed decisions on whether an encounter is billable, classifying accounts as likely billable or non-billable."
ScienceLogic Artificial Intelligence Operations (AIOPS) Software Subscriptions with Maintenance and Professional Support Services.,"The ScienceLogic AIOps software provides a performance monitoring solution for cloud applications, enabling the VA to diagnose and address outages effectively. It offers maintenance and professional support services that enhance the VA's ability to respond to, resolve, and prevent outages across their operational domain."
ECG/EKG Machines- Interpretation of Results,"The ECG/EKG interpretation software assists VA clinicians by accurately analyzing Electrocardiogram tracings and integrating with CPRS to output patient demographics on the print-out. It generates a list of significant findings for review by a licensed provider, which are often confirmed as correct."
Appointment Comments Categorization,"The Appointment Comments Categorization project aims to provide patients with relevant alerts regarding their mental or physical health when signing up for appointments. Currently, the focus is on mental health, with the model designed to generate alerts such as ""Timely_Alert_Needed, 0.xxxxx"" to notify patients of immediate needs."
TeraRecon,"TeraRecon is an FDA-cleared medical device designed to assist clinicians in their decision-making processes, thereby enhancing healthcare outcomes. Its approval is documented in FDA records, which outline its specifications and capabilities."
Ambient AI scribe,"The Ambient AI scribe project aims to automate clinical documentation by using AI technology to produce written summaries of patient encounters, thereby reducing the burden on physicians. Unlike human scribes, which can be costly and offer variable quality, this AI solution is designed to alleviate physician burnout and improve efficiency during patient visits. The VA plans to pilot several of these AI-driven documentation solutions at its medical centers following a successful AI Tech Sprint."
Pension Optimization Initiative (POI),"The Pension Optimization Initiative (POI) aims to automate 75% of Pension and Survivor claims processing by partnering with a Managed Services Provider (MSP) to enhance efficiency and maintain or improve claim quality. The automation will streamline data extraction from various application formats and integrate this with existing Veteran and Beneficiary information to determine claim outcomes. The expected outputs include updated beneficiary files, finalized Pension claims, and notification letters to claimants."
Limited Use of Azure Speech Services in PETALS Platform,The PETALS Platform integrates Azure Speech Services to provide specific audio feedback during user interactions. It will vocalize either a participant's first name or a numerical step count to validate the information provided by the user during program engagement. This limited use enhances user experience through real-time audio verbalization.
Medallia SaaS - VSignals and ESignals,"Medallia is a customer experience management platform that utilizes AI, specifically natural language processing (NLP), to analyze survey comments from Veterans. The platform identifies potentially at-risk individuals concerning homelessness and mental health by flagging relevant comments, which then triggers the creation of a case for the Crisis Line and Homeless Program to review and take appropriate action."
AGFA Dose Monitor system,The AGFA Dose Monitor system is an FDA-cleared medical device designed to assist clinicians in monitoring patient doses during medical imaging procedures. Its primary objective is to enhance healthcare outcomes by ensuring accurate dose management and providing valuable data to healthcare providers. Further details and specifications can be found in the FDA documentation.
Volpara Imaging Patient Hub,"The Volpara Imaging Patient Hub is an FDA-cleared medical device designed to assist clinicians in improving healthcare outcomes. This device is documented in the FDA records, highlighting its capabilities and regulatory approval."
Identity Governance and Administration (IGA),"The Identity Governance and Administration (IGA) project aims to enhance access management within the VA workforce by utilizing AI to generate risk scores for access requests. This tool will automate the approval process for low-risk requests while flagging high-risk ones for manual review, and it will also feature a dashboard for displaying risk scores and sending email notifications regarding access requests that require attention. Overall, the IGA system is designed to reduce risks associated with access management effectively."
VET-HOME Contact Center AI ,"The VET-HOME Contact Center AI project aims to enhance the situational awareness of VA customer service agents by utilizing AI tools to summarize and contextualize Veteran queries. Custom AI co-pilots will be trained on contact center CRM data to proactively present relevant information during conversations, ensuring that agents have immediate access to the necessary resources to address Veterans' needs effectively."
Beckam Coulter DxH 800,"The Beckman Coulter DxH 800 is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. It is documented in detail in FDA submissions, providing insights into its operational capabilities and intended uses."
UIPath Document Understanding,"UiPath Document Understanding is a tool that utilizes Optical Character Recognition and AI for accurate data extraction from various documents, including handwritten and computer-generated forms. This enables automation processes to efficiently input data into other applications and support decision-making for Veterans' agents."
Potential Fraud or Waste,"The Purchase Card dashboards, enhanced with advanced data analytics, enable purchase card managers to monitor employee spending and detect potential fraud, waste, and abuse effectively. The analytics model predicts expected delivery dates for items, flagging those that are late or not received, thereby streamlining the investigation process and saving analysts time. This system improves compliance oversight with purchase card regulations and policies."
Roche Digital Pathology ,The Roche Digital Pathology project is designed to assist pathologists in diagnosing pathology cases by analyzing slide images. This technology enhances the efficiency and accuracy of the diagnostic process.
Activity recognition using wearable sensors for use in closed loop deep brain stimulation systems,"The project focuses on developing a classifier that utilizes accelerometry and gyroscopic data from wearable sensors to accurately recognize and classify various daily activities, such as walking, standing, sitting, and lying down. This classification technology is intended for integration into closed-loop deep brain stimulation systems and other applications that require real-time behavior recognition."
VCA & PPMS Chatbot ,"The VCA & PPMS Chatbot is a virtual assistant created to help field staff by answering frequently asked questions related to VCA and PPMS. This tool offers instant access to a comprehensive range of resources compiled by the VCA and PPMS teams, enhancing support for users at any time."
AgileMD eCART Clinical Deterioration Model,"The AgileMD eCART Clinical Deterioration Model is an FDA-cleared medical device designed to support clinicians in identifying patient deterioration and enhancing healthcare outcomes. It utilizes data analytics to provide timely insights, improving decision-making in clinical settings. Further details can be found in the FDA documentation for the device."
PINGOO.AI,"PINGOO.AI is an educational information app designed for veterans with diabetes, utilizing a Retrieval-Augmented Generation (RAG) model to deliver up-to-date and trustworthy information. The app communicates this information through a language model interface, ensuring veterans receive relevant insights tailored to their specific needs."
Persyst 14 EEG Review And Analysis Software,"Persyst 14 EEG Review and Analysis Software is a comprehensive tool designed for Computer Assisted Review of EEG, facilitating accurate and efficient analysis of EEG data. The software includes customizable parameters for seizure detection, spike detection, EEG signal trending, artifact reduction, and monitoring. It is widely used in both public and private hospitals and is available as a commercial off-the-shelf product."
Computer Aided Detection (CADe) of Neoplasia during Colonoscopy - GI Genius,"GI Genius is an AI-powered computer-aided detection module developed by Medtronic, Inc. to assist endoscopists in identifying colonic mucosal lesions during colonoscopy. FDA-cleared in April 2021, the device integrates with existing endoscopic equipment and has been shown to increase adenoma detection rates by 21%, leading to improved colorectal cancer prevention efforts among Veterans. The device utilizes real-time detection and highlighting of suspected lesions, enhancing the overall quality of colonoscopy procedures."
Digizens,Digizens is a behavioral prediction model designed to facilitate the creation of clinical trials without relying on actual patients or their information. It generates behavioral analyses and predictions based on messaging and contextual factors.
TrueFidelity CT Deep Learning Image Reconstruction,TrueFidelity CT Deep Learning Image Reconstruction is a project focused on enhancing the quality of CT images by reducing noise. This advanced deep learning approach aims to produce clearer and more accurate medical imaging results.
Pangaea,"The Pangaea project aims to develop a predictive model for chronic diseases in Veterans, providing tailored treatment recommendations aligned with current guidelines. The model will identify chronic diseases and suggest necessary treatment modalities before referring patients to specialty services."
AIDOC,"AIDOC is an FDA-cleared medical device designed to assist clinicians in their decision-making processes and enhance healthcare outcomes. The device is detailed in FDA documentation, which outlines its intended use and regulatory approval."
Cogitativo,"Cogitativo predicts chronic diseases by leveraging a data model built from historical Veteran profiles. The output is generated based on unique profiles, though the method of data acquisition remains unspecified."
"Analytics, Data, and Decision Support Unified Platform (ADDSUP)","The Analytics, Data, and Decision Support Unified Platform (ADDSUP) leverages AI to streamline the search process for contracts and line items, enabling users to quickly filter through data. This tool enhances decision-making by providing rapid access to information that supports cost avoidance strategies."
iCAD ProFound AI,iCAD ProFound AI is an FDA-cleared medical device designed to assist clinicians in improving healthcare outcomes. It employs advanced artificial intelligence technology to enhance diagnostic accuracy and efficiency in clinical settings. The device has documented approvals and specifications as outlined in FDA documentation.
VA Section 508 Office URL Ownership Prediction Model,"The VA Section 508 Office URL Ownership Prediction Model is designed to identify the administrative agency responsible for various URLs, thereby streamlining the process of ensuring accessibility compliance. This AI system produces two key outputs: the predicted agency owner and a prediction score, while also utilizing manually structured scripts to facilitate data organization for quarterly review. By implementing this model, the 508 Office significantly decreases the time and effort required to coordinate URL ownership with VA Administrations."
Circle CVI42 ,"Circle CVI42 is an AI-based software designed to enhance the efficiency of post-processing and reporting for Cardiac MRI and Cardiac CT images. It automates the segmentation of cardiac structures, providing outputs such as ejection fraction, strain, stroke volume, and coronary calcium score. All results are thoroughly validated by cardiologists, allowing for adjustments by the reading physician before inclusion in the patient's chart."
National Cemetery Administration (NCA) Automated Claims Processing,"The National Cemetery Administration (NCA) is implementing an AI-driven automated claims processing system to streamline benefits and application handling for the Pre-Need and Presidential Memorial Certificate programs. This system utilizes the Hyperscience platform, incorporating optical character recognition, natural language processing, and machine learning to automate data entry, case creation, and document generation while integrating with existing legacy systems. Future expansions may include additional NCA programs, further enhancing operational efficiency."
VA CART Adenoma Detection NLP,The VA CART Adenoma Detection project utilizes Natural Language Processing (NLP) to extract adenoma status from VistA colonoscopy surgical pathology reports for veterans. The results indicate adenoma presence with a binary output: 0 for no evidence of adenoma and 1 for evidence of adenoma.
Call Center Knowledge Navigator,"The Call Center Knowledge Navigator is designed to assist call center agents by providing quick answers to their questions, supported by cited references from VA-provided procedural materials. This tool aims to enhance response times by efficiently identifying relevant information and summarizing procedures, while also allowing agents to access the source material for further verification."
National Training Team | Schools  FAQ Dashboard,"The FAQ Dashboard for the National Training Team aggregates and categorizes thousands of questions submitted during monthly Office Hours with School Certifying Officials. It features a ""top ten"" list highlighting the most frequently asked topics along with sentiment scores for better understanding of the inquiries' context."
National Training Team | Schools  FAQ Dashboard,The National Training Team is developing a FAQ Dashboard for schools that will organize thousands of questions into specific categories. The model will generate sample questions related to each category and offer suggested answers based on prior responses to similar inquiries. This initiative aims to enhance the efficiency of responding to frequently asked questions in educational settings.
Audit of Service Connection Designations Associated with Prescriptions,"The project involves auditing service connection designations linked to prescriptions to identify and reduce instances of waste, fraud, and abuse. The objective is to ensure accurate designations are maintained to enhance accountability and efficiency in prescription management."
PsychCorpCenter,PsychCorpCenter is a program designed to provide multiculturally sensitive scoring of cognitive assessments to enhance the accuracy of diagnostic impressions. It processes input data from providers about specific Veterans or patients and generates detailed reports based on that information.
ReflexAI,"ReflexAI is an AI-driven simulation platform designed to enhance the training of responders for the Veterans Crisis Line by offering tailored, high-quality practice and immediate feedback. The platform, hosted on the secure VA Enterprise Cloud, provides training staff with access to simulation content and real-time feedback that evaluates training effectiveness and tracks individual progress."
"Prostate Cancer, Genetic Risk, and Equitable Screening Study (ProGRESS) - Prostate Cancer Risk Prediction Model","The Prostate Cancer, Genetic Risk, and Equitable Screening Study (ProGRESS) develops a prostate cancer risk prediction model utilizing machine learning and genetic data to categorize participants into low, average, or high-risk groups. This classification is part of a comprehensive report given to participants and their VA healthcare providers to aid in informed decision-making about prostate cancer screening. The model aims to enhance precision screening interventions within a nationwide randomized controlled trial setting."
"Using AI to enhance/augment classification of reported patient safety events, and to proactively identify patient safety vulnerabilities and potential areas of improvement","This project utilizes AI to improve the classification of reported patient safety events and to proactively detect vulnerabilities in patient safety. The system enables statisticians to identify trends and anomalies, allowing for timely intervention to prevent the escalation of new or increased safety events. Additionally, it enhances the classification of event types for more effective monitoring."
App feedback model for NLP tasks,"The project aims to develop an app feedback model using Natural Language Processing (NLP) to analyze comment reviews by identifying named entities (NER), profanity, and stop words. It employs spaCy's en_core_web_sm model to process reviews from both external sources like Google and Apple stores and internal sources such as FeedbackUI and VA Mobile. The primary users of this system are the OCC Data Science Team, and the target audience includes mobile application developers and internal stakeholders interested in understanding sentiment and feedback from user reviews."
TERA Memorandum Automation,"The TERA Memorandum Automation project employs natural language processing algorithms to facilitate the completion of the TERA Memorandum form necessary for Veteran Disability Claims. It enables approved Veteran Service Representatives (VSRs) to auto-populate questions using evidence from Claims Evidence, significantly reducing the time spent on manual document review and streamlining the claims process. The system delivers an open-text response with confidence scores and links to relevant documents for further manual review by VSRs."
XtractOne,"The XtractOne project aims to modernize the weapons detection system (WDS) for VA Police by centralizing reporting and enhancing operational efficiency through a SaaS solution. This advanced system allows for better monitoring, quicker response to security incidents, and efficient manpower allocation. It employs machine learning to continuously improve detection capabilities, thereby increasing safety within VA facilities."
 Using AI to weekly monitoring of any harms resulting from the use of newly implemented electronic health record system  FEHR across VA,"The project involves using AI for weekly monitoring of potential harms associated with the newly implemented electronic health record (EHR) system, FEHR, within the VA. This monitoring will help inform improvements to the EHR system and its functionalities, focusing on preventing and mitigating patient safety events. Additionally, the project includes classifying harm categories identified from the EHR data."
Podimetrics,"Our involvement with Podimetrics is confined to receiving and processing escalation reports from their SmartMat system. We act as a conduit for sharing these reports with the appropriate clinicians to enhance care for Veterans, without engaging in the development or decision-making processes of their proprietary technology. Our role is strictly supportive, focusing on data transfer and integration for effective clinical follow-up."
Thematic Analysis of Chief Resident in Quality and Patient Safety (CRQS) Capstone Projects Using BERT Modeling,"The project utilizes BERT modeling to conduct a thematic analysis of Chief Resident in Quality and Patient Safety (CRQS) capstone projects, aiming to identify key themes and trends. The findings will be used to enhance the national curriculum for quality and patient safety in healthcare by informing curriculum development and improvement strategies."
My HealtheVet VSignals Main Improvement Summary,"My HealtheVet is the VHA patient portal that allows Veterans to refill medications, communicate with care teams, access medical records, and view appointments. To improve user experience, the portal collects over 26,000 surveys monthly, utilizing AI to summarize and categorize open-text responses for identifying trends and feature requests. This process enhances the identification of issues and prioritization of resources while ensuring the privacy of Veterans' feedback."
ESD-Speech Sentiment and Analytics,"The ESD-Speech Sentiment and Analytics project leverages AI technology to analyze the speech sentiment of internal customers to enhance service quality at the Enterprise Service Desk. It generates various reports and dashboards for ESD leadership and Tier 1 vendor partners to evaluate service quality, allowing for the analysis of 100% of contacts rather than the current 2% assessed through manual methods."
Privacy Act Automation Services - Disclosure.AI,"The Privacy Act Automation Services (PAA) System automates the processing of Privacy Act requests, significantly reducing the wait time for Veterans to receive their records and minimizing the support needed from VA staff. Utilizing AI and machine learning, the system improves document identification, data extraction, and automated redactions while incorporating Human in the Loop (HITL) and Government in the Loop (GITL) roles for quality assurance. Final outputs are reviewed for accuracy and completeness before being released to the requesters."
Sentiment analysis for app feedback,"The project aims to conduct sentiment analysis on app feedback, classifying reviews as positive, negative, or neutral, and supplying a processed dataset for subsequent analysis. Utilizing a fine-tuned model on text reviews from both external sources (Google and Apple stores) and internal sources (FeedbackUI and VA Mobile), the system primarily serves the OCC Data Science Team and OCC mobile application developers. The goal is to enhance understanding of user sentiment and feedback among stakeholders."
ESD-Predictive Intelligence,"ESD-Predictive Intelligence aims to utilize Machine Learning on existing ticketing data to enhance the efficiency of resolving internal customer issues by decreasing mean time to resolution and improving ticket routing accuracy. The project will generate outputs such as pre-populated assignment groups in ServiceNow, facilitating better ticket routing and providing dashboards for Incident Management teams to identify potential major incidents promptly."
AI Health Coach,"The AI Health Coach project combines a traditional Health Coach with AI technology to enhance patient adherence to health protocols. The Health Coach provides evidence-based nudges using a pre-selected decision tree, while the AI analyzes engagement levels to optimize the frequency of these nudges. This approach aims to improve overall health outcomes for users, particularly Veterans."
Verathon Prime Plus,Verathon Prime Plus is a bladder scanner that incorporates AI technology to enhance the detection of bladder size and shape. Its primary goal is to improve measurement accuracy for medical assessments. The device provides assisted outputs that aid healthcare professionals in making informed decisions.
App Feedback categorization model,"The project involves creating an app feedback categorization model that classifies review texts into categories such as Tech, Usability, Content, Idea, and Other. It utilizes a fine-tuned open-source model trained on various data sources, including external app store reviews and internal feedback systems. The primary users of this system are the OCC Data Science Team, who will leverage it for trend identification and data analytics."
LINQ and  LINQ II Loop Recorder ,The LINQ and LINQ II Loop Recorder are implantable heart monitoring devices that continuously monitor heart rhythm and rate. They transmit recordings remotely for interpretation by medical providers. This technology enhances patient care by allowing for real-time monitoring and data analysis.
VA.gov Chatbot: Use of AI for summative and/or intent classification of Va.gov content,"The VA.gov Chatbot employs Natural Language Understanding technology to interpret and respond to Veterans' inquiries. The future plan aims to enhance the chatbot's capabilities by integrating advanced AI services, allowing it to address a wider range of questions with improved accuracy and facilitate proper routing for channel escalations. This will enable the chatbot to better understand user intent and generate relevant responses effectively."
ZIO PATCH HEART MONITOR,The Zio Patch Heart Monitor is a wearable device that tracks heart rate and rhythm for a duration of up to 14 days. It is designed to diagnose arrhythmias and other electrical conduction issues in the heart.
Caller intent classification using Google Dialogflow (VoiceBot),"This project utilizes Google Dialogflow to develop a VoiceBot aimed at modernizing call centers, particularly for Veterans. The VoiceBot serves as a caller concierge, efficiently triaging inquiries, improving agent matching, and performing routine tasks without requiring agent intervention. Conversational scripts, consisting of intents, entities, and slots, will be managed within established databases used by VA call centers."
Ordr,"Ordr SCE Analytics utilizes advanced AI and machine learning technologies to classify local networked devices for accurate inventory management while employing non-invasive passive classification techniques. This approach identifies unique behavior patterns of devices without the need for disruptive active scanning methods, ensuring minimal impact on sensitive IoT devices. The system forwards only essential network device metadata to the SCE Analytics server, discarding sensitive information like PHI to maintain data privacy."
Machine Algorithm for Report Surveillance (MARS),The Machine Algorithm for Report Surveillance (MARS) tool is designed to identify federal EHR incident reports submitted by end-users that may impact patient safety. MARS enhances the manual review process by generating a list of ServiceNow tickets that need human validation to confirm their significance regarding patient safety issues.
Pharmacy AI Managed Inventory System (PHAIMIS),"PHAIMIS is an AI-powered inventory management system designed to centralize and optimize inventory processes within the VA Pharmacy Service. By integrating AI and data analytics, the system will provide real-time notifications, demand forecasting, procurement strategy optimization, and dynamic inventory thresholds, ultimately enhancing the user experience and workflow efficiency. Additional features may include anomaly detection alerts."
Silverberry Surgery Planning AI,"The Silverberry Surgery Planning AI project focuses on optimizing the perioperative process through the use of multiple AI agents. These agents will assist with surgical planning, supply management, personnel coordination, and patient scheduling to enhance operational efficiency."
ICU CIS/ARK PDF Medical Entity and Clinical Scoring Extraction (PHI 3.5 LLM),"The ICU CIS/ARK project focuses on extracting clinical data elements from unstructured clinical notes and converting them into structured and semi-structured formats. It maps these extracted elements to standardized terminologies like SNOMED, LOINC, ICD-10, and RxNorm, facilitating downstream analytics processes and integration with clinical information systems."
BlueTeam AI,BlueTeam AI offers network monitoring solutions that ensure governance and compliance for the use of LLM Generative AI in enterprises. It restricts the output to only approved data categories and notifies users of any violations.
"OAWP Investigative, Analytics, and Reporting Capabilities","The project focuses on developing an audio transcription application utilizing Azure AI Speech Services to facilitate the creation of transcripts for OAWP investigators. Additionally, the Compliance Analytics and Reporting Division aims to implement supervised machine learning to classify external oversight entity reports and is exploring the use of deep learning models for data analysis, trend identification, and anomaly detection."
Multi-Modal Digital Image Exchange - AI (MDIE-AI),"The Multi-Modal Digital Image Exchange - AI (MDIE-AI) project develops an AI-driven orchestration layer that automates the processing of computer vision models using saved DICOM diagnostic images. It generates a summary PDF of the results for review, which can be directly accessed from the DICOM file."
VA Supply Chain Knowledge Management Dashboard,"The VA Supply Chain Knowledge Management Dashboard project aims to enhance internal knowledge management and learning capabilities by utilizing existing Power BI tools to analyze publicly available documentation, such as congressional reports. By implementing advanced data analysis tools and dynamic dashboards, the project facilitates improved collaboration and risk mitigation within the VALOR mission, ensuring effective capture and sharing of knowledge. The initiative focuses solely on publicly accessible data and does not involve any individual information, further emphasizing its safety and rights non-impacting nature."
Clinical outcomes for asynchronous teledermatology,"The project aims to evaluate clinical outcomes in patients with skin diseases utilizing asynchronous teledermatology for research and quality improvement (QI) purposes. Dermatology progress notes will be classified into six distinct categories: Resolved, Improved, Unchanged (clinically significant), Unchanged (not clinically significant), Worse, and No outcome stated."
VA TryOpenAI,"TryOpenAI is a project designed to enhance the efficiency and satisfaction of VA employees by automating and improving various administrative tasks. It provides support for writing and communication, streamlines documentation workflows, assists in creative problem-solving and technical issues, and facilitates research and learning. The tool enables users to draft emails, summarize documents, generate performance appraisals, and more, ultimately optimizing their productivity."
Lyssn for Mental Health,"Lyssn for Mental Health enhances the adherence to evidence-based practices in Behavioral Health by utilizing AI algorithms to automatically generate clinical quality metrics from recordings or transcripts of provider-patient sessions. These metrics assess various aspects of counseling, including patient-centered communication and fidelity to techniques such as Motivational Interviewing and Cognitive Behavioral Therapy."
SOMATOM go.Up; SOMATOM go.Now; SOMATOM go.All; SOMATOM go.Top; SOMATOM go.Sim; SOMATOM go.Open Pro; SOMATOM X.cite; SOMATOM X.ceed,"The project involves several FDA-cleared medical devices, including the SOMATOM series, designed to assist clinicians and enhance healthcare outcomes. Detailed information about the devices is available in the FDA documentation. The devices aim to improve diagnostic capabilities and patient care in medical settings."
"HCD User Feedback Summary, Analysis, and Design","The Human-Centered Design (HCD) team leverages Large Language Models (LLMs) and custom agents to enhance user experience research focused on Veterans and healthcare providers. This project aims to improve usability, accessibility, and clarity of user feedback by generating insights like user stories, personas, and workshop summaries to inform design decisions."
3M/Solventum 360 Encompass Computer Assisted Coding - Auto Suggestion,"The 3M/Solventum 360 Encompass project aims to enhance the efficiency and accuracy of medical coding by providing coders with suggested ICD 10, CPT, and HCPCS codes based on clinical documentation from outpatient, inpatient, or surgery encounters. This AI-driven auto suggestion system is designed to facilitate timely and precise coding, ultimately improving the overall medical coding process."
Vivid iq,"Vivid IQ is an FDA-cleared medical device designed to assist clinicians in their decision-making processes and enhance healthcare outcomes. This device has been documented in FDA submissions, confirming its safety and efficacy for use in clinical settings."
Vivid E80/ Vivid E90/ Vivid E95,"The Vivid E80, Vivid E90, and Vivid E95 are FDA-cleared medical devices designed to assist clinicians in enhancing healthcare outcomes. These devices utilize advanced technology and are documented in the FDA's official records for their effectiveness and compliance."
Payment Redirect Fraud (PRF) Model,"The Payment Redirect Fraud (PRF) model is designed to detect potentially fraudulent direct deposit changes made by criminals targeting Veterans' benefit payments. By analyzing data, the model identifies referrals with the highest likelihood of fraud, allowing investigators to review and address these cases. The model outputs include sensitive Veteran information and direct deposit bank account details in both R data and Excel file formats."
"EchoPAC Software Only, EchoPAC Plug-In","EchoPAC is an FDA-cleared medical software device designed to assist clinicians in enhancing healthcare outcomes. It includes both a software-only version and a plug-in, as outlined in the FDA documentation. This technology aims to improve diagnostic capabilities in medical settings."
Using Partially Observed Markov Decision Process to Implement a Response to Intervention Framework for Veterans with Post-Traumatic Stress Disorder ,"The project aims to utilize a Partially Observed Markov Decision Process (POMDP) model to enhance personalized treatment for veterans with Post-Traumatic Stress Disorder (PTSD). This approach seeks to reduce PTSD symptoms efficiently, thereby lowering costs and facilitating a quicker transition of veterans back to civilian life compared to current practices."
Microsoft Power Automate and AI  ,"The project utilizes Microsoft Power Automate and AI to streamline the scheduling process for transporting eligible veterans by extracting information from request forms in PDF format. This data is automatically populated into an Excel spreadsheet, capturing essential details such as transport dates, the requesting facility, veteran identifiers, and specific transport requirements. This automation aims to enhance the efficiency of the Veterans Transport Program in coordinating transportation to and from healthcare appointments."
IVC Access Transformation Transformative Care Modalities VA Health Connect Using Machine Learning to Evaluate First Contact Resolution (FCR),"The IVC Access Transformation project aims to enhance performance metrics for First Contact Resolution (FCR) within the Clinical Triage core service at VA Health Connect by utilizing machine learning techniques. The model classifies clinical triages as resolved or not resolved, enabling effective analysis of FCR without impacting medical decisions or using sensitive Veteran data."
ECG system software,"The ECG system software is a commercially available tool designed to assist healthcare professionals with the interpretation of electrocardiograms. It generates ECG tracings and offers readings on various ECG parameters, enhancing diagnostic accuracy."
Avicenna ICH ,"The Avicenna ICH project utilizes AI to detect possible intracranial hemorrhage (ICH) in CT head exams, enhancing the diagnostic process. It accepts DICOM format CT images from VHA facilities and generates DICOM objects for review by VHA NTP Diagnostic Radiologists. Future enhancements will include DICOM structured reports for integration with the VHA NTP PACS Powerscribe dictation software."
Densitas Density AI,"Densitas Density AI combines quantitative mammographic density measurements with a qualitative breast density scale aligned with the ACR BI-RADS Atlas. It processes DICOM mammography image data from VHA facilities to facilitate and enhance mammographic diagnoses. The outputs include DICOM objects stored in the NTP PACS for radiologist review, with plans to integrate structured reports for dictation software in the future."
CLARUS,"CLARUS is an FDA-cleared medical device designed to assist healthcare professionals and enhance patient outcomes. It is documented in the FDA records, providing detailed information about its approval and intended use in clinical settings."
Riverain ClearRead CT,"Riverain ClearRead CT is an AI tool designed to analyze chest CT exams and enhance the identification and characterization of various types of pulmonary nodules, particularly in lung cancer screenings. It features a CT Vessel Suppression function to improve the visibility of nodules and a ClearRead CT Compare function to track nodule changes over time by matching current and prior exams. Managed by the VHA National Teleradiology Program, the AI processes DICOM CT data and outputs results in DICOM format for review by diagnostic radiologists."
Clinical Key | Elsevier ,Clinical Key is a search platform developed by Elsevier that provides clinicians with access to current evidence-based medical practices. It summarizes medical literature and offers answers to medical questions based on user search prompts.
ACS NSQIP Risk Score,The ACS NSQIP Risk Score is a clinical decision support tool that evaluates surgical risk for patients. It generates a risk assessment based on specific input values provided by healthcare providers. This system aids in informed decision-making regarding surgical procedures.
Avicenna LVO,"Avicenna LVO is an AI system designed to detect large vessel occlusion in the anterior intracranial circulation using Head CT Angiography exams. It processes DICOM Head CT image data from VHA facilities and produces DICOM objects for review by diagnostic radiologists, with plans for future integration of structured reports into the VHA NTP PACS Powerscribe dictation software."
Ysio Max,"Ysio Max is an FDA-cleared medical device designed to assist clinicians in their workflows and enhance healthcare outcomes. It offers advanced imaging capabilities, contributing to more efficient diagnosis and treatment processes. The device's specifications and functionalities are detailed in the FDA documentation."
Transpara Breast Care,"Transpara Breast Care utilizes artificial intelligence to analyze digital mammograms for patterns indicative of breast cancer, aiming to enhance the speed and accuracy of cancer detection. The system processes DICOM mammography images submitted by VHA facilities and generates outputs for further review by Diagnostic Radiologists. Upcoming enhancements will include structured reports integrated with VHA's Powerscribe dictation software."
"XIDF-AWS801, Angio Workstation (Alphenix Workstation), V9.5","XIDF-AWS801, also known as the Alphenix Workstation, is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. It is detailed in FDA documentation, providing guidelines and specifications for its use in medical settings."
BlackBox Code research,"The BlackBox Code research project utilizes various programming languages like Java, SQL, and Python to identify code errors, enhance performance, and improve data loading processes within the VA systems. It leverages AI tools like ASkSage and ChatGPT to provide solutions, code reviews, and creative writing, emphasizing clarity and engagement across multiple domains of knowledge and inquiry. The system aims to deliver informative and useful outputs that assist users in coding, analysis, and learning."
Synthetic Data Creation,"This project involves generating synthetic, non-personally identifiable information (PII) test data using Generative AI to accurately reflect the diverse characteristics of the beneficiary population. The aim is to support educational user acceptance testing (UAT) by ensuring the created data is of sufficient scale and representation. Synthetic beneficiary population data will be utilized to enhance testing processes while maintaining privacy."
Billie GPT,"Billie GPT is a generative AI knowledge portal designed to assist School Certifying Officials with inquiries related to VA education benefits and the Enrollment Manager System. It provides automated responses to user queries, enhancing support and information accessibility."
X100HT with Slide Loader with Full Field Peripheral Blood Smear (PBS) Application,The X100HT is an FDA-cleared medical device designed to assist clinicians in the analysis of full field peripheral blood smears (PBS) applications. It aims to enhance healthcare outcomes by providing advanced capabilities for blood sample examination. Detailed information about the device can be found in the FDA documentation.
WRDensity by Whiterabbit.ai,"WRDensity, developed by Whiterabbit.ai, is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. The device's functionalities and efficacy are detailed in the FDA documentation for its clearance."
Workflow Box,"Workflow Box is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. Its effectiveness and safety are documented in FDA filings, which detail its approval and intended uses in medical settings."
BTSSS 3542 Review,"The BTSSS 3542 AI model automates the claims processing workflow by extracting information from patient-filled paper forms and organizing scanned documents chronologically. This automation reduces manual labor hours, lowers operational costs, and minimizes overtime, allowing staff to focus on patient care and improving overall productivity. The model outputs renamed files to a designated SharePoint folder and updates specific columns for easier sorting by dates, ensuring quick access to organized claims information."
Withings Scan Monitor 2.0,"The Withings Scan Monitor 2.0 is an FDA-cleared medical device designed to support clinicians in enhancing healthcare outcomes. It provides reliable health monitoring capabilities, as detailed in the FDA documentation. This device aims to facilitate better patient management and improve overall clinical efficiency."
HTM-LLM,HTM-LLM is a RAG chatbot designed to assist Healthcare Technology Management staff by providing information from technical service manuals for medical device maintenance and troubleshooting. It leverages machine learning to generate accurate responses relevant to healthcare technology. The chatbot aims to improve the efficiency and effectiveness of managing medical devices.
Clinician-Administered PTSD Scale for DSM-5 (CAPS-5) Clinician Training Simulator,"The CAPS-5 Clinician Training Simulator offers three online courses designed to teach clinicians, trainees, and researchers the administration and scoring of the CAPS-5. Utilizing advanced technologies such as voice recognition, 3-D visualization, and artificial intelligence, the simulator provides an immersive learning experience, where learners interact with virtual patients and receive feedback on their performance. The system emphasizes accuracy in prompt delivery and scoring, enabling participants to improve their skills in a controlled, AI-driven environment."
WellDoc BlueStar,WellDoc BlueStar is an FDA-cleared medical device designed to support clinicians in managing patient care and enhancing healthcare outcomes. It utilizes evidence-based methodologies to provide personalized treatment recommendations and improve the overall management of chronic conditions. The device's effectiveness and safety are documented in FDA regulatory submissions.
Electronic Virtual Assistant (e-VA),"The Electronic Virtual Assistant (e-VA) is an innovative digital assistant designed to support the Veterans Benefits Administration's Vocational Rehabilitation & Employment services by automating client follow-up, data entry, and documentation tasks. By managing administrative duties, e-VA allows Vocational Rehabilitation Counselors to concentrate on providing quality service to Veterans. The system facilitates communication with program participants through text and email, enabling them to schedule appointments and submit relevant documents seamlessly."
WAVE Clinical Platform,The WAVE Clinical Platform is an FDA-cleared medical device designed to assist healthcare professionals and enhance patient outcomes. It provides clinical insights and support for better decision-making in medical practice. Detailed information about the device can be found in the FDA documentation.
"VX1, VX1+","VX1 and VX1+ are FDA-cleared medical devices designed to assist clinicians in providing better healthcare outcomes. The devices are detailed in the FDA documentation, which outlines their intended use and efficacy. Their approval signifies compliance with regulatory standards for safety and effectiveness in medical settings."
Sybil - Lung Cancer Prediction Model by MIT,"The Sybil lung cancer prediction model, developed by MIT, is designed to personalize screening protocols by identifying high-risk patients for earlier intervention and minimizing the screening burden on low-risk individuals. It analyzes low-dose CT scans of the lungs and generates a JSON output that predicts the likelihood of developing cancer over the next six years, with annual predictions provided."
eCaremanager (Philips),"eCaremanager is a software developed by Philips that integrates clinical, physiological, and demographic data from patients in the National TeleCC Program to generate acuity scores and alerts. It visually presents patient data to providers, enabling them to monitor and manage a larger patient population effectively. The system helps identify patients needing intervention, promoting timely treatment to restore health."
VUNO Med-DeepBrain,"VUNO Med-DeepBrain is an FDA-cleared medical device designed to assist clinicians in diagnosing and treating patients, thereby improving healthcare outcomes. The device utilizes advanced technology to enhance clinical decision-making, as outlined in the FDA documentation."
Policy AId,"Policy AId is a generative AI application designed to streamline the policy lookup process in the VA by providing relevant answers to policy-related questions based on Medical Center reference materials. It aims to reduce the time spent on finding facility policy, thereby enhancing efficiency and employee satisfaction while also standardizing meeting minutes according to the Dayton governance structure. The application utilizes a Retrieval-Augmented Generation (RAG) approach, offering feedback linked to pertinent medical center publications."
"Voluson Expert 22, Voluson Expert 20, Voluson Expert 18","The Voluson Expert 22, 20, and 18 are FDA-cleared medical devices designed to assist clinicians in diagnostics and enhance healthcare outcomes. Detailed information about these devices can be found in the FDA documentation."
Volta AF-Xplorer,"The Volta AF-Xplorer is an FDA-cleared medical device designed to assist clinicians in diagnosing and treating healthcare conditions, ultimately aiming to enhance patient outcomes. It is detailed in the FDA documentation available through their official website. The device leverages advanced technology to improve clinical workflows and patient care."
Biotronik Home Monitoring System,"The Biotronik Home Monitoring System collects data from patients with implanted cardiac monitors and transmits it for clinician review through a secure web platform. Using proprietary AI technology, the system classifies transmitted data into true arrhythmias and false positives for conditions like atrial fibrillation and bradycardia, thus enhancing diagnostic accuracy and patient care. This system is utilized by the VA National Cardiac Device Surveillance program and local VA clinics to better evaluate patient health."
"Synthetic Data Generation:  Experimenting with OpenSource, Third Party and GenAI ","The project focuses on generating synthetic patient clinical and demographic data by experimenting with open-source tools, third-party solutions, and generative AI. Its goal is to enhance the agility of both research and operational development processes."
CareLink Home Monitoring,"The CareLink home monitoring system enables patients with implanted cardiac monitors to transmit data to clinicians for evaluation via a secure web platform. Using proprietary AI deep learning algorithms, the system accurately distinguishes between true arrhythmias and false positives, specifically eliminating incorrect atrial fibrillation and pause events. This technology is utilized by the VA National Cardiac Device Surveillance program and local VA clinic providers to enhance patient care and monitoring."
Nuance Dragon Medical One (DMO),"Nuance Dragon Medical One is a voice-to-text technology that allows healthcare professionals to enter documentation into electronic health records efficiently. This system converts voice-generated content into clinical documentation, streamlining the documentation process in medical settings."
Stratification Tool for Opioid Risk Mitigation (STORM) predictive model ,"The Stratification Tool for Opioid Risk Mitigation (STORM) is a predictive model designed to estimate the risk of overdose or suicide-related healthcare events for patients receiving opioid prescriptions from the VA. It identifies patients at elevated risk for referral to interdisciplinary teams, supports clinical decision-making for opioid prescribing, and enhances care coordination for patients with opioid use disorders, ultimately aiming to reduce adverse outcomes and all-cause mortality. STORM leverages patient-specific data and risk estimates to inform treatment options while ensuring compliance with guidelines and improving safety in opioid management."
Vitrea CT Brain Perfusion,Vitrea CT Brain Perfusion is an FDA-cleared medical device designed to assist clinicians in evaluating brain perfusion and ultimately enhance healthcare outcomes. The device utilizes advanced imaging technology to provide critical information that aids in the diagnosis and treatment of various neurological conditions. Detailed information about the device can be found in the FDA documentation linked above.
Deep-Learning approaches to develop candidate lists of terms for use in text searches ,"The project employs deep-learning techniques to generate comprehensive candidate term lists for text-matching approaches in free-text medical records. By utilizing pre-trained large language models and word embedding models, the project aims to augment human-generated term lists, reducing bias and limitations associated with individual vocabulary. The augmented candidate lists are then reviewed by subject matter experts to ensure their appropriateness and accuracy for clinical concept extraction."
Vereos PET/CT,"The Vereos PET/CT is an FDA-cleared medical device designed to assist clinicians in diagnosing and treating medical conditions more effectively. It enhances healthcare outcomes by providing advanced imaging capabilities, as outlined in the FDA documentation. This technology represents a significant advancement in the field of medical imaging."
Recovery Engagement and Coordination for Health  Veterans Enhanced Treatment (REACH VET) 1.0 predictive model,"The Recovery Engagement and Coordination for Health  Veterans Enhanced Treatment (REACH VET) 1.0 model is a predictive tool that analyzes patient medical records to assess the risk of suicide within the upcoming month. Its primary function is to facilitate the identification and referral of at-risk patients to a clinical review and outreach program, while its secondary use assists in risk stratifying patients for enhanced clinical attention based on historical healthcare interactions. Since its national implementation in 2017, REACH VET has been associated with increased treatment engagement and reduced rates of mental health crises among participating Veterans."
Venue; Venue Fit; Venue Go,The project involves a FDA-cleared medical device designed to aid clinicians and enhance healthcare outcomes. Detailed information about the device can be found in the FDA documentation.
Velacur,"Velacur is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. It is detailed in the FDA documentation, emphasizing its role in improving the efficiency and effectiveness of medical care."
2268 Next Generation (2268NextGen),"The 2268 Next Generation project utilizes Microsofts AI Builder to extract information from PDF VA Forms and input it directly into a D-365 CRM database. This automation reduces the reliance on human intervention and minimizes typographical errors, streamlining the data transfer process. The project enhances efficiency by converting digital data from PDF documents."
Syngo Application Software,"The Syngo Application Software is an FDA-cleared medical device designed to assist clinicians in their diagnostic processes. By enhancing healthcare outcomes, it aims to improve the overall quality of patient care. Detailed information about the device is available in the FDA documentation."
Operationalizing Coronary Artery Calcium Computer Vision Model,"The project focuses on implementing an AI model that analyzes Chest CT scans to identify coronary artery calcification, thereby alerting physicians to patients at heightened risk for cardiovascular disease. The model generates a coronary artery calcium score and provides image masks indicating the locations of detected calcification, enabling earlier detection and improved treatment for affected patients."
Rapid AI,"Rapid AI is an FDA-cleared medical device designed to assist clinicians in improving healthcare outcomes. Its capabilities and functionalities are detailed in FDA documentation, which can be accessed online. This device aims to enhance the efficiency and effectiveness of medical care delivery."
"Spine Planning (2.0), Elements Spine Planning, Elements Planning Spine","Spine Planning (2.0) is an FDA-cleared medical device designed to aid clinicians in performing spine surgery more effectively, ultimately enhancing healthcare outcomes. Detailed information about the device is available in FDA documentation."
VRS Employment Support,The VRS Employment Support project utilizes ChatGPT to assist veterans in developing resumes and preparing for mock interviews. The primary deliverables are polished resumes and tailored mock interview questions.
Classifying the reportability of and extracting cancer diagnosis information from pathology reports or other clinical documents ,"The project aims to improve the efficiency of nurse coordinators in the National Oncology Program Office by classifying cancer diagnoses in pathology reports and extracting pertinent information. The system provides extracted details, such as diagnosis and histology, alongside the original context for coordinators to review, thus reducing their information-gathering time. It ensures compliance with relevant regulations, focuses on enhancing support for Veterans, and maintains the existing workflows and oversight through electronic health records (EHR)."
Post discharge 30-day readmission or death prediction model to select patients for expedited postdischarge clinic follow-up.,"This project involves the development of an AI-powered prediction model designed to identify patients at high risk of readmission or death within 30 days post-discharge, thereby informing their follow-up care. The model serves as a supplementary tool for clinicians, providing insights based on various factors that may not be readily available during discharge discussions, ultimately aiming to reduce readmission rates and mortality through more systematic and timely follow-up care for vulnerable patients. Utilizing an XGBoost system, the model outputs probabilities that assist in clinical decision-making regarding expedited follow-up appointments."
Using Artificial Intelligence to Predict Suicide,"This project utilizes artificial intelligence to predict suicide risks among veterans by identifying two critical factors: access to guns and active opioid use disorder (OUD). Through natural language processing, the AI algorithms analyze clinical notes to flag patients who may have these risk factors, providing mental health clinicians with valuable insights to inform their care. The initiative aims to enhance suicide prevention efforts by enabling timely interventions tailored to the unique circumstances of veteran patients."
RayStation 11B,"RayStation 11B is an FDA-cleared medical device designed to support clinicians in their practice and enhance healthcare outcomes. The device is detailed in FDA documentation, emphasizing its safety and efficacy in clinical settings."
Identify access to genetic testing in Veterans with breast cancer. ,"The project aims to identify access to germline genetic testing for Veterans with breast cancer, allowing stakeholders in the National Oncology Program to assess and improve the standard of care access provided by the VA. By leveraging AI, the system facilitates real-time identification of Veterans lacking access to genetic testing, enabling care coordinators to offer necessary support and adherence to VA guidelines. The initiative is designed to enhance coordinator efficiency, improve Veteran interaction, and address potential inequities in healthcare access without impacting patient safety or rights."
Classify clinical pathway for cancer patients,"The VA National Oncology Program is developing and implementing AI-driven workflows to classify and assess adherence to clinical pathways for cancer treatment, specifically focusing on genetic testing for Veterans with prostate cancer. By extracting information from electronic health records, the project aims to evaluate the quality of care provided and identify areas for quality improvement, while ensuring compliance with privacy regulations. This initiative is designed to enhance care delivery and support efforts to address disparities, without impacting patient safety or rights."
Enterprise Command Center - Generative AI ,"The Enterprise Command Center project aims to enhance alert communication for service owners by transforming existing alerts into plain English messages using a large language model (LLM). This initiative seeks to reduce the volume of unaddressed alerts by making them more comprehensible, allowing recipients to take appropriate actions more effectively. Ultimately, the project focuses on improving the clarity and usability of alert messages."
Extract patients diagnosis information and map the diagnosis to oncotree,"The project aims to extract patients' diagnosis information encoded in ICD0 codes and map it to the oncotree framework to facilitate clinical trial matching and improve the efficiency of nurse coordinator document reviews. The AI system will highlight oncotree diagnosis information within clinical documents, allowing coordinators to spend less time on information gathering and more on direct interactions with Veterans, thereby enhancing patient support and care coordination. Importantly, the system will not impact clinical decision-making, safety, or equity, as coordinators are expected to verify AI outputs with information from electronic health records."
Adobe Creative Cloud ,"The project utilizes Adobe Creative Cloud to create nursing education presentations, incorporating animations and AI-generated art. This approach enhances the visual engagement and educational value of nursing material."
QLAB Advanced Quantification Software,"QLAB Advanced Quantification Software is an FDA-cleared medical device designed to assist clinicians in enhancing healthcare outcomes. The software utilizes advanced algorithms for accurate quantification in medical imaging, thereby improving diagnostic accuracy and patient care. Detailed information regarding its specifications and approval can be found in the FDA documentation."
"Identify cancer patients symptom burden, including symptoms supported by embedded mental health.  ","The project aims to develop an health information technology tool that utilizes AI to extract and highlight cancer patients symptom burden, particularly focusing on mental health needs, to aid embedded mental health specialists in oncology clinics. This tool will enhance the efficiency and effectiveness of mental health support for Veterans, allowing providers to easily identify patients who may benefit from additional help while improving patient engagement and quality of care. The system will operate within secure VA IT frameworks, ensuring compliance with relevant regulations, and will not directly impact decision-making in clinical care."
Ambulatory heart rhythm monitoring,"The project utilizes AI to analyze 14 days of heart rhythm data, effectively identifying and narrowing down periods of abnormalities. It produces a report that lists various detected heart rhythm irregularities for clinicians to interpret and make informed recommendations."
Insights Engine,"The Insights Engine is a human-language interface designed to query aggregate-level and anonymized customer experience and operational data for VA research and design initiatives. It utilizes large language model interpretation to generate queries and provide clear, relevant responses, acting as a research librarian for teams to access past findings and insights. This tool aims to streamline research efforts by reducing redundancy and building on existing knowledge."
"Philips EPIQ Diagnostic Ultrasound System, Philips Affiniti Diagnostic Ultrasound System",The Philips EPIQ and Affiniti Diagnostic Ultrasound Systems are FDA-cleared medical devices designed to assist clinicians in diagnosing patients and enhancing healthcare outcomes. Detailed information about these devices is available in FDA documentation.
Glassbeam Clinsights ,"Glassbeam Clinsights utilizes AI to collect and analyze medical device data to predict potential failures. The system assesses hardware information and determines whether it is functioning normally, declining, or has failed, enabling timely alerts to technicians for repairs or replacements before devices are used in medical procedures."
VX Insights Hub Agent,"The VX Insights Hub Agent is a tool designed to enhance decision-making and performance improvement for VA staff by providing a user-friendly interface for querying aggregated customer experience and operational data. Utilizing large language model technology, it allows users without a data science background to formulate queries and receive natural language responses, along with validation details of the generated queries. This innovation aims to simplify access to essential metrics and support informed decision-making within the organization."
"OPTIS Mobile Next Imaging System, OPTIS Integrated Next Imaging System","The OPTIS Mobile Next Imaging System and the OPTIS Integrated Next Imaging System are FDA-cleared medical devices designed to assist clinicians in their practice, thereby enhancing healthcare outcomes. Detailed information about these devices can be found in the FDA documentation."
Automated Decision Support,"The Automated Decision Support (ADS) system streamlines the processing of VA claims and contentions by utilizing advanced technologies such as machine learning and Natural Language Processing (NLP) to extract and analyze data from various submissions. It automates key actions like medical record retrieval, summarization of claims, and submission of examination requests, achieving an average extraction of 95 fields from over 1500 form layouts. Ultimately, the platform enhances efficiency by changing the claim status to Ready For Decision (RFD)."
Compliance Made Easy (CME) Cloud Optimization,"The Compliance Made Easy (CME) project focuses on automating the review of official communications to ensure adherence to the VA style guide and enhance effectiveness. By utilizing AI, it aims to reduce the time and resources spent on document creation and review, while providing updates, suggestions, and data analytics to improve communication quality over time. This approach minimizes reliance on human oversight, streamlining the process of producing compliant and clear communications."
O-arm O2 Imaging System,"The O-arm O2 Imaging System is an FDA-cleared medical device designed to assist clinicians in enhancing healthcare outcomes. It provides advanced imaging capabilities, facilitating improved surgical precision and patient care. Detailed information about the device can be found in the official FDA documentation."
Mail Automation Services,"Mail Automation Services (MAS) is an ITTT service that processes 25,000 to 40,000 packets of VA claims materials and stakeholder submissions daily. The platform employs machine learning and Natural Language Processing (NLP) technologies, including Intelligent Form Recognition (IFR) and Optical Character Recognition (OCR), to extract data from over 1,500 form layouts. The primary output of MAS is the establishment of VBA end-products and accurate business line orientation for the ingested submissions under the Veterans Benefits Administration Automation Platform (VBAAP)."
NeuroQuant,"NeuroQuant is an FDA-cleared medical device designed to assist clinicians in analyzing brain MRI scans. It aims to enhance healthcare outcomes by providing objective measurements of brain structures, which can aid in the diagnosis and management of neurological conditions. The device is documented thoroughly in FDA materials, confirming its efficacy and safety for clinical use."
Master Claims Assistance Tool (M-CAT),"The Master Claims Assistance Tool (M-CAT) is a generative AI system designed to support VA personnel by processing inputs such as policies, procedures, and user inquiries. It generates responses using a RAG model through a chatbot interface, catering specifically to VA or VBA staff as directed by SES."
MAGNETOM Vida; MAGNETOM Lumina; MAGNETOM Aera; MAGNETOM Skyra; MAGNETOM Prisma; MAGNETOM Prisma fit,"The MAGNETOM Vida, Lumina, Aera, Skyra, Prisma, and Prisma fit are FDA-cleared medical devices designed to assist clinicians and enhance healthcare outcomes. These devices leverage advanced imaging technology to improve patient diagnostics and treatment processes. Details regarding their FDA clearance can be found in the relevant documentation."
3D Quorum ,"3D Quorum is an AI-powered mammography analytics tool that generates 6mm 'SmartSlices' from high-resolution 3D data, identifying clinically relevant regions of interest. This technology reduces the number of 3D images Radiologists must review by two-thirds and enhances their decision-making process while allowing them to accept or reject the AI's suggestions."
INtuition-Structural Heart Module,"The INtuition-Structural Heart Module is an FDA-cleared medical device designed to assist clinicians in the treatment of structural heart conditions. By providing enhanced guidance and support during procedures, it aims to improve healthcare outcomes for patients. Details about the device can be found in the FDA documentation."
Intelligent 2D ,"The Intelligent 2D Mammography project generates synthetic 2D images from 3D mammography data to enhance breast lesion detection while decreasing radiation exposure. This technology minimizes image noise and artifacts, leading to clearer visuals of breast tissue for interpreting radiologists. It has received FDA approval and aims to improve diagnostic accuracy."
QV CAD,"QV CAD is an Automated Breast Ultrasound (ABUS) solution from QView Medical designed to assist radiologists in interpreting screening procedures for women with dense breast tissue and negative mammograms. The system utilizes advanced image pattern recognition and artificial neural networks to identify suspicious areas in the breast, enhancing the decision-making process of radiologists while allowing them to accept or reject the suggested outputs. This technology integrates standard DICOM input images with native ABUS imaging for comprehensive analysis."
FlexLine: Detect patterns and make corrective action recommendations in application and dependency time to mitigation data. ,"FlexLine is an AI-driven capability integrated within the materials management application that analyzes patterns in application and dependency time-to-mitigation data to identify vulnerabilities. It aims to recommend corrective actions for teams that are not addressing these vulnerabilities within specified timeframes (30, 45, 60 days), thereby protecting products and enhancing Veteran care. The project will automate the generation of Jira tickets, providing teams with detailed insights and recommendations to expedite the resolution of issues."
Medical Imaging Auto-segmentation,"The Medical Imaging Auto-segmentation project aims to enhance efficiency in defining regions of interest by utilizing an AI system. This technology automates the process of outlining lesions or organs, such as the liver, by generating proposed outlines based on imaging data and anatomical atlases, which physicians can then refine or approve."
FFRangio,"FFRangio is an FDA-cleared medical device designed to assist clinicians in their practice and enhance healthcare outcomes. Its effectiveness and safety were detailed in the FDA documentation, demonstrating its potential to improve patient care."
Quantra ,"Quantra utilizes a multi-class support vector machine (SVM) classification technique to categorize breast types into four distinct categories based on their parenchymal tissue pattern and texture representation. This tool assists radiologists in their interpretations and aims to reduce variability in readings, while ultimately allowing radiologists to accept or reject the classification outputs."
VSTOne  AI-Driven Patient Monitoring and Care Delivery,"VSTOne is an innovative AI-driven solution for patient monitoring and care delivery, designed to alleviate the burdens faced by nurses amid staffing shortages in the healthcare industry. It enhances patient outcomes by providing automated monitoring that assists nurses, predicts potential falls 30-65 seconds in advance, detects pressure ulcer risks, and tracks vital signs through wearable technology for real-time telehealth consultations. This system aims to improve care quality while allowing healthcare professionals to concentrate on higher-level tasks."
 Surveillance and Reporting of Suicidal Ideation Assessment in PTSD Specialty Care Clinical Notes using Natural Language Processing (NLP),"The project aims to enhance the consistency and quality of suicidal ideation assessments in PTSD specialty care through the use of natural language processing (NLP) on clinical documentation. By identifying and quantifying mentions of suicidal ideation in treatment notes, the project seeks to improve clinical management of suicide risk and provide detailed reports on assessment quality at national and local levels. Ultimately, the goal is to monitor and improve suicide ideation assessment practices in PTSD care across the country."
"FastStroke, CT Perfusion 4D","FastStroke is an FDA-cleared medical device designed to enhance clinician capabilities and improve healthcare outcomes in CT perfusion imaging. It offers advanced analysis and visualization of blood flow in the brain, aiding in the diagnosis and management of stroke. The device is detailed in the FDA documentation, which outlines its specifications and clinical applications."
Koios,"Koios is an automated system designed for use with Automated Breast Ultrasound (ABUS) that classifies breast ultrasound lesions and automates reporting to enhance efficiency and streamline workflows. It improves diagnostic accuracy by increasing sensitivity and specificity while reducing variability, allowing for safe downgrading of existing BI-RADS 3 cases and providing probabilities of malignancy that align with BI-RADS categories. The tool supports Board Certified or Board Eligible Radiologists in their decision-making process, while ensuring they can review and either accept or reject the system's suggestions."
Evaluation of Autonomous Assistive Feeding System in Spinal Cord Injury Patients,"This project focuses on enhancing an Autonomous Assistive Feeding System designed for spinal cord injury patients to support bite acquisition and transfer using a robotic arm. It employs video analysis of caretakers and a web interface for stakeholder feedback to refine the arm's autonomous capabilities, aiming to boost functional independence in patients with upper extremity weakness. The system will be tested in both fully autonomous and shared autonomy settings, allowing for real-time input during the bite acquisition process."
Using AI to read PDFs and parse the information to SharePoint list,The project involves using AI to read PDFs from the TPA and extract data into a SharePoint list. This automation is expected to reduce employee processing time by 20% and will facilitate data utilization in Power BI.
Discovery MI Gen2,"Discovery MI Gen2 is an FDA-cleared medical device designed to assist clinicians in their practice and enhance healthcare outcomes. It provides advanced functionalities that support clinical decision-making and patient management, as detailed in its FDA documentation."
Genius AI,"Genius AI enhances mammography by assisting radiologists in locating potential breast cancer lesions within tomosynthesis image sets. It marks lesions on the relevant slices, which can be overlaid on synthesized 2D images and 3DQuorum SmartSlices, providing an overview and enabling quick navigation to the original tomosynthesis slice. This tool augments radiologists' capabilities by improving efficiency and accuracy in identifying suspicious areas."
Implementation of a Severe COVID-19 Risk Prediction Tool,"The project implements a Severe COVID-19 Risk Prediction Tool using a machine-learning model to identify Veterans at higher risk for severe symptoms, aiming to improve vaccination outreach. By estimating patients' risks and current vaccine eligibility, the tool facilitates timely vaccination offers, thereby enhancing health outcomes. The model generates a risk score for hospitalized patients and notifies clinical teams about eligible individuals for vaccination based on CDC guidelines."
CVI42,"CVI42 is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. It is detailed in the FDA documentation, which outlines its safety and effectiveness in clinical applications."
Discharge Predictive Model,"The Discharge Predictive Model aims to enhance communication among clinical and ancillary staff by accurately identifying acute inpatients likely to be discharged within 24 hours. By leveraging vital signs and lab result trends, the model provides an estimated aggregate discharge volume, leading to improved hospital throughput, bed coordination, and the ability to accommodate additional admissions and transfers. This automated process addresses inconsistencies in pre-discharge orders due to trainee turnover, ultimately streamlining discharge planning."
HSRD IIR 19-069 Optimizing Renin Angiotensin System Blocker Use among Veterans with Kidney Disease,"The project aims to optimize the use of Renin Angiotensin System blockers among veterans with chronic kidney disease (CKD) by summarizing narrative clinical notes from electronic health records. It delivers a concise summary of relevant information, including side effects and medication details, to primary care providers before patient encounters, enhancing clinical decision-making. The narrative note includes justifications for clinical summarization and pertinent documentation for the provider's review."
CT CoPilot,"CT CoPilot is an FDA-cleared medical device designed to assist clinicians in their diagnostic processes and enhance healthcare outcomes. The device is detailed in FDA documentation, which outlines its intended use and regulatory compliance."
"Cranial Navigation, Navigation Software Cranial, Navigation Software Craniofacial, Cranial EM System, Automatic Registration iMRI","This project involves the development of FDA-cleared cranial navigation software and systems, designed to assist clinicians in performing cranial and craniofacial procedures. The technology includes automatic registration and intraoperative magnetic resonance imaging (iMRI) capabilities to enhance healthcare outcomes. Detailed information about the device can be found in the FDA documentation."
Aquilion ONE (TSX-305A/6) V8.9 With AiCE,"The Aquilion ONE (TSX-305A/6) V8.9 is a computed tomography (CT) device equipped with AI Deep Learning CT Reconstruction technology, termed AiCE. This device has undergone evaluation and is documented for its capabilities in enhancing image quality through advanced AI algorithms, as outlined in its FDA documentation."
CellaVision DM1200 with the body fluid application,"The CellaVision DM1200 is an FDA-cleared medical device designed to assist clinicians in analyzing body fluids, ultimately enhancing healthcare outcomes. The device utilizes advanced imaging technology to streamline the diagnostic process for medical professionals. Detailed information about its FDA clearance and functionalities can be found in official documentation."
Nediser reports QA,"Nediser is an AI-powered system designed to assist radiologists in drafting radiology reports by utilizing computer vision and machine learning techniques. It evaluates various medical conditions, including patella alignment, leg length discrepancies, and arthritis grading, while providing draft outputs for radiologists to review and potentially incorporate into their final reports. The system ensures that original DICOM images are deleted post-processing, with only de-identified data retained for auditing and further model training."
"CARTO 3 EP Navigation System Software V8.0 (FG-5400-00, FG-5400-00U)","The CARTO 3 EP Navigation System Software V8.0 is an FDA-cleared medical device designed to assist clinicians in cardiac procedures and enhance healthcare outcomes. This software is detailed in FDA documentation, which outlines its functionalities and usage in medical settings."
Care Assessment Needs (CAN) Score,The Care Assessment Needs (CAN) Score is a set of logistic regression models designed to assess the risk of 90-day hospitalization or death among Veterans receiving healthcare through the Veterans Health Administration (VHA). This tool aids in stratifying patients based on their health care needs.
Cartesion Prime (PCD-1000A/3) V10.15,Cartesion Prime (PCD-1000A/3) V10.15 is an FDA-cleared medical device designed to assist clinicians and enhance healthcare outcomes. The device's specifications and regulatory approval details can be found in the FDA documentation available online.
VA CART Percutaneous Coronary Intervention SYNTAX Score ,The VA CART SYNTAX risk model predicts 30-day post-PCI mortality by integrating clinical and anatomic variables. It is designed to aid personalized informed consent discussions and better prepare for high-risk PCI cases by assessing the risk of major adverse cardiovascular events over time.
Cardiac CT Function Software Application,"The Cardiac CT Function Software Application is an FDA-cleared medical device designed to assist clinicians in their decision-making processes and enhance healthcare outcomes. It provides advanced imaging and analysis capabilities for cardiac assessments, as outlined in the FDA documentation. This software aims to improve patient care through accurate diagnostics and efficient workflows."
Falls Prediction Tool,"The Falls Prediction Tool aims to automate the determination of co-pay exemption eligibility for veterans under the PACT Act, addressing the manual process and lack of awareness about toxic exposure among some veterans. The project will develop an algorithm that provides a binary output to indicate whether a veteran qualifies for the co-pay exemption based on relevant criteria."
VA CART Percutaneous Coronary Intervention Mortality Model ,"The VA CART Percutaneous Coronary Intervention Mortality Model uses logistic regression to predict the risk of 30-day mortality following PCI, based on baseline clinical and procedural data. This model aids in risk stratification at the point of care, enhancing clinical decision-making for patient management."
Pact Act Co-Pay Exemption Prediction Tool,"The Pact Act Co-Pay Exemption Prediction Tool aims to automate the determination of veterans' eligibility for co-pay exemptions related to toxic exposure. By developing an algorithm, the tool will provide a binary output indicating whether a veteran qualifies for the PACT Act co-pay exemption, thereby streamlining the current manual process."
VA CART Percutaneous Coronary Intervention Nephropathy Model ,The VA CART nephropathy risk model utilizes logistic regression to predict post-percutaneous coronary intervention (PCI) acute kidney injury based on baseline clinical and procedural variables. This model is designed to assist healthcare professionals in risk stratification at the point of care.
Purchase Order Filing,"The Purchase Order Filing project utilizes Microsoft Power Automate's AI builder to efficiently file purchase orders and related documents (invoices, returns, amendments, packing slips) on SharePoint. This automation streamlines document organization by creating a consistent naming convention and consolidating all related documents into organized folders by Purchase Order number, simplifying audit responses and saving staff time."
"Brainlab Elements Image Fusion, Contouring (4.5);Image Fusion (4.5);Fibertracking (2.0);BOLD MRI Mapping (1.0);Image Fusion Angio (1.0)","The Brainlab Elements Image Fusion is an FDA-cleared medical device designed to assist clinicians in enhancing healthcare outcomes through advanced imaging techniques such as image fusion and fiber tracking. It incorporates various functionalities including contouring and BOLD MRI mapping to support improved diagnosis and treatment planning. The device is detailed in FDA documentation, indicating its compliance with regulatory standards."
VA CART Myocardial Ischemia NLP,"The VA CART Myocardial Ischemia NLP project utilizes Natural Language Processing to extract myocardial ischemia information from Radiology reports in VistA. The NLP results categorize stress test outcomes as 0 for negative, 1 for positive, and -1 for inconclusive."
VA CART Ejection Fraction NLP,"The VA CART Ejection Fraction NLP project utilizes Natural Language Processing to extract ejection fraction (EF) information from Echocardiogram TIU report text in the VistA system. The results categorize EF by determination methodsHuman Observation, Biplane, 4-Chamber, and 2-Chamberprioritizing the best value in that order, while a NULL Best EF Value signifies the absence of identifiable ejection fraction data."
BioPlex 2200 ANA Screen with Medical Decision Support Software for Use with BioPlex 2200 Multi-Analyte Detection System,"The BioPlex 2200 ANA Screen is an FDA-cleared medical device designed to assist clinicians in diagnosing autoimmune diseases, thereby enhancing healthcare outcomes. It integrates medical decision support software with the BioPlex 2200 Multi-Analyte Detection System, facilitating accurate and efficient patient assessments. Detailed information about the device can be found in the FDA documentation."
VA CART Percutaneous Coronary Intervention Bleeding Risk Model,"The VA CART bleeding risk model utilizes logistic regression to assess baseline clinical and procedural factors in order to predict in-hospital bleeding events following Percutaneous Coronary Intervention (PCI). It serves as a tool for risk stratification at the point of care, enabling healthcare providers to identify patients at higher risk for bleeding prior to hospital discharge."
"Biograph Vision, Biograph MCT Family Of PET/CTs","The Biograph Vision and Biograph MCT Family of PET/CTs are FDA-cleared medical devices designed to assist clinicians and enhance healthcare outcomes. These devices improve diagnostic capabilities by integrating advanced imaging technology, as detailed in the FDA documentation."
Rythm Express,Rythm Express is a project focused on predicting potassium levels using electrocardiogram (ECG) data. It aims to enhance the evaluation of potassium levels through analysis of ECG readings. This approach seeks to provide a non-invasive method for monitoring potassium status in patients.
AutoContour Model RADAC V3,The AutoContour Model RADAC V3 is an FDA-cleared medical device designed to assist clinicians in their workflow. It aims to enhance healthcare outcomes by providing improved contouring capabilities. Detailed information regarding the device is available in FDA documentation.
A computer vision framework (CVF) for the image classification in the Veteran Health Administration (VHA),"The project aims to develop a computer vision framework (CVF) for classifying medical test images within the Veteran Health Administration (VHA). This framework will aid in generating decisions regarding disease presence based on the analysis of medical test images. Ultimately, the CVF will enhance the decision-making process for patient diagnoses."
Github Copilot,"GitHub Copilot is an AI-powered tool that assists developers by offering intelligent code suggestions and completions, thereby enhancing productivity and code quality. It reduces the time spent on boilerplate coding, serves as a learning resource, mitigates cognitive load, and accelerates prototyping. Additionally, it provides security warnings, best practices, and documentation to help developers manage code securely and efficiently."
aPROMISE X,aPROMISE X is an FDA-cleared medical device designed to support clinicians in enhancing healthcare outcomes. Its effectiveness and safety are detailed in the FDA documentation available at the provided link. This device aims to improve patient care through advanced clinical assistance.
AI coding,"The project focuses on integrating AI into coding and creative design to enhance productivity, quality, and accessibility. By automating routine tasks, AI allows coders and designers to work more efficiently while driving innovation through intelligent analysis and suggestions. Key features include automatically generated code snippets, bug reports, documentation, refactored code, and suggested test cases, all aimed at improving overall outcomes in these fields."
"Aplio i900, Aplio i800 and Aplio i700 Software V8.1 Diagnostic Ultrasound System","The Aplio i900, Aplio i800, and Aplio i700 Software V8.1 are FDA-cleared diagnostic ultrasound systems designed to assist clinicians in improving healthcare outcomes. The systems utilize advanced imaging technology to enhance diagnostic capabilities in medical settings. Detailed information about the device can be found in the FDA documentation."
"Alignment System Cranial, Alignment Software Cranial, Cirq Alignment Software Cranial Biopsy, Cirq Alignment Software Cranial sEEG, Varioguide Alignment Software Cranial","The project involves the development of various FDA-cleared alignment software and systems for cranial applications, including tools for biopsy and sEEG. These medical devices are designed to assist clinicians and enhance healthcare outcomes as outlined in the FDA documentation."
Dental - Dentsply Sirona CERE,The Dentsply Sirona CERE project utilizes intelligent automation to quickly generate dental reconstruction proposals based on scans. This technology enhances the efficiency of dental practice by streamlining the reconstruction planning process.
Fusion 2024 (JAWS/ZoomText),"Fusion 2024 (JAWS/ZoomText) is a software solution designed to enhance access to visual content for blind and low vision employees, ensuring compliance with Section 508 legal requirements. It provides detailed descriptions of charts, graphs, tables, and images on the screen, and enables users to ask follow-up questions for further insights regarding trends and specific information."
"Acumen Hypotension Prediction Index - EV1000 Clinical Platform, Acumen Hypotension Prediction Index - Hemosphere Advanced Monitoring Platform, Acumen Hypotension Prediction Index, Hemosphere Advanced Monitoring Platform - Pressure",The Acumen Hypotension Prediction Index is an FDA-cleared medical device designed to assist clinicians in predicting hypotension to enhance healthcare outcomes. It is available on both the EV1000 Clinical Platform and the Hemosphere Advanced Monitoring Platform. This device leverages advanced monitoring capabilities to improve patient care and prevent adverse events.
Xtract WDS - OSSO,Xtract WDS - OSSO focuses on developing heat map detection capabilities for weapon detection software. The project identifies areas of interest that emit heat indicators correlated with the heat signatures of various known weapon types. This technology aims to enhance the accuracy and efficiency of weapon detection systems.
Transcription Services,The project focuses on providing transcription services to enhance efficiency by transcribing meetings and interviews. This ensures accurate documentation and facilitates easier access to important information. The goal is to streamline communication and improve overall productivity.
Chatbot within ESMS,The project involves the development of an internal-facing chatbot within the Enterprise Sustainability Management System (ESMS) to assist employees with policy-related inquiries. This initiative aims to enhance efficiency by providing quick and accessible responses to commonly asked questions.
Extreme Load Analysis,"Extreme load analysis estimates the likelihood of peak energy demand across various months and hours, assisting in energy forecasting. An RShiny Web App is developed to present extreme value distributions (EVD) for different time frames and plants, enabling users to filter data and adjust percentiles to view specific quantile values."
Materials Intelligent Catalog Assistant,"The Materials Intelligent Catalog Assistant enhances inventory management by offering an intelligent search engine that enables users to efficiently locate items using various filters. It provides detailed information on item specifics, location, and cost, while also identifying similar items to reduce duplication in inventory ordering. This innovation aims to streamline the catalog experience and improve overall inventory control."
Vegetation Management,"The Vegetation Management project involves monitoring vegetation surrounding transmission lines and towers, utilizing predictive analytics to determine optimal trimming times and locations. Reports are generated with the assistance of NV5, highlighting areas that require vegetation trimming."
CAP Automation,"The CAP Automation project involves utilizing natural language processing (NLP) to categorize condition reports into three classification levels: C, E, or WO. Each report will receive a label based on its assessment, streamlining the classification process."
CR intelligent search,CR Intelligent Search is a natural language processing (NLP) tool designed to efficiently search through condition reports (CRs). It incorporates pattern recognition to enhance search capabilities and allows the addition of relevant safety data for comprehensive topic modeling. This search engine facilitates more effective analysis and retrieval of information from CRs.
Materials tracking,The project involves developing a materials tracking system that employs predictive analytics to assess the status of materials throughout the supply chain. A dashboard will be created to monitor the location of items in the supply chain and evaluate their risk of late delivery. This system aims to improve efficiency by providing real-time insights into material flow and potential delays.
Heliviewer,"Heliviewer is a project that utilizes helicopter image data for conducting surveys and gaining insights into various projects. It features a search engine that allows users to easily navigate through images, project details, flight patterns, and other relevant information. This tool enhances the accessibility and usability of aerial data for analysis and decision-making."
ICI camera ,"The ICI camera project leverages computer vision technology to monitor the rate of change in water temperature using thermal imaging, which can indicate potential dam leakage. It also includes predictive analysis to determine expected water temperatures and implements risk alerts when temperatures exceed certain thresholds."
GET,"The Groundwater Evaluation Tool (GET) facilitates the statistical analysis of groundwater monitoring data in compliance with state regulations and the federal Coal Combustion Residuals (CCR) rule. It employs advanced statistical methods across three monitoring phasesDetection, Assessment, and Corrective Actionto identify significant changes in groundwater quality and assess compliance with groundwater protection standards. The tool also features a dashboard and reporting capabilities to present the results of the statistical analyses."
GMET,GMET is an R Shiny application designed to evaluate groundwater chemistry data at TVA's CCR sites using Phreeqc geochemical models. The tool generates geochemical reports that detail the chemical composition of groundwater at these locations.
Optiwatt EV Load Model,The Optiwatt EV Load Model is a linear model designed to predict hourly charging loads from non-fleet electric vehicles (EVs) over a typical meteorological year (TMY). It generates hourly load shape profiles to effectively represent EV charging behavior.
Cold-Weather Heat Pump Model,"The Cold-Weather Heat Pump Model utilizes KNN regression to predict the hourly impact of an upgraded cold-weather heat pump in residential settings, considering both historical and forecasted weather data. It generates a detailed hourly load shape profile for the heat pump's performance."
EE/DR Smart Thermostat Impact Model,"The EE/DR Smart Thermostat Impact Model simulates the hourly effects of energy efficiency (EE) and demand response (DR) smart thermostats in residential settings, utilizing historical and forecasted weather and load data. It generates an hourly load shape profile to assess the unitized impact of these thermostats on energy consumption and demand."
Standard EE/BE Measure Impact Models,"The project develops approximately 200 linear models to assess the hourly impact of energy efficiency (EE) and building energy (BE) measures. These models utilize a standardized set of calendar and weather features to predict the unitized impact under both historical and forecasted weather conditions. Additionally, it includes the creation of hourly load shape profiles for EE and BE measures."
EnergyRightPSPImpactsForecasting,"The EnergyRightPSPImpactsForecasting app functions as an ETL tool for ancillary data and a lightweight MLOps platform for modeling the impact shapes of energy efficiency and electrification measures. It supports system planning assumptions and serves as a user interface to ES&P's forecast aggregation engine for supply-side resource management. Additionally, the app generates energy efficiency direct load response (EEDR) shapes and forecasts."
CESASolarModel,"The CESASolarModel app enables TVA internal users to create sample bills for directly served and BCD-rate customers by using current wholesale rates, historical load data, and anticipated patterns of new behind-the-meter solar arrays. Users can input data to generate accurate sample bills."
CESAFCAAllocator,"CESAFCAAllocator is an application designed to assist in the 3-class allocation of TVA's total monthly fuel cost to large general service customers, large manufacturing customers, and those smaller than 5 MW. It functions as one of two co-calculators in this process. The app ensures accurate distribution of monthly fuel expenses among the specified customer categories."
EnergyRightDERPortfolioEvaluation,"The EnergyRightDERPortfolioEvaluation app serves as a visualization and export tool for the outputs of ES&P's system planning processes, allowing Enterprise Planning to access aggregated ES&P forecasts. It provides insights into evaluation methodologies and includes a connection to the ES&P forecast aggregation engine for reporting and stochastic simulation purposes. The app aims to facilitate understanding and reporting of ES&P's aggregated forecasts."
Prism Models for MDM,"The project involves utilizing clustering and nearest neighbor models to analyze analog signal data for the detection of signal anomalies. It aims to identify deviations from normal signal patterns, generating an OMR (Outlier Metric Ratio) to quantify the distance of the current vector from normal. The system also includes automated email notifications for human validation of detected anomalies."
Load Forecasting,The Load Forecasting project aims to predict energy demand for the next 30 years to aid in power supply planning. It provides long-term capacity and energy forecasts to ensure adequate resources are available to meet future energy needs.
ArcGIS,"ArcGIS is a comprehensive platform for mapping, analyzing, managing, and visualizing geospatial data. It supports various GIS services, enabling organizations to effectively utilize spatial information through mapping, spatial analysis, and image processing. This robust solution enhances decision-making and improves the management of geographic data."
Advanced Network Anomaly Detection,"The Advanced Network Anomaly Detection project focuses on enhancing threat detection for Security Operations Center (SOC) analysts by utilizing automated tools that analyze extensive datasets to identify unusual network behavior. By correlating network traffic with proxy communications, the system effectively detects compromised systems and provides actionable intelligence. Additionally, it includes metrics and alerting features, with options for preventative and proactive security measures."
Security Information and Event Management (SIEM) Alerting Models,"The project focuses on developing Security Information and Event Management (SIEM) alerting models to enhance the interpretation of contextual information, expedite event detection, and boost productivity through human-assisted automation for Security Operations (SecOps) and IT Operations (ITOps). These automated tools facilitate quicker alerting, review, and response to large volumes of log data while refining alerts using aggregated data and analyst expertise. Additionally, the project incorporates metrics and optional preventative measures for proactive protection."
Vulnerability Tracking,"Vulnerability analysts monitor thousands of vulnerabilities in real-time across various technologies within an enterprise. They prioritize these vulnerabilities based on severity, contextual information, exploitability, and additional metrics while integrating alerting and optional preventative measures for effective risk management. The tools employed assist in navigating the complexities of prioritizing vulnerabilities, especially when faced with numerous CVEs of similar severity."
Advanced Threat Protection,"The Advanced Threat Protection project focuses on safeguarding organizations by employing strategies similar to those used by attackers. It utilizes a vast array of data across various systems to make informed, mathematical decisions that effectively mitigate threats. Additionally, the project implements machine learning and artificial intelligence technologies to reduce phishing, malware, and compromised account issues while enhancing visibility into potential risks."
AI -Driven Adaptive Protection,"AI-Driven Adaptive Protection enhances cybersecurity by facilitating real-time sharing of machine-readable threat indicators and defensive strategies to mitigate cyber incidents. It effectively defends against human-operated ransomware by utilizing predictive analytics to implement active blocking measures and prevent further exploitation. The system also includes features for metrics, alerting, and optional proactive protections."
Attack Surface Management,"The Attack Surface Management project employs proprietary machine learning models to identify and inventory TVA's systems and applications across the internet. This initiative allows TVA to implement necessary protections for external services, continuously monitor potential vulnerabilities, and prioritize remediation efforts. Additionally, it provides metrics and alerting capabilities, along with optional preventative measures."
Extended Threat Detection,"The Extended Threat Detection project utilizes AI-based technology to enhance threat detection and response through automated detection capabilities, deep packet inspection, and real-time analysis. By employing unsupervised machine learning models, it accurately identifies anomalous behaviors against established baselines of normalcy. This system significantly improves visibility and accuracy in identifying both benign and malicious threats, while also incorporating metrics, alerting, and optional preventative measures."
Augmented Email Protection,"Augmented Email Protection is an email security service that utilizes advanced analysis to detect malicious messages and content by examining various signals, including AI-generated indicators of normal human behavior and established threats. The service includes metrics tracking, alert notifications, and optional preventive measures to enhance email security."
Natural Reader,"Natural Reader is a user-friendly text-to-speech desktop software designed for individual use. It features natural-sounding voices and can read a wide range of text formats, including Microsoft Word documents, webpages, PDF files, and emails. The software enhances accessibility and convenience for users seeking assistance with reading."
River Forecast,The River Forecast project utilizes a multi-scale graph neural network-based autoregressive model to predict atmospheric variables. It is trained on historical weather data from ECMWF's ERA5 reanalysis archive and generates predictions at 6-hour intervals. This tool aims to enhance forecasting accuracy for surface and atmospheric conditions.
Security Operations Enhancement,"The Security Operations Enhancement project focuses on empowering Security Operations Center (SOC) analysts by integrating AI-enriched threat intelligence to improve their understanding of security landscapes and ongoing attacks. It promotes the prioritization of event handling and investigative actions to effectively identify and mitigate threats, while also incorporating metrics and alerting systems for proactive protection."
Advanced Threat Protection,"The Advanced Threat Protection project focuses on safeguarding organizations by employing strategies similar to those used by attackers. It utilizes a vast array of data across various systems to make informed, mathematical decisions that effectively mitigate threats. Additionally, the project implements machine learning and artificial intelligence technologies to reduce phishing, malware, and compromised account issues while enhancing visibility into potential risks."
Perimeter Defense,"Perimeter Defense is a security tool that uses tailored ruleset definitions and a proprietary machine learning algorithm to safeguard web applications from malicious activity. It proactively detects and prevents threats by analyzing millions of network traffic samples. The tool also includes metrics, alerting capabilities, and optional preventative measures to enhance security."
Intrusion Detection Analysis,"The Intrusion Detection Analysis project focuses on enhancing threat hunting and security operations by utilizing automated tools to refine alerts for detecting anomalous network behaviors. By correlating extensive network traffic data with proxy communications, the project aims to identify compromised systems and networks effectively. Additionally, it incorporates metrics and alerting features, along with optional preventative measures, to strengthen overall security posture."
Malware Reverse Engineering,"The Malware Reverse Engineering project focuses on the analysis of malware and software to enhance TVA's cybersecurity efforts. By utilizing multiple antivirus scanners and blocking services, the project aims to improve efficiency and reduce the time analysts spend evaluating potentially malicious content in TVA's technology ecosystem. This initiative is integral to maintaining robust threat intelligence and protection against cyber threats."
Threat Intelligence Feed,The Threat Intelligence Feed project focuses on information sharing by utilizing advanced technology and industry expertise. It aims to deliver participants near real-time access to relevant and actionable threat information concerning external network traffic.
AI-Enhanced Search,"The AI-Enhanced Search project aims to improve user experience by enabling faster and easier access to information through features such as auto-complete search queries, natural language processing, and typo handling. It enhances the Knowledge Base Catalog Data, making it more efficient for users to find answers."
Network Anomaly Detection,"The project focuses on real-time network anomaly detection, providing visibility into network communications, assets, connections, and protocols. It aims to identify unusual behavior that could threaten the security or reliability of operational technology (OT) systems."
