Use Case ID,Use Case Name,Agency,Component,What is the intended purpose and expected benefits of the AI?,Describe the AI system’s outputs.
HHS-ACF-00001,Design Your Facility,HHS,ACF,"The Office of Refugee Resettlement (ORR) manages many facilities for unaccompanied children and must regularly determine bed availability, configuration, and assignments. The current process for gathering this information takes lengthy training and assistance from system administrators.

The Design Your Facility interface leverages LLMs to help users more quickly configure the correct building, room, and bed layout needed to create their facility’s “digital twin” in the UC Bed Network Facility Mapper without lengthy training or deskside assistance from system administrators.","The Design Your Facility tool uses large language models (LLMs) to transform building layout information shared by users in a conversational manner into data about buildings, rooms, and bed layers within the Unaccompanied Children (UC) Bed Network tooling.

The AI model suggests object configurations that should be applied to correctly model a facility’s “digital twin” of the building, room, and bed layout. The workflow relies solely on user descriptions and user confirmations."
HHS-ACF-00002,Discover Financial Business Intelligence System (FBIS) Report Analysis (Sub-CAN Line Items),HHS,ACF,"This project provides a resource for ACF Discover users in the budget community to identify related line items across disparate reports from FBIS. The process searches the data and aggregates information (e.g. supplier name, document number, total obligations) to create an up-to-date, real-time spend plan that pulls from the open-closed report, requisition purchase order report, and integrates with funds distribution report.

AI returns line items from the open-closed report and requisition purchase order report related to the sub-CAN line item description such as supplier name, document number, document type, and total obligations for that sub-CAN line item. The Discover FBIS Report Analysis (Sub-CAN Line Items) LLM helps find related obligations and line items from various reports and returns information crucial for a budget officer when they are creating a spend plan for their office. The LLM aids ACF Discover track various line items and pulls the information into one place: the Spend Plan module where ACF can track yearly budgets and monitor budget health.","A large-language model helps compile an aggregated report of costs by intaking a specific Congressional Appropriation Number (CAN), category, sub-CAN line item descriptions (which are not standardized), and a projection cost from the user (either by a CSV or manual entry)."
HHS-ACF-00003,Grant Spend Health Analysis,HHS,ACF,"The mission of the Office of Grants Management (OGM)is to provide high-quality fiscal stewardship and management for ACF-funded recipients across the country and in U.S. territories. This includes responsive oversight and technical assistance for discretionary awards, non-discretionary awards, and cooperative agreements. OGM seeks ways to prioritize proactive technical assistance to grant recipients based on likelihood that awarded funds may not be fully utilized. 

The goal is to identify still-active grants that are potentially on the path towards deobligating funding. This information would be visible to grant specialists within ACF. OGM anticipates developing customized training and technical assistance materials that can assist recipients if we predict that their grant is trending towards leaving funds unutilized.","As part of this project, we are conducting exploratory analyses including supervised and unsupervised AI techniques to determine whether the data we have on grant spend over time can power a predictive model that reasonably identifies grants with a higher likelihood of under-utilizing funds. "
HHS-ACF-00004,Structuring and Validating Completeness of Case Data Information,HHS,ACF,"In accordance with the Ms L vs ICE settlement, the U.S. Customs and Border Protection (CBP) must provide specific pieces of information about family separations. Beginning November 2024, CPB will release this information. ACF's Office of Refugee Resettlement (ORR) plans to add family separation information to existing child profile information for reference.

The AI output structures free form data into a more easily searchable format. These data will be used to assist in the placement process.","Creates a structured data asset of  the critical data points needed about a separation case. AI will be used to conduct initial parsing of the data provided by CBP and highlight whether or not the required fields from the Ms L vs. ICE settlement are included and can therefore be updated into the child's profile in ORR's data system.  ORR's Intakes Team does final review and in cases where data appears to be missing, the ORR Intakes Team reaches back out to CBP for that information."
HHS-ACF-00005,Triaging Notice of Concern Submissions,HHS,ACF,"The Office of Refugee Resettlement (ORR) has amassed a large backlog of Notice of Concern (NOC) PDF forms that contain critical information regarding safety of children who have left ORR's care. 

The AI-powered triage tool will support Office of Refugee Resettlement staff more effectively and efficiently review NOCs by helping structure and prioritize received NOCs. Through more effective triage, ORR will begin to cut down on the large backlog that has accumulated.","In the NOC triage system, AI will be used for two purposes:

1. We will use AI to parse the NOCs to generate structured fields from the text and validate categorizations.

2. AI will provide prioritization recommendations -- but not make decisions -- on the most critical NOCs for the ORR team to review first. "
HHS-ACF-00006,Unaccompanied Children Program Policy & Procedure Research Tool,HHS,ACF,"The Office of Refugee Resettlement (ORR) conducts monitoring visits at least monthly to ensure that care providers meet minimum standards for the care and timely release of unaccompanied children, and that they abide by all Federal and State laws and regulations, licensing and accreditation standards, ORR policies and procedures, and child welfare standards. If ORR monitoring finds a care provider to be out of compliance with requirements, ORR issues corrective action findings and requires the care provider to resolve the issue within a specified time frame. Compliance determination involves research into the various laws, standards, policies, and procedures.

The UC Program Policy & Research Tool assists the UC monitoring team with research that in many cases take a long time. The goal of the  UC Program Policy & Research Tool is to speed up this research as children's health and well-being may be impacted before a corrective action finding is issued and the issue is resolved.","The UC Program Policy & Procedure Research Tool speeds up research of relevant laws, standards, policies, and procedures content curated and approved by ORR's policy team. This research is one part of the process that informs ORR's monitoring team's decisions on whether corrective actions are needed and if so, what corrective actions. AI is not used to suggest corrective actions but rather support determination of whether care providers are in compliance."
HHS-ACF-00007,Unaccompanied Children Process Model Digital Twins,HHS,ACF,"The Office of Refugee Resettlement (ORR) Unaccompanied Children Bureau provides a safe and appropriate environment to children who enter the United States without immigration status and without a parent or legal guardian who is able to provide for their physical and mental well-being (referred to as “unaccompanied children”). ORR funds residential care provider facilities that provide temporary housing and other services to unaccompanied children in ORR custody. ORR and its care providers work to ensure that children are released timely and safely from ORR custody to parents, other family members, or other adults (often referred to as “sponsors”) who can care for the child’s physical and mental well-being. Unaccompanied children remain in ORR’s care and custody until they are released to a parent or other sponsor in the United States, are repatriated to their home country, obtain legal status, or turn 18 years old, at which time they are transferred to the custody of DHS. There are many processes involved throughout.

The goal is for ORR to be more proactive in strategic planning and contingency planning.","ORR is exploring use of process digital twins to provide the ability to run ""what if"" scenarios"
HHS-ACF-00008,Analyzing Public Comments on Proposed Rule,HHS,ACF,"In the federal rulemaking process, the public has an opportunity to provide comments on proposed new regulation. AI was used to support the public comment review process for a proposed rule to make quality improvements in the Head Start program.

The public comment analysis pipeline provided an Excel spreadsheet of comment segments that were tagged and Word files of topic-based summary drafts. Subject matter experts from the Office of Head Start reviewed comments by topic and further analyzed and refined the topic-based summaries.

The benefit of using AI for this purpose is improved baseline information following public comment to support more expeditious final rule development.","A large language model (LLM) was used to tag public comments by: topics selected primarily by policy experts; sentiment; and intent (e.g. question, suggestion) alongside first drafts of topic-based summaries. "
HHS-ACF-00009,Outreach List Segmentation,HHS,ACF,"The Office of External Affairs (OEA) is responsible for sharing information from ACF with external constituents. OEA had a long list of constituent email addresses that were without context. They wanted the ability to send targeted emails to different groups of people whose organizations work in particular policy spaces.

The AI tool returned a spreadsheet of the provided domains with structured information on likely organization name, summary of their mission, policy domains (e.g. public health, education), and website. This spreadsheet allows OEA to segment their lists and target organizations more efficiently.","An AI-enabled search tool was used to research likely organization name, purpose, and policy space based on the domains (e.g. ""@organization.com"")  from contact email addresses."
HHS-ACF-00010,Ask HR Policy,HHS,ACF,"This project provides a resource for ACF Executive Officers/Administrative Officers and managers to easily navigate Human Resources (HR) Policy documentation and quickly get answers to their questions that are based on the official HR Policy Library that is on the HHS.gov website (https://www.hhs.gov/about/agencies/asa/ohr/hr-library/index.html)

Ask HR Policy provides a secure interface permissioned only to select ACF Executive Officers and Administrative Officers.  Users type in questions about managing employees covered by the HR Policy Library, and Ask HR Policy provides a narrative of its “thought process” then suggests an answer based in the documentation, alongside links that take the user to the relevant section of the official document.",We are using LLMs to analyze the questions inputted by users. The AI model synthesizes the provided documentation sources and then summarizes and answers the users questions with cited sources.
HHS-ACF-00011,Child Welfare Information Gateway OneReach Application,HHS,ACF,"The Childrens Bureau runs the Children Welfare Information Gateway, a connection to trusted resources on the child welfare continuum. The Information Gateway has a hotline for answering questions or requesting information: https://www.childwelfare.gov/stay-connected/contact/

The Information Gateway hotline automates some of the more routine questions and requests, allowing staff to focus on more complex, nuanced situations.","The Information Gateway hotline connects to a phone interactive voice response (IVR) managed by OneReach AI. OneReach maintains a database of state hotlines for reporting child abuse and neglect that it can connect a caller to based on their inbound phone area code. Additionally, OneReach offers a limited FAQ texting service that utilizes natural language processing to answer user queries. User queries are used for reinforcement training by a human AI trainer and to develop additional FAQs."
HHS-ACF-00012,Collective Bargaining Compass,HHS,ACF,"This project provides a resource for ACF managers to easily navigate Collective Bargaining Agreement documentation and quickly get answers to their questions that are based on the official 400-page rulebook.

The Collective Bargaining Compass provides a secure Virtual Assistant interface permissioned only to select ACF managers.  Users type in questions about managing employees covered by the Collective Bargaining Agreement, and the Virtual Assistant provides a narrative of its “thought process” then suggests an answer based in the documentation, alongside links that take the user to the relevant section of the official document.","We are using LLMs to analyze the questions inputted by users, which then the AI model synthesizes the provided documentation sources and then summarizes and answers the users questions with cited sources."
HHS-ACF-00013,Discover User Assistant,HHS,ACF,"This project provides a resource for ACF Discover Staff Management Module users (i.e. ACF Executive Officers and other ACF administrative and management staff) to easily navigate ACF Discover Staff Management platform and instructional documentation and quickly get answers to their questions about the module’s features.

The User Documentation Assistant provides a secure virtual assistant interface that is only available to ACF Discover Users.  Users are able to ask the assistant specific questions about the capabilities of ACF Discover along with how to leverage tools and applications. The Virtual Assistant is able to provide answers by referencing the User Reference guide.","We are using LLMs to analyze the questions inputted by users, which then the AI model synthesizes the provided documentation sources and then summarizes and answers the users' questions with cited sources."
HHS-ACF-00014,Policy Knowledge Base Data Migration,HHS,ACF,"The Office of Family Assistance (OFA) provides technical assistance to grantees, including answering questions about policy regarding the Temporary Assistance for Needy Families (TANF) program. Historically, OFA has tracked its accumulated TANF knowledge across disparate locations and file types.﻿

Given the quantity of knowledge base articles involved in this project (>1,100), the AI draft article topics and categories helped speed up the creation of the knowledge base minimum viable product.","As part of a broader effort to establish a TANF knowledge base on a unified platform, large language models were used to: 1) generate draft knowledge base article topics based on historical tracker information; and 2) categorize articles to help organize the knowledge base."
HHS-ACF-00015,Qualitative analysis,HHS,ACF,"ACF staff often conduct surveys and interviews, which generate qualitative data that needs to be analyzed for themes and trends.

The AI functionality assists users in identifying relevant passages in their narrative data related to specific topics.",We use commercial off-the-shelf software that have built-in AI functionality to suggest topic tagging of qualitative data.
HHS-AHRQ-00001,AHRQ Search,HHS,AHRQ,"Organization wide search that includes Relevancy Tailoring, Auto-generation Synonyms, Automated Suggestions,  Suggested Related Content, Auto Tagging, and ""Did you mean?"" to allow visitors to find specific content.

This AI use case enhances our agency's efficiency and user experience by optimizing search results, auto-completing queries, suggesting relevant searches and content tags, as well as proposing spelling corrections. ","This AI use case aims to optimize search results by adjusting their ranking, ensuring that the most pertinent information is displayed at the top. It also enhances search effectiveness by adding synonyms to queries behind the scenes. It further improves user experience by auto-completing queries as they are being typed, and showing related searches that might offer additional valuable insights. The system also proposes content tags automatically, leveraging machine learning to assess existing content tagging patterns. Additionally, it suggests spelling corrections and reformats search queries based on data from Google Analytics."
HHS-AHRQ-00002,Chatbot,HHS,AHRQ,"This use case introduces a conversational interface that enables users to ask questions about AHRQ content using natural language. This will serve as a modern, efficient replacement for the traditional public inquiry telephone line.

Improved user experience and reduced resources responding to public inquiries",An interactive interface that can respond to plain language queries in real time using natural language processing
HHS-AHRQ-00003,Chatbot,HHS,AHRQ,"For the Patient Safety Organization Privacy Protection Center website, this use case provides an interface that allows users to conversationally ask questions about content in natural language.

Improved user experience and reduced resources responding to public inquiries",An interactive interface that can respond to plain language queries in real time using natural language processing
HHS-AHRQ-00004,Enhancing Diversity in Peer Review - Pilot,HHS,AHRQ,"The Division of Scientific Review (DSR) is aiming to enhance diversity in AHRQ peer review groups by revising recruitment strategies, aiming for 20% representation from underrepresented minorities in each study section. This process, involving networking, outreach, and various resources, typically takes at least three months.

By utilizing AI to swiftly and accurately identify diverse and qualified grant reviewers, our agency will foster a more efficient process for identifying scientific reviewers and a more equitable and inclusive scientific review process. This will help us achieve our goal of providing safer, high-quality, accessible, and affordable healthcare to individuals and communities throughout the U.S., thereby improving the overall effectiveness of our agency.","This AI use case will involve training an artificial intelligence system to examine the background of peer reviewers - taking into account factors such as expertise, race/ethnicity, gender, and geographic area - and match these inputs to the relevant study section, subsequently referring the reviewer to the Scientific Review Officer (SRO). This flexible system will empower SROs to make the final recruitment decision or to refer the expert to another study section or Special Emphasis Panel (SEP)."
HHS-AHRQ-00005,NLQuery- As Data or Pulse,HHS,AHRQ,"As a feature to clinical dashboards available on a secured page on the Patient Safety Organization Privacy Protection Center website for PSOs who submit data, provides capability to allow user to type a question in common language and instantly get a response. Answers come in the form of automatic data visualizations, with no need to manually drag-and-drop fields or understand the nuances of user's data’s structure.

Improved functionality of the clinical dashboards.  Potential to encourage additional reporting of data in light of benefit to user.","Provide capability to allow user to type a question in common language and instantly get a response . Answers come in the form of automatic data visualizations, with no need to manually drag-and-drop fields or understand the nuances of user's data’s structure."
HHS-AHRQ-00006,Quality and Safety Review System AI-enabled automated abstraction,HHS,AHRQ,"The aim of this AI use case is to enhance or eliminate the need for manual abstraction of patient records and manual data entry into the QSRS tool, thereby streamlining the data entry process.

This AI use case has the potential to significantly help by increasing the volume of cases abstracted while maintaining or lowering government expenditure, thereby enabling more work to be done at the same or reduced cost. Additionally, it can maintain the number of cases abstracted with improved efficiency, thus also reducing government costs by achieving the same output at a lower cost. Furthermore, it will improve abstraction accuracy and expand AI/ML capabilities at both the national and local hospital levels while ensuring data quality improvements so there is trusted and reliable data for reporting purposes.","This AI use case is designed to automate the data abstraction process once the OCR system has transformed PDF images into text. It also aims to automate data entry into the Quality and Safety Review System (QSRS), thereby increasing efficiency and accuracy."
HHS-ASPR-00001,Document Q&A Interface ,HHS,ASPR,"The SCCT consolidates a number of documents for every response that it monitors, and often analysts have questions about response context stored in those documents

Increase an analyst / user on Protect's knowledge of a specific response or MCM by allowing them to ""ask questions"" of associated / uploaded  SCCT media",Large Language Models are used to query existing documents for answers based on a user's query
HHS-ASPR-00002,Emergency Inventory Redistribution Model,HHS,ASPR,"Optimization models are needed to identify efficient preparedness and responses strategies for inventory management and distribution during an emergency.

This can be used to identify possible interventions.",This linear programming (constrained optimization) model can identify the optimal strategy for meeting demand for medical supplies during an emergency event.
HHS-ASPR-00003,emPOWER AI,HHS,ASPR,"Public health authorities, first responders and others across the emergency management spectrum indicated that they had to be able to more rapidly access emPOWER publicly available data, particularly in unstable internet conditions, during disasters. emPOWER AI, an  Amazon Alexa Skill, was created to allow anyone with a smartphone to be able to request the data and informational resources.  

First responders, public health authorities, emergency managers, health care providers, and other community partners can use emPOWER AI prior to, during, and after an incident, emergency, or disaster to anticipate, plan for, and respond to the access and functional needs of at-risk populations in their communities using publicly available emPOWER data, informational resources and training.","emPOWER AI gives the user publicly available data from the HHS emPOWER Map on the number of electricity-dependent Medicare beneficiaries at the national, state, territory, county, and ZIP Code levels. It also provides information on other HHS emPOWER Program tools and resources that collectively support emergency preparedness, response, recovery, mitigation, and resilience activities. "
HHS-ASPR-00004,Entity Resolution Tool,HHS,ASPR,"SCCT receives order information that references thousands of manufacturers and customers. These data need to be standardized.

This allows analysts to aggregate data by manufacturer or customer to better characterize order and delivery patterns.","This tool uses embedding models, hierarchical clustering, and large language models to identify groups of duplicate entity names and assign a new standardized name."
HHS-ASPR-00005,Executive Report Generation AI Copilot ,HHS,ASPR,"SCCT produces executive summaries and commercial product awareness reports (CPARs) on supply chain disruptions, weather events, shortages, etc. These utilize a large amount of SCCT data that needs to be summarized and explained in detail.

Used to decrease the amount of time needed to produce an executive report, reducing the need for SCCT analysts to create them from scratch every time",Large language models are utilized to summarize existing documents and data in order to produce the base text for an executive report. 
HHS-ASPR-00006,Flow Model Edge Prioritization Estimation Tool,HHS,ASPR,"This model is needed to investigate potential impacts of supply disruptions.

This is one component in a simulation tool used to quantify the impact of supply chain disruptions on customers.",This model uses linear regression to summarize patterns in preferential order fulfillment and predict future fill rates.
HHS-ASPR-00007,Generalized Demand Model Sensitivity Analyzer,HHS,ASPR,"The generalized demand model is used by SCCT to create demand projections for critical medical products.

This is a diagnostic tool used to help analysts understand and refine their models.",This constrained regression model is used to identify the primary drivers of uncertainty in demand models and quantify their impact.
HHS-ASPR-00008,Google Search Model Alerts,HHS,ASPR,"Publicly available information can enhance the ability to identify supply chain disruptions.

This provides automated alerts that can help trigger review of the relevant data by analysts.","This model, based on exponentially weighted moving averages, identifies rising trends in timeseries related to google search volume for keywords of interest."
HHS-ASPR-00009,Google Search Model Rising Trend Entity Extraction,HHS,ASPR,"Publicly available information can enhance the ability to identify supply chain disruptions.

The list of products produced by this model helps analysts identify products that may be in shortage.",This tool uses language models to identify the object in shortage from a list of shortage related rising search terms identified by Google.
HHS-ASPR-00010,Manufacturer Name Standardization,HHS,ASPR,"The SCCT receives many manufacturer name variants from its many distributors that need to be consolidated and standardized

This allows analysts to have more standardized manufacturer names for reporting","An advanced grouping algorithm groups similar manufacturer names together, and a Large Language Model recommends a standardized name based on all variants"
HHS-ASPR-00011,Model based open source reporting search and summarization,HHS,ASPR,"SCCT collects open source information for monitoring supply chain events.

Language models provide an initial summary that analysts can use to select topics of interest in order to focus on relevant events.",Large language models are used to search open source information and summarize topics related to supply chain events.
HHS-ASPR-00012,PPE Product Classification Model,HHS,ASPR,"SCCT receives information about thousands of products from distributors.  This is used to predict if the product falls into one of the following 7 categories: 1) Gloves – Surgical & Exam, 2) Needles & Syringes, 3) Gowns – Isolation & Surgical, 4) Masks – N95, 5) Masks – Surgical/Procedural, 6) Eye / Face Shields, 7) Test Kits.

These classifications are used to aggregate data in order to make it possible to analyze trends.",This model uses bayesian anomaly detection and random forests to assign products to a list of predefined product classifications.
HHS-CDC-00002,Adverse Childhood Experiences (ACEs) Literature Review Dashboard,HHS,CDC,"This solution will impact the process of conducting literature reviews for scientific research related to ACEs.

Identifying relevant articles in a literature review is a time intensive process. Utilizing large language models, this system enables quick identification of relevant articles to be included in a ACEs literature database. This database allows ACEs researchers within CDC's National Center for Injury Prevention and Control a quick reference to develop hypotheses and identify gaps in the ACEs literature",This solution automatically determines the relevancy of published journal articles. Relevant articles are included in a master dataset that is linked to a PowerBI
HHS-CDC-00003,Automated Analysis of Injury Control Research Center (ICRC) Annual Progress Reports (APRs) using Large Language Models,HHS,CDC,"This AI affects the process of reviewing and analyzing the Annual Progress Reports (APRs) submitted by Injury Control Research Centers (ICRCs). Specifically, the AI will focus on identifying and analyzing text sections of the APRs that detail reported challenges, as well as other text-heavy sections in future stages of the project. The AI is designed to streamline the review process, improve efficiency, and support the evaluation of the performance and progress of ICRC-funded activities.

The output of the AI will help to quickly and efficiently identify key challenges and insights from ICRC APRs, enabling more effective decision-making in the review process. By automating the extraction and analysis of critical information, the AI allows the ICRC team to focus on higher-level evaluation and strategic planning. The AI will help reduce the time and resources needed for manual review, improve the consistency and accuracy of assessments, and facilitate faster responses to ICRC needs. Ultimately, this will support ICRCs in overcoming challenges and achieving their research and injury control goals, benefiting the public health system as a whole.","The AI analyzes the textual content of APRs. We have started our analysis by focusing on the sections detailing the challenges faced by ICRCs during the 2019 funding cycle. The AI identifies key themes, trends, and critical information that may require further attention. The AI methodology extracts insights and patterns from the data, which can then be compared with manual qualitative analysis outcomes. In subsequent stages, the AI will be expanded to analyze other sections of the APRs, such as progress toward goals and program impact."
HHS-CDC-00004,Detecting Stimulant and Opioid Misuse and Illicit Use,HHS,CDC,"Federal Health Survey analysis. The machine learning models created in this project will have an impact on the statistical analysis of electronic health record (EHR) data gathered through the (NHCS) National Hospital Care Survey. Furthermore, when the model is made available to the public, it may also influence the analysis of other user datasets that contain EHR clinical notes.

Certain non-therapeutic models do not have corresponding medical codes available in clinical notes and the information is only available in free-text fields. The machine learning models help to discover non-therapeutic drug use as described in EHR clinical notes which are novel insights previously impossible to gleam from EHRs without AI.","Two machine learning models will be created, one for internal use and another for public release. In both instances, these models will be utilized alongside rule-based text analysis to ascertain whether a patient in a hospital setting has used a drug therapeutically (in accordance with medical prescription) or non-therapeutically. This information is used to gather new insights from EHRs for health statistics published through the NHCS."
HHS-CDC-00005,DHP Virtual Assistant,HHS,CDC,"Literature Review for HIV research. The AI virtual assistant will help HIV researchers with information retrieval on information related to HIV and HIV research. 

Our AI virtual assistant will help increase productivity among our HIV researchers by retrieving information related to HIV and HIV research.",This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query and other documents.
HHS-CDC-00006,Fuzzy matching tool,HHS,CDC,"Clearance and review management of CDC publication. CDC's Office of Science (OS) manages the eClearance information system, which is responsible for tracking the submission of CDC-authored journal manuscripts and Morbidity and Mortality Weekly Reports (MMWRs) for CDC's internal peer review process.

This tool will help ensure CDC-authored publications have completed the National Institutes of Health Manuscript Submission (NIHMS) process and are compliant with CDC's public access to publications policy. It will also be used to help centers and divisions identify publications from their organization for science prioritization and impact analyses.","The fuzzy matching tool uses pre-trained, open source LLMs to identify similar records between eClearance submissions and CDC-authored publications. This tool is intended for internal use only."
HHS-CDC-00007,Global (GIB) Initiative for Influenza Vaccine Equity (GIIVE): Ensuring Universal Access,HHS,CDC,"Literature Review

The output is a list of abstracts that may have related information to vaccine inequity. These identified abstracts will be reviewed ""by-hand"" and then those associated publications will be reviewed by epidemiologists further.","The Through APIs, large language models are used to review a large number of abstracts to help identify which kinds of groups may be least likely to obtain vaccines in the global space--marginalized groups within country, for example."
HHS-CDC-00008,HIV Data Virtual Assistant,HHS,CDC,"The AI will impact the data retrieval and automation process for HIV researchers, specifically in providing information from datasets and potentially generating code for desired variable names and analysis or generating information about a particular dataset.

This solution aims to alleviate the challenges faced by scientists searching for the appropriate HIV-related data to address their inquiries. This will improve productivity and research efforts.","This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query. Our aim is to input all dataset documentation and metadata into an index with the goal of creating a virtual assistant. This assistant offers support to our HIV researchers by providing the information they seek from the data and potentially generating SAS, R, or Python code for desired variable names. For instance, if we require a dataset containing HIV PrEP information, we can request it to generate a list of current datasets that contain data on PrEP medication usage in 2019, along with the associated variable names. Subsequently, we can instruct it to produce lines of code, such as a logistic regression, which can be readily copied and pasted into our analysis software of choice. Another example would be if our researchers would like information returned about a given dataset, this assistant could return specific information based on the researcher's query."
HHS-CDC-00009,Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images,HHS,CDC,"The physical environment, such as sidewalk availability, in areas may be correlated to levels of physical activity. The Physical Activity (PA) and Health Branch is responsible for monitoring and gathering data on physical activity behaviors, as well as assessing the environments that promote physical activity.

The implementation of this technology has the potential to streamline the surveillance of sidewalks, which play a crucial role in supporting physical activity (PA). The existing methods for cataloging sidewalks, such as manual inspection, are labor-intensive and costly. However, this technology has the capability to significantly minimize the effort required for such tasks.","The Division of Nutrition, Physical Activity, and Obesity within CDC's National Center for Chronic Disease Prevention and Health Promotion aims to explore and advance the use of machine learning methods for identifying sidewalks, bicycle lanes, and other relevant infrastructure in various types of images, including satellite and roadway images. The input data would consist of image-based data, while the outputs could take the form of geocoded data tables, maps, GIS layers, or summary reports. The goal is to develop and promote these techniques to enhance understanding and analysis of built environments related to physical activity."
HHS-CDC-00010,Immunization Information Systems Guidance Documentation Navigation and Management (IDAB EDAV Azure OpenAI Technology Use),HHS,CDC,"This AI solution (chatbot) helps with retrieving information and updating guidance documentation by increasing interactivity and discoverability of information in the Immunization Information Systems (IIS) domains of HL7 electronic data exchange standards, CDSi (Clinical decision support for immunizations), and IIS operational best practices. It provides a modernized approach to knowledge retrieval and real-time guidance, as well as support the creation of new guidance by leveraging the AI capabilities in natural language processing and content generation to draft, refine, and validate new guidance documents efficiently and accurately.

This AI solution creates a better, faster, and more actionable method for IIS SMEs to obtain IIS guidance from previously published and publicly available IIS documentation. This solution will provide a more modernized approach to knowledge retrieval and real-time guidance, as well as support the creation of new guidance by leveraging the chatbots capabilities in natural language processing and content generation to draft, refine, and validate new guidance documents efficiently and accurately.
This AI solution (chatbot) provides an efficient and user-friendly way to search, interact, and update these IIS guidance documents. It can help experts answer questions faster, new employees find information more easily, and employees better understand best practices.","This AI solution (chatbot) uses Retrieval Augmented Generation (RAG) to retrieve and synthesize information from a limited set of publicly available IIS guidance documents related to the HL7 Electronic Exchange Standard specification, Clinical Decision Support for Immunization (CDSi) and IIS Operational Best Practices. It does this using a Question-and-Answer style interface, allowing team members to retrieve answers in an efficient and user-friendly way.
On 07/26/2024 the CDC Information Technology and Data Governance (ITDG) Executive Committee has approved this investment “to use AI to create a system that can conduct a dialogue with a user and answer questions about the contents of already approved public documents”."
HHS-CDC-00011,LaserAI,HHS,CDC,"This project aims to evaluate a commercial off the shelf, software as a service systematic review project management software. This software uses machine learning/ natural language processing to support title and abstract screening, PDF retrieval, full text review, and most importantly data extraction to reduce screening time and improve accuracy of all phases of a systematic review.

The extracted data will be synthesized and graded, and will be used to inform the development of evidence-based infection prevention and control recommendations for healthcare settings.","This AI uses natural language process to (1) identify potentially relevant articles and prioritize them for screening, (2) retrieve PDFs from PubMed, and (3) suggest data in PDFs for extraction."
HHS-CDC-00012,NewsScape,HHS,CDC,"Development of early warning indicators. News articles can form an early warning indicator of public health events and other pieces of information which can be utilized across all major domains of public health. Because of the quantity of news articles, manual efforts are impossible to gather this information.

There are a variety of endpoints that this AI output could help support. Various teams across the CDC have expressed interest in being able to quickly get the right news content, with summaries of those articles to help support outbreak detection, report generation, surveillance and monitoring of pathogen specific news, etc. AI lets us efficiently filter and summarize thousands of news articles a day into a handful of daily ""news events"" that user can glean information from. ","NewsScape is a AI enabled news aggregation and summarization that is hosted within the 1CDP platform. The main motivation to build  NewsScape was to develop a system that uses Large Language Models (LLMs) to surface relevant insight from recent news articles. NewsScape ingests a high volume of news articles, in the order of thousands of news articles everyday, and surfaces the information from them that related to the topic we were interested (for example, pathogen related news articles, or U.S. medical supply chain updates).  The tool can be customized based on specific program office needs, and can be deployed independently of one another so that one program office can have their own custom version of NewsScape installed."
HHS-CDC-00014,RAPID Analysis of Policy and Program Documents (RAPID),HHS,CDC,"Policy and documentation awareness and evaluation

The web application will: 1) save staff time by streamlining laborious document reviews; 2) expand capacity by reducing the need for specialized staff training and skills; 3) provide complete, plain language answers to policy surveillance and evaluation questions along with binary codes or scores; 4) answer questions consistently (i.e., reduce intra-rater variability for redundant coding); and 5) enable easy validation of AI-provided answers.",An internal web application  will enable CDC users to: 1) import and securely store policy or program documents; 2) search for relevant documents; 3) ask questions of relevant text segments; 4) validate answers; and 5) collaborate on policy surveillance and evaluation projects.
HHS-CDC-00015,SewerScout: Automated on-site sewage facility detection from aerial imagery to identify failed systems,HHS,CDC,"This business process focuses on the automation of the accurate identification of onsite wastewater systems in state, tribal, local, and territorial (STLT) health jurisdictions. This application scans aerial imagery and uses object detection and image classification models to detect onsite sewage facilities. Initial work is focusing on the ability to identify known systems.

 The intent of this project is to identify failed systems, which can be sources of soil and drinking water contamination as well as vectors that carry or transmit disease in the community. This project will allow STLT partners to readily characterize the location and functional status of septic systems without the time and resource consuming effort of visiting each household. The resources in many local health districts (LHDs) are barely adequate to undertake assessments of suitability  for new systems (if not entirely contracted out) and most LHDs do not have any program to routinely inspect current systems. If successful, this project will allow state, tribal, local, and territorial public health departments to more easily identify failing septic systems and work to address them.  If successful, subsequent work will work on differentiating functional from failed systems. Identification of septic systems during routine operations would help bolster and expedite disaster response efforts after major disasters  by having a ready catalog of systems and using pre- / post-disaster satellite images to direct resources in a much more efficient way than on-the-ground door-to-door surveys in rural / remote locations. ","The intent of this project is to identify failed wastewater systems, which can be sources of soil and drinking water contamination as well as vectors that carry or transmit disease in the community."
HHS-CDC-00016,Sidekick Comms bot Offering User-friendly Tips (SCOUT),HHS,CDC,"The AI will impact the content creation processes for CDC.GOV and reduce burden in creating new webpages. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.

The solution aims to reduce the workload of health communicators by simplifying the process of creating new web pages and social media posts. By leveraging Generative AI technology, we can produce new content much more quickly than if communications staff were to do it on their own. The goal is to make the published content more accessible and understandable for the general public, ensuring that CDC information reaches a wider audience. It's important to note that all content generated by the AI is carefully reviewed and edited by a human before it is used and the follow disclaimer is stated with public content that this tool has been used with: ""CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.""","CDC's National Center for Chronic Disease Prevention and Health Promotion use of Generative AI in this use case is to help convert existing web content into plain and clear language. This solution uses Gen AI to create new versions of publicly available content that are easier for end-users to understand. By incorporating prompts, the tool makes the content more suitable for a general lay audience. In addition to web articles, the Generative AI tool also allows for the creation of social media posts. The goal of this project is to make information more accessible by providing plain language content on various platforms. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release."
HHS-CDC-00017,Transcribing Cognitive Interviews with Whisper,HHS,CDC,"Federal Health Survey Research. Specifically, Cognitive interviews are a form of qualitative research where interviewers ask probing questions to understand how the interviewee understands a concept which is being asked about in a federal survey. These interviews are a key part of survey design to identify any potential misconceptions and prevent lengthy and hard to answer questions which could create potentially wrong health statistics. These interviews are time consuming to perform and report as they are inherently individual and require extensive hours to transcribe. By using AI to transcribe the interviews, researchers can potentially cut down on the hours or qualitative review, increasing the speed of research publication and quality of survey questions used on federal surveys.

Without transcripts, these interviews have to be listened to repeatedly taking at least the same amount of time as the full length of the interview to find important pieces of information for their work. These transcripts can greatly reduce the burden on researchers by enabling immediate comparison of concepts and answers along with timestamps created for researchers to reference in review.",This AI generates transcripts from recorded interviews for staff to use when performing qualitative research to assist with Federal Health Survey research.
HHS-CDC-00018,Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking,HHS,CDC,"This use case is aimed to assist in the review of public comments for Notices of Proposed Rulemaking. All responses are manually reviewed following this tool usage.

By law, Public comments are required to be manually review for any notice of public rule making. These comments are highly labor intensive due to both the quantity and wide range of potential opinions shared by the public. These comments can range in both length of response and quantity serving as a challenge for properly ensuring the insights from the public are accurately gathered in the review process. By using an LLM based Topic Modeling approach, manual reviewers can organize responses based upon theme to enhance both the insights gained, the speed of manual review, and ensure all topics mentioned can be accurately reported in all review processes. This process can use open source python libraries and open-source LLMs to complete different actions. This AI methodology enables manual review processes to be more effective in gaining insights from the public, better organized in themes and categories present within text, and reduce the burden of manual review of comments from notices of proposed rulemaking required by law.",Generates clusters of similar public comments to a 'notice of proposed rulemaking' to aid in manual review.
HHS-CDC-00019,Center for Forecasting and Outbreak Analytics Disease Modeling,HHS,CDC,"Federal and State, Tribal, Local, and Territorial health department responses to disease outbreaks depends on being able to predict the future behavior of a given outbreak as well as the potential impact of different responses to the outbreak. This project aims to build models of disease spread that allow for (1) determining if and where infection/impact rates are growing or increasing (2) forecasting future disease progression (3) modeling specific scenarios such as the impact of vaccination.

We use model output to provide information to Federal and SLTT decision makers to improve disease response. This allows those decision makers to determine where and how to direct resources in a disease out break as well as the impact of potential response actions. This kind of insight is critically dependent on mathematical modeling.","This project  models disease spread and impact based upon a set of models, a variety of data sources, and allows for the inclusion of the impact of potential public health actions such as vaccinations. These insights can be used by public health decision makers to inform current and future responses to public health emergencies"
HHS-CDC-00020,ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Data Analysis),HHS,CDC,"This AI system is an extension of the GenAI chatbot but is only available to a small group of pilot testers as of November 5, 2024. It operates through an ATO'ed instance of Microsoft Azure OpenAI through CDC's Enterprise Data Analytics and Visualization Platform. Using a method called retrieval augmented generation (RAG), this enhancement enables staff to augment the existing GenAI chatbot with access and “knowledge” of internal or enterprise data such as documents, spreadsheets, and PDFs. Additionally, each chatbot response has citations referencing to the sections of source text that informed the response, which facilitates human-in-the-loop validation for accuracy and relevancy of AI-generated content.

One way users are using this tool is for data extraction, which accelerates analysis of large document sets. By extracting key points from large volumes of text in various file formats, the enterprise-data-enhanced chatbot streamlines access to critical insights from reports, internal documentation, publications, and other documents. For example, one team is using the chatbot to support literature review by extracting information related to housing status and HIV in the US from a set of pre-screened publications. Examples of this information include a binary yes/no on whether the research paper focuses on the topic of interest, the paper’s population of focus, and the type of paper.

The enterprise data chatbot’s ability to quickly and accurately extract relevant information reduces manual search time and errors associated with human data retrieval. The output will be leveraged for more accurate data analysis, timely insights, and better-informed decision-making processes.","When the user enters a prompt or query related to data extraction into the chatbot, the tool uses a GPT-4 model and Azure AI Search within a RAG architecture to retrieve relevant sections of text from the provided enterprise data sources and extract key information as instructed by the user’s prompt."
HHS-CDC-00021,ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Summarization),HHS,CDC,"This AI system is an extension of the GenAI chatbot but is only available to a small group of pilot testers as of November 5, 2024. It operates through an ATO'ed instance of Microsoft Azure OpenAI through CDC's Enterprise Data Analytics and Visualization Platform. Using a method called retrieval augmented generation (RAG), this enhancement enables staff to augment the existing GenAI chatbot with access and “knowledge” of internal or enterprise data such as documents, spreadsheets, and PDFs. Additionally, each chatbot response has citations referencing to the sections of source text that informed the response, which facilitates human-in-the-loop validation for accuracy and relevancy of AI-generated content.

The enterprise data chatbot’s summaries will enhance operational, informational, and decision-making processes that would otherwise require extensive research and reading time. For an example of a more informational use case, one team provided the chatbot with documentation and resources about a division’s organizational structure, projects, administrative processes, and tools to support the orientation of new staff and (re)orientation of existing staff. The chatbot enables the division’s staff to efficiently find resources for their roles; better understand the division’s initiatives; and track the activities involved in the onboarding process for new staff.","When the user enters a prompt or query related to summarization into the chatbot, the tool uses a GPT-4 model and Azure AI Search within a RAG architecture to retrieve relevant sections of text from the provided enterprise data sources and condense that information into concise summaries in response to the user’s prompt. "
HHS-CDC-00022,Leveraging AI for Metadata Tagging for Enterprise Data Catalog of CDC,HHS,CDC,"CDC’s Enterprise Data Catalog provides an internal single centralized inventory of available datasets within CDC staff. It provides data management and search tools to help users find what they need and aims to provide descriptions to aid in relevance determinations for users. This is from the appropriate metadata, e.g. project title, description, or other important information describing the dataset. Because of the previous manual metadata tagging process, many datasets catalogued do not have the appropriate tags to help staff determine the relevance of any particular dataset available within CDC for particular tasks.

Because of the lack of standardization and gaps in metadata fields, this AI's output will greatly increase the speed for applying the appropriate metadata fields for each dataset within the catalogue to increase the usability of the product. This reduces the time and effort required for manual tagging and improves the consistency and completeness of metadata. ",AI is used in this case to generate suggested metadata fields based upon existing metadata information provided by a dataset. These tags would then be used for staff accessing the enterprise data catalogue to discover datasets and find connections to support existing on-going work.
HHS-CDC-00023,Malaria parasites DNA barcode geography classification,HHS,CDC,"Epidemiological investigations of Malaria

To complement epidemiologic investigations of domestic malaria cases, including cases that were domestically acquired. This information can help assess the origin of the malaria strain in question, which can help us understand how the strain entered the US. For more information, please see the following manuscript: https://journals.asm.org/doi/full/10.1128/aac.01203-24","Algorithm examines a sequence barcode/genotype (our use case is for malaria, but it can be applied to other contexts) and it assigns the malaria parasite genotype to a geographic origin, which may be a continent or some other geographic regional category. While this use case has the barcode as a set of genetic loci from malaria parasites, and the categories are geographic (i.e., continents, subregions), the algorithm could be trained to assign genetic barcodes from other pathogens to any number of different categories assuming the appropriate training dataset exists."
HHS-CDC-00024,The School Closure Awareness System,HHS,CDC,"Identifying unplanned school closures. CDC is responsible for supporting schools before, during, and after and emergency. During COVID 19 this included monitoring school closure or virtual status and reporting this to federal partners, the White House, and the public. Due to cost the process used during COVID was no longer feasible and ceased in DEC 2022. We explored multiple ways to capture this data and our current system met the need best. 

This AI has allowed us to save nearly 2-million-dollars from contracting fees and decrease human work hours by 200 hours. It has made the capture of some of this data possible after cessation of the process used during COVID 19 which we could no longer support. The AI supported system is faster and captures more information about individual closures than the original human-powered process.","This system uses publicly available Facebook posts from approximately 40,000 school or district Facebook accounts. Then uses a large language model to categorize posts as unplanned school closure for several types of events (weather, health, facility issues, safety). It also will denote the type of status change (full closure, virtual, hybrid, or early / late dismissal). The data is checked and recoded (if needed) by a staff person every 24 hours."
HHS-CDC-00025,Using Generative AI for Stance Analysis of Public Comments on CDC’s Proposed Rules,HHS,CDC,"By law, Public comments are required to be manually review for any notice of public rule making. These comments are highly labor intensive due to both the quantity and wide range of potential opinions shared by the public. These comments can range in both length of response and quantity serving as a challenge for properly ensuring the insights from the public are accurately gathered in the review process. By using an LLM based Topic Modeling approach, manual reviewers can organize responses based upon theme to enhance both the insights gained, the speed of manual review, and ensure all topics mentioned can be accurately reported in all review processes. This process can use open source python libraries and open-source LLMs to complete different actions.

 As public feedback on various rules gets collected across the CDC’s divisions, this initiative along with other NLP approaches can potentially save time for CDC’s public policy experts during public comment review. ","Reviewing the public comments currently involves a manual review process that necessitates a high level of time and effort on the part of regulatory analysts. To improve the process of reviewing public comments as part of regulatory analysis, our team implemented topic modeling (Grootendorst et al., 2022) and sentiment analysis (Hartman et al., 2023) of comments published to the new amendment to foreign quarantine regulation published by CDC on July 10, 2023. This solution expands these efforts by using generative AI models  to try for capture stance expressed in each comment. While there is also an option to manually label and train models for stance detection, custom-trained text classification models may not be transferable to future rules due to rule-specific discussions and arguments. In contrast, using generative AI models for stance detection can be transferable to future rules irrespective of the discussion contexts and arguments."
HHS-CDC-00026,A reusable NLP pipeline for clinical narratives preprocessing and characterization,HHS,CDC,"Data cleaning of Clinical narratives from health records. At scale, clinical narratives are a dataset available to CDC currently underutilized as there is not a structured pipeline to identify structured information output. We are currently working on setting up a process to create a pipeline that cleans data markup (html, rtf, xml) and identifies signs and symptoms using pre-trained Named Entity Recognition (NER) tasks from relevant models published in peer review journals. 





The use of these pretrained models significantly reduces  the amount of time a human to spend tagging data and provides additional features and increased consistency from unstructured data for identification of more novel insights. ","The objective of this project is to take unstructured data, clean it, and use pretrained Named Entity Recognition (NER) tools to extract signs/symptoms in deidentified electronic health records that can be used to characterize a cohort or make further analysis."
HHS-CDC-00027,Autocoding to Support Adverse Drug Event Surveillance,HHS,CDC,"The model will help surveillance epidemiologists working at CDC to determine whether reported potential adverse drug events in the National Electronic Injury Surveillance System Cooperative Adverse Drug event Surveillance meet the agency's surveillance case definition for the same.

It will speed up coding of the drug event reports, helping epidemiologists produce prevalence estimates for the surveillance system.","The model will take a de-identified free-text description of the patient's emergency department visit encounter, along with a handful of other pre-coded variables, and output the probability that the encounter meets the case definition."
HHS-CDC-00028,Automating LIMS Bioinformatics Workflow Configuration and Enhancing Lab Quality Management with AI,HHS,CDC,"The tool proposed will impact the laboratory bioinformatics workflow configuration within the Core Laboratory's Genomics Sequencing Lab (GSL). Specifically, it will improve the efficacy with Clarity LIMS for tracking and processing Next Generation Sequencing (NGS) samples. This includes the creation and customization of bioinformatics workflows in the Laboratory Information Management System, which is currently a time-consuming and expertise-intensive task for bioinformaticians and laboratory scientists.

The RAG system can potentially reduce the time required to configure Clarity LIMS workflows, enabling rapid deployment which is particularly crucial during pandemics or outbreak responses. By simplifying the workflow customization process through natural language inputs, it lowers the barrier to entry for laboratory scientists and bioinformaticians who may not be familiar with XML scripting. The system also enhances team learning and training by providing easy access to relevant documents on quality management and regulations, ensuring that all team members are well-informed about best practices.","We propose to use a Retrieval-Augmented Generation (RAG) framework for two primary functions: It converts natural language lab protocols into precise XML workflows that are compatible with Clarity LIMS. This conversion process involves understanding technical documentations and generating corresponding script code. In addition, it serves as an interactive knowledge base for documentation of Clarity LIMS and Laboratory Quality Management and Regulations. "
HHS-CDC-00029,DGMH AI Chatbot,HHS,CDC,"The DGMH AI chatbot would assist with developing an initial draft response to  inquiries where the response could have been found on our website. This would allow DGMH staff to have a starting point on a response to edit and clear. Additionally, the response could be adjusted for plain language to assist in ensuring the inquirer understands the response being sent back to them. The AI chatbot would allow inquiries to be responded to quicker and would allow staff to focus on other high priority items as well.   

The project will rely on using Retrieval-Augmentation Generation (RAG) to identify relevant information from CDC’s relevant website pages to generate relevant responses using AI. Evaluation of the project will assess how accurate the response was, how complete it was, and how much revision was needed. Evaluation would also explore the answer and if the answer that was generated was consistent throughout time if multiple people asked similar questions.   The goal is consistency of content rather than tone/plain language. The chatbot will help to reduce the turnaround time for responding to inquiries and free up time for staff to address other priorities.","CDC's Division of Global Migration Health receives inquires for information which is available publicly in some form but may be hard to find and requires staff responding to these inquiries to have a broad knowledge and can be time intensive to respond to. The AI Chatbot will draft an initial response to questions using content available on CDC’s public-facing webpages. Each response goes through the existing CDC clearance process regardless of if AI is used, but the Chatbot helps provide an initial draft based on previously published content. The goal is to help with responding to different inquiries the division receives, including but not limited to CDC-INFO and media. "
HHS-CDC-00030,Distiller SR: AI to screen research articles for Community Guide reviews,HHS,CDC,"This tool will be used to screen research articles that will be used to inform Community Preventive Services Task Force recommendations (a body that produces guidelines independent of CDC). 

Use of this technology may increase the speed with which systematic reviews can be conducted. This may expedite the time it takes to evaluate the effectiveness of public health programs for a CPSTF recommendation (not a CDC guideline). ",Machine learning will be used to more efficiently screen research articles relevant to evaluating the effectiveness of an intervention. 
HHS-CDC-00031,Evaluating Generative AI for polio containment.,HHS,CDC,"The AI will impact the data retrieval and automation process for HIV researchers, specifically in providing information from datasets and potentially generating code for desired variable names and analysis or generating information about a particular dataset.

As polio eradication progresses, containment of poliovirus becomes critical. This project aims to identify and evaluate Generative AI tools to extract information from publications in an effort to identify poliovirus in places previously thought to be polio-free.  Identification of such a tool may diversify Polio and Picornavirus Branch's surveillance portfolio and increase Branch's capability of processing large volume of data for containment purposes. This project may support CDC PPLB’s polio surveillance activity and containment efforts.","This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query. Our aim is to input all dataset documentation and metadata into an index with the goal of creating a virtual assistant. This assistant offers support to our HIV researchers by providing the information they seek from the data and potentially generating SAS, R, or Python code for desired variable names. For instance, if we require a dataset containing HIV PrEP information, we can request it to generate a list of current datasets that contain data on PrEP medication usage in 2019, along with the associated variable names. Subsequently, we can instruct it to produce lines of code, such as a logistic regression, which can be readily copied and pasted into our analysis software of choice. Another example would be if our researchers would like information returned about a given dataset, this assistant could return specific information based on the researcher's query."
HHS-CDC-00032,Respiratory Virus Response (RVR) Data Analysis Concept,HHS,CDC,"This solution will impact the process of summarizing subject matter expert (SME) interpretations/knowledge during a response. 

Response efforts require prompt turnaround of essential information to the public. This project will impact public health by improving the efficiency of dissemination of information through production of key takeaways which can then be quickly reviewed by SMEs and cleared. This project will also allow for improved understanding of limitations and uncertainties in use of AI methods that could contribute to improved implementation of such methods in public health.","The goal of this solution is to evaluate how AI can be implemented in the process of summarizing subject matter expert (SME) interpretations/knowledge to improve efficiency in knowledge dissemination during a response.  As part of the proof-of-concept, we  seek to evaluate the limitations and uncertainties of AI methods in this use-case, such as bias and hallucinations as such issues will require mitigation before this method can be broadly adopted. Our proposed approach would make use of the ChatGPT interface through EDAV (or alternative accepted platform) as our prompts will include uncleared data from the Respiratory Virus Response (RVR). In this response,  SMEs from different groups provide bulleted information that then needs to be further summarized to address key takeaways.   Bullets from prior weeks will prompt AI to generate summaries. The initial approach will focus on engineering prompts to get key takeaways while future iterations may require fine-tuning to allow for better contextualization of responses as well as improvements in tone and style. "
HHS-CDC-00033,School LLM initial abstract review process ,HHS,CDC,"Reviewing research related to school readiness science. CDC/DRRS' School Preparedness unit is responsible for developing research around readiness science. As part of this a large language model was used to abstract themes and code publications that were identified as related to school closure to aid us in supporting our research. If funding were to become available, we would like to develop this static, one-time product into a modifiable tool that could be used for ongoing article abstraction across school and other settings and population.

The AI allows us to efficiently categorize thousands of abstracts in a much shorter time-frame with much less human time required into a user-friendly dashboard. ",The AI used a LLM to extract data from an abstract review and categorize relevant themes and topics into a user-friendly dashboard. This dashboard can be used by a health scientist to pull resources from 2012-2022   for specific school closure outcomes or themes.
HHS-CDC-00034,ChatCDC - CDC Enterprise Generative AI Chatbot (Content Editing),HHS,CDC,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with editing text previously written, or content editing. This may refer to using the chatbot to help refine emails or messages to other CDC staff, reviewing internal documents, reviewing scheduling or other bureaucratic information and other such information. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. This includes internal guidance on using AI for External Communications.

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of data uploads. This tool can be used by all CDC staff to support general business operations and enables a quick review for finding any spelling or grammatical errors, fixing formatting, or other copy-editing type corrections and saves staff time will increasing the quality of communications. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user. In this case, responses will be recommendations on edits for content provided by the user such as a draft email. The chatbot's output can then be copied and pasted or manually entered based upon the users review. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release."
HHS-CDC-00035,ChatCDC - CDC Enterprise Generative AI Chatbot (Data Extraction),HHS,CDC,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose tool to assist with extracting information from larger pieces of text. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

From larger documents which may be time consuming to find specific pieces of information, this AI system enables staff to extract key pieces of information to be used in later tasks. This can include action items from meeting transcripts, specific discussion focuses from larger meetings, specific mentions, or other such information. this makes the finding of information from larger document far faster and reduces the manual burden of reading larger documents for one or two specific pieces of information.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case about some larger piece of text and any specific pieces of information to extract. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task."
HHS-CDC-00036,ChatCDC - CDC Enterprise Generative AI Chatbot (Ideation),HHS,CDC,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with the development of ideas or to overcome writers block in different tasks. When doing a task, staff can ask this tool to ask questions to help evolve any ideas being developed. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of 3rd party AI powered general purpose chatbots. This ensures staff can provide information regarding a current task along with general information with current tasks to help organize thinking, actions to take, and developing ideas for staff to use or reject as a part of their process. This reduces the time spent by staff dealing with situations such as writers block.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task. The output must be copied and pasted or manually entered somewhere for the output to be used by staff."
HHS-CDC-00037,ChatCDC - CDC Enterprise Generative AI Chatbot (Software Development),HHS,CDC,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with the development of software code which can be used for research, data analysis, software development, or other such systems. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

When the AI chatbot is being used for coding assistance or software development, it affects several business processes related to agency operations and core task structures. Specifically, it can be utilized by various personnel within an organization such as the CDC, including software programmers using AI-specific code, those involved in encoding for software development, data analysts, scientific researchers conducting data analysis, data scientists implementing and testing new models, and software engineers developing or updating applications.
The chatbot enhances productivity and efficiency across these roles by providing coding assistance and acting as a learning tool. For instance, data engineers may use the chatbot to generate PySpark code for their data transformation scripts within a larger pipeline. Additionally, individuals new to programming languages like Python can leverage the chatbot as a tutor to help them with tasks such as cleaning up datasets for evaluation purposes.
In summary, the AI chatbot impacts business processes by aiding staff members in performing complex analytical tasks more efficiently and supporting their development work through guided coding assistance. This ultimately contributes to enhancing overall operations within the agency by streamlining research activities and internal process workflows.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case about either some software code, software code documentation, code concepts, or to help generate software code. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task."
HHS-CDC-00038,ChatCDC - CDC Enterprise Generative AI Chatbot (Summarization),HHS,CDC,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose tool to summarize and synthesize information from larger documents such as meeting transcripts, research articles, or other documents. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of data uploads to third party tools. Using ChatCDC, Staff can have smaller, more easily digestible summaries to save staff time from reading larger documents if the time to read the full document is not available.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case a summary of a larger document. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task."
HHS-CDC-00039,DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (AI Summarization),HHS,CDC,"This AI solution impacts the process of investigating foodborne disease outbreaks. These foodborne outbreaks require cooperative efforts from CDC staff, FDA, USDA, and local agencies and the AI system is used through a centralized data platform System for Enteric Disease Response, Investigation, and Coordination (also known as SEDRIC). For more information on SEDRIC, please go to our website: https://www.cdc.gov/foodborne-outbreaks/php/foodsafety/tools/index.html

SEDRIC's AIP use case provides CDC epidemiologists the ability to accelerate their investigations of multi-state foodborne disease outbreaks by more effectively leveraging data available in a rich data source, such as receipts from grocery stores, that otherwise requires extensive time and human effort to parse through. In addition, this workflow would free up epidemiologists' time and, potentially, increase the frequency with which both CDC and STLT partners could utilize shopper card, receipts, and free text responses to support investigations. Using the summarization capability, the extensive process of mapping common names of different food items is done automatically, greatly reducing the human labor time to generate dashboards of information regarding current foodborne investigations to serve as a decision point to aid in outbreak response.","The Artificial Intelligence Platform (AIP) available within SEDRIC provides CDC epidemiologists the power to accelerate their investigations of multi-state foodborne disease outbreaks. Using the information previously extracted from receipts and other records, AIP can summarize these results to provide insights from information pulled from shopper receipts. Given ingredients can be found in multiple food products, and some ingredients such as herbs like coriander/cilantro may go by multiple names or be reported in multiple languages, this summarization tool provides a faster way to gather summary information from receipts on different food items which may be part of a foodborne investigation."
HHS-CDC-00040,DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (Receipt Reading),HHS,CDC,"This AI solution impacts the process of investigating foodborne disease outbreaks. These foodborne outbreaks require cooperative efforts from CDC staff, FDA, USDA, and local agencies and the AI system is used through a centralized data platform System for Enteric Disease Response, Investigation, and Coordination (also known as SEDRIC). For more information on SEDRIC, please go to our website: https://www.cdc.gov/foodborne-outbreaks/php/foodsafety/tools/index.html

SEDRIC's AIP use case provides CDC epidemiologists the ability to accelerate their investigations of multi-state foodborne disease outbreaks by more effectively leveraging data available in a rich data source, such as receipts from grocery stores, that otherwise requires extensive time and human effort to parse through. In addition, this workflow would free up epidemiologists' time and, potentially, increase the frequency with which both CDC and STLT partners could utilize shopper card, receipts, and free text responses to support investigations. Manually entering receipt information, shopper card information, or other such free text field is traditionally error prone and time intensive for a variety of information. This AI system provides a human-in-the-loop opportunity to review and update data entry points while reducing time spent by staff to gain these insights. Having a set structured output as well increased standardization of this information and eases reporting in situations requiring cooperation from multiple organizations.","Palantir’s Artificial Intelligence Platform (AIP) available within SEDRIC provides CDC epidemiologists the power to accelerate their investigations of multi-state foodborne disease outbreaks. It can extract structured data from grocery receipts, shopper card records, and free-text responses in order to catalog the food items purchased by affected patients. It can also map those items to SEDRIC-defined vehicles which categorize the items and highlight commonalities across patients, helping to pinpoint potential outbreak vehicles."
HHS-CDC-00041,DFWED Food Vehicle Investigation Module,HHS,CDC,"Foodborne outbreak investigation

Outbreak investigation by providing estimates of output of potential food vehicles can increase speed of tracking foodborne outbreaks in terms of identification of hypothesis generation. This reduces operational burdens in foodborne response efforts.","NLP and Food Vehicle Investigation Module (FVIM) uses language learning models and Text Classification Tools to identify potential vehicles. NLP tool uses text classification to provide probabilities that a food is associated with the outbreak based on reports in the SEDRIC line list. FVIM identifies past outbreak with similar key demographic and temporal characteristics to the selected outbreak to guide hypothesis generation. FVIM analyses reported food exposures uploaded to the SEDRIC line list and categorizes responses into food commodity types that are then compared to FoodNet Population survey results weighted by age, sex and ethnicity and generates a statistical comparison"
HHS-CDC-00042,Genetic distance computation method for comparing complex multi-locus parasite (Cyclospora) genotypes,HHS,CDC,"Investigating the similarity of infections used during epidemiologic investigations of cyclosporiasis outbreaks.

It helps produce a clustering output for massive datasets comprising genotypes that are too complex to be analyzed using traditional genetic distance computation methods and aid in identifying similarities of infections when tracking cyclosporiasis outbreaks and other potential parasites.","The AI algorithm compares sets of haplotypes sequenced from a set of clinical samples and computes a set of genetic distances. It performs these comparisons across thousands of genotypes to identify infections that are closely related or unrelated. The resultant genetic distances are then clustered to define groups of closely related infections. This information is used routinely to complement epidemiologic investigations of cyclosporiasis (Cyclospora) outbreaks, and traceback investigations performed by state public health agencies and FDA. While this AI has mostly been applied to Cyclospora, we have also applied it to other parasites, including malaria, and certain parasitic worms."
HHS-CDC-00043,MedCoder - Coding literal text cause of death information reported on death certificates to ICD-10,HHS,CDC,"MedCoder is a subsystem of CDC's National Center for Health Statistics (NCHS) National Vital Statistics System for coding causes of death indicated on the death certificates to the International Classification of Diseases 10th Revision (ICD-10) codes.

With the implementation of MedCoder, the percentage of deaths that can be automatically and accurately coded has risen from 70-75% using the previous coding system to over 85%. This improvement translates into substantial cost savings, amounting to hundreds of thousands of dollars that would have been spent on manual coding. Additionally, it significantly enhances the timeliness of data related to urgent public health concerns such as COVID and drug overdose deaths, enabling near real-time surveillance.","MedCoder assists with the identifying cause of death codes from death certificates using ICD-10 Underlying cause codes and automatically identifies and rejects complex causes of death as well as frequently miscoded ones, requiring manual coding or review. Additionally, in production, MedCoder utilizes natural language processing (NLP) to cleanse and standardize literal text cause of death statements before performing coding."
HHS-CDC-00044,NCIRD SmartFind ChatBots - Public and Internal ,HHS,CDC,"Internal partner mailbox email management including managing knowledge base. Previously, this included public facing chatbots but the public ChatBots are no longer active. This uses previously cleared FAQs and other reviewed information accessible publicly as the knowledge base.

The internal Knowledge-Bot's SharePoint component is helping program staff manage emails from partners more efficiently and effectively including creation and maintenance of a knowledge base that can be utilized across staff managing the mailbox. ","Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search, QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps. "
HHS-CDC-00045,NIOSH Industry and Occupation Computerized Coding System (NIOCCS),HHS,CDC,"Replaces manual coding of industry and occupation text to standardized codes so that they can be used for research and analysis.

Reduces the high cost of manually coding industry and occupation data while promoting increased coding speed, accuracy, and consistency.",Uses machine learning models to translate industry and occupation text into standardized codes that can be used for research and analysis.
HHS-CDC-00046,Nowcasting Injury Trends ,HHS,CDC,"Predicting current injury rates and real time estimates of injuries and deaths. The internal dashboard that will be created as a result of this effort will enhance the understanding of injury trends and expedite surveillance and research activities. This initiative will have a direct impact on the speed at which emerging trends in injuries resulting in deaths are identified and investigated.

Gold standard data take time to process and be made available. Real-time insight of injury trends when gold standard data are not available can be a resource resulting in timelier situational awareness to inform injury surveillance efforts. ","An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' injury death trends nationally on a week-to-week basis. "
HHS-CDC-00047,Risk Assessment Module (RAM) for the National Diabetes Prevention Program (National DPP) Operations Center.,HHS,CDC,"Tracking program progress. This AI assists in determining if an organization that is currently operating within the National DPP is at risk of improperly starting, at risk of going inactive, or at risk of not achieving the goals necessary to continue successfully in CDC’s Diabetes Prevention Recognition Program.

The RAM module will help program managers synthesize large amounts of organization-level data in making decisions on how best to assist organizations with their programs, ultimately leading to increased program participation and improved health outcomes in program participants. ","The RAM is a reporting tool within the National DPP Operations Center which already has an ATO. The RAM module ingests large amounts of organization-level data including National DPP participant enrollment records, demographics, and specific risk factors to perform supervised learning and model generation. This machine learning model is used to predict and quantitatively rank those organizations that are at highest risk of failing to meet program objectives. This information, both input and RAM output, is currently fully sequestered to associates of the National DPP of the CDC. In the future, with continued development and validation, the plan is to allow external-to-CDC State Quality Specialist (SQS) users access to the outputs of RAM for additional assistance with improving organization success."
HHS-CDC-00048,Semi-Automated Nonresponse Detection for Surveys (SANDS),HHS,CDC,"SANDS is a fine-tuned large language model (LLM) designed to assist with human-in-the-loop procedures specifically for open-ended survey responses. Open-ended survey responses vary in quality and are challenging to use effectively because they are labor-intensive to review and therefore cost-prohibitive to use at scale. SANDS is intended to reduce the burden by filtering out clear and obvious non-response such as  ""This is so dumb, why I am I wasting my time on such a stupid question"" or ""Because It is true"" which provide no value to researchers. This LLM is available on HuggingFace and is not routinely updated, but it can be used like any open-source LLM through secure instances of Python.

Manual curation of open-ended survey responses is time-consuming, often requiring extensive hours to identify themes and review outputs. SANDS significantly reduces this manual burden by providing scores for responses, enabling researchers to quickly compile an initial high-quality dataset for qualitative research. SANDS also flags responses needing further examination, streamlining the review process.",CDC's National Center for Health Statistics (NCHS) has developed and released a model to detect nonresponses in open-text survey responses. This helps improve survey data quality and question and questionnaire design. The system is a natural language processing (NLP) model that has been fine-tuned on a custom dataset of survey responses. 
HHS-CDC-00049,Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage,HHS,CDC,"CDC's National Center for Health Statistics (NCHS) Data Linkage Program has developed a record linkage program designed to maximize the scientific value of the Center’s population-based surveys. Linked data files enable researchers to examine the factors that influence disability, chronic disease, health care utilization, morbidity, and mortality. The linkage algorithms initially used by the program did not implement machine learning in either deterministic or probabilistic linkages and required several manual steps for these processes. 

Using machine learning in the CDC's National Center for Health Statistics (NCHS) Data Linkage Program offers several benefits. Machine learning algorithms help improve the accuracy and efficiency of data linkage by developing joining methods or blocking groups.  Working with very large datasets can be time-consuming and resource-intensive. By implementing supervised and unsupervised machine learning techniques, the Data Linkage Program can automate the process of developing and selecting blocking groups, reducing manual effort and increasing efficiency. This additionally improves the scalability of data linkages. Machine learning algorithms can continuously learn and adapt based on new data inputs and feedback. This allows the Data Linkage Program to refine their linkage algorithms over time.","CDC's National Center for Health Statistics (NCHS) Data Linkage Program has implemented both supervised and unsupervised machine learning (ML) techniques in their linkage algorithms. The Sequential Coverage Algorithm (SCA), a supervised ML algorithm, is used to develop joining methods (or blocking groups) when working with very large datasets. The unsupervised partial Expectation-Maximization (EM) estimation is used to estimate the proportion of pairs that are matches within each block. Both methods improve linkage accuracy and efficiency."
HHS-CDC-00050,TowerScout: Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation,HHS,CDC,"During Legionella outbreaks, the National Center for Immunization and Respiratory Diseases (NCIRD)/Division of Bacterial Diseases (DBD) needs to identify cooling towers that could potentially be spreading Legionella bacteria. 

Using AI object detection, TowerScout detects cooling towers approximately 600 times faster than manual searches, allowing researchers to more efficiently respond during outbreaks. ",TowerScout uses object detection and image classification models to detect cooling towers within aerial imagery.  
HHS-CDC-00051,Creation of synthetic Survey-like Insurance Names for use coding NHIS private insurance responses,HHS,CDC,"This solution will impact the process of manual coding and reviewing text errors in the National Health Interview Survey 

Previous efforts to augment the manual coding have proven ineffective. Given the complex nature of insurance programs, this results in over 200 FTE hours a year being spent on just the initial coding of open text insurance fields. Additional hours are spent reviewing the manual coding for errors. By creating survey-like insurance responses, this could theoretically save over 100 hours of staff labor a year, greatly increasing efficiency and timeliness.","The National Health Interview Survey calculates insurance coverage rates among the US non-institutionalized resident population, including statistics of the percentage of people with private insurance coverage. The collection of information on insurance coverage is accomplished in two parts. First, survey respondents self-identify the type of insurance they have. Secondly, to aid in the verification of insurance type, survey respondents also provide the name of the health plan or program they have in an open text field. The information collected in the open text field may include misspellings, acronyms, and rarely match exactly the true complete insurance plan name. 

This leads to a time intensive process as staff may need to decipher the plan name in the open text field mentioned by the respondent and/or abbreviated by the interviewer and if that plan name confirms the correct type of insurance initially indicated during the interview process. By creating AI generated known acronyms as data points for projects, as an example Blue Cross Blue Shield of Alabama to BCBS of AL and BC/BS of AL, this will create a more representative set of information for staff to use when coding potential saving up to hundreds of FTE hours reviewing responses. This also works in combination with existing efforts to augment manual coding with AI and Machine Learning to increase efficiency.
"
HHS-CDC-00052,Development of in-silico genomic and patient datasets using generative ML algorithms,HHS,CDC,"This solution will impact the process of finding reference genomes

Reduce the development time of custom tools, finding reference genomes, and additional administrative burdens. The datasets developed would be beneficial in testing out bioinformatic pipelines. ","This solution uses NLP generative AI toolsets (e.g. ChatGPT, co-pilot, etc.) to generate code for the development of bacterial and viral in-silico genomic sequences and patient data. This will be compared to already established pipelines to determine factors such as code viability, data accuracy, code licensing, and any drawbacks and/or advantages these services provide. For example, we would ask GPT-4 a prompt, ""generate python code to create Sars COV2 in-silico fastq sequencing data."". We will look at where did it reference the code base to generate the code and is it open source or have licensing requirements.  "
HHS-CDC-00053,Mastering Metadata: AI-Powered Governance for Data Insights,HHS,CDC,"The implementation of this solution will have a significant influence on the maintenance of data quality and data assets on the data.cdc.gov platform.

Accurate, reliable, and timely data available in data.cdc.gov is critical in making meaningful public health decisions. This publicly available data repository is used worldwide by researchers, policy makers, and general public to access, manage, analyze, and visualize public health data. Through this project, we will be able to scale up the magnitude and quality of datasets from NCIRD that’s made available via data.cdc.gov and thus maximizing public health impact for a diverse audience at multiple levels.","data.cdc.gov serves as a publicly accessible repository for CDC data, utilized by researchers, policymakers, and the general public to monitor and comprehend public health trends. Ensuring the accuracy and reliability of the data on data.cdc.gov is crucial for informed decision-making in public health. To achieve this, the proposed solution involves leveraging AI to maintain CDC's National Center for Immunization and Respiratory Diseases data assets on data.cdc.gov to automate various tasks such as checking metadata completeness, validating metadata against a schema, comparing metadata with other sources, and monitoring metadata changes over time."
HHS-CDC-00055,PII detection using Private AI ,HHS,CDC,"Numerous data sources contain personally identifiable information (PII) and protected health information (PHI), which cannot be publicly published or shared among federal partners due to confidentiality concerns. This includes sensitive records like death certificates, survey responses, and electronic health records. To enable broader utilization of this data and enhance insights, a PII detection system was explored in this project. Specifically, the availability of an off-the-shelf tool called Private AI was investigated for identifying PII. However, it is important to note that the license for this tool expired after one year and there are no current plans to renew the contract.

At present, the presence of PII within data and the labor intensive process to ensure PII redaction and removal has prevented broader sharing of data available within CDC. However, implementing an automated system which performs as well as humans and more quickly could significantly reduce the time required for human review, enabling faster dissemination of crucial public health information and data sources.","CDC's National Center for Health Statistics (NCHS) has been assessing the NLP solution provided by Private AI, which is specifically designed to detect, mask, and substitute personally identifiable information (PII) within textual data. This collection of models aims to securely identify and eliminate PII from unstructured text datasets across various platforms within the CDC network."
HHS-CDC-00056,Reddit Post Analysis for Sexual Health Using Large Language Models,HHS,CDC,"The AI will impact the data extraction and analysis processes for understanding how users seek sexual health advice online using Reddit.

In additional to traditional public health impacts this can include reducing administrative burdens and other ancillary benefits. This is an important criteria when selecting the initial round of projects.
Understand how and why people seek sexual health advice online. This may lead to finding gaps in online health resources, identifying underserved populations who resort to using online resources, and discovering changes in sexual health behavior over time.","Reddit is a social media website where users can submit and respond to posts around a wide variety of topics. Reddit is organized into subcommunities called subreddits, and many people turn to sexual health focused subreddits, such as the “r/STD” subreddit, for advice. The Reddit posts can be a valuable source of text and image data since these posts reveal immediate sexual health concerns and questions that may be overlooked. However, the volume of posts makes large scale manual analysis impractical, and extracting insights using conventional methods is difficult. This solution uses large language models (LLMs) to assist in and automate data extraction and analysis to better understand how users seek sexual health advice online."
HHS-CDC-00057,Retrieval Augmented Generation (RAG) with Q-Bank,HHS,CDC,"This solution will impact the process of searching CCQDER’s Q-Bank research publications on question evaluation for surveys. 

Q-Bank reports provide context needed to better understand and interpret data from survey estimates, as well as information about question performance and fit-for-use in various data collection contexts.
This project aims to improve access and visibility of CCQDER’s Q-Bank research publications on question evaluation for surveys. Additionally, indexing Q-Bank as part of this project should help to relieve some of the administrative burden of tagging and organizing reports.","This solution uses Retrieval Augmented Generation to develop an LLM-based search tool based on the Collaborating Center for Questionnaire Design and Evaluation Research’s (CCQDER) Q-Bank reports. The main motivation of the solution is to make it easier to navigate and identify reports relevant to a user’s research interests. Because the reports are already publicly available and they represent a relatively small corpus, they provide an excellent opportunity to develop prototype AI tools."
HHS-CDC-00058,Using generative AI to gain insight of older adult falls,HHS,CDC,"This solution will impact the process of extracting information from medical narratives 

Traditional methods of data and information extraction from medical narratives involve manual scrutiny and the use of rule-based models. These methods are time-consuming and can overlook crucial details. By utilizing generative AI, a more comprehensive understanding of the circumstances surrounding injuries from falls can be achieved. Understanding the specific causes, circumstances, and outcomes of falls can lead to more targeted public health interventions.",This solution extracts insights regarding older adult falls injuries from Emergency Department medical narratives and testing out methods submitted. The data source to be used is the National Electronic Injury Surveillance System (NEISS) data.
HHS-CMS-00001,AI-assisted comment triaging tool,HHS,CMS,"Annual rulemaking-- the Physician Fee Schedule receives thousands of public comments and require assistance with reviewing and assigning the comments to the particular topics they address. 

Assists with workload for the PFS team","We use AI to assist in comment review, such as identifying form letters. "
HHS-CMS-00002,Bankruptcy BOT,HHS,CMS,"The Bankruptcy/Overpayment Division of IFM is responsible for carrying out the Agency's oversight responsibilities for our contractors' debt management functions, and for protecting Medicare's interest in debt recoupment activities complicated by bankruptcy.

A timely identification of filed provider bankruptcies allows Medicare to secure recovery rights before timeframes to file a proof of claim expire.",The Bankruptcy BOT proactively identifies bankruptcy case with Medicare interest.
HHS-CMS-00003,Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool,HHS,CMS,"Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits

Eliminates manual review of Medical Record (MR) submissions, expedites the Intake process and realizes cost savings in both time and resources.",The PA-BOT tool will replace the RADV audit Intake manual functions for Steps 2 & 3 of the RADV audit process.  The RADV Intake process conducts a review of the MAO Medical Record (MR) submissions and validates that the MR submissions from MAOs have met RADV audit intake requirements and can proceed to MR abstraction/coding.
HHS-CMS-00004,CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot),HHS,CMS,"CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management

 - Empowers users to find information or troubleshoot issues more efficiently
 - Reduces load on system help desks
 - Provides better insight into customer inquiries and issues informing process and design improvements
"," - Automated text-based bot providing support to Portal users
 - Uses machine learning via Amazon Lex to answer a user’s question
 - Takes user input and finds the best match to the question or problem statement
 - Automates tasks such as: customer support; processing of user questions; and solving user problems/issues"
HHS-CMS-00005,Enhanced Direct Enrollment Outlier Detection,HHS,CMS,"Enhanced Direct Enrollment (EDE) allows consumers to apply for and enroll in an exchange plan directly through an approved partner’s UI, without being redirected through the Healthcare.gov application. These partner systems directly interface with the APIs developed by the FFE. As EDE Partners gain more control over their application process, the FFE must ensure program integrity.

Ensure FFE EDE program integrity","This use-case will implement Machine Learning to identify anomalies/quality issues with partner-submitted person, application, and policy data​."
HHS-CMS-00006,Exchange Complaints Review Categorization  ML/AI ,HHS,CMS,"The Exchange Complaints Review Contractor (ECRC) receives hundreds of consumer complaints from the Federally-facilitated Exchange (FFE) call center daily, who then must manually read each complaint and categorize each complaint into one or more categories according to the Complaint Review Standard Operating Procedure (SOP). The categorization assists CPI in determining the nature of the complaint, the action necessary, and the component within CMS who the complaint should be routed to. In general, each complaint can take up to 10 minutes to review and categorize, including a quality review component.   

The output (list of all complaints categorized) allows CMS to expediate routing the complaint to the appropriate CMS caseworker or Issuer to take the appropriate action necessary to make the consumer whole and ensure they can receive the necessary medical treatment. The output when done by AI is done in a matter of minutes, versus weeks when completed by human reviewers. ","CPI utilizes machine learning/artificial intelligence (AI) and continuously feeds the complaints review model thousands of complaints in order to teach the model how to accurately categorize the complaints, based on keywords. This is done in a matter of minutes instead of weeks by a human complaint reviewer."
HHS-CMS-00007,Feedback Analysis Solution (FAS),HHS,CMS,"The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  

FAS help categorize stakeholder comments or feedback (collected in multiple venues), thereby enabling analysts to use the system to quickly identify comments that may impact program/policy decisions.","Feedback Analysis Solution (FAS) uses AI/ML/NLP tools to identify topics, themes, and sentiments outputs for the target datasets. Groups and offices within CCSQ use the solution in slightly different ways to ingest unstructured data, interpret and structure it for use in ML models after de-duplication of comments."
HHS-CMS-00010,IT System Utilization Optimization,HHS,CMS,"The FFE application usage patterns vary and are dependent on differing environment usage periods. CMS resources are currently manually scaled, not allowing immediate actions in correlation with usage changes.

Automation of application scaling",This use-case will implement Machine Learning to determine optimized infrastructure/application scaling to support system volume.
HHS-CMS-00011,Knowledge Management Platform,HHS,CMS,"The business process it affects involves accessing and using structured and unstructured data sources to enable data-driven decision-making. 

It helps by creating efficiencies, reducing burden, and generating an increased return on investment in the achievement of CMS's mission and business objectives.","It leverages natural language processing, knowledge graphs, and large language models to make the knowledge within structured and unstructured data sources accessible and meaningful to users."
HHS-CMS-00014,Risk Adjustment Outlier Analysis,HHS,CMS,"The RA program spreads the financial risk borne by Issuers due to offering a variety of plans meeting the need of the diverse population. RA payments are distributed based on population risk levels. The FFE uses a distributed data solution to calculate plan average actuarial risk and associated payments and must avoid potential impacts to annual calculations.

Maintain RA Program risk integrity",This use-case will implement Machine Learning to identify outliers in issuer data / behavior that may unduly influence risk adjustment payments.
HHS-CMS-00015,Agent/Broker Fraud Analysis,HHS,CMS,"Agent/Brokers (A/Bs) support the consumer enrollment and eligibility process. Because of this, they have learned the intricate details of the FFE for accessing applications, submitting eligibility determinations, and adding enrollments to their line of business, opening up the possibility of fraud. 

Improves the oversight and integrity of Marketplace Applications and Enrollments assisted by Agents and Brokers.  Helps CCIIO identify suspicious behaviors to refer to CPI.",Utilizes Machine Learning to identify suspicious behaviors of Agents and Brokers in the Marketplace
HHS-CMS-00016,CCSQ ServiceNow AI Search,HHS,CMS,"CCSQ ServiceNow AI Search is a product inside ServiceNow (SaaS).  It replaces traditional Zing search tool (exact search), and enables users with more flexible searches to get relevant and actionable answers quickly.

* Improve search relevance
* Promote self-service by empowering users to find information independently, and potential reduce number of cases","AI Search will
* Display most relevant results first
* Support synonyms, auto-corrections, stop words, and auto-completion
AI Search analytics will provide insights into search usage, performance, trends, metrics, and how to improve search experiences.
Plan to do AI Search tune-up next"
HHS-CMS-00017,MSP Assignment Bot,HHS,CMS,"This impacts automatically retrieving records from a contractor's system, and importing them into an internal OPOLE Access database.  Once populated in the database the record is assigned to staff to review and adjudicate.

Pulls more cases out of BCRC and assigns much faster than an analyst. By allowing BOT to pull and assign cases instead of an analyst, this approach provides maximum time for staff to process cases which decreases the response time.",The Medicare Secondary Payer Operations Group (MSPOG) uses a BOT to pull compromise cases out of BCRC and assign to staff in our internal Management Information System (MIS)
HHS-CMS-00018,"Relationships, Events, Contacts, and Outreach Network (RECON)",HHS,CMS,"RECON AI for Recommender System| Sentiment Analysis

It has the potential to analyze data faster.","This was “native” Salesforce AI capabilities, not anything custom – and that platform-level AI is not being used in RECON at this time."
HHS-CMS-00019,Complaint Analysis POC,HHS,CMS,"The business process this AI could affect involves the analysis of complaint data used by the OPOLE team.

It could help the OPOLE team to understand the main issues and potential root causes of the complaints, enabling them to address these issues more efficiently and effectively.",It utilized data science techniques and an LLM to analyze complaint data.
HHS-CMS-00020,Data Lake/Load-Extract-Transform-Load (L-ETL),HHS,CMS,"CMS is using Security Data Lake to modernize the Load-Extract-Transform-Load (L-ETL) pipelines and data tooling. There is no actual ML/AI work being done here today, rather, we are beginning work on the scaffolding that will open up these opportunities in 1-2 years time. 

Building on top of a modern data platform will provide opportunities to experiment with machine learning model development against this data--solving any number of problems that require decisions to be made about inferences over time series data. ","CMS will be enhancing Agency security to bring together more system, telemetry and program data in one place with a unifying governance model."
HHS-CMS-00021,FOIA Document Review/Redaction Automation,HHS,CMS,"OIT & OSORA partnership: Internal business process of reviewing and redacting CMS business documents subject to FOIA requests.

Reduces burden on FOIA staff to manually redacting business documents subject to FOIA requests.",Utilizes GenAI technology to automate review and redaction of CMS documents per FOIA requests/process.
HHS-CMS-00022,Help Desk Responses,HHS,CMS,"The Division of Issuer Management and Operations has talked with their contractor, LMI, about using an AI tool for the Help Desk contract.

This would reduce the amount of time staff contractors need to generate answers for SME review and approve responses to QHP issuers and other external entities that ask questions to the help desk.   ",This AI feature in the issuer help desk would help generate responses to common questions from issuers and external organizations based on previously cleared material.
HHS-CMS-00023,508 Accessibility Automation for Documents,HHS,CMS,"OIT: Internal business process at individual employee level to automate review, identification, and correction of potential 508 accessibility issues in documents.

Reduces burden associated with making documents 508 compliant (for individual CMS employees).",Utilizes GenAI technology to automate review and generation of corrected documents compliant with 508 accessibility rules.
HHS-CMS-00024,Brand vs Generic Market Share,HHS,CMS,"The Drug Data Processing System (DDPS) needs to predict changes in Medicare Part D costs 

Understanding beneficiary changes from Brand to Generic drugs allows for more accurate financial estimates.",Analyze generic drugs compared to brand drugs over time and forecast future market shares based on Part D claims volume
HHS-CMS-00025,Chat Client - Resource Library,HHS,CMS,"Continue to assess and refine content present in both the informational public side of QPP, Resource Library, Webinar Library, and Top Navigation as the site continues to grow.

The Chat Client would benefit the program by improving user experience through easier access to information, increased program understanding, and ability to communicate in multiple languages. ","Powered by Amazon Bedrock, by loading all resources, files, references etc. available to the QPP user community, we can establish a knowledge base that allows the bot to scan all available program documentation to construct a message that accurately answers a user's question. "
HHS-CMS-00026,Chatbot within Hub,HHS,CMS,"Currently the following help support activities are handle by a person:
Personalized FAQ’s; 
Clarify questions with schema and onboarding etc.; 
Handle - Where is “My file” or “My Request” inquiries
Provide a - Talk to Agent feature
Scheduling a testing window
Provide data summarization and reporting for internal stakeholders
Report operational health of the system
Include training materials, Q/A about the system and such.

Help support team in day-to-day communication with external partners","Build a chatbot that will address some help support activates through:
Access to Internal Knowledge base Including RAG (Retrieval Augmented Generation).
Personalized FAQ’s & Contextual generation.
Interaction with Live Agent.
Chat & Talk Feature.
Ability to query custom data source for File or Case status."
HHS-CMS-00028,Drug cost anomaly detection,HHS,CMS,"CMS Division of Payment Reconciliation is responsible for monitoring Prescription Drug Event  (PDE) data for accuracy

Allows for identification of outliers in PDE which can be corrected through Part D plan outreach in order to prevent overpayments.",Identify anomalies in drug costs on Part D claims
HHS-CMS-00029,Drug Cost Increase Predictions,HHS,CMS,"The Drug Data Processing System (DDPS) needs to predict changes in Medicare Part D costs 

Machine Learning model uses multiple methods to predict changes to Part D drug costs based on market changes.",Use Historical drug costs increases to predict future increases
HHS-CMS-00030,Medicare Part C/D Marketing Material Review,HHS,CMS,"Drug and Health Plan Operations (DHPO) staff reviews both advertising mediums and channels materials that includes over 22  different types of media marketing materials ranging from written, digital, and more. The marketing materials are submitted to CMS from either the Medicare Health Plans and/or their third party marketing organizations. DHPO staff reviews these marketing materials to ensure they meet Medicare Marketing Guidelines. 

The current process is time consuming and resource intensive. This reduces the efficiency and quality of staff reviews. AI can improve the efficiency and quality of the marketing materials reviewed; with human validation of results. Incorporating AI into current review process can reduce the time it takes to review marketing materials, improve efficiency and allow existing FTE resources to be utilized more efficiently, and potentially reduce the volume of marketing misrepresentation complaints.  Ideally this will improve efficiency and quality, help beneficiaries access to care, and also ensure marketing materials meets Medicare Marketing Guidelines.",The AI tool required has not been identified as we still need to develop a proof of concept.  We anticipate AI would learn the various requirements for Marketing materials to help identify issues and compliance with applicable policies and regulations.
HHS-CMS-00031,Medicare Part C/D Plan Oversight of AI Used for Prior Authorization and Utilization Management,HHS,CMS,"Medicare beneficiary access to benefits, services, and prescriptions associated with managed care plans and prescription drug plans.

AI tools can increase the capacity to analyze vast data sets based on combined sources. The results can then be further analyzed and refined by SMEs to issue compliance actions, identify plans for program auditing, and help protect the integrity of the Medicare program. ","Evaluate claims, payments, and complaints data to identify outliers. Determine if plans may be out of compliance with CMS rules or are negatively impacting beneficiary health outcomes based on plan use of AI and associated potential bias in system, process, or social determinates of health."
HHS-CMS-00032,Negotiated Drug Predictions,HHS,CMS,"The Inflation Reduction Act authorizes Medicare to directly negotiate drug prices for certain high expenditure, single source Medicare Part B or Part D drugs. For the first year of the Negotiation Program, the Secretary will select 10 Part high expenditure, single source drugs for negotiation.

Will assist with drug price negotiation for selected drugs",Use historical drug data to predict costs and claim volume for Selected drugs
HHS-CMS-00033,QPP Admin Bot,HHS,CMS,"Provides custom reporting and analysis to meet the ongoing and emerging needs to address analytics and reporting needs and supports key business processes in the QPP cycle - such as delivering feedback to providers, calculating final scores, and delivering payment adjustments to the Medicare contractors.

The Admin Bot would benefit the program by increasing availability of data, thus empowering users and informing decisions, through a simple-to-use communication platform.","Powered by Amazon Bedrock, the out-of-the-box solution can interface directly with data lakes like QPP's Universal Data Set (UDS) empowering users to ask very pointed questions on model data and/or model performance."
HHS-CMS-00034,Operational Efficiency Analytics ,HHS,CMS,"OHI/MAG is responsible for providing Marketplace consumers with an accurate, efficient and timely appeals adjudication process.

Examples where we can use predictive analytics:
 * Identifying trends in operations for managing and completing appeals processing
* Predicting the number of appeals during open enrollment
* Looking for regional or demographic trends in appeal complexity, completion time, and success",Eligibility Appeals Case Management System (EACMS) - Training a model on the data in our future data lake to be able to do predictive analytics.
HHS-CMS-00035,ICPG Governance Tool,HHS,CMS,"The business process it will affect involves the processing and analysis of acquisition plans (APs).

It will help by streamlining the manual steps involved in validating and classifying acquisition plans, reducing the time and effort required. ",It will automate the processing and analysis of acquisition plans and classify them as IT-related or non-IT.
HHS-CMS-00036,Innovation Center Investment Proposal (ICIP) Model Analysis POC,HHS,CMS,"It will affect the process of document analysis, specifically the analysis of ICIP documents.

It will help in  ICIP document analysis, with the goal of extracting of insights and recommendations from these documents.","It will extract relevant insights and recommendations from the ICIPs, making use of a RAG-based architecture, and present them through a natural language interface. This interface will allow users to interact with the documents and retrieve the information they need easily."
HHS-CMS-00037,OAGM Rate Card,HHS,CMS,"The business process it will affect involves the analysis of historical price history/trends for labor categories in business proposals for the Office of Acquisition and Grants Management (OAGM).

It will help OAGM make better decisions on future contracts by providing them with a comprehensive and standardized view of historical price data for labor categories.","It will assist in normalizing labor categories, enabling the OAGM team to easily identify the most relevant labor category despite the variations in naming conventions found in business proposals."
HHS-CMS-00038,CCSQ Now Assist for CSM ,HHS,CMS,"CCSQ Now Assist for CSM (Customer Service Management) is a product inside ServiceNow (SaaS).  It integrates Gen AI with CSM, and uses Now LLM (ServiceNow native Large Language Model) to generate contents based on machine learning (ML).  Now Assist for CSM helps agents to improve productivity and efficiency and deliver better services.  

Improve agents' responsiveness and productivity
* Quickly get familiar with a case/chat by getting case/chat summarization
* Quickly resolve the case by using auto-generated resolution notes.","Agents have quick access to 
- Case summarization
- Chat and agent hand-off summarization
- Resolution Notes Generation"
HHS-CMS-00039,AI Workspace,HHS,CMS,"The business process this affects involves the ability to easily run AI experiments in a safe and secure environment. 

It helps by reducing barriers to AI experimentation, supporting strategic AI infrastructure enablement, and providing hands-on experience for teams to learn and understand the potential risks and benefits of AI.","It utilizes data science tooling, large language models, and other approved AWS services such as Sage Maker and Bedrock to provide a secure and supportive environment for AI experimentation and prototype development."
HHS-CMS-00040,Citation Analysis and Survey Assistant (CASA - Nursing Home Survey CMS 2567),HHS,CMS,"2567 (CASA) enhances the efficiency and effectiveness of monitoring and reviewing nursing home surveys across the US. It enhances how the Quality, Safety, and Oversight Group (QSOG) and Survey Operations Group (SOG) assess how State Survey Agencies (SSAs) are citing nursing home deficiencies, reported on CMS Form 2567, by employing advanced natural language processing and machine learning technologies.

 The system would support the Nursing Home Survey CMS Form 2567 survey work allowing QSOG and SOG staff to follow up on cases of under and over citations at the facilities that are flagged by the system and sent to the State Agencies","It will allow for real-time interaction with survey data, facilitating a deeper understanding of trends and individual case specifics. By flagging discrepancies in citations and providing a robust platform for detailed analysis. CASA supports CMS’s mission to ensure high standards of care and accountability in nursing homes"
HHS-CMS-00042,Hazards & Threats Awareness Data Processing Automation,HHS,CMS,"EPRO is responsible for developing agency-wide situation reports from various open web and email materials. 

More effective prioritization and processing of materials for situational awareness, faster delivery of usable work product to decision-makers agency-wide. The manual process takes 2-3 hours per day, and the AI system will reduce the work to a human quality assurance/inspection step estimated to take approximately 30 minutes.","The AI will scrape known websites and monitor relevant resource mailboxes, use a categorization algorithm, and summarize and format the significant events each morning."
HHS-CMS-00043,Independent Dispute Resolution (IDR) Eligibility Rules Engine,HHS,CMS,"The current Independent Dispute Resolution (IDR) Technical Assistance (TA) process is very manual and time intensive which limits throughput.  The rules engine should significantly expedite processing and expand capacity. Automating more of the process may also increase consistency across recommendations and result in a more predictable timeframe for the workflow by better positioning disputes for analyst review.

The AI tool will help automate the eligibility review process, reducing time-intensive manual steps and increasing consistency of results.  ","Use of artificial intelligence (AI) models to identify the presence or absence of necessary data points within documentation.  AI tool searches documentation to identify and store necessary data points such as document title, file type, payment date, service code, claim number, and date of service. "
HHS-CMS-00044,Medicare Fee for Service Requirements Modernization (MFRM),HHS,CMS,"EIG is developing a business process to parse, curate, and simplify Medicare coverage and coding requirements by medical condition using AI LLMs. 

After rigorous testing for accuracy, AI output will be uploaded to the MFRM application to be used to enhance CMS and healthcare operational efficiencies, including organization of guidance documents, and identification of source complexities to be triaged with owners.
","Utilizing an LLM (Anthropic’s Claude 3.5) to curate current, accurate, and reliable Medicare requirements information sourced from FFS policy and guidance documents."
HHS-CMS-00046,Review Regulatory Comments,HHS,CMS,"The Division of Issuer Management and Operations is considering having our contractor, AIR, use an AI tool for comment analysis in the Letter to Issuers (LTI) and Notice of Benefits and Payment Parameters (NBPP). This would streamline review of stakeholder comments. 

This tool would reduce the amount of time and resources CCIIO and contracting staff would have to review the LTI and NBPP by 25%. ",The AI tool would identify trends in responses from stakeholders in policy and operational issues proposed by CMS.  
HHS-CMS-00047,Improved Data Quality Checks,HHS,CMS,"Improve consumer experience by providing an asynchronous solution to detect and provide near real time feedback via outreach to the consumer shortening the overall return cycle time without requiring UI changes. 

Improvement of user experience", develop a POC classifier model to identify incorrect document upload types / low-quality images through use of OCR.
HHS-CMS-00048,Plan Certification Recommendation Model,HHS,CMS,"Identify trends/patterns within plan certification justification templates, containing free-form text data through use of NLP and classification techniques. 

Improve efficiency of the plan certification review process", build a supervised machine learning model using historical justification data and associated plan certification outcomes that can be recommended to CMS to build towards a more efficient review process.
HHS-COTS-00001,AI-Assisted Data Entry,HHS,HHS,"The intended purpose is to leverage AI technology to intake paper forms and assist in the data entry process, which will increase efficiency and reducing human error.",The output is a digital data set converted from physical forms with the assistance of AI tool.
HHS-COTS-00002,Transcription in Zoom and Teams,HHS,HHS,"Meetings scheduled via Zoom or Teams can be transcribed live or from recorded meetings, which improves communication. ",The output is a transcribed text from a live meeting or recorded meetings.
HHS-COTS-00003,Email Prioritization in Outlook,HHS,HHS,"The Outlook in Office365 suite can categorize incoming emails based on users' definitions, which can help users manage their inbox more efficiently. The output is categorized emails.",The output is categorized emails.
HHS-COTS-00004,AI-assisted Pattern Detection,HHS,HHS,"AI technologies have been integrated into many existing log systems to identify unusual patterns, which can help detect system log issues and raise alerts for human intervention. ",The output is alerts and reports that highlight unusual patterns in system logs.
HHS-COTS-00005,Report Summarization by commercial GenAI platform,HHS,HHS,"Some GenAI platforms, such as ChatGPT and Google Gemini, can summarize documents with non-sensitive information. ",The output is a summary of provided paragraphs or documents.
HHS-COTS-00006,Information Search from Google,HHS,HHS,Google's search engine provides AI-assisted techniques to process search requests efficiently. ,The output is relevant search results.
HHS-COTS-00007,Document Digitization by AdobePro,HHS,HHS,Adobe Pro can convert scanned documents into digital data., The output is digital data with searchable functionality.
HHS-COTS-00008,Autocorrect in MS Word,HHS,HHS,"MS Word's autocorrect feature uses AI to suggest corrections, which improves the quality of written communications. ",The output is autocorrected words or sentences in written documents.
HHS-COTS-00009,AI-Assisted Real-time Collaboration,HHS,HHS,"The AI-assisted real-time collaboration tool can process the inputs from team members and provide real-times stats using NLP, which offers real-time feedback for collaboration. ",The output includes summarization and statistical data derived from the inputs of multiple users.
HHS-COTS-00010,Presentation Design by MS PowerPoint,HHS,HHS,MS PowerPoint can provide more appealing design suggestions based on the content. ,The output is multiple visual design suggestions for the user to select.
HHS-COTS-00011,Data modeling and visualization by MS Excel,HHS,HHS,"MS Excel contains many data analysis toolkits to provide AI-powered data analysis and visualization, which can improve understanding and presentation of data. ","The outputs from these features are machine learning models and statistical analyses of given data, along with their visual representations."
HHS-COTS-00012,News from commercial publisher such as Google News,HHS,HHS,"Major news publishers, such as Google News, send selective news based on users' preferences and recent visits. ",The outputs from these news providers are more customized news feeds.
HHS-COTS-00013,Travel Route Optimization by Google Maps and Apple Maps,HHS,HHS,"Major commercial map service providers, such as Google Maps or Apple Maps, can automate and optimize travel routes based on algorithms and live traffic data, which can save time and provide optimal routes. ",The output from these map services is an optimized travel route based on the user's preferences and live traffic data.
HHS-COTS-00014,AI-Powered Travel Booking,HHS,HHS,"Major travel booking websites, such as hotels.com, can provide booking options based on customers' preferences. Algorithms running in such services can optimize travel accommodations, which can save time and provide better deals. ",The output is a list of travel accommodations for customers to choose from and make booking decisions.
HHS-COTS-00015,Facial Recognition Unlock,HHS,HHS,The Face ID feature in iPhones takes advantage of AI technology to securely unlock the phone. ,This feature allows the phone to be unlocked using facial recognition technology.
HHS-DAB-00001,AI to Improve Public Access to the Administrative Appeals Process,HHS,DAB,"The DAB adjudicates  disputes under more than 60 statutory authorities.  The workload is divided between the DAB's four adjudicatory divisions (e.g., the Board, the Civil Remedies Division, the Medicare Operations Division and the Alternative Disputes Resolution Division. Helping appellants decide which entity within the DAB is responsible for adjudicating their appeal will increase efficiency in adjudication and customer experience. 

The DAB's appellant community (e.g., e-file users) will be provided immediate assistance and accurate information; deaf and hard-of-hearing populations and individuals with limited English proficiency are helped without the use of intermediaries, such as interpreters, translators, and relay services. After determining the appropriate division within the DAB responsible for adjudicating the appeal, the Chatbot can provide a link to the e-file website directly connecting the user to the correct e-file system.  Other benefits include: Improve public access to the appeals process by providing instant, accurate and complete filing information; Increase the DAB's productivity by refocusing the workforce to case resolution instead of responding the filing inquires and processing and appropriately routing misfiled appeals; and Improve resource allocation based on each Division's actual workload.  ","A chatbot on the DAB's website can direct filers to the correct Division and e-file system with which the appeal should be filed by using natural language processing (e.g., questions and responses) with the ability to further refine and increase accuracy based on user response. "
HHS-DAB-00002,AI Use Policy Tool,HHS,DAB,"The DAB is responsible for issuing fair, impartial, legally correct and defensible determinations which serve as the final decision of the DHHS Secretary.  The AI Use Policy is designed to promote public confidence in the integrity of DAB decisions.  

More effective quality review tool and faster identification of data trends that require additional analysis.  ","AI Use Policy Tool will scan DAB decisions to ensure compliance with quality review standards (e.g., protect PHI, PII and FTI) and identify work product that potentially violates the prohibition of the use of generative AI in DAB decisions.  "
HHS-DAB-00003,Resources to Assist the Advisory Board In Identifying AI Tools for Use In An Adjudication Environment,HHS,DAB,"The adjudication process from docket analysis, case processing, issuing a decision and quality review (after adjudication) relies on the analysis of large quantities of data. 

AI or machine learning tools will help the Advisory Board determine which technology will best serve the Agency's needs in an adjudication environment. ",The use of AI to analyze the voluminous data received from appellants and interested parties to identify trends and increase efficiency in the adjudication process.  
HHS-FDA-00001,356H ML Facility Supply Chain Role Classification,HHS,FDA,"Applicants submit unstructured text to indicate a facility’s supply chain role, which range from manufacturing, testing, storing, packaging, etc. This use case extracts the supply chain role based on the text and presents it to data stewards who perform data operations

Improve the efficiency of evaluating 356H forms to assess a facility's supply chain role, thereby decreasing the time required for the processing of submissions.",Extracts a facility's supply chain role from industry submissions and displays identified roles on a data-stewards screen for human verification and final determination.
HHS-FDA-00002,AI Tool for Risk-based FAR Review & Decision Support,HHS,FDA,"Assist Field Alert Report (FAR) reviewers by providing risk-based intelligence and insights for review and decision support with a Human-in-the-Loop.

Assist with streamlining an efficient FAR review process by summarizing risk profiles for human exploration that is evaluated with additional data to assist human decisioning.","AI-based machine learning classification of FAR risk into low, medium, and high; provides insights on problem clusters, rare-events, and source variables."
HHS-FDA-00003,Analytics-Driven Supplement Evaluation (ASE),HHS,FDA,"This AI use case supports the triage and staff assignment process for the review of post-market Change Being Effected (CBE) supplement submissions.

The output of the AI component contributes to the triage and staff assignment process, and summarizes submitted information to support the decision of the reviewers of the CBE 30/0 supplemental submissions.","Using a Convolutional Neural Network (NN) model, in combination with a rules-based approach, produces an output that helps staff triage CBE submission review"
HHS-FDA-00004,Augmenting death and cause of death ascertainment in observational data sources,HHS,FDA,"Augment assessment of mortality in electronic health records to support investigations to develop probabilistic estimates for causes of death in the Sentinel system.

The extraction of mortality information improves studies in Sentinel using mortality as an endpoint by enhancing on the quality of mortality data.","Augment assessment of mortality (date of death, cause of death) by applying Natural Language Processing (NLP) on healthcare narrative text and administrative codes."
HHS-FDA-00005,CLAT (Computerized Labeling Assessment Tool) ,HHS,FDA,"CLAT uses computer programming, image processing, and AI to assist the human review of drug labeling, including container labels, carton labeling, prescribing information, and Instructions for Use. CLAT assists the human visual comparison of drug labeling against a library of FDA regulations, guidances, standards, and best practices. CLAT identifies potential labeling deviations for human evaluation. 

CLAT is used to improve efficiencies in the manual labeling review process to help the reviewer mitigate medication errors and standardize labeling across therapeutic drug classes and product types. CLAT also assists the reviewer to catch deviations between label versions so no unintended errors have been introduced.","The tool processes images of carton and container labeling to identify minimum requirements on a label, identify availability of objects on an image, color differentiation of strength, missing barcode and orientation, incorrect or missing strength statement, error prone abbreviation, look-alike labels and text prominence. This will assist the reviewer by  improving the efficiency of drug labeling reviews, including container labels, carton labeling, prescribing information, and Instructions for Use. "
HHS-FDA-00006,Empirical evaluation of EHR-based signal detection approaches,HHS,FDA,"This supports Electronic Health Record (EHR) signal detection by extracting information using Natural Language Processing (NLP) and expanding the tree based scan statistic (TBSS) methods for EHR-based signal detection.


Extracts data to facilitate the identification of signals for outcomes, improving the manual identification of signals for outcomes derived from electronic health records.",The AI component in this study leverages an Natural Language Processing (NLP) approach to extract data from unstructured clinical notes.
HHS-FDA-00007,FAR-based Facility Signal Detection Tool ,HHS,FDA,"Identifies problem clusters for the flagged signals in an objective manner for triage/review. 

Assist with objectively identifying problem clusters for the flagged signals, which then go through a dedicated triage & review process for further actions, and if needed, CMS (inspection) work activities can be opened. ",Identifies problem clusters for the flagged signals in an objective manner for triage/review. 
HHS-FDA-00008,MedWatch Dashboard ,HHS,FDA,"Assist with consistent monitoring and identification of product risks from MedWatch reporting patterns and report content to support review staff.

Supports efficient, objective, risk-based product quality assessments from MedWatch reports for verification by review staff ",Identify product risk signals from MedWatch reports by using time series analysis to flag products and topic modeling to summarize the comments.
HHS-FDA-00009,Quality Surveillance Dashboard (QSD),HHS,FDA,"Extracts unstructured text from documents and pools that with other available data to form a dashboard that enables consistent assessment of CDER regulated manufacturing facilities

Assists in the efficient, objective, risk-based assessments of CDER regulated manufacturing facilities.",Identifies and extracts keywords/phrases from unstructured documents and presents sentences containing keywords/phrases in context.
HHS-FDA-00010,Scalable automated NLP-assisted chart abstraction and feature extraction tool,HHS,FDA,"Examine the usability of electronic medical records in conducting pharmacoepidemiology studies through a case study of montelukast use among patients with asthma and neuropsychiatric events

The project will involve an “end-to-end” implementation of a full pharmacoepidemiologic study using one or more product-outcome pairs to demonstrate how NLP and other advanced analytic methods or tools can be used to accurately identify study outcomes and covariates from unstructured Electronic Health Record (EHR) data.","Natural language processing (NLP), a computational linguistics technology, will be used to read, interpret and organize health data that may be contained within unstructured data fields within EHRs. This activity intends to build a semi-automated system that uses advanced methods and tools, including NLP, to enable large-scale outcome identification, confounder feature extraction, and longitudinal contextualization of Electronic Health Record (EHR) data."
HHS-FDA-00011,Annual Report CMC,HHS,FDA,"Objective of this use case was to extract CMC changes reported within unstructured annual report industry submission documents to build a complete repository for downstream analysis

The extracted data are presented in a dashboard (along with other data) for downstream human analysis.",Support information extraction from unstructured documents
HHS-FDA-00012,Application-DMF Reference,HHS,FDA,"Extracts references to DMFs from marketing application (ANDA/NDA/BLA) submissions. These submission documents may be structured (356H form) or unstructured (eCTD module 1-4). This pipeline parses content from these documents, extracts DMF references (e.g., ANDA123456 references DMF123456), and exposes the data in a structured format for analysis. 

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis. The purpose of this use case is to build a comprehensive inventory of all application to DMF references to support OPQ in reviewing applications since many application to DMF references were previously missing from structured sources.",Support information extraction from unstructured documents
HHS-FDA-00013,Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS) ,HHS,FDA,"The deduplication algorithm is applied to all historical and incoming case report submissions to the FDA Adverse Event Reporting System (FAERS) to identify duplicate individual case safety reports (ICSRs). Unstructured data that is in free text FAERS narratives is processed through a natural language processing system to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record linkage approach to identify duplicates. Application of the deduplication algorithm is optimized for processing entire FAERS database to support the data mining analytics process. 

Enhance the efficiency of removing duplicate FAERS reports to support data mining.",Uses Natural Language Processing (NLP) to extract out clinical features from free text narratives in a case safety report and uses them in the identification of duplicative case safety reports in the FAERS database.
HHS-FDA-00014,Development of automation tools and data warehouse to facilitate BE assessments,HHS,FDA,"Enhancing and streamlining the data entry associated with the review of bioequivalence data in Abbreviated New Drug Application (ANDA) submissions

Reduce manual effort by preparing data for analysis and exporting results as part of the bioequivalence review. This tool will facilitate data collection and Information retrieval from the firm-submitted ANDA packages but will not involve reviewers' evaluation or judgement.",Transform submitted PK data into a usable format so that the reviewer can perform the routine bioequivalence analysis using the authorized pre-written SAS codes. Then it exports results to a draft bioequivalence review  document with the firm-submitted eCTD tables.
HHS-FDA-00015,DMF (Drug Master File) Facilities,HHS,FDA,"Extracts facility references from Type II (Drug Substance) DMF manufacturing submissions (i.e., DMF123456 discloses that it uses Facility X for manufacturing and Facility Y for stability testing). These DMF submissions may include structured documents (3938 form) or unstructured documents (eCTD module 3). This pipeline parses content from these documents, extracts facility references and supply chain roles (i.e., FEI 6789 – manufacturing facility), and exposes the data in a structured format for analysis. This allows OPQ to identify discrepancies between facilities reported on marketing applications and those disclosed by DMFs referenced by those applications. 

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis. The ultimate purpose of this use case is to build a comprehensive inventory of facilities reported within DMF submissions as well as the applications that reference those DMFs.",Support information extraction from unstructured documents
HHS-FDA-00016,Four Part Harmony Identification,HHS,FDA,"Accuracy of language used to report back deficiencies to submitters.

This will reduce the amount of time it takes and reduce staff burden, thus allowing for MDUFA requirements to be met.",This will reduce the amount of time it takes to verify and identify issues with language used for deficiency letters and ensure the adherence to the language necessary.
HHS-FDA-00017,Information Visualization Platform (InfoViP) to Support Analysis of adverse event reports,HHS,FDA,"Information Visualization Platform (InfoVIP) supports post-market surveillance using AI to assist prioritization and analysis of adverse event reports by extracting data from unstructured case narratives and combining it with structured data to support analysis and review of adverse event reports. The tool assists with   case series analyses, creating data visualization, and classifying adverse event reports by information quality.

Improve the efficiency in preparing and analyzing data during the review and evaluation of adverse event reports.",Performs Natural Language Processing (NLP) and applying Machine Learning (ML) algorithm to extract data from unstructured case narratives and combine with structured data to support analysis and review of adverse event reports.
HHS-FDA-00018,LLM-Assisted VAERS Analyses,HHS,FDA,"Build capacity for and assess the application of a LLM to VAERS (Vaccine Adverse Events Reporting System) to provide reviewers adhoc VAERS queries and efficiently generate customized query outputs

Efficiently generate customized query outputs of VAERS queries for reviewers.",To provide reviewers adhoc VAERS queries.
HHS-FDA-00019,Pharmacovigilance machine learning to detect excess safety signal,HHS,FDA,"Post-market adverse event reporting

Using a computer algorithm assists FDA in finding ""needle in the haystack"" events that are difficult to uncover with manual review of reports",Generate potential safety signals to investigate further using statistical based algorithms
HHS-FDA-00020,Module 3 Faculties,HHS,FDA,"Objective of this use case was to identify and extract all drug manufacturing facilities reported within unstructured module 3 submissions from marketing applications to build an comprehensive inventory of drug facilities

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis.",Support information extraction from unstructured documents
HHS-FDA-00021,OPPQ Policy Bot (AKA Policy and Guidance Documents Search) ,HHS,FDA,"Helps policy staff in searching documents containing regulations and responding to inquiries, and other policy related work. 

In developing policy and responding to inquiries, OPPQ staff often need to reference  previously published policy documents in order to ensure consistency. This AI-enabled tool will allow policy leads and other staff to quickly identify and query the appropriate documents.","Identifies applicable published MAPPS, guidances, and policy related documents based on queries from users. Includes link to the document for further human review."
HHS-FDA-00022,Packaging Materials and Suppliers,HHS,FDA,"Objective of this use case aims is to extract data from unstructured sources to build an inventory of drug packaging materials and their suppliers to support staff on conducting drug supply chain analysis

The extracted data are presented in a dashboard for downstream analysis.",Support information extraction from unstructured documents
HHS-FDA-00023,Process Large Amount of Submitted Docket Comments,HHS,FDA,"To enhance the automatic process of dockets, we have created an AI/ML tool in CBER/HIVE that automatically download dockets and process them to accelerate the review of docket comments, significantly improving the efficiency and accuracy of our regulatory processes

Efficiently generate customized query outputs of VAERS queries for reviewers.",To provide reviewers adhoc VAERS queries.
HHS-FDA-00024,Real World Data/Evidence ,HHS,FDA,"Identify industry unstructured submissions containing Real World Data/Evidence (RWD/E) by analyzing parsed content for likely indicators of Real World Data/Evidence RWD/E to support congressional reporting.

The extracted data are presented in a dashboard for downstream human analysis.",Supports extracting text from unstructured documents and tagging for documents containing Real World Evidence and Real World Data
HHS-FDA-00025,Regulatory Starting Material ,HHS,FDA,"Extract RSMs and their suppliers from unstructured module 3 industry submissions to create an inventory that will illuminate the upstream supply chain.

The extracted data are presented in a dashboard for downstream analysis.",Support information extraction from unstructured documents
HHS-FDA-00026,Resource Capacity Planning,HHS,FDA,"Forecasting human drug review program submissions and corresponding FDA workload 

Improve the forecasting of human drug review program expected workload in order to adjust fee revenue and fees to fund resources needed to complete expected workload  ",Forecasts workload submissions across major user fee programs to support fee setting for the human drug review programs
HHS-FDA-00027,Supply Chain Resilience Program,HHS,FDA,"Forecasting demand of medical devices and supplies.

Forecast demand for critical devices during a variety of scenarios (e.g. natural disaster, PHE)  ",Aids in forecasting demand for critical devices under a variety of scenarios.    
HHS-HRSA-00001,AI Audit Resolution Assistant,HHS,HRSA,"The objective of this initiative is to reduce the time for HRSA auditors to review/resolve Single audits. HRSA has experienced an exponential increase in Single audits which is attributable in COVID funding attributable to the Provider Relief Fund programs. 

Success will be measured through the increase in the number of Single audits assigned to each auditor.  e.g., improved technological capabilities should allow HRSA Auditors to more efficiently review and closeout Single audits. ","HRSA will utilize generative AI to streamline the Single Audit resolution process and the creation of Management Decision Letters to formally close out and resolve Single audit findings.  The AI Audit Resolution Assistant (AIARA) includes a vector database comprised of Single audit documents assigned to HRSA, creates a retrieval augmented generation which integrates with a large language model to intelligently summarize audit findings and recommendations, and provides chatbot capability and reduce the cognitive load on HRSA auditors for any audit-specific questions. "
HHS-HRSA-00002,Knowledge Navigator,HHS,HRSA,"The objective is to develop an AI model that can answer detailed and complex questions about the key programmatic document, Application and Program Guidance (APG), that is issued annually before the application cycle opens. The PoC LLM has Applicant and Program Guidance (APG) documents for 10 loan repayments and scholarship programs.

This will allow loan repayment and scholarship analysts and call center agents to  better respond to public inquiries from applicants and participants.  If successful the Knowledge Navigator could be made available to applicants and participants and reduce the volume of calls to the BHW Call Center along with the number of call center agents.  ",BHW has implemented a proof of concept Generative AI (GenAI) Large Language Model (LLM) Knowledge Navigator (KN) to support National Health Service Corps (NHSC) and Nurse Corps loan repayment and scholarship program analysts and call center agents respond to program applicants and participants. 
HHS-HRSA-00004,Policy Assistant,HHS,HRSA,"HRSA is looking forward to leveraging Generative AI tools to support and enhance the current drafting of several policy documents, funding opportunities, and notices. This could streamline the policy development process, reduce drafting time, and improve document quality by providing critical analysis and suggestions for improvement, thus enhancing the overall policy-making workflow.

Reduce the amount of time required to develop first drafts of key BHW policy documents including APGs, NOFOs, budget documents","The Policy Assistant (PA) is an innovative application utilizing large language models (LLMs) to generate first drafts of key policy documents. Inputs can include example documents, style guides, and key policy decisions and other documents in the Knowledge Navigator. PA also features an editing tool that scrutinizes drafts for inconsistencies or errors, offering feedback for refinement. Current planning leverages Cloud-based services, LLM, Text processing and analysis tools, Natural Language Generation (NLG) and Text Analysis for the implementation."
HHS-HRSA-00006,Scholar Match,HHS,HRSA,"The current candidate evaluations and placement process is complex and challenging for both analysts and participants. By enhancing this process with AI/ML support could optimize resource allocation and candidate satisfaction, significantly impacting workforce distribution and efficiency in critical health areas.

This would improve the process of matching NHSC and Nurse Corps Scholars going into clinical service in underserved communities."," The Scholar Match (SM) leverages AI to enhance the placement process of NHSC and Nurse Corps scholars in communities of need across the U.S. and territories. By analyzing candidate profiles and regional needs, SM recommends optimal placements, ensuring both the fulfillment of organizational needs and the satisfaction of the candidates. Current planning leverages Machine Learning, Recommendation Systems, Cloud-based platforms and Data analytics services for the implementation."
HHS-HRSA-00007,Scholarship Insight,HHS,HRSA,"The NHSC and Nurse Corps Scholarship reviewers need to receive and score thousands of essays submitted and the manual process delays the application processes. We are looking forward to building a Generative AI program that looks at all of the previous essays and how the scoring rubric was done and train it to do the first cut at scoring the essays. This could enhance the fairness and efficiency of scholarship evaluations, ensuring a thorough review process that supports equitable student opportunities.

Reduce the amount of time required for internal or external reviews to evaluated NHSC and Nurse Corps scholarship applications and ensure that human reviewers are following the appropriate scoring rubric.","The Scholarship Insight (SI) is designed to support the evaluation of scholarship essays for both the NHSC and Nurse Corps Scholarship Programs by providing detailed analysis to human graders. Aligning with directives to ensure human oversight, SI identifies key themes, strengths, and weaknesses in essays, facilitating a more informed grading process without replacing human judgment. Current planning leverages Cloud-based services, Natural Language Understanding (NLU), Text Analysis, LLM API and Data analysis tools for the implementation."
HHS-HRSA-00008,Site Application Analysis,HHS,HRSA,"The current application review process requires internal analysis to review many complex documents to determine Site Eligibility to employ a member of the NHSC or Nurse Corps. By enhancing this process with AI/ML support could revolutionize and streamline the NHSC, Substance Use Disorder Treatment and Recovery (STAR)and Nurse Corps Site Application Process.

This would improve the current highly manual process for reviewing Site applications for internal analysts but ensure that clinical sites are being approved for NHSC, Nurse Corps, and STAR LRP.","The Site Application Analysis (SA) is designed to support the evaluation of NHSC, STAR and Nurse Corps Site Applications. SA will allow for faster more accurate review of Site Applications and allow BHW Regional Analysts to focus on a higher value task. Current planning leverages Cloud-based services, Machine Learning, Recommendation Systems, Natural Language Understanding (NLU) and Text Analysis for the implementation."
HHS-NIH-00001,A Cluster-Based Machine Learning Approach for Evaluating Factors Associated with Plasma Neurodegenerative Biomarkers,HHS,NIH,"This AI Use Case is Retired, No Longer in Use. This study investigated whether incorporating health-related risk factors can improve the predictive power of plasma biomarkers (related to neurodegeneration and inflammation) for incident dementia. 

Improve incident dementia prediction using plasma neurodegeneration biomarkers in a diverse population. ","Using ~450 common health-related risk factors and plasma neurodegeneration and inflammation biomarkers from the population-based cohort with the follow-up period over 20 years - the Age, Gene/Environment Susceptibility – Reykjavik Study.   "
HHS-NIH-00002,AccessGUDID Data Validation,HHS,NIH,"The artificial intelligence (AI) system for AccessGUDID will focus on enhancing data quality assurance by detecting anomalies in medical device metrics, such as inconsistent units of measurement or unusual device dimensions. It will analyze both structured data, like numerical measurements, and unstructured data, such as free text entries. The AI will not modify data directly but will flag potential issues for human review. Integrated into the U.S. Food and Drug Administration (FDA)'s processing workflow, it will leverage standard codes for precise grouping and employ advanced language models to process unstructured data. Deployed within the regulatory compliance and data management areas of NLM, this AI system aims to streamline data validation processes, reduce manual workload, and maintain the integrity of the AccessGUDID database, without overstepping into areas requiring human oversight.

The key problem the AI aims to address is the presence of inconsistent or incorrect data entries, such as mismatched units of measurement or outlier device dimensions, which can lead to regulatory compliance issues and potential risks in device usage. By automating the anomaly detection process, the AI will improve the efficiency of data validation, significantly reducing the manual effort required to identify and correct errors. This will not only enhance the accuracy of the data but also speed up the processing and integration of new submissions into the AccessGUDID database. Improved data integrity will lead to better decision-making for manufacturers, healthcare providers, and regulators, ensuring that medical devices on the market meet safety and performance standards. Ultimately, the positive outcomes of this AI application include increased trust in the medical device information provided to end users, which contributes to the broader goal of improving public health and ensuring patient safety across the nation.","For inputs, it handles structured data, such as numerical metrics (e.g., device dimensions, units of measurement), and unstructured data, such as free-hand text entries describing medical devices. This data is sourced from the AccessGUDID database, which aggregates information submitted by manufacturers to the FDA. The frequency of data processing aligns with the batch submissions from the FDA, typically occurring daily or whenever new data is received. The system processes large volumes of data to detect anomalies, making it scalable to accommodate growing datasets. For outputs, the AI generates predictions and classifications, specifically identifying potential anomalies in the data, such as incorrect units of measurement or outlier device specifications. The results are presented as flags or labels indicating the presence of an anomaly, which are then reviewed by human analysts. The AI produces these results in real-time as part of the batch processing workflow, ensuring that each data submission is evaluated promptly before being fully integrated into the AccessGUDID database. The output helps in streamlining the data validation process and improving overall data quality."
HHS-NIH-00003,AI Solution for Image Duplication Detection,HHS,NIH,"NIA researchers generate a significant number of microscopic images for each publication, ranging from 100 to 200 TIFF files per study. Ensuring that these images are not duplicated or overlapped in any publications is crucial for maintaining research quality and credibility. The current manual verification process is time-consuming, prone to human error, and insufficient for handling large volumes of data. 

NIA researchers generate a significant number of microscopic images for each publication, ranging from 100 to 200 TIFF files per study. Ensuring that these images are not duplicated or overlapped in any publications is crucial for maintaining research quality and credibility.",Identification of image duplications.
HHS-NIH-00004,AI Solution for Research Funding Gap Analysis (RF-GAP),HHS,NIH,"NIA is focusing on identifying and addressing funding and publication gaps in NIH-funded research. Using text-mining and artificial intelligence techniques on data from both NIH and external sources, NIA aims to uncover research areas that need more funding or lack sufficient publication coverage. This approach will help NIA leadership make informed decisions, refine funding strategies, and enhance the overall impact of NIH-funded research. Program officers will utilize a user-friendly dashboard for actionable insights, simplifying the tracking of research outputs and identification of gaps.  1. Improved allocation of NIH funding through targeted identification of underfunded research areas and initiatives to address publication gaps. 2. Enhanced integration of data sources will provide a comprehensive view of research trends. AI-driven analysis will offer actionable insights into emerging research areas and future funding needs.  3. Customized dashboards will empower program officers with efficient tools to monitor and manage research portfolios, fostering transparency and maximizing operational efficiency across NIA. 

This approach will help NIA leadership make informed decisions, refine funding strategies, and enhance the overall impact of NIH-funded research.",Publication and Gap analysis reports.  
HHS-NIH-00005,AI/ML for Study Section Prediction in NICHD,HHS,NIH,"The project of AI/ML for Study Section Prediction is to classify the grant applications to specific Study Sections in the Scientific Review Branch in NICHD.  It employs human-in-the-loop development which enables human evaluation and offers the ability to override and alter model outputs.  Source data are from the NIH IMPAC II system via the eRA Review Module. The AI process and output data have no impact on the NIH IMPAC II system. The business area addressed is the alignment of appropriate Study Section for a given grant application to assist the Scientific Review Branch (SRB) at NICHD.

This project adapts the methods and systems developed for the RPAB AI/ML Referral System project to optimize the assignment of grant applications to the most suitable study sections. The AI system will contribute to NIH's mission by improving the efficiency and accuracy of alignment of grant applications to study sections, ensuring that applications are reviewed by the most appropriate researchers, leading to scientific discoveries and health advancement.",Internal: NIH ImpacII and eRA Review Module queries. Results are presented as study section (class) predictions and class probabilities.
HHS-NIH-00006,AI-enabled landscape analysis of New Approach Methodologies (NAMs) in biomedical research literature,HHS,NIH,"Part of NIH Common Fund strategic planning efforts for new program. Complement Animal Research in Experimentation (Complement-ARIE) aims to identify opportunities and use trends for NAMs in biomedical research. Methods development in using genAI for literature searching and extraction applicable to other use cases.

GenAI was used to survey the biomedical research literature to inform potential investment of resources and opportunities for the NIH Common Fund program. Methods are also applicable to other systematic literature review approaches.","Identify trends in use of New Approach Methodologies, gaps, and opportunities for investment by NIH."
HHS-NIH-00007,Applying for Grants Chat Bot,HHS,NIH,"A chatbot can significantly aid prospective grantees by providing instant, detailed information on specific grants, including eligibility criteria, application deadlines, and required documentation. It can guide users through the application process step-by-step, recommend additional resources for grant writing, and help determine eligibility to save time. Additionally, chatbots can assist in tracking application status, address common FAQs, and gather data on user needs. A chatbot streamlines the grant application process, reduces frustration, and enhances the overall experience for those seeking funding. 

It can guide users through the application process step-by-step, recommend additional resources for grant writing, and help determine eligibility to save time.",Targets resources related to probing questions for end users.
HHS-NIH-00008,Assessment of DTT/NTP research effectiveness,HHS,NIH,"Dextr/LaserAI does not use PII, PHI or demographic data. Dextr is FEDRAMP certified and ATO in the cloud. Data sources for Dextr are published PDFs accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).

Modification and customization of the DEXTR automated extraction tool has been implemented to identify and capture Division of Translational Toxicology (DTT) and National Toxicology Program (NTP) research citations in the published literature, regulations, and popular press. The DEXTR automated workflow with user-verification supports the identification of these citations that will be used to assess impact and effectiveness of DTT and NTP research. Division Directors and Branch Chiefs require an evidence-based approach to assess the effectiveness of current and past research. Such an approach would be highly valuable for research prioritization. ",Identifies how DTT/NTP research was used or impacted the publication.
HHS-NIH-00009,Assisted Referral Tool,HHS,NIH,"Review activities of the Center for Scientific Review (CSR) are organized into Review Branches (RBs). Each RB represents a cluster of study sections around a general scientific area. Grant applications generally are assigned first to an RB, and then to a specific study section within that RB for evaluation of scientific merit.

To provide assistance in assigning appropriate scientific areas for grant applications.","The Assisted Referral Tool (ART) recommends potentially appropriate study sections, based on the scientific content of a user’s grant application.  The user enters the application text and hits the Submit button to get a list of relevant study sections (scientific areas) in two groups, as “Strong” and “Possible” matches. The information provided to ART is only used to recommend study sections and is not stored or persisted.   The recommendations made by ART are solely for the benefit of the user. "
HHS-NIH-00010,Autism Spectrum Disorder (ASD) Classification Model for Children using Deep Neural Network,HHS,NIH,"This AI Use Case is Retired, No Longer in Use. The AI was used for evaluating whether a child around the age of 10 is exhibiting Autism Spectrum Disorder (ASD), and its severity. 

This AI Use Case is Retired, No Longer in Use. The primary objective of the AI use case was to enhance the accuracy and efficiency of diagnosing Autism Spectrum Disorder (ASD) by automatically categorizing ASD using deep learning models trained on Inertial Measurement Unit (IMU) hand tracking data. The AI aimed to address the complexity and variability in ASD diagnosis, which currently relies on subjective behavioral assessments. ","The input data consists of four 3-dimensional vectors obtained from an IMU attached to the participant's hand while they perform cognitive and motor tasks. The classification result from the deep learning model outputs a value of 0 or 1, indicating ASD or typical development, respectively."
HHS-NIH-00011,Automated annotation of study data using knowledge organization systems,HHS,NIH,"Application to support automation of systematic review processes and annotation of extracted information from studies in the published literature.

Automating the annotation of extracted information from environmental health studies will support joining with other structured datasets to serve as training data for predictive model development, validation of new approaches, and more robust analyses on weight of evidence of chemical effects on biological systems.",Annotation of information using knowledge organization systems.
HHS-NIH-00012,Automated approaches for table extraction,HHS,NIH,"The Division of Translational Toxicology (DTT) is an intramural division at NIEHS. DTT's mission is to improve public health through data and knowledge development that are translatable, predictive, and timely. DTT scientists use a variety of traditional and cutting-edge approaches to better understand how factors in our environment may impact health. 

Automated approaches for identifying and extracting data from tables will save time and reduce level of effort for teams evaluating published studies (epidemiology reviews or meta-analyses, hazard assessments, etc.) and ultimately impacts development of health effect conclusions.","This project developed an automated, model-based processes to reduce the time and level of effort for manual  extraction of data from tables. Published data tables are a particularly data-rich and challenging presentation of critical information in published research."
HHS-NIH-00013,Automated Basic-Applied Categorization of extramural grants,HHS,NIH,"This machine-learning algorithm is in development. Currently it uses information on NIMH-funded extramural research projects to categorize them as basic or applied research per the federal definitions for each. The data it is trained on is supplied from extramural grant applications and the same fields will be used for subsequent classification of new grants. For new grants, the algorithm will propose a categorization which can be reviewed, confirmed, or edited by an NIMH staff member. The resulting information will be used for internal, analytical purposes and annual reporting of NIMH-funded basic and applied research. The AI will NOT influence funding decisions, require or use PII, or use any other sensitive, personal, or health information.

The algorithm is intended to be consistent in identifying basic and applied research, reduce burden of review by NIMH staff, and provide a complementary perspective to human review.","The algorithm produces categorization of basic and applied research that is used for internal analysis and annual reporting. The algorithm is trained on the following data from extramural grants from fiscal years (FY) 2000-2022 and will use the same for grants in FY2025 and going forward to propose a categorization of basic or applied research: Program Class Code, NIMH Division, NIH Research, Condition, and Disease Categorization (RCDC), Human Subjects Codes, Animal Subjects Code, Clinical Trial NIMH Division, text of grant title, abstracts, specific aims. These data categories are all obtained from NIH IMPACII and will be applied to 100% of NIMH extramural grants, excluding L activity codes. This constitutes approximately 1,500 new grants per FY. Algorithm performance will be assessed each year, comparing the proposed classifications to a manually reviewed sample, and input received from NIMH staff regarding edits to proposed classifications. The frequency of processing is yet to be determined. No anonymization or de-identification processes are employed as personal information is used neither to train, nor classify grants using this algorithm."
HHS-NIH-00014,Automated extraction of study methods and assessment of reliability,HHS,NIH,"Application to support automation of systematic review processes and quality assessment of studies in the published literature (environmental health studies).

This project is focused on automating the identification of studies with reliable/well established methods (e.g., corresponding to regulatory guidelines) from the literature. Supervised and unsupervised methods are being applied to a) extract the methods details from known studies, and b) identify studies whose methods fulfill reliability criteria.   Identification and critical assessment of existing research is required for developing evidence-based conclusions, directing future research, and informing policy decisions by scientists, Branch Chiefs and Division Directors. Study reliability or quality are important considerations in the assessment of published research studies and are very time and labor intensive using manual approaches. ",Input: published environmental health studies; Output: identification of study methods and categorization of reliability/methods quality.
HHS-NIH-00015,Automation of Receipt & Referral Process of NIDDK grant applications,HHS,NIH,"This use case is centrally reported under OER's Internal Referral Module. NIDDK receives about 100 to 500 applications per week. NIDDK referral staff uses the IMPAC II QVR tool to stratify the applications between divisions based on a “Like Matrix” function to match the Division’s portfolios and the Title, Abstract, and specific aims of grant applications. This process is laborious and manual. Hence, automation was proposed. The scope of the effort is to provide a capability for NIDDK to analyze grant applications using NIDDK-specific business rules, complete the pilot, and the full implementation of the Artificial Intelligence (AI) and Natural Language Processing (NLP) tools for auto assignment of program class codes.

NIDDK receives about 100 to 500 applications per week. The AI and machine learning tool will stratify the applications between programmatic divisions and Program Class Code (PCC) to match the Division’s portfolios based on the Title, Abstract, and specific aims of grant applications. It collectively saves NIDDK Program and Referral Staff 3000+ hours annually on Receipt and Referral activities. In addition, it instantly recommends PCC, allows Division designees to accept or change recommendations, tracks all grants that need PCC assignment, gives real-time information about the application status, and support business rules/generates reports.","Input: Title, Abstract, Public Health Narrative, Specific Aims of grant applications from the FY 2018 to 2022.

Output: Division and Program Class Code (PCC) of grants from FY 23/24."
HHS-NIH-00016,Best Match: New relevance search for PubMed,HHS,NIH,"NLM is the world’s largest biomedical library. Best Match is a relevance search algorithm for NLM’s PubMed – a free search engine for biomedical literature accessed by millions of users around the world every day. 

Best Match increases the effectiveness of PubMed searches across the rapidly growing collection of biomedical literature to help users efficiently find the most relevant and high-quality information they need. PubMed comprises more than 37 million citations for biomedical literature from MEDLINE, life science journals, and online books.","This AI technique leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date-sort order that appears in many traditional search engines. Trained with past user searches with dozens of relevance-ranking factors, the Best Match algorithm demonstrates state-of-the-art retrieval performance and an improved user experience. "
HHS-NIH-00017,Biomedical Citation Selector (BmCS),HHS,NIH,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. 

Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.",The output is sets of citation records that are classified as relevant to biomedicine and the life sciences. Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. 
HHS-NIH-00018,Chatbot for researchers to find data sets for environmental health research efforts,HHS,NIH,"This project is focused on the use of large language models and chatbot technology to provide a way for researchers to find data sets of relevance for environmental health research efforts.

The primary objective is providing a tool that aids researchers in finding useful resources, specifically data sets, thus benefitting research efforts in finding the best data to use quickly.","The AI will use description of data sets that come from both NIH and federal data catalogs.  This will be periodically updated.  As output, the AI will provide rank order listings of recommended data sets."
HHS-NIH-00019,Clinical Trial Predictor,HHS,NIH,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

The AI tool predicts whether grant applications may involve clinical trials based on the text of their titles, abstracts, narratives, specific aims, and research strategies. ","The Clinical Trial Predictor uses an ensemble of several NLP and ML algorithms to predict whether applications may involve clinical trials based on the text of their titles, abstracts, narratives, specific aims, and research strategies. The responses are only used to make extramural officers aware of the fact that an application submitted to a NOFO that doesn't allow clinical trials may contain a clinical trial.  The extramural officers then evaluate the identified applications for the presence of a clinical trial.  No decisions are made by the AI, nor is the AI output used as the principle basis of a decision; it is just used to help the extramural officers identify applications containing clinical trials more quickly."
HHS-NIH-00020,ClinicalTrials.gov Protocol Registration and Results System Review Assistant,HHS,NIH,"ClinicalTrials.gov is a website and online database of clinical research studies and information about their results. The purpose of ClinicalTrials.gov is to provide information about clinical research studies to the public, researchers, and health care professionals. 

This project aims to help ClinicalTrials.gov determine whether the addition of AI could make reviewing study records more efficient and effective.",The classifier takes as input free-text related to a study’s endpoint and returns a prediction of whether one or more issues is present. 
HHS-NIH-00021,Collections Summarization Chatbot,HHS,NIH,"The artificial intelligence (AI) use case involves developing a chatbot that can answer contextual questions about collection objects that users are browsing within the NLM Digital Collections. The chatbot will not handle inquiries unrelated to collection objects or queries outside its defined scope. It utilizes the Retrieval-Augmented Generation (RAG) framework on Amazon Web Services (AWS) to generate summaries or detailed answers based on the content users are viewing. The chatbot interface will integrate with existing NLM web technologies, activating when a user spends an extended time on a resource page. The AI system will use text data from the collection objects and associated metadata to generate responses. The primary business area for deployment will be within NLM’s digital services, focusing on enhancing user interaction and accessibility. 

The main goal is to provide users with concise summaries and detailed answers about NLM Digital Collections.","The input consists of text from documents or books within the Collection objects that users are viewing. The frequency of AI processing depends on how long users spend on the resource page. If users linger, the AI chatbot will prompt them with a summary of the resource they are viewing. The AI-generated output will be a summary of the resource presented in text format. "
HHS-NIH-00022,Computed Author: author name disambiguation for PubMed,HHS,NIH,"NLM is the world’s largest biomedical library. PubMed comprises more than 37 million citations for biomedical literature from MEDLINE, life science journals, and online books.

 NLM developed a machine-learning method to score the features for disambiguating a pair of papers with ambiguous names. Subsequently, agglomerative clustering is employed to collect all papers belonging to the same authors from those classified pairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering results, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate author name searches.","PubMed users frequently use author names in queries for retrieving scientific literature. However, author name ambiguity (different authors share the same name) may lead to irrelevant retrieval results."
HHS-NIH-00023,COVID-19 Pandemic Vulnerability Index Dashboard,HHS,NIH,"The dashboard creates risk profiles, called PVI scorecards, for every county in the United States, continuously updated with the latest data that summarize and visualize overall disease risk. 

Aims to reduce the impact of COVID-19 on vulnerable populations by aiding equitable decision-making on resource allocation and implementation of local- and state-level interventions. Available at https://covid19pvi.niehs.nih.gov/. ","Inputs are location-specific current infection rates, baseline population concentration, current interventions, and health and environmental vulnerabilities. Outputs are data visualizations and vulnerability estimates."
HHS-NIH-00024,CSR Public Chatbot (CPC),HHS,NIH,"This tool is a chatbot that answers questions from potential applicants and reviewers. Instead of providing lists of links to look through, the chatbot provides answers with links where the answers were drawn from. Source materials are limited to official government web pages, and a disclaimer is included cautioning the user to check the source materials to confirm the accuracy of the answers.

This chatbot is intended to provide answers to the public about questions related to NIH peer review policies and procedures. ","Input: Applicant/Reviewer Questions. 
Output: Answers to the questions "
HHS-NIH-00025,DAIT AIDS-Related Research Solution,HHS,NIH,"NIAID administers HIV/AIDS grant portfolios.

The incoming grant applications are ranked based on these predictions and more highly-ranked applications are prioritized for review.","The tool uses natural language processing text extraction and classification algorithms to predict both priority (High, Medium, Low) and category (Area of research) for a grant application. After DAIT awards grants, they review all awarded grants to determine if any of the awardees are conducting research that could be considered AIDS-Related. NIH’s Office of AIDS Research (OAR) will fund all or part of the grants if the research is considered AIDS-Related. The DAIT AIDS-Related Research solution (DAIT ARR), categorizes the awarded grants into research topics. This categorization is based on the title and abstract of the grant application."
HHS-NIH-00026,Detecting Overlapping Science (DOS),HHS,NIH,"This tool detects applications that represent potential duplicate funding (funding the same research in different projects). It examines applications as they are submitted to the NIH and sends a report to relevant personnel in the agency.

Detect and prevent duplicate funding with real-time examination of incoming grant applications.","Input: Text of grant applications.
Output: Pairs of possible duplication."
HHS-NIH-00027,Detection of Implementation Science focus within incoming grant applications,HHS,NIH,"Grants management oversight and administration.

Assign the grant application to a particular division for routine grants management oversight and administration.","This tool uses natural language processing and machine learning to calculate an Implementation Science score that is used to predict if a newly submitted grant application proposes to use science that can be categorized as ""Implementation Science."""
HHS-NIH-00028,DEXTR - automated data extraction tool,HHS,NIH,"Dextr/LaserAI does not use PII, PHI or demographic data. Dextr is FEDRAMP certified and ATO in the cloud. Data sources for Dextr are published PDFs accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).

The primary objective of the DEXTR/Laser AI use case is to streamline the process of data extraction from published studies for literature reviews, addressing the key problem of time and labor intensity involved in manual data identification and capture. DEXTR leverages natural language processing (NLP) models, regular expressions and large language models to automatically identify and predict pertinent entities of data extraction within scientific studies. By doing so, it reduces the burden of manual extraction while still supporting user verification, offering a semi-automated approach that ensures accuracy and quality control. One of the key tasks DEXTR enhances is the annotation of studies during the normal workflow, allowing the tool to generate annotated corpora for the development of future models. Dextr also provides automated extraction of information from tables in PDFs expanding the supported data extraction capabilities.  As a dynamic platform for multiple AI projects, DEXTR/LaserAI is continually being optimized and expanded to support a growing number of use cases. This automation not only accelerates data extraction but also aids in creating a robust, scalable system for handling the ever-increasing volume of published research. The anticipated positive outcomes include improved efficiency and accuracy in data extraction, which is critical for developing evidence-based conclusions, guiding future research directions, and informing policy decisions. By enabling faster and more comprehensive reviews of existing literature the tool has the potential to significantly enhance the ability to process large volumes of scientific data.","DEXTR leverages natural language processing (NLP) models, regular expressions and large language models to automatically identify and predict pertinent entities of data extraction within scientific studies."
HHS-NIH-00029,Division of International Services Customer Service Chatbot,HHS,NIH,"The initial version is designed to allow both foreign nationals and administrative officers (AOs) to interactively receive accurate answers to general questions about immigration policy and operations managed by NIH Division of International Services.

The AI data store is compiled from DIS Frequently Asked questions and other relevant policy and general information. The benefit of the AI is to alleviate manual calls to the division for questions that can be covered more efficiently and accurately.","Generates text, images and data. Input data source is a local database. Frequency is TBD."
HHS-NIH-00030,Enhance NLM Website Accessibility,HHS,NIH,"NLM is pilot testing the use of artificial intelligence (AI) to enhance the accessibility of the NLM website in alignment with Section 508 standards.  This initiative is critical to mitigate the enterprise risk associated with non-compliance with Section 508 standards covering web sites. The AI will focus solely on identifying and resolving accessibility errors associated with Section 508 standards for websites, including suggestions from the U.S. Web Design System framework when possible. The AI is currently being developed behind NIH's firewall for a select internal user base. The tool will not make direct changes to general web design or web content. The AI will integrate with existing web content management systems and accessibility compliance tools (like pa11y).  The AI will use website data (HTML, CSS, JavaScript) and accessibility compliance standards as input and will be deployed in the web development and IT departments, particularly those focused on accessibility and compliance.

The project may reduce costs and time associated with manual accessibility evaluation and remediation. Additionally, it is expected to enhance the accuracy and quality of accessibility features on the website. Importantly, the project aims to improve the user experience by making the site more accessible to a broader audience, thus increasing user access and discovery. Ultimately, this initiative will help reduce the enterprise risk associated with non-compliance and ensure that NLM's website meets the evolving standards for government web accessibility.","Inputs: Website data (HTML, CSS, JavaScript), accessibility standards.

Outputs: Accessibility issue reports, suggested code fixes, task lists for implementation.

Frequency: The AI performs both site-wide scans and single URL audits on demand. "
HHS-NIH-00031,Enhancing Responses to Customer Questions about NLM Products,HHS,NIH,"NLM is piloting the creation of an application which uses the GPT family of models from OpenAI (via Azure) and data retrieved from public facing NIH/NLM web domains to answer questions about select NLM products. This is currently being developed behind NIH's firewall for a select internal user base. The artificial intelligence (AI) will generate responses to questions but will not engage in direct conversations with customers. Additional safeguards would make sense in a production environment. The AI will integrate with a knowledge base and use text data from user technical questions and knowledge base articles. It will be deployed within customer service and technical support offices.

Primary Objectives: Provide accurate and timely responses to technical questions about NLM products. 

Anticipated Positive Outcomes: Improved efficiency and accuracy in customer service, better user experience, and higher satisfaction rates.","Inputs: User technical questions, knowledge base articles.

Outputs: AI-generated responses, gold standard responses, knowledge base links.

Frequency: Responses generated in real-time based on user inquiries."
HHS-NIH-00032,Environmental health research annotation for model development,HHS,NIH,"By creating annotated datasets that account for diverse study types, the project will enable the development of AI and machine-learning models that can significantly reduce the time and effort required to identify and capture critical data from environmental health studies. This improvement will streamline tasks for teams conducting literature assessments and reviews, improving their efficiency.

The primary objective of this AI use case is to enhance the development of datasets specifically focused on toxicology and environmental health. The key problem it aims to address is the current scarcity of relevant training datasets or corpora, which limits the ability to create effective AI models for identifying and extracting environmental health data from published studies. This challenge is compounded by the diverse nature of environmental health research, which includes various study designs such as epidemiological studies, in vitro research, exposure assessments, and experimental animal studies.  ","Input: published environmental health studies.

Output: annotated corpus to support model development (e.g., BRAT format)."
HHS-NIH-00033,Expansion of Generative AI (GenAI) Caption Generation for all Collections Videos,HHS,NIH,"The artificial intelligence (AI) use case builds on an existing Generative AI (GenAI) workflow in NLM Digital Collections that generates transcripts and captions for all videos stored in the Digital Repository dark archive. The expansion of this workflow will apply to all videos and films targeted for Digital Collections. The AI will not be used for content outside of these collections or for non-video materials, as well as already captioned videos. It will integrate with existing video processing systems to automate the captioning process. The types of data utilized will include video files and associated metadata. The deployment will occur within NLM’s Digital Collections management area, with the primary goals being cost savings by reducing reliance on third-party vendors and standardizing video caption workflows across all collections.

The objective is to expand AI-driven captioning across all videos in the NLM Digital Collections, ensuring standardized and accuracy. ",The inputs consist of video or audio mp4 or mp3 format comes from Collections videos that don't have captions. The AI generated captions will be in text format.
HHS-NIH-00034,Federal IT Acquisition Reform Act (FITARA) Tool,HHS,NIH,"NIAID administers contracts to execute mission initiatives.

The tool's classifications inform SOW clarifications/revisions relevant to the FITARA.",The tool classifies contract statement of work (SOW) documents as being IT-related or not. 
HHS-NIH-00035,Generative AI (GenAI) Still Image Tagging,HHS,NIH,"The artificial intelligence (AI) use case will focus on identifying still images within the NLM Digital Collections that lack descriptions. This use case will employ Generative AI (GenAI) tools such as Amazon Web Services (AWS) Recognition and/or AWS Bedrock to identify concepts and embedded text within these images. The AI system will not generate metadata for images that already have detailed descriptions or analyze images outside the NLM Digital Collections. The AI will connect with existing NLM metadata management systems, where the generated metadata will be stored and indexed. The primary types of data used will include image files from the digital collections and textual data derived from embedded text within those images. The AI system will be deployed within the NLM's business area, focusing specifically on enhancing the search and retrieval capabilities of the NLM Digital Collections.

The use case aims to automatically generate accurate metadata for under-described images in the NLM Digital Collections, enhancing their searchability and discoverability. This improvement will increase access to valuable medical and scientific resources, supporting research and public health initiatives. ","Input consists of image binaries (tif, jpeg or PDF format) served from Collections website can be hosted on S3; Amount consists of untagged images within the repository, ballparked about 75,000 image objects, then about 10-100 per month based on monthly content ingestions. 

Output should be AI generated classifications tags and/or AI generated image summary in text form. "
HHS-NIH-00036,Grant Application Subject-Matter Classification Tool,HHS,NIH,"The algorithm is used to recommend a specific scientific area within the Division's portfolio with a specific confidence level. This reduces the time it takes to assign a Program Class Code and personnel assignment to every grant application received by NIEHS. It searches for key words within the title, abstract and specific aims in each grant application to determine the best scientific category. It is not used in combination with any other data sets. It uses grant application data from IMPAC II, which is imported into the Grants Funding Decision Tool (a NIEHS Custom Product).

Natural language processing of grant applications to assign scientific topics and corresponding Program Officer staff.  The subject-matter classification tool improves the efficiency of the grant administration process by automatically assigning incoming applications a subject matter classification based on the text content of their abstracts using a model derived from past human-classified examples. This classification helps route each application to the program officer with the greatest expertise in the inferred field of study.",Training set consists of an Excel spreadsheet containing human-classified grant proposal abstracts. Input file is an Excel table containing new unclassified grant proposal abstracts. Output is input file updated to include tool-assigned subject matter classifications.
HHS-NIH-00037,HIV-related grant classifier tool,HHS,NIH,"A front-end application for scientific staff to input grant information, which then runs an automated algorithm to classify HIV-related grants. 

The tool allows OAR staff to determine the best categorization for a grant application after reviewing data and visualization of confidence levels through a heat map. Natural language processing of grant applications to assign scientific topics and corresponding Program Officer staff.  The subject-matter classification tool improves the efficiency of the grant administration process by automatically assigning incoming applications a subject matter classification based on the text content of their abstracts using a model derived from past human-classified examples. This classification helps route each application to the program officer with the greatest expertise in the inferred field of study.","Input: Grant text data.

Output: Predicted categorization."
HHS-NIH-00038,Improving Customer Response,HHS,NIH,"NLM is pilot testing the utilization of artificial intelligence (AI) to assist Customer Service Representatives (CSRs) in drafting responses to customer inquiries. It is currently being developed behind NIH's firewall for a select internal user base. The AI is focused on generating draft responses for customer service but will not make final decisions or engage in direct communication with customers. CSRs are instructed to not enter personally identified info into the AI system. In the event this info is entered, the AI system is automatically prompted to not include any personally identified information in its generated response. Additional safeguards would make sense in a production environment or if it was released to the public. The AI will integrate with customer service platforms and databases like Medline Plus and DailyMed. The AI will use text data from customer inquiries and publicly accessible NLM-managed biomedical information services and be deployed within the customer service department. 

The project aims to enhance customer response metrics, increase customer satisfaction, and improve the efficiency of handling customer service inquiries.","Inputs: Customer inquiries, publicly accessible, NLM-managed biomedical information services (such as Medline Plus, DailyMed, etc.).

Outputs: Draft responses, resource links, disclaimers.

Frequency: Responses generated in real-time as inquiries are received."
HHS-NIH-00039,Improving Metadata Retrieval and Transformation for Metadata Management,HHS,NIH,"The Dataset Catalog (catalog) is a catalog of biomedical datasets from various repositories for users to search, discover, retrieve, and connect with datasets to accelerate scientific research. Metadata from included repositories and their datasets are needed to appropriately index them in the catalog. This manual process can be labor intense, and thus NLM is pilot testing the development of a working interface for internal users to retrieve the metadata information from external repositories' websites and then transform the data to a specific format used in internal metadata management for the Dataset Catalog. This is currently being developed behind NIH's firewall for a select internal user base. The artificial intelligence (AI) will automate the retrieval and transformation of metadata but will not replace human oversight in critical metadata curation tasks. Additional safeguards would make sense in a production environment. The AI uses information from publicly available biomedical data repository websites and internal metadata management systems. The AI uses metadata from biomedical repositories and will be deployed within data management and IT departments, particularly those involved in cataloging and metadata management.

Primary Objectives: Streamline metadata retrieval and transformation to improve efficiency and accuracy. 

Anticipated Positive Outcomes: Resource savings, enhanced data quality, and improved management of the Data Set Catalog.","Inputs: Metadata from various biomedical repositories, internal schemas.

Outputs: Transformed metadata, Python scripts, user-friendly tools for metadata retrieval.

Frequency: Continuous retrieval and transformation as new metadata is ingested."
HHS-NIH-00041,Internal Referral Module ,HHS,NIH,"The NIH Extramural Research Program uses the eRA system to efficiently award and manage grants.

The AI system is designed for use by IC ‘internal referral’ officers who manage a pool of applications and are responsible for assigning the applications to program officials. It creates efficiencies by automating the ‘internal referral’ assignments, currently done manually on spreadsheets by the ICs. The inputs are grant applications, the outputs are referrals to Program Officers, Program Class Codes, Organizational units - Divisions and Branches and Scientific Research Clusters.","The Internal Referral initiative automates a manual process by using AI and NLP capabilities to help assign grant applications to NIH Institute and Center Program Officers to make informed decisions.

The inputs are grant applications, the outputs are referrals to Program Officers, Program Class Codes, Organizational units - Divisions and Branches and Scientific Research Clusters."
HHS-NIH-00042,IT System Outage Alerts,HHS,NIH,"Use Generative AI to create maintenance and IT system outage alerts that will be sent to NIDCD staff.

General communication to the NIDCD staff. The GenAI tool will reduce staff time to create and distribute e-mail alerts.","Communicates alerts for IT System outages. Output: System, building, day, time."
HHS-NIH-00043,JIT Automated Calculator (JAC),HHS,NIH,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

NIGMS needs to know how much total support an investigator has to ensure that it is not funding Principal Investigators who are already adequately resourced. The tool can determine how much funding a Principal Investigators has been awarded.",The JIT Automated Calculator (JAC) uses NLP to parse Just-In-Time (JIT) Other Support forms and determine how much outside support PIs are receiving from sources other than the pending application.
HHS-NIH-00044,Large Language Automation,HHS,NIH,"Automate use cases as indicated below.

1. Automate BOT to locate and extract Resource Sharing Plan from post awarded grant application and feed into Microsoft Azure AI to teach it to determine if grant application as written has met compliance. The RFA provides guidelines for grantees.
2. Generate summary for published papers.
3. Generate summary for papers for concept development, research data analysis or other internal work.
4. Generate summary as part of a preliminary review of documents.
5. Generate summary of public meetings.
6. Utilize existing MS Excel worksheets to automate templated emails.
7. Generate FAQs.
8. Produce training materials. 

The RFA: 
1) provides guidelines for grantees, 
2) generates summary for published papers, 
3) generates summary for papers for concept development, research data analysis or other internal work,
4) generates summary as part of a preliminary review of documents,
5) generates summary of public meetings,
6) utilizes existing MS Excel worksheets to automate templated emails,
7) generates FAQs, and
8) produces training materials. ","Input: Push data into Microsoft Azure AI from QVR post awarded grant application data.

Output: Integration of Microsoft Azure AI with UiPath. "
HHS-NIH-00045,Leveraging User-Generated Content for Digital Behavioral Interventions,HHS,NIH,"The project uses AI-based automated text classification technology to build a predictive model to categorize smoking-related tweets into six distinct categories (e.g., quitting strategies). Specifically, the project uses the AI-based BERT pre-trained language model, which will be further fine-tuned using neural network models to capture the contextual nuances of our use case. AI will also be used to select data for the training dataset that will form the basis of the predictive model. Then, we use ChatGPT to classify extracted and labelled tweets according to its sentiment, presence of sarcasm, presence of irony, presence of emojis. 

The primary objective of the project is to classify thousands of tweets to six categories (e.g., strategies for quitting, quitting benefits) and according to their sentiment and presence of irony, sarcasm, and emojis. Tweets that are positive, not ironic, nor sarcastic would then be tested with target audiences for message effectiveness and possible integration in a smoking cessation intervention.","Input: Publicly available tweets.

Output: sentiment (very positive, positive, neutral, negative, very negative), presence of sarcasm (yes, no), presence of irony (yes, no), presence of emojis (yes, no - and if yes, a description of the emojis present in the tweet)."
HHS-NIH-00046,LLM Support for Admin Services,HHS,NIH,"This project aims to explore the integration of large language models (LLMs) into administrative operations, aiming to enhance efficiency, accuracy, and productivity. By leveraging LLMs, repetitive tasks can be automated including data analysis, documentation drafting, and customer support, thereby freeing up valuable time for administrative personnel to focus on more strategic initiatives. Additionally, LLMs can facilitate natural language processing (NLP) for documentation, ensuring consistency and accuracy in communication across various channels. Through process automation, policy monitoring, and virtual assistance, LLMs offer the potential to streamline our administrative workflow, reduce manual workload, and mitigate the risk of errors. This assessment will provide valuable insights into the feasibility and effectiveness of integrating LLMs into our administrative framework, ultimately optimizing our operations and enhancing organizational performance.

It will reduce the burden of administrative tasks, faster response to administrative inquiries, fewer resources required to support administrative operations.","Uses NLM administrative and operational data to output procedures, forms, schedules, etc."
HHS-NIH-00047,Mapping Sequence Data to Research Outcomes,HHS,NIH,"A proof-of-principle analysis is being conducted to identify downstream research products related to sequence records included in NLM-managed repositories.

To identify sequence records in NLM-NCBI-managed data repositories and related research products to inform operations and prioritize resources.",Sequence records included in NLM-NCBI-managed data repositories and abstracts for citations records indexed in PubMed; outputs are text summaries identifying in a yes/no fashion if research products were identified
HHS-NIH-00048,Medical Text Indexer-NeXt Generation (MTIX) MEDLINE Indexing,HHS,NIH,"Machine learning-based system for the automated indexing of MEDLINE citation records using Medical Subject Heading (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach.

MeSH indexing has been shown to improve information retrieval in PubMed, but manual indexing was not sustainable due to the increasing volume of published biomedical literature. Automated indexing allows for cost-effective and timely indexing of MEDLINE citation records.","The input is PubMed citation data including the article title and abstract, and the output is a set of MeSH terms describing the topic of the article."
HHS-NIH-00049,MetaMap,HHS,NIH,"NLM is the world’s largest biomedical library. MetaMap is a program providing access from biomedical text to the concepts in the Unified Medical Language System Metathesaurus. 

MetaMap uses NLP to provide a link between the text of biomedical literature and the knowledge.","Metamap is used to map biomedical text to the Unified Medical Language System Metathesaurus or, equivalently, to discover Metathesaurus concepts referred to in text. "
HHS-NIH-00050,MicroStrategy Evaluation,HHS,NIH,"The software to be evaluated should provide a business intelligence/reporting/visualization interface for possible use for 2 systems (Azure DevOps and OneStream). This software should provide robust development capabilities for manually-generated reports and AI capabilities for end-users to generate additional reports without the need for development. 

This software should provide robust development capabilities for manually-generated reports and AI capabilities for end-users to generate additional reports without the need for development. ","Input: Financial data from OneStream and Project Management data from Azure DevOps.

Output: Data driven business intelligence dashboards. "
HHS-NIH-00051,MTIX,HHS,NIH,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. 

This is a machine learning-based system for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach. ",Automated indexing allows for cost-effective and timely indexing of MEDLINE articles.
HHS-NIH-00052,NanCI: Connecting Scientists,HHS,NIH,"NCI is helping to connect scientists.

NanCI is the app for biomedical scientists that helps discover scientific papers, build a career network, and explore events. ",NanCI is a new mobile application that uses machine learning algorithms to match users’ interests and provide a unique experience by recommending tailored content.
HHS-NIH-00053,NBS Virtual Assistant,HHS,NIH,"The NIH Business System (NBS) is NIH's financial system.

Streamlined Service Desk Operations. The AI-powered chatbot can handle routine user inquiries, reducing the burden on IT service desk. Provides self-service options for users to resolve issues independently.","The NIH Business System (NBS) Assistant is an AI-powered chatbot  to redefine how NBS users engage, and to offer seamless support and personalized assistance across various NBS workstreams. NBS is NIH's financial system."
HHS-NIH-00054,"NCI-DOE Collaboration, MOSSAIC project (Modeling Outcomes using Surveillance Data and Scalable AI for Cancer)",HHS,NIH,"MOSSAIC applies deep learning natural language processing (NLP) and foundation models to population-based cancer data collected by NCI's Surveillance, Epidemiology, and End Results (SEER) program. DOE's Oak Ridge National Lab (ORNL) has data use agreements (DUAs) with multiple SEER registries to access and train models using SEER data. To date, the MOSSAIC pathology-coding API is deployed in 22 SEER registries, moving the US towards near real-time cancer incidence reporting. Other APIs are still in the validation phase or research and development phase.

MOSSAIC enhances the infrastructure of the SEER cancer registries by providing tools that can increase the efficiency and accuracy of manual data abstraction by automatically extracting cancer surveillance data elements.  SEER registries receive millions of unstructured clinical text documents that must be manually reviewed, leading to a lag in reporting of US cancer incidence trends.  Automated tools such as those developed by MOSSAIC will help us achieve near real-time incidence trends and ultimately a more meaningful report card on the status of cancer in the US.","Input: unstructured (free text) cancer pathology reports. 

Output: varies depending on the algorithm but generally a predicted class (eg, tumor site) and associated relative confidence score that can be used to tune accuracy."
HHS-NIH-00055,NHLBI Chat,HHS,NIH,"NHLBI Chat is a secure LLM tooling providing access to the Azure OpenAI API so that all NHLBI staff can explore generative AI for their day-to-day need.

NHLBI Chat is a secure LLM tooling providing access to the Azure OpenAI API so that all NHLBI staff can explore generative AI for their day-to-day need.",The Azure OpenAI API accepts text as input and return text as output. Users enter text through a chat interface in a website.
HHS-NIH-00056,NIAID GenAI Toolkit,HHS,NIH,"The NIAID GenAI Chat and Document Bot are Azure-hosted GenAI applications that leverage commercially available large language models from the Azure OpenAI Service to assist NIAID employees in a variety of task such as content generation, summarization, etc.

The Azure-hosted NIAID GenAI Chat and Document Bot helps employees be more efficient with a wide variety of administrative tasks, such as summarizing/querying documents, drafting emails, and creating presentation outlines​, etc. ","Input: natural text in the form of user questions, user uploaded documents. 

Output: Generated text in the form of answers to user questions, generated answers (summaries/queries) based on user documents. "
HHS-NIH-00057,NIAMS AI Chatbot Pilot,HHS,NIH,"To develop a secured AI Chatbot environment where NIAMS staff can 1) conduct general research, 2) help staff in writing grants/publications/papers (e.g. foreign researcher with their English grammar, sentence structure, etc.), 3) scientific and IT code generation, 4) summarizing meeting minutes and 5) providing a platform to learn how AI can be used in their daily work tasks.

Aside from what is described in 'Use Case Scope', other expected benefits are to assess the cost vs benefit value of having our own chatbot vs paying per user per month to use the NIH Enterprise versions of MS Copilot and OpenAI ChatGPT. This pilot will also be used to understand and develop a tiered business case on which NIAMS staff would fit which chatbot (NIAMS chatbot, MS copilot and OpenAI ChatGPT).","Inputs: Text input, text-based documents or PDF uploaded by users entered into a prompt. Amount or frequency of data are based on how often users use the chatbot, which will be determined during or after the pilot. 

Outputs: Text summaries, information, recommendations and classifications. Output will be presented in text form. The frequency the AI produces the results is based on how often users use the chatbot."
HHS-NIH-00058,NICHD RPAB AI/ML Application Referral System,HHS,NIH,"The NICHD RPAB AI/ML Application Referral System leverages the advanced AI/ML technologies to predict extramural branch assignments of new, incoming NICHD grant applications.  It employs human-in-the-loop development which enables human evaluation and offers the ability to override and alter model outputs.  Source data are from the NIH IMPAC II system and stored in the existing NICHD IT application CHIRP (Child Health Information Retrieval Program).  The AI process and output data have no impact on the NIH IMPAC II system. The business area addressed is the internal referral assignment performed by RPAB.

The primary objective is to enhance the efficiency, accuracy, and consistency of grant application referral assignments, while reducing the burden on Subject Matter Experts in RPAB. The AI system is expected to streamline the process of internal referral of new grant applications.",Internal: NIH ImpacII and CHIRP results are presented as class predictions and class probabilities.
HHS-NIH-00059,NLM-Chem: towards automatic chemical indexing in PubMed articles,HHS,NIH,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. Chemical indexing improves literature retrieval and information access. 

To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. ","Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. "
HHS-NIH-00060,NLM-Gene: towards automatic gene indexing in PubMed articles,HHS,NIH,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. Gene indexing improves literature retrieval and information access. 

 To assist this time-consuming and resource-intensive process, NLM developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature using advanced natural language processing and deep learning methods. ","Gene indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, gene indexing is performed manually by expert indexers."
HHS-NIH-00061,NLP Automated Referral,HHS,NIH,"Publicly reported under OER. NIGMS worked with eRA for over a year to incorporate natural language processing (NLP) and machine learning (ML) algorithms into eRA's Internal Referral Module (IRM).  IRM is now capable of using ML/NLP to assign applications directly to program officers (POs) based on the titles, abstracts, narratives, and specific aims of those applications, as well as the application histories of the PIs. The current process runs in the background on eRA's AWS cloud instances, and assigns the majority of new NIGMS applications to POs as soon as they are referred to NIGMS by CSR.  ML/NLP is also used to provide POs with the three most relevant NIH institutions to applications to facilitate IC fit determinations.

Automated referral allows NIGMS to retain institutional referral knowledge by training on historical data, eliminates delays in referral by assigning applications as soon as they come in, and reduces burden on staff members and allows them to allocate more of their time to other high value tasks.","The tools uses IMPAC II application data, including titles, abstracts, narratives and specific aims to produce a top three of most relevant ICs and POs. "
HHS-NIH-00062,OCIO GenAI Advisor,HHS,NIH,"The OCIO GenAI Advisor is a general productivity enhancement tool that uses Retrieval Augmented Generation (RAG) setup and user-provided data to answer questions about that data. This is a pilot project for experimentation to discover specific use cases, data needs, security and privacy concerns.

If used effectively, the OCIO GenAI Advisor can shorten time to find the correct information and generate a non-trivial response for a complex question in a desired format such as security, architecture, PMO policy, reports.","Publicly available OMB, NIST policy in pdf format as user-provided data. Prompt and output are in natural language. "
HHS-NIH-00063,OIT Help Desk Chatbot,HHS,NIH,"A general productivity enhancement tool that uses Retrieval Augmented Generation (RAG) setup to answer questions about that data. This is a proof of concept project for experimentation to discover specific use cases, data needs, security and privacy concerns.

If used effectively, the OIT help desk can shorten resolution time for tickets, help empower users and  generate a non-trivial response for a complex question in a desired format such as security, architecture, PMO policy, reports.","Publicly available help desk data, NIST policy in pdf format as user-provided data. Prompt and output are in natural language. "
HHS-NIH-00064,Person-level disambiguation for PubMed authors and NIH grant applicants,HHS,NIH,"The Office of Portfolio Analysis employs AI-based approaches to support analysis of the biomedical research landscape and inform data-driven decision-making by NIH leadership and extramural research administrators in other federal agencies.

High-quality disambiguation is required to correctly link researchers to their grants and outputs including articles, patents, and clinical trials. ","The NIH Office of Portfolio Analysis developed a disambiguation solution that used article level metadata to assign 24.5M unique papers from the PubMed database to 16.0M unique author names, then used a novel neural network model to determine whether author-publication pairs refer to variant representations of the same person. "
HHS-NIH-00065,Portfolio Analysis Summarization Tool (PAST),HHS,NIH,"This AI Use Case is leveraging Power BI to present a dynamic view of grants within their portfolio, enabling program staff to explore their data interactively. Program staff face challenges in navigating and understanding extensive narratives within grants due to time constraints and the volume of information. The proposed Open AI sandbox will address these challenges by providing concise, AI-generated summaries of grant-related texts, including Titles, Abstracts, Specific Aims, and Research Strategies.  

Rapid summarization of custom research portfolios which will be used to support program staff and others across the institute.","Input: Grants data from QVR.

Output: Summaries of grant-related texts "
HHS-NIH-00066,Program Classification Coding,HHS,NIH,"A machine learning model has been developed to provide Program Classification Code (PCC) suggestions to assist NIA Division Staff with their work. The model is trained using IMPAC II data and generates a report of the top three PCC suggestions for a selected council date. Users can filter the data view by IC/OrgCode and Program Officer names to further customize the results.

The Division staff is responsible for handling a large volume of applications during each council round, with the task of processing and assigning PCCs. To aid users, a solution has been developed that suggests the specific PCC that should be assigned to each application.","Model Inputs: Impac II data fields (Specific Aims, Project Title, and Study Section). 

Output is top 3 predicted PCCs. User views list of applications and top 3 suggestions by clicking on a report for the selected council date. User can filter view by IC/OrgCode and Program Officers names.  "
HHS-NIH-00067,RCDC AI Validation Tool,HHS,NIH,"Annually, NIH reports the support level for various research, condition, and disease categories based on grants, contracts, and other funding mechanisms used across the agency.

To provide the public the transparency into the reporting of NIH's funded research.",The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. 
HHS-NIH-00068,Remediate Adobe .pdf documents to be more accessible,HHS,NIH,"Manual curation and remediation of PDF files is time-consuming and can require substantial expertise to remediate previously published artifacts.  

PDF documents should conformed to Section 508 accessibility standards. NLM is using AI to remediate Adobe .pdf files not currently accessible to Section 508 standards. ",PDF improved files are more accessible to readers who use assistive technology.
HHS-NIH-00069,Research Performance Progress Report (RPPR) Report Comparison,HHS,NIH,"The National Institute on Aging (NIA) handles a significant number of grant applications annually, requiring thorough review to prevent duplication, identify changes, and ensure optimal resource allocation. The current manual review process involves detailed comparisons across grant documents from different years, checking for overlaps with other projects, and summarizing extensive scientific text. With each Program Officer (PO) managing between 50 to 200+ grants and overseeing a total of $4 billion in grant funding, the process is highly time-consuming and prone to errors. 

Streamline the NIA grant application review process.","Input: Grants data from QVR.

Output: Identification of duplication and overlap in grants year over year."
HHS-NIH-00070,Scientific summaries tool,HHS,NIH,"The goal is to generate justifications for personnel actions including appointments, conversions, pay adjustments, and hiring/retention incentives for physicians, scientists, and veterinarians.

Within NIAID DIR, we have team that drafts justifications for personnel actions based on the research being performed. This tool will be created to help them quickly and effectively prepare justifications for personnel actions for investigators in specific research fields.","Inputs: scientific publications, CV/Bib, BSC submissions and outcome memos, prior justifications, and, clinical protocols. 

Outputs: Scientific summary."
HHS-NIH-00071,Semantic group prediction in the UMLS Metathesaurus,HHS,NIH,"Developing AI approaches (neural networks, heuristics) to predict the semantic groups of new terms to be added to the Unified Medical Language System (UMLS) Metathesaurus.   This is used during new concept integration into the UMLS Metathesaurus and is only intended to interact with the new concepts that will be added and existing UMLS Metathesaurus concepts.  There is no training or intended use of this product for sensitive data.  The hybrid system combining deep learning and heuristics should be able to effectively support UMLS editing and quality assurance. 

Support UMLS Metathesaurus editing.  This should dramatically reduce the time needed to integrate new concepts into the UMLS Metathesaurus and increase the consistency. ","Input: UMLS Metathesaurus (new concepts). 

Output: Semantic group(s) for the new concept. Concepts are typically text words or phrases for example """"Lung Cancer"""", """"heart attack"""". This is used yearly when it is time to add new concepts to the UMLS Metathesaurus. "
HHS-NIH-00072,Similarity-based Application and Investigator Matching (SAIM),HHS,NIH,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

NIGMS needs to know how much total support an investigator has to ensure that it is not funding Principal Investigators who are already adequately resourced. The tool can determine if an application has significant overlap (Just-In-Time Other Support) with an application that is funded by another agency.",The Similarity-based Application and Investigator Matching (SAIM) system uses NLP to find non-NIH grants awarded to NIGMS Principal Investigators.
HHS-NIH-00073,SingleCite: Improving single citation search in PubMed,HHS,NIH,"NLM is the world’s largest biomedical library. SingleCite is search algorithm designed to improve single citation searches in the PubMed database. 

SingleCite helps increase the effectiveness of PubMed searches by making a user’s search for a specific document in PubMed more successful.","SingleCite predicts the probability of a retrieved document being the target of a query based on predefined variables. This search is important for scholarly databases, such as PubMed."
HHS-NIH-00074,SRDMS NLP COI,HHS,NIH,"NIAID administers grant portfolios in the extramural research program areas including Allergy, Immunology, & Transplantation, Infectious Diseases, and HIV/AIDS.

Detect individuals who may pose a conflict-of-interest during the grant review process. ",The tool allows NIAID’s Scientific Review Program team to more easily identify conflicts of interest (COI) between grant reviewers and applicants using NLP methods.
HHS-NIH-00075,Stem Cell Auto Coder,HHS,NIH,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

Manually coding Stem Cell Research subcategories is a time intensive process. NIGMS sped up this process by using automation.","The Stem Cell Auto Coder uses NLP and ML to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic."
HHS-NIH-00076,Study Section Clustering Tool (SSCT),HHS,NIH,"This tool suggests how study sections might be organized into groups of similar scientific fields to decide how applications might be grouped into new study sections. Subject matter experts ultimately finalize the study section groupings. 

This tool helps to ensure that applications are grouped into study sections in a way that maps on to the current state of the science.  ","Input: Text of grant applications. 

Output: Lists of study sections that should be grouped together for further review.  "
HHS-NIH-00077,Synonymy prediction in the UMLS Metathesaurus,HHS,NIH,"Developing artificial intelligence (AI) approaches (neural networks) to predict synonymy among biomedical concepts in the Unified Medical Language System (UMLS) Metathesaurus, with application to the insertion of new concepts into the UMLS Metathesaurus.  This is used during new concept integration into the UMLS Metathesaurus and is only intended to interact with the new concepts that will be added and existing UMLS Metathesaurus concepts.  There is no training or intended use of this product for sensitive data. Preliminary results indicate the performance of the system should be sufficient to support the insertion of new terms into the UMLS Metathesaurus. 

Support UMLS Metathesaurus editing.  This should dramatically reduce the time needed to integrate new concepts into the UMLS Metathesaurus and increase the consistency. ","Input: UMLS Metathesaurus (new concepts). 

Output: Synonymy with existing Metathesaurus concepts. Concepts are typically text words or phrases for example """"Lung Cancer"""", """"heart attack"""". This is used yearly when it is time to add new concepts to the UMLS Metathesaurus.   "
HHS-NIH-00078,TB Case Browser Image Text Detection,HHS,NIH,"The NIAID TB Portals Program is a multi-national collaboration for tuberculosis (TB) data sharing and analysis to advance TB research.

A tool that uses AWS Recognition managed AI service to detect text in images which could be potentially Personally Identifiable Information (PII)/ Protected Health Information (PHI) in TB Portals data. ",The tool detects and counts instances of text and if above a threshold throws a warning to the user who is uploading the image. User must then affirmatively bypass to upload.
HHS-NIH-00079,Tech Support Chatbot,HHS,NIH,"It is designed to address two usage scenarios: (1) provide the ORS/ORF community with an interactive customer service chat interface for inquiries related to OIIT technology services, policy, and general information and (2) provide OIIT staff with the ability to receive answers in a variety of technical areas as they troubleshoot or manage efforts in their respective teams.

The benefit of the AI is to improve administrative questions and efficiency of the information to the internal OIIT team.","Provides text, images and data. Input data source is local database. Frequency is TBD."
HHS-NIH-00080,Tool for PO Lookup Assignment (TPAL),HHS,NIH,"Similar to publicly reported IRM use case. The Tool for PO Assignment Lookup (TPAL) provides NIGMS Program staff with the ability to automatically search for appropriate Program Officers (POs), including their corresponding Program Area Codes (PACs), and NIH ICs to assign or reassign project proposals, or to provide advice to prospective applicants. TPAL uses natural language processing and machine learning to predict the three most relevant NIGMS POs, including their corresponding PACs, and the three most relevant NIH ICs from the project description/abstract text entered into a textbox. Note that because the PO and IC prediction algorithms are independent of each other, TPAL will always try to provide the most relevant program​ officers, even when NIGMS is not one of the top three recommended NIH ICs.  

There are many occasions in which Division Directors, Branch Chiefs, and Program Officers wish to receive suggestions for the most appropriate people to talk to about a project proposal or where to send a proposal that might not be appropriate for NIGMS.","Input: Free form text in an online textbox. 

Output: Top three most relevant ICs and POs and their probabilities. "
HHS-NIH-00081,Transformative Research Award Anonymization Check (TRAAC),HHS,NIH,"This tool helps to determine whether grant applications for NIH Director's Transformative Research Awards are properly anonymized by quickly detecting information that might identify the applicant in the Specific Aims or Research Strategy sections. 

This tool automatically screens many pages and highlights any text that might allow identification of the applicants. The highlighted text is then examined by subject matter experts. This streamlines content screening and aids both NIH staff and the external scientific community in making more rapid and efficient determinations about whether anonymity has been compromised. ","Input: PDF files including text and images from two sections of the NIH grant applications.

Output: Spreadsheets containing records of identified text/phrases as well as PDF files with text/phrases highlighted. "
HHS-NIH-00082,Machine learning pipeline for mining citations from full-text scientific articles,HHS,NIH,"The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003). 

Retired use case","The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service."
HHS-NIH-00083,Machine learning system to predict translational progress in biomedical research,HHS,NIH,"A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. Translational progress in biomedicine can therefore be assessed and predicted in real time based on information conveyed by the scientific community’s early reaction to a paper. For more information see the publication describing this system: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416) 

Retired use case",A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. 
HHS-OASH-00001,"Assessing developing possible version of ""HHSGPT"" for OIDP-specific internal use",HHS,OASH,"OIDP's HIV.gov: an exploration of possibly using a custom knowledge-based walled/isolated version of ""Chat GPT"" for our internal OIDP users to access information to help with internal operational efficiencies related to our work on national strategies.  We have been meeting for almost 1 year with senior HHS officials working on AI to keep them up to date on our approach and efforts in both RAG LLM and generative AI. We describe our work as an internal library. The tool is called Ask ABE! (v3.0.0-alpha.1) - AI-Driven. Beneficial. Equitable (ABE). It's like having a digital librarian who can help us at OIDP easily access and use all the valuable resources from HIV.gov to support our work in ending new HIV transmissions! Our work is critical to ensuring the following issues are addressed: (1) Security: FedRAMP certified Azure Open AI 3.5 Turbo / 4o Global. (2) Privacy: Not tracking conversations nor usage. PII stripped. (3) Equity: HIV Language and HIV Language Guideline through internal system prompt. (4) Hallucinations: Internal system prompt  - ABE HIV.gov knowledge base and conversation history. There is a low risk of this occurring compared to open systems like ChatGPT. (5) Risk: NIST AI Risk Management Framework: Govern, Map, Measure, Manage for Responsible AI, Observable AI, and Explainable AI (6) Certifications / Training / Support: Azure AI Certifications / Data Science DoJo / Corporate Thought Leadership Support: Responsible AI Framework.","OIDP internal federal staff would possibly be able to ask questions, develop content, and revise existing content using a unique dataset of OIDP information. Inclusion of NIH HIV guideline is embedded in the internal prompting. "
HHS-OASH-00002,Informal generative AI research for OIDP's HIV.gov,HHS,OASH,"OIDP's HIV.gov monitors (1) new and emerging AI tools/policies, generative AI use in the field of communications, and (2) the impact of generative AI on HIV federal content delivery through major search engines. This work is done by an ORISE fellow in conjunction with the HIV.gov communications team. The information is synthesized and discussed during a weekly communications meeting to determine any possible application or if additional follow-up is needed. The purpose of this activity is to determine potential tools that we may be able to use to extend the reach of our work. For example, we have been monitoring tools that potentially can synthesize weekly content into a short narrated video.",This practice helps us guide our planning.
HHS-OASH-00003,Presenting/providing technical assistance on HIV.gov's cautious & transparent use of generative AI,HHS,OASH,"OIDP's HIV.gov hosts generative AI workshops, 1-on-1 trainings, and limited generative AI labs to share our cautious and transparent use of generative AI to create communications content. These activities also include information on generative AI basics and information on federal guidance. Our limited AI-generated content is disclosed with a watermark or a tag saying, ""Created by AI, Reviewed By Humans."" These trainings have occurred at 5 national HIV-related conferences and include multiple 1-1 training sessions and workshops that reinforce the importance of following best practices, being transparent, and being cautious. We have trained over 500 people on the cautious and transparent use of generative AI.","These offerings help our audiences understand the importance of cautious and transparent use, federal resources, and additionally promote information about our office's HIV programs."
HHS-OASH-00004,Utilizing HHSGPT Pilot for writing/editing ,HHS,OASH,"Limited OIDP staff have been selected to have access to HHSGPT, an internal generative AI tool in its pilot phase. Team members have been using it for editing, brainstorming, idea generating, drafting text, revisions, gap analysis, organization/structure, evaluations, etc. HHSGPT has been used to assess national strategies, such as the 2026-2030 vaccine national strategy, the 2026-2030 viral hepatitis strategy, and others. When utilizing HHSGPT, we work to report back how this use has reduced labor burden and note any interesting findings when using the tool. Use reporting is done on an Excel file. ","HHSGPT uses a closed tool to generate suggestions, responses, edits, and information that may be useful for OIDP tasks related to infectious diseases or HIV information/policies. Team members have been using it for editing, brainstorming, idea generating, drafting text, revisions, gap analysis, organization/structure, evaluations, etc.  "
HHS-OCIO-00001,HHSGPT,HHS,OCIO,"ChatGPT is an AI-powered chatbot developed by OpenAI, and it can be integrated with Azure, Microsoft's cloud computing platform. ChatGPT leverages the power of OpenAI's language model to provide natural language understanding and generation capabilities.

Scalability: As an AI-powered chatbot, ChatGPT can handle multiple conversations simultaneously, scaling up to meet high demand without the need for additional human resources.
Increased Efficiency: ChatGPT can automate repetitive tasks, freeing up human agents to focus on more complex or value-added activities, improving overall efficiency.

Persona Benefits:
Assist data scientists in data exploration, model prototyping, analysis, collaboration, and accessing relevant knowledge, enhancing their productivity and efficiency.

Assist policy analysts by providing instant insights, answering complex policy-related questions, and facilitating interactive discussions, enabling faster and more informed decision-making. 
Assist in writing large policy documents by providing suggestions, generating coherent content, and offering language refinement, streamlining the writing process and ensuring high-quality outputs.","At present, HHSGPT is undergoing a pilot phase throughout the entire HHS organization under an IATT."
HHS-SAMHSA-00001,DECIDE,HHS,SAMHSA,"At present, SAMHSA's Office of Behavioral Health Equity (OBHE) manually reviews grantee organizations' progress towards achieving their health disparity reduction goals. This process involves manually extracting Disparity Impact Statements, annual reports, enrollment data, and external population data to verify the accuracy of grantees' reported progress. This is a time-consuming process, thus the development of an AI-based tool for doing this review is in development.

DECIDE will reduce the administrative burden on OBHE staff and allow them to provide feedback to grantees more quickly.","DECIDE will use generative AI to automate the process of extracting data from various sources, then comparing across data sources to determine (a) whether a grantee has accurately reported the demographic data of the population they serve and (b) how much progress they have made towards decreasing health disparities for the vulnerable population they have identified."
HHS-SAMHSA-00002,Document drafting and editing,HHS,SAMHSA,"SAMHSA employees routinely write internal reports, public-facing written products, and other documents. Some parts of the writing process, such as structuring thoughts into an outline and proofreading, can be enhanced through the use of AI.

The document drafting and editing tool will increase employee productivity and help produce polished written work products.","The document drafting and editing tool will serve as a writing assistant to help SAMHSA employees present their ideas clearly and effectively. It will function similarly to a standard large language model chatbot, allowing the user to query the model to perform specific writing tasks, such as outlining and proofreading."
HHS-SAMHSA-00003,Document summarization,HHS,SAMHSA,"SAMHSA employees routinely read and summarize large amounts of documentation for grantmaking, management, and other day-to-day work. Ingesting and condensing such vast amounts of information can take time away from SAMHSA's most important mission-driven work.

The document summarization tool will expedite day-to-day workflows and help employees ingest large amounts of information more quickly.","The document summarization tool will allow users to upload documents and produce a summary of these documents. The tool will have enhanced data privacy mechanisms. Additionally, the tool will not use any SAMHSA-provided input as training data, ensuring that private information stays private to SAMHSA."
HHS-SAMHSA-00004,Smart Search,HHS,SAMHSA,"SAMHSA.gov team would like to procure ""Kendra""to implement a smart search on store.samhsa.gov—improving access to the Federal Government’s leading source of behavioral health information. Currently the search on store.samhsa.gov relies on key words pulled from document titles, descriptions, and manually generated tags. Both anecdotal evidence and results of usability testing have demonstrated that the Store’s search capability is the single greatest barrier to users accessing materials they need

Kendra will allow for scanning of all documents in the store to respond more accurately to consumer queries while providing a faster search. ","Kendra is not generative AI and does not provide AI-generated responses to queries. Kendra operates within strict guardrails to ensure the security and privacy of information, particularly concerning the handling of sensitive data like Personally Identifiable Information (PII)."
HUD-001-2024,Counterparty Risk Anomaly Detection ,Department of HUD ,Ginnie Mae ,"Ginnie Mae is responsible for analyzing counterparty risk profiles of mortgage issuers who participate in Ginnie Mae�s program. Ginnie Mae analyzes data from multiple sources to identify potential risks and areas of focus. To enhance the identification of data patterns, Ginnie Mae uses machine learning algorithms, specifically clustering and genetic techniques. These algorithms detect potential risk areas, enabling a focused approach to subsequent analysis by Ginnie Mae staff. ",Data patterns 
HUD-002-2024,Subledger Data Quality Machine Learning,Department of HUD ,Ginnie Mae ,"Ginnie Mae analyzes Master Sub-Servicer (MSS) transaction data on a monthly cadence. Through its use of machine learning models, Ginnie Mae has enhanced its ability to identify data inconsistencies and exceptions associated with its MSS transaction data. By automating the analysis of a significant number of MSS transactions, the machine learning algorithms enhance the efficiency and accuracy of key reporting processes. ",The AI solution identifies data anomalies. 
HUD-003-2024,Automating Draft Counterparty Credit Narrative Reports,Department of HUD ,Ginnie Mae ,"Ginnie Mae performs counterparty credit reviews of mortgage issuers who participate in Ginnie Mae�s program. The reviews are based on written analysis and financial data. As an initial step in counterparty credit reviews, Ginnie Mae uses Natural Language Generation (NLG) to implement coded rules and generate draft narratives. This application of AI enables processing efficiency and reduces errors that can occur in a manual process. ",Draft memos/reports�
HUD-004-2024,Voice of the Customer,Department of HUD ,Office of the Chief Financial Officer (OCFO),"The Office of the Chief Financial Officer, Customer Experience Team works across the department to develop a deep understanding of who our customers are and how we can best serve their needs. The Voice of the Customer application brings the best-in-class voice transcription, speech, and text analytics to customer feedback surveys,  contact center calls and chats. It allows HUD to unlock critical insights that provide deeper understanding of how to support and manage our program/service delivery and contact center providers, and ultimately to improve customers� experiences.","A data analytics dashboard that transforms customer feedback into succinct, easy-to-understand metrics, such as customer satisfaction rates across different customer interaction and call center topics."
HUD-005-2024,Quantitative Text Analysis,Department of HUD ,Office of the Chief Financial Officer (OCFO),"Analysis of large amounts of text for patterns (commonly appearing words, common word clusters, etc.)","The outputs are charts and graphs showing which words appear most commonly across the documents, which words appear clustered together most often, and the sentiment of the words, etc. "
HUD-006-2024,Translation of Digital Media,Department of HUD ,Office of Public Affairs (OPA),"OPA is using Google Translate to translate information on public-facing websites. On every HUD.gov webpage, there is an �Espa�ol� button that calls Google Translate to translate the page into Spanish. From there, a Google Translate banner appears on the page allowing for the translation into any available language. This is a free, off-the-shelf solution with no customization. It is also an interim solution to improve language access at HUD while a permanent solution is being developed in line with HUD�s Language Access Plan in response to Executive Order 13166. ",Translated content on HUD.gov
VA-36,Evolv WDS - OSSO,VA,VHA: Veterans Health Administration,Using heat map technology to identify heat signature of known weapons.,Areas of interest for a heat map that include objects that would produce heat indicators aligned with heat signatures of known types of different weapons.
VA-52,VA Chat Copilot Meta Pilot,VA,OIT: Office of Information & Technology,Administrative efficiency for VA employees ,"Chat Copilot is a generative AI interface that allows users to upload documents and query the tool about those documents. Outputs can include draft emails, draft communications, document summaries, draft project templates, responses to questions about content of documents, etc."
VA-77,Avigilon Camera/Search Function - OSSO,VA,VHA: Veterans Health Administration,A search function in a security video surveillance system that search's for points of interest in the video.,Video or picture of requested searches from the video surveillance systems.
VA-93,CareCentra Next Level Personalized AI Health Coach,VA,VHA: Veterans Health Administration,"This is an evidence based, randomized control trialed AI solution that focuses on precision nudging.  It is intended to improve quality of care and reduce view alerts.  Its focus is on identifying personalized behavioral change algorithms for each veteran to identify timing, channel, ",
VA-118,SafePointe WDS - OSSO,VA,VHA: Veterans Health Administration,Heat map detection for weapon detection software.,Areas of interest for a heat map that include objects that would produce heat indicators aligned with heat signatures of known types of different weapons.
VA-1397,GE Xeleris ,VA,VHA: Veterans Health Administration,Xeleris V leverages AI to accurately segment organs for quantitation and dosimetry calculations. Q.Thera AI demonstrated an average reduction of 58% in the time required for the user to process and calculate dose3.,Provide patient dosimetry calculations.
VA-130,Genesys Cloud Contact Center,VA,OIT: Office of Information & Technology,"Assist staff with knowledge based recommendations, conversation summarization and quality assurance metrics automation. This will allow the staff to react quicker to customer needs and spend less time researching for information or performing repetitive tasks and instead focus more on customer interactions.",Most of genesys outputs are surfacing knowledge to assist the staff with customers interactions or automating repetitive tasks such as scoring quality forms for those interactions or routing of customers upon discovered intents.
VA-159,Verkada Camera - OSSO,VA,VHA: Veterans Health Administration,Video search function inside a physical security camera solution.,Video and images from the AI searches inside the physical security camera solutions.
VA-163,MRI - GE Signa Artist,VA,VHA: Veterans Health Administration,"AIR™ Recon DL is a deep-learning-based reconstruction algorithm that enables radiologists to achieve pin-sharp images quicker. By removing noise and ringing from raw images, scans are consistently crisp. Improved signal-to-noise ratio (SNR) means scan times are cut by up to 50%, smoothing workflow and enhancing the patient experience",MRI image reconstruction.
VA-171,Google Cloud Platform - CCAI / Dialogflow ,VA,OIT: Office of Information & Technology,to allow for better self service options to veterans to include virtual voice/chat agents,the output of GCP voice/chat is text to speech (TTS) and speech to text (STT)
VA-200,Axon Body Camera and DMS - OSSO,VA,VHA: Veterans Health Administration,"To be able to search the data repository with better results, better redaction abilities for certain capabilities and on the Fleet System only to have better license plate recognition. ","To have better outputs in searching the systems data repository for case files, evidence locker, and DMS; to have a better result when doing the redaction of evidence, files, videos and photos; and on the Fleet system only to have better results in identifying licenses plates in the licenses plate recognition part of the system."
VA-204,Ultrasound - GE Logic E10,VA,VHA: Veterans Health Administration,"Auto Preset Assistant:
Automatically activates the correct preset for the anatomy being scanned

Auto Abdominal Color Assistant:
Detects which abdominal organ is being scanned, automatically switching to the optimal color flow parameters

Auto Renal Measure Assistant:
Automatically detects the kidney and measures the length, height, and width",Clinician decision support and workflow error reduction.
VA-216,Smart AI Bot Assistant,VA,VHA: Veterans Health Administration,"A machine learning and natural language processing algorithm will be trained to provide real-time prompts of resources to improve the quality of crisis calls for the Veterans Crisis Line (VCL). Curated, vetted resources will be prompted by keywords for responders to consider during a crisis call. Natural language processing will be used to listen and document during and after the call, organizing the documentation to include topic areas and key points. This will decrease the time spent on documentation, improve the responder workflow, and provide needed downtime for responders to debrief with colleagues and take breaks. Additionally, the chat bot could detect the need for supervisory support during a call, improving real-time communication between a VCL responder and their supervisor. The use cases for the AI will be reviewed by VA experts and subject matter experts, with the draft use cases requiring technical steps to build, pilot test, and refine.","Smart Responder Chat Bot Use Case #1 – Real time resources for VCL responders   Using machine learning and natural language processing an algorithm will be trained based on feedback from the Veterans Crisis Line staff and crisis line responders to provide real-time prompts of resources to improve the quality of the crisis call. Curated, vetted resources will be prompted by key words for the responder to consider using during a crisis call.   Smart Responder Chat Bot Use Case #2 – AI documentation for VCL responders   To improve the time each Veterans Crisis Line responder spends on documentation during and after a crisis call, natural language processing will be used to listen and document during and after the call. The documentation will be organized to include the topic areas and key points required in documentation and provide a final draft editable by the responder. This use case will; decrease the time spent by responders on documentation, improve the responder workflow for VCL operations, and provide needed downtime away from both answering calls and documentation for responder to debrief with colleagues, accomplish other tasks and take necessary breaks to improve overall responder wellbeing.   Smart Responder Chat Bot Use Case #3 – AI for supervisory support during a call   Using machine learning and natural language processing including sentiment analysis, a chat bot could detect the need for a responder to seek supervisory support. Improving the real-time communication between a VCL responder and their supervisor during a call that is challenging (eg. Inappropriate language, escalating rapidly, etc.) could be a useful use case."
VA-245,Radiology - Siemens YSIO Max,VA,VHA: Veterans Health Administration,Bone supression: Supressess bones on digital images without the need for two exposures. Diamond View: improves image contrast and detail to improve image quality.,Increase radiology digital image quality.
VA-257,Enterprise Precision Scanning and Indexing (EPSI) Next: Enhancing Healthcare Services for Veterans,VA,VHA: Veterans Health Administration,Generative AI required for summarization and note creation.,The output generates a summary of the patient health record for the EPSI product indexer workflow.
VA-294,Nursing Proficiency Coach & Nurse Proficiency Evaluator...and beyond!,VA,VHA: Veterans Health Administration,"Two custom GPTs have been created: Nurse Proficiency Writer and Nursing Proficiency Coach.  A GS version is in development.  The Nurse GPTs are used to compare the nurse's self-input against 600+ functional statements and standards (externally accessible or approved by the Office of Nursing Service).  It evaluates the nurse's performance against the standards, reports on positive findings, identifies weak areas, provides an estimated rating, and grade assessment.  The interactive GPT allows nurses to have a dialog to better understand how their practice can be improved.   Many of our 90,000+ RNs are not proficient in understanding the standards nor adept in writing performance reports. This leads to end-user frustration, quality issues with content, submission gaps compared to the standard, interrater reliability variances, and a host of other challenges with the our current process. The tool aids the nurses in developing the content for their ePerformance submission.  No PHI is allowed in nursing proficiencies (by standard), and PHII is scrubbed prior to submission by the nurse. ","
The output takes the nurse's input and returns a summary of each practice dimension and positive accomplishments offering suggestions where the nurse can improve.  The tool can help the nurse in generating a written summary for ePerformance submission.  This is a tremendous time saver and improves the quality of their submission.  Most importantly, the Custom GPT does not impact the staff rating.  It is a tool is designed to help the nurse.  The nurse is ultimately responsible for the content and final submission (data accuracy and validity), and the proficiency evaluations are the responsibility of the Supervisor with knowledge regarding the staffs performance.  The improvment in content can greatly assist the Supervisor in their evaluation process (win-win).      
"
VA-372,Parable 3D Wound Care Management System,VA,VHA: Veterans Health Administration,"Traditional wound care methods call for hand measurements to be taken of the patients wound, increasing imprecision that comes with manual measurements, along with the increased contact with the wound and potential for infection. Parable 3D Wound Care Management System aims to automate the process of wound care by using traditional computer vision based volumetric measurements to capture images of the wound and create 3D polygon mesh representation of said wound. The main benefit of the system is the automated, contactless measurements that will reduce vectors for infection and alleviate the difficulty, imprecision, and variability of manual measurements. This allows the clinicians to spend more time on patient care, analyzing wounds, and encourage proper healing for the patient.","2D and 3D volumetric measurements are computed based on the segmented 3D reconstruction to produce length, width, surface area, depth, and volume measurements."
VA-380,VEO Virtual Analyst Proof of Concept,VA,OIT: Office of Information & Technology,The AIDV Dev/Test environment will provide a proof of concept to provide generative AI capabilities in CX Insights and SDP. This will show capability to allow users to intuitively and easily work with dummy data and provide a sandbox to develop generative AI tools. The development of Virtual Analyst tool will provide value to the veteran by using generative AI to predict and improve services to the veteran.,Outputs will include data-informed English-language responses to English-language questions asked about VEO machine learning models and customer experience metrics. These outputs will be informed by dummy versions of these data.
VA-413,GE Portable Critical Care Suite 2.x,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K183182.pdf).
VA-421,Patient Care Systems Integration Program (PCSIP),VA,VHA: Veterans Health Administration,"The PCSIP AI is intended to improve the access to care for Veterans by increasing capacity of VAMCs up to 20% without adding more staff or resources. 
The expected benefits of the AI are listed below. 
(1) Between 20% to 50% reduction in charting time. 
(2) Reduced cancellations/delays/no-shows between 5% and 40% depending on type of appointment of patient. 
(3) Between 5% and 20% increase in number of scheduled cases in surgery, primary care, radiology, behavioral health, and specialty care.
(4) Between 5% and 20% improvement in Door-to-Doc times and Length of Stay in Emergency Department.
(5) Between 5% and 20% improvement in patient flow between ED and Wards; and between Surgery and Wards.
","All outputs listed below are written to patient record in Vista/CPRS and Cerner after review by care providers and electronic signature by them. 1. Ambient Dictation and AI generates,       a. ED Triage Note,        b. ED Evaluation Note,        c. Columbia SSRS,        d. After Visit Summary,        e. Follow up appointment note,        f. Patient Letter       g. Care Pathway Mapping for generating list of diagnostic orders, medication orders etc. 2. Radiology        a. Resulting Note in MRI, CT, Ultrasound, X-Ray, and others.       b. Protocoling by Radiologist and Technologist notes written to Vista  3. Surgery       a. Scheduling optimization       b. Preop readiness checks and reports       c. Preop Instruction Compliance       d. Discharge Instruction Compliance       e. ERAS protocol compliance 4. Behavioral Health       a. Generation of Columbia-SSRS and Comprehensive SSRS for suicide reduction       b. Video monitoring of mental health inpatients 5. Primary Care       a. Ambient Dictation driven note generation.       b. Outside records consolidation for Patient Summary extracted from faxes. 6. Instant availability of all the relevant patient information at the point of care based on schedule of the patient and location of the patient and care provider at the point of care."
VA-462,Billing Claims Prediction,VA,VHA: Veterans Health Administration,The intended purpose of the AI is to support Revenue Operations Billing activities by providing a propensity to bill flag based on previous user activity in the Revenue Operations Workflow Tool. The output of the AI is strictly intended to be used for decision support for users who are determining whether an encounter is billable or not. ,"The model was trained on Third Party Community Care Billing and Facility Revenue Activity Codes 10, 30, 31, 32, 33, 34, 35 applied from 2021-2023. Initial run at Florida Caribbean Consolidated Patient Account Center (FCCPAC) was trained on 1.2 Million accounts. By training the model on previous activity data, an account can be classified as likely to have a billable or non-billable outcome."
VA-503,ScienceLogic Artificial Intelligence Operations (AIOPS) Software Subscriptions with Maintenance and Professional Support Services.,VA,OIT: Office of Information & Technology,Performance monitor of cloud applications ,"The SL1 AIOps solution enables VA to  diagnose reasons for outages and rapid capability to respond, resolve and prevent such  outages across the full domain."
VA-540,ECG/EKG Machines- Interpretation of Results,VA,VHA: Veterans Health Administration,This software aids with interpretation of  clinical Electrocardiogram tracings for VA clinicians. ,"The system integrates w/ CPRS and outputs patient demographics on the ECG print-out.  It then prints a list of notable findings from the ECG on the form that is later reviewed and confirmed or overturned by a licensed provider.   In many cases, the machine interpretation is correct and is confirmed by the provider."
VA-544,Appointment Comments Categorization,VA,OIT: Office of Information & Technology,To deliver additional timely options for patients that are having mental or physical issues during appointment signup.,"Right now, I'm focusing on alerting around mental health, so the model will return, ""Timely_Alert_Needed, 0.xxxxx"""
VA-659,TeraRecon,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220349.pdf).
VA-708,Ambient AI scribe,VA,VHA: Veterans Health Administration,"Human scribes have been effective toward decreasing clinical documentation burden, increasing physician satisfaction, and decreasing physician time spent in the EHR during patient visits. However, notes written by humans are variable in quality. In addition, scribes are costly, requiring time to train and have high turnover. Ambient AI medical scribes and solutions to automate document processing show promising as potential solutions to reduce physician burnout. VA recently completed an AI Tech Sprint in this space and intends to pilot several of these solutions at VA Medical Centers. ",The system produces written summaries of clinical encounters
VA-790,Pension Optimization Initiative (POI),VA,VBA: Veterans Benefits Administration,"VBA’s POI is a transformative effort that seeks a Managed Services Provider (MSP) to convert an existing manual business process into automated processing of Pension and Survivor claims. The goal is to have 75% of claims completed by automation with claims processing quality that is equivalent to, or greater than, existing manual processes. ","The following is high-level scenarios describe the inputs --->automated processes--->outputs:  Scenario A:  Claimant submits application for benefits via handwritten, typed, or VA.gov submission  --->  POI automation extracts data from forms and other documents submitted with application  --->  extracted data and existing Veteran/Beneficiary file data is processed in accordance with business rules to determine outcome of claim  --->  outputs are:  -updated Veteran/Beneficiary files, -completed Pension-related claim actions to include stop and start of awards (delivery of benefits), and -Notification Letters to Claimants.  Scenario B:  same as above, except, claim is established via computer matching agreement with other Government agencies (e.g. Social Security Administration) or other VBA-internal process rather than actually receiving an application from a claimant."
VA-913,Limited Use of Azure Speech Services in PETALS Platform,VA,VHA: Veterans Health Administration,"We have specific and limited use of Azure Speech Services in PETALS Platform, where Azure Speech Services will read either (a) a participant first name or (b) a numerical step count, and then read-aloud that content to validate the user and information input provided by user during program engagement. ",Audio verbalization (speak-aloud during telephone engagement) of a first name and of a numerical step count.
VA-954,Medallia SaaS - VSignals and ESignals,VA,VEO: Veterans Experience Office,"Medallia is a customer experience management platform which can leverage AI (NLP) to review survey comments for actioning.   VSignal survey comments (from Veterans) are processed by NLP to HELP determine if a Veteran is potentially in risk of crisis (related to homelessness and mental health).   If NLP flags a comment as a potential risk, a case is created and sent to the Crisis Line and Homeless Program for review and actioning.",See above
VA-1069,AGFA Dose Monitor system,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K180589.pdf).
VA-1114,Volpara Imaging Patient Hub,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf21/K211279.pdf).
VA-1159,Identity Governance and Administration (IGA),VA,OIT: Office of Information & Technology,"The purpose and expected benefits of the AI are to reduce risks within VA workforce regarding access management. For example, the IGA tool will generate risk scores for access requests, allowing automation to approve low risk requests automatically while flagging others that are high-risk, sensitive, or critical for manual review. ","The system will display risk scores on a dashboard, send email notifications about access requests needing to be reviewed, or recommend access certifications/reviews."
VA-1200,VET-HOME Contact Center AI ,VA,OIT: Office of Information & Technology,We're looking to explore the use of AI to give VA customer service agents better situational awareness to a Veteran through the use of AI tools to summarize and contextualize queries received through our contact centers.  ,"We'd like to train custom co-pilots on data used by the contact center CRMs, to be able to proactively pull up information relevant to the conversation and the Veteran's queries.  The output would be a window that would display information relevant to the Veterans needs at that time based on the contact center they are working with."
VA-1237,Beckam Coulter DxH 800,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf12/K120771.pdf).
VA-1323,UIPath Document Understanding,VA,VHA: Veterans Health Administration,The tool enables Optical Character Recognition and data extraction from submitted documents through AI document processing.  This tool can extract data accurately and efficiently to allow automations to input or use the data for other applications.  ,"UiPath's Document Understanding will provide computerized information from forms and documents (computer generated or handwritten) that can be used by the automation to add information to other applications, or present to assist in decisions by the Agents for Veterans."
VA-1360,Potential Fraud or Waste,VA,OM: Office of Management,"The Purchase Card dashboards are a suite of dashboards that allow various purchase card managers to monitor purchase card spending of employees. The dashboards help monitor for fraud, waste, and abuse, and assist in providing oversight for compliance with purchase card laws and policies. We have now incorporated advanced data analytics within the dashboard. The Advanced data Analytics model generates an expected received date for items. It then flags items that have gone beyond the expected generated date by flagging items that were received late (possible waste) and/or items that have not been received yet (possible fraud). This has the potential to save the analyst time by investigating cases that have been flagged as opposed to investigating potentially an entire dataset, which is what they have been doing up until now. The model analyzes all purchase card transactions including ordered, delivery, and recieved dates as its inputs. It outputs expected recieved dates. The intended users of the product are purhase card managers. ",The Advanced data Analytics model generates an expected received date for items. It then flags items that have gone beyond the expected generated date by flagging items that were received late (possible waste) and/or items that have not been received yet (possible fraud).
VA-1442,Roche Digital Pathology ,VA,VHA: Veterans Health Administration,To aid pathologists in diagnosing pathology cases.,It analyzes slide images to aid in diagnosing
VA-1475,Activity recognition using wearable sensors for use in closed loop deep brain stimulation systems,VA,VHA: Veterans Health Administration,"To accurately recognize/classify a number of different activities of daily living (walking, standing, sitting, lying down, etc.) using accelerometry/gyroscopic data. This could be used in a number of different applications. ",Described above. A classifier that outputs a recognized behavior in real-time based on changes in accelerometry/gyroscopic data.
VA-1561,VCA & PPMS Chatbot ,VA,VHA: Veterans Health Administration,"The Network Support VCA & PPMS ChatBot, a virtual agent designed to assist field staff with questions related to VCA & PPMS. This tool was designed to provide answers to frequently asked questions received from the field.","The VCA and PPMS teams have compiled a wide range of FAQs received from field staff to develop this easy-to-use tool that instantly provides users with the VCA & PPMS resources they need, whenever they might need them."
VA-1565,AgileMD eCART Clinical Deterioration Model,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K233253.pdf).
VA-1647,PINGOO.AI,VA,VHA: Veterans Health Administration,Edcuational infomrational app that uses a RAG model to provide up to date and trustrowthy infomration to Veterans who are diabetic. ,Output is infomation that is related to the RAG model communicated to the Veteran through a language model interface.
VA-4648,Persyst 14 EEG Review And Analysis Software,VA,VHA: Veterans Health Administration,"Persyst EEG Review and Analysis Software provides the complete set of tools needed for C.A.R.E (Computer Assisted Review of EEG), resulting in accurate, efficient and rapid review of EEG data.Link to the vendors website -
https://www.persyst.com/","It uses prespecified but customizable parameters for seizure detection, spike detection, trending of EEG signals, artifact reduction and monitoring. Its a commercial off the shelf product used widely in the field as well as public and private hospitals.
"
VA-1684,Computer Aided Detection (CADe) of Neoplasia during Colonoscopy - “GI Genius”,VA,VHA: Veterans Health Administration,"GI Genius™, a commercial product distributed by Medtronic, Inc., is a computer-aided detection module, powered by artificial intelligence, designed to aid endoscopists in detecting colonic mucosal lesions (such as polyps and adenomas) during colonoscopy. The FDA cleared this commercial product in April 2021.
The device physically connects to existing endoscopes, video processors, and display monitors, but does not connect to the VA network.
During endoscopy, the CADe device automatically detects, and highlights suspected neoplastic lesions / polyps in real time. The module was trained and validated with white-light endoscopy videos and continues to be refined with growing datasets. Information about the indications, safety and warnings can be found here: GI Genius™ Intelligent Endoscopy Module - Indications, Safety, and Warnings | Medtronic (https://www.medtronic.com/covidien/en-us/products/gastrointestinal-artificial-intelligence/gi-genius-intelligent-endoscopy/indications-safety-warnings.html)
Multiple studies and meta-analyses have found these devices increase adenoma detection rates, a well-established metric for colonoscopy quality that is related to colon cancer incidence and death. Initial randomized implementation of the devices across VA facilities allowed for a pragmatic evaluation of the impact of these devices on adenoma detection. The evaluation demonstrated that the provision of colonoscopy CADe devices resulted in a statistically significant 21% increase in the odds of adenoma detection and an absolute increase in ADR of approximately 4% compared to colonoscopy without CADe. These devices will improve ADR, which should decrease colorectal cancer incidence and mortality amongst Veterans over time.
","The device physically connects to existing endoscopes, video processors, and display monitors, but does not connect to the VA network.  During endoscopy, the CADe device automatically detects, and highlights suspected neoplastic lesions / polyps in real time on the display monitor."
VA-1729,Digizens,VA,VHA: Veterans Health Administration,Behavioral prediction model used to create clinical trials without the need for actual patients or patient information. ,Output is behavioral analysis and predictions based on messaging and circumstances.
VA-1766,TrueFidelity CT Deep Learning Image Reconstruction,VA,VHA: Veterans Health Administration,Decreases noise in CT images ,
VA-1770,Pangaea,VA,VHA: Veterans Health Administration,Devellop predictive model for chronic disease with treatment recommendations based on current guidelines. ,Output will be identification of chronic disease in Veterans and treatment modalities required prior to consulting specialty services.
VA-1803,AIDOC,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K230020.pdf).
VA-1811,Cogitativo,VA,VHA: Veterans Health Administration,Predict chronic disease,Output is based on Veteran profiles utilizing data model built from previously obtained Veteran profiles by the company Cogitativo. It is unclear how the company obtained the data.
VA-1815,"Analytics, Data, and Decision Support Unified Platform (ADDSUP)",VA,"OALC: Office of Acquisitions Logistics, and Construction","Using AI enhancements, this tool can quickly filter contracts and line items to facilitate easy searching, as well as provide quick answers to enhance our ability to obtain cost avoidance.  ",The system will output a list of contracts or line items based on search criteria entered by the user.
VA-1848,iCAD ProFound AI,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf20/K203822.pdf).
VA-1897,VA Section 508 Office URL Ownership Prediction Model,VA,OIT: Office of Information & Technology,"Purpose of the AI system is to predict the administrative agency that owns URLs.  The AI system reduces the level of effort and turnaround time for the OIT 508 Office to curate URLs and coordinate with VA Administrations to review and, as necessary, remediate URLs for accessibility compliance.  In the absence of the AI system both the 508 Office and VA Administrations would be required to undertake a lengthy and iterative process to identify the VA Administration that is the formal owner of a URL.","The AI Model has two outputs.  1) Agency Owner with responses as: VHA, VBA, NCA, VACO, OIT, OCTO, and Unknown.  2) Prediction Score ranging from 0 to 1.  The system is comprised of manually executed scripts using the AI model on local GFE.  Besides the AI model, the scripts additionally apply manually constructed business rules and create prepopulated excel files for each VA Administration to use for quarterly reviews and data entry."
VA-1934,Circle CVI42 ,VA,VHA: Veterans Health Administration,This software is for improving efficiency in post processing and reporting of Cardiac MRI and Cardiac CT images. ,"It replaces manual contouring of different cardiac structures by automated segmentation. Output includes: ejection fraction, strain, stroke volume , coronary calcium score etc. All outputs of the AI based software are FULLY CHECKED  by the cardiologists for accuracy and the outputs can be easily altered by the reading physician  before they are reported in the patients chart."
VA-1938,National Cemetery Administration (NCA) Automated Claims Processing,VA,NCA: National Cemetery Administration,"The purpose of the AI is to automate aspects of NCA benefits and application processing.  Currently it is applicable to the Pre-Need and Presidential Memorial Certificate programs. In the future other business lines may be included, such as the Headstones, Markers, Medallions, and Urns and Plaques programs. This benefits NCA by automating aspects of the workload (data entry, case creation, document digitization, letter creation, status updates). ","The Hyperscience platform (optical character recognition (OCR), natural language processing (NLP), and machine learning (ML)) extracts document data, uses application programming interfaces (APIs) to query data from other VA systems, and applies robotic process automation (RPA) to enter data into existing legacy NCA systems: Eligibility Office Automation System and Web Presidential Memorial Certificates.  As the case is processed, automation creates documents that combine relevant claimant information for use by claim agents, updates statuses, and creates letters as appropriate. No original content is created through these processes."
VA-2008,VA CART Adenoma Detection NLP,VA,VHA: Veterans Health Administration, Extracts adenoma status for CART Veterans using Natural Language Processing (NLP) of VistA colonoscopy surgical pathology reports,Results contain 0 for no evidence of adenoma or 1 for evidence of adenoma in the pathology report
VA-2143,Call Center Knowledge Navigator,VA,VBA: Veterans Benefits Administration,"Using VA-provided procedural reference material, the tool will respond to call center agent questions with an answer and a cited reference to verify the answer. The tool is intended to speed responses by quickly identifying relevant references and summarizing procedures in the form of an answer, while also providing the agent with the means to look up the referenced material.",The system will output a generated response to a user's question.
VA-2184,National Training Team | Schools — FAQ Dashboard,VA,VBA: Veterans Benefits Administration,"The 1.0 dashboard clusters thousands of submitted questions during a monthly Office Hours session with School Certifying Officials and presents a ""top ten"" list of associated categories that have the most questions.",Classification and sentiment score
VA-2266,National Training Team | Schools — FAQ Dashboard,VA,VBA: Veterans Benefits Administration,"The model should classify thousands of questions into categories, generate a sample question based on the category, and provide a suggested answer based on previous responses to similar questions.","Classification, list of questions, answers to questions"
VA-2307,Audit of Service Connection Designations Associated with Prescriptions,VA,VHA: Veterans Health Administration,"Reduction in waste, fraud and abuse. ",Binary
VA-2336,PsychCorpCenter,VA,VHA: Veterans Health Administration,The program is used to do multiculturally sensitive scoring of cognitive scores to make diagnostic impressions more accurate.,The information processed from the input of the providers on a specific Veteran/patient  and then a report is generated/processed from the information that was inputted.
VA-2348,ReflexAI,VA,VHA: Veterans Health Administration,"AI-powered simulations to provide nuanced, high-quality practice and real-time feedback to every individual undergoing training to serve as a responder on Veterans Crisis Line.","All information is accessible for training staff within the secure platform hosted on VA Enterprise Cloud. This data include simulation content and the instantaneous feedback across the scoring dimensions. This output includes insights on training effectiveness overall, as well as progress of individual trainees who are going through the training process."
VA-2377,"Prostate Cancer, Genetic Risk, and Equitable Screening Study (ProGRESS) - Prostate Cancer Risk Prediction Model",VA,VHA: Veterans Health Administration,"This risk model is being used within the framework of a nationwide, VA funded randomized controlled trial to deliver a precision prostate cancer screening intervention to research participants. The model uses machine learning components (e.g., training and validation sets from MVP and other external sources, LASSO-regularized Cox model) and genetic, ancestry, and self-report family history of prostate cancer data to develop and validate a risk prediction model to help stratify new participants into three distinct prostate cancer risk categories (low risk, average risk, high risk). The risk classification is then included as part of a comprehensive report, including a full risk model report from a VA-approved genetic testing laboratory, a monogenic genetic variant report from a VA-approved genetic testing laboratory, and a summary sheet which provide general information and risk-specific recommendations surrounding prostate cancer screening. The report is shared with the participant and their VA healthcare providers as additional information to be used within the  framework of shared decision-making regarding future prostate cancer screening. ","The risk model uses new participant data to output a risk classification for prostate cancer based on genetic, ancestry, and self-report family history of prostate cancer data (low risk, average risk, high risk). The classification is is then included as part of a comprehensive report that is delivered to the participant and their VA healthcare providers to be used within the framework of shared decision-making regarding future prostate cancer screening."
VA-2422,"Using AI to enhance/augment classification of reported patient safety events, and to proactively identify patient safety vulnerabilities and potential areas of improvement",VA,VHA: Veterans Health Administration,This system allows statisticians to identify trends and anomalies to proactively determine patient safety areas of improvement by identifying any new type of safety event and any abnormal increase in frequency of events and stop them before they become widespread.,Augmented event type classifications
VA-2426,App feedback model for NLP tasks,VA,VHA: Veterans Health Administration,"Functional Overview: The objective is to utilize Natural Language Processing (NLP) with comment reviews for App feedback, specifically to identify named entities (NER), profanity, and stop words, and provide an automated approach to pre-processing and cleaning text for downstream analytics tools.
 
System Overview: The system uses spaCy's en_core_web_sm model, an open-source software and model, to analyze text reviews from various sources, including external sources (Google and Apple stores) and internal sources (FeedbackUI and VA Mobile). The model provides an out-of-the-box approach for NLP tasks, including NER, profanity detection, and stop word removal.
 
Data: The data sources include:
 
Text reviews from the VA's mobile applications on the Google and Apple stores (external sources)

Reviews from FeedbackUI (internal source, available in the OIA_MobileHealth database)

Reviews from VA Mobile (internal source, available via CSV files on the Mobile VA's internal website)

Users: The users of this system are likely the OCC Data Science Team, who are responsible for developing and maintaining the pipeline.
 
Target Audience: The target audience mobile application developers and other internal stakeholders who may be interested in analyzing and understanding the sentiment and feedback from these reviews.
 ","The objective is to utilize Natural Language Processing (NLP) with comment reviews for App feedback, specifically to identify named entities (NER), profanity, and stop words, and provide an automated approach to pre-processing and cleaning text for downstream analytics tools."
VA-2430,TERA Memorandum Automation,VA,OIT: Office of Information & Technology,"Toxic Exposure Risk Activity (TERA) Memorandum Automation utilizes natural language processing (NLP) based algorithms to provide recommended decisions to support completing the TERA Memorandum form, a form that is required to be completed for most Veteran Disability Claims. This functionality will allow approved Veteran Service Representatives (VSRs) to auto-populate certain questions within the TERA Memorandum form in VBMS using evidence stored in the Claims Evidence drastically reducing the amount of time needed to manually review documents in Claim Evidence (eFolder) and streamlines claim processing. The system currently leverages data from C&P’s Smart Search service and utilizes NLP-based algorithms to identify potential evidence to support recommended decisions on specific questions of the TERA memo. The specific output includes an open-text field response with confidence score and links to documents for manual review. The intended users of the system are VSRs who complete the TERA memo. ","Toxic Exposure Risk Activity (TERA) Memorandum Automation utilizes natural language processing (NLP) based algorithms to provide recommended decisions to support completing the TERA Memorandum form, a form that is required to be completed for most Veteran Disability Claims. This functionality will allow approved Veteran Service Representatives (VSRs) to auto-populate certain questions within the TERA Memorandum form in VBMS using evidence stored in the Claims Evidence drastically reducing the amount of time needed to manually review documents in Claim Evidence (eFolder) and streamlines claim processing. The system currently leverages data from C&P’s Smart Search service and utilizes NLP-based algorithms to identify potential evidence to support recommended decisions on specific questions of the TERA memo. The specific output includes an open-text field response with confidence score and links to documents for manual review. The intended users of the system are VSRs who complete the TERA memo."
VA-2459,XtractOne,VA,VHA: Veterans Health Administration,"The new WDS will allow the VA Police to centralize all the facilities WDS reporting to one place allowing the VA to use manpower properly, allow them to also have better eyes on the WDS, and also allow them to have Enterprise solutions to allow upper management to see what is going on through the SaaS solution. This solution will also allow the VA Police to send out reports or alerts to Upper management and VA Police so they can mobilize and report to where the issues are quicker, efficiently, and effectively. This will also allow the VA Police to lock down facilities easier than before where that was not possible without going to said doors and locking them physically. The WDS can do that for the VA Police now.

The key benefits are having a fully modernized weapons detection system to help the VA Police better detect unauthorized weapons entering and exiting the VA Facilities allowing the VA Police to do their job more efficiently and effectively. This will also all the VA Police to use their manpower in proper means instead of wasting man hours and money.","Xtract One View is equipped with advanced analytical tools that process vast amounts of data to detect unusual patterns and potential threats before they escalate. Using machine learning algorithms, it continuously improves its concealed weapons detection capabilities, adapting to new types of risks and optimizing security protocols accordingly."
VA-2463, Using AI to weekly monitoring of any harms resulting from the use of newly implemented electronic health record system – FEHR across VA,VA,VHA: Veterans Health Administration,This AI based monitoring system will be used to inform and improve the EHR system and it's functionalities to prevent and mitigate any patient safety events.,Classification of harm categories from EHR
VA-2500,Podimetrics,VA,VHA: Veterans Health Administration,"Our involvement with Podimetrics is limited to receiving and processing escalation reports generated by their SmartMat system. Podimetrics’ platform uses its proprietary technology, to generate these reports. However, our role does not involve developing, deploying, or controlling  AI systems. Instead, we serve as a conduit, ensuring that these escalation reports are shared with the appropriate clinicians to facilitate timely and informed care for Veterans.","Our interaction with the Podimetrics platform is strictly limited to data transfer and integration of the generated reports. We do not engage with their proprietary technology, or decision-making processes inherent in the Podimetrics platform. Our role is supportive and integration-focused, solely aimed at ensuring seamless communication and clinical follow-up based on the provided reports."
VA-2504,Thematic Analysis of Chief Resident in Quality and Patient Safety (CRQS) Capstone Projects Using BERT Modeling,VA,VHA: Veterans Health Administration,"The intended purpose of the AI is to perform a detailed thematic analysis of CRQS capstone projects to identify key themes and trends, with the expected benefit of enhancing the national curriculum for quality and patient safety in healthcare.","The AI system's outputs will be categorized themes, patterns, and trends derived from the analysis of CRQS capstone projects, which will inform curriculum development and improvement strategies."
VA-2508,My HealtheVet VSignals Main Improvement Summary,VA,VHA: Veterans Health Administration,"My HealtheVet is the VHA patient portal to access to refill medications, secure message with care teams, access medical records and view appointment information.  To ensure Veterans are being provided the best patient portal experiences, My HealtheVet collects many surveys (over 26k a month).  AI provides initial summarizing and grouping functions for open-text questions to identify trending issues and new features requested.  Rather than having humans read each comment and manually sorting, AI enhances trend identification and resource prioritization.","Veteran feedback is stripped of PII and then sorts comments based on product area, summary is primarily based on how often key words are mentioned."
VA-2512,ESD-Speech Sentiment and Analytics,VA,OIT: Office of Information & Technology,Utilizing AI to analyze speech sentiment of internal customers (non-veterans) to improve quality of service at the Enterprise Service Desk.,Various reports and dashboards for ESD leadership and the Tier 1 vendor partner to assess quality of service.  The AI component makes it possible to assess and analyze all contacts with the ESD as opposed to the ~2% of contacts we can assess today using manual approaches.
VA-2545,Privacy Act Automation Services - Disclosure.AI,VA,VBA: Veterans Benefits Administration,"The PAA System will automate PA workflows that are currently highly manual. Automating PA processing will benefit Veterans by decreasing the time they have to wait to receive requested records, and it will benefit the VA by reducing the time that staff need to support PA request processing. Tools/techniques that may be categorized as AI improve the automated processing that provide these benefits, but AI technology is ancillary to other technology utilized in the PAA system. Machine learning is used to identify specific documents (DD-214, Decision Letters, Service Records, etc.) and AI is used to improve and expedite data extraction as well as identify and apply automated redactions. The process is designed with Human in the Loop (HITL) and Government in the Loop (GITL) roles.","The PAA System automates the process of ingesting PA requests, retrieving requested records, and redacting requested records when necessary. The outputs of the PAA System are reviewed by Deloitte’s managed service team and by the VA for accuracy and completeness before the requested records are sent to the requester. The outputs consist of records held by VBA within Claim Evidence (VBMS) that have appropriate redactions applied for 3rd party information before release to the 1st party requestor or their designee."
VA-2549,Sentiment analysis for app feedback,VA,VHA: Veterans Health Administration,"Functional Overview: The objective is to perform sentiment analysis on text reviews to classify their content as positive, negative, or neutral, and to provide a processed dataset for further downstream analytics.
 
System Overview: The system uses a trained model, derived from an open-source model and fine-tuned for the specific dataset, to analyze text reviews from various sources, including external sources (Google and Apple stores) and internal sources (FeedbackUI and VA Mobile). The model classifies reviews as positive, negative, or neutral.
 
Data: The data sources include:
 
Text reviews from the VA's mobile applications on the Google and Apple stores (external sources)

Reviews from FeedbackUI (internal source, available in the OIA_MobileHealth database)

Reviews from VA Mobile (internal source, available via CSV files on the Mobile VA's internal website)

Users: The users of this system are likely the OCC Data Science Team, who are responsible for developing and maintaining the pipeline.
 
Target Audience: The target audience OCC mobile application developers and internal stakeholders who may be interested in analyzing and understanding the sentiment and feedback from these reviews.
 ","perform sentiment analysis on text reviews to classify their content as positive, negative, or neutral, and to provide a processed dataset for further downstream analytics."
VA-2553,ESD-Predictive Intelligence,VA,OIT: Office of Information & Technology,The intended purpose is to leverage Machine Learning on existing ticketing data supporting internal customers (non-veterans) to reduce mean time to resolution for internal customers while also increasing ticket routing accuracy and identifying major incidents more quickly as they occur.,Outputs involve pre-populated assignment groups in tickets within the ServiceNow IT Service Management platform to provide more accurate ticket routing and dashboard information for Incident Management staff to review highlighting potential major incidents beginning to occur in the environment.
VA-2582,AI Health Coach,VA,VHA: Veterans Health Administration,The Health Coach and AI components are different. The Health Coach helps improve adherence by sending evidence based nudges (this doesn't involve AI). The AI makes the health coach more effective by adjusting the number of nudges sent to the engagement of the Veteran.,"The Health Coach has a pre-selected decision tree (ex: did you miss your medication -> if yes, how many medications did you miss -> did you miss them because you ran out of refills). The AI simply helps determine how often to send those nudges based on response rates."
VA-2623,Verathon Prime Plus,VA,VHA: Veterans Health Administration,It's a bladder scanner.  The AI component is used in relation with detection of bladder.  It's aim is to increase accuracy.,It outputs assisted measurements related to bladder size and shape.
VA-2672,App Feedback categorization model,VA,VHA: Veterans Health Administration,"Functional Overview: The objective is to categorize review texts into specific categories to provide more granularity and enable users to identify trends and perform analytics on the data.
 
System Overview: The system uses a trained open-source model that has been fine-tuned on the app feedback data to categorize review texts into specific categories, including Tech, Usability, Content, Idea, and Other.
 
Data: The data sources include:
 
Text reviews from the VA's mobile applications on the Google and Apple stores (external sources)

Reviews from FeedbackUI (internal source, available in the OIA_MobileHealth database)

Reviews from VA Mobile (internal source, available via CSV files on the Mobile VA's internal website)

Users: The users of this system are likely the OCC Data Science Team, who are responsible for developing and maintaining the pipeline.
 ",The objective is to categorize review texts into specific categories to provide more granularity and enable users to identify trends and perform analytics on the data.
VA-2713,LINQ and  LINQ II Loop Recorder ,VA,VHA: Veterans Health Administration,Implantable heart monitoring device. This continuously checks the heart rhythm and rate.  ,The information (recordings) are remotely transmitted and recorded for interpretation by a Medical provider.
VA-2717,VA.gov Chatbot: Use of AI for summative and/or intent classification of Va.gov content,VA,OIT: Office of Information & Technology,"The VA.gov Chatbot currently uses Natural Language Understanding (primarily driven by Microsoft Power Virtual Agents (PVA) and Custom Question Answer (CQA)) to interpret Veterans' intent and match it to responses within the knowledge base.

The future state vision for the VA’s chatbot solution involves leveraging advanced AI services and capabilities to increase the breadth of questions that the Chatbot will be able answer, to improve the accuracy of each answer, and in cases of necessary channel escalation, to accurately match user utterances to contact center routing queues.",Input: Understanding user intent: Copilot can determine what the user is trying to accomplish based on their query. Output: Generating relevant responses: The AI can then provide a suitable response or action based on the user's intent.
VA-2754,ZIO PATCH HEART MONITOR,VA,VHA: Veterans Health Administration,Records the heart rate and rhythm for up to 14 days to diagnose arrhythmias and any other electrical conduction issues.,
VA-2758,Caller intent classification using Google Dialogflow (VoiceBot),VA,OIT: Office of Information & Technology,"This project is part of the Unified Communications goal of modernizing call centers. AI (as NLU/NLP) can expedite triage, improve caller-to-agent matching, and handle routine tasks (through APIs) without agent support. ","Mainly conversational output. The VoiceBot will act as a caller-concierge, helping Veterans locate the right agent and/or solve tasks (e.g., claims status checks). Conversational scripts, including intents, entities and slots will be stored in CXI and/or other databases (e.g., Clarabridge) standard to VA call centers today."
VA-2791,Ordr,VA,VHA: Veterans Health Administration,Ordr SCE Analytics employs advanced artificial intelligence and machine learning (AI/ML) technologies to further assist in the classification of local networked devices required for accurate device inventory. AI/ML enhances and accelerates the classification process by identifying specific behavior patterns that are unique to certain devices. These passive classification techniques are minimally invasive and do not rely on active scanning methods which are often disruptive to sensitive business-critical IoT devices.,Only network device metadata is forwarded to the SCE Analytics server. Sensitive data such as PHI is immediately discarded so that only metadata which contains information pertinent to device identification is forwarded.
VA-2795,Machine Algorithm for Report Surveillance (MARS),VA,OEHRM: Office of Electronic Health Record Modernization,The purpose of the MARS tool is to identify end-user submitted federal EHR incident reports that are likely to affect patient safety.  The MARS tool will augment the existing manual incident report review process.       ,The output of the system is a list of ServiceNow tickets that require human review to validate the MARS determination that the issue described in the ticket is a patient safety issue.
VA-2828,Pharmacy AI Managed Inventory System (PHAIMIS),VA,VHA: Veterans Health Administration,"PHAIMIS will be an AI-powered inventory management system to centralize and optimize inventory processes within the VA Pharmacy Service. This system will integrate AI and data analytics to streamline inventory management, provide real-time notifications, and enhance user experience through seamless integration into existing workflows.","System outputs will include demand forecasting, procurement strategy optimization, and dynamic inventory thresholds.  It may also include anomaly detection alerts and other features."
VA-2836,Silverberry Surgery Planning AI,VA,VHA: Veterans Health Administration,"Assist in planning and operations in the perioperative process including sps, supplies, personell requirements and patinet planning. ",Output will be multiple AI agents responsible for various tasks related to the peri operative process.
VA-2869,ICU CIS/ARK PDF Medical Entity and Clinical Scoring Extraction (PHI 3.5 LLM),VA,VHA: Veterans Health Administration,"Extract clinical data elements from unstructured clinical note text into structured and semi-structured formats, mapping to standardized terminologies, thus making unstructured note text available to downstream analytics processes and clinical information systems.","Extracted data elements in structured and semi-structured formats, and mappings to standardized terminologies such as SNOMED, LOINC, ICD-10 and RxNorm."
VA-2910,BlueTeam AI,VA,VHA: Veterans Health Administration,BlueTeam AI enables network monitoring capabilities to provide governance and guardrails for LLM Generative AI use for the enterprise.,The system outputs only approved data and data categories to LLM as well as outputs a return notification to the user for any violations.
VA-3004,"OAWP Investigative, Analytics, and Reporting Capabilities",VA,OAWP: Office of Accountability and Whistleblower Protection,"We are in the initial phases of prototyping an audio transcription application using Azure AI Speech Services.  The goal of this project is to provide a streamlined means for OAWP investigators to receive transcripts of subject interviews.
 
Additionally, OAWP's Compliance Analytics and Reporting Division has long-term goals to use a supervised machine learning model to classify external oversight entity reports.  They are also evaluating opportunities to use deep learning models to explore data, and identify trends and anomalies.","Enhanced Analytics, Reporting, and Transcription Services."
VA-3033,Multi-Modal Digital Image Exchange - AI (MDIE-AI),VA,VHA: Veterans Health Administration,It creates an AI driven orchestration layer and generative AI summary for  automating computer vision models with saved dicom diagnostic images.,The system will output the results of each model into a generated summary PDF that is available for review directly from the dicom file.
VA-3045,VA Supply Chain Knowledge Management Dashboard,VA,VHA: Veterans Health Administration,"The goal is to leverage already existing Power BI tools to enhance search and learning capabilities. 
The Power BI dashboards are for internal VALOR mission topics that require timely and more precise knowledge management (KM) and lessons learned output from publicly available documentation (ex. congressional reports). 

THIS CAPABILITY IS NOT RIGHTS OR SAFETY IMPACTING AS IT DOES NOT ACCESS ANY INDIVIDUALS INFORMATION.","This involves enabling a knowledge management strategy that includes advanced data analysis tools (AI and ML) from Power BI stakeholder engagement for validation, dynamic dashboards for knowledge sharing, and continuous improvement processes. This strategy ensures that knowledge is effectively captured, validated, shared, and utilized to drive continuous improvement and mitigate risks.   The expected impact includes internal mission use by VALOR for improved risk mitigation, enhanced collaboration, and continuous process improvement.  And the overall outputs are only data provided by the public documents."
VA-3082,Clinical outcomes for asynchronous teledermatology,VA,VHA: Veterans Health Administration,Determine clinical outcomes of patients with skin disease for research and QI purposes.,"Classify dermatology progress notes into 6 classes:  Resolved, improved, unchanged (clinically significant), unchanged (not clinically significant), worse, and No outcome stated."
VA-3086,VA TryOpenAI,VA,OIT: Office of Information & Technology,"TryOpenAI aims to improve VA employee efficiency and satisfaction. TryOpenAI can be used complete basic administrative tasks like drafting emails and communications, summarizing long text, and draft template project plans (among other similar uses). ","Tasks pilot users use TryOpenAI for    Writing Enhancement and Communication Support:  - Drafting and editing professional emails, letters of recommendation, and narrative write-ups.  - Generating and refining performance appraisals, award write-ups, and administrative correspondence.  - Summarizing large documents including meeting transcripts and project reports for email announcements    Administrative Task Automation:  - Streamlining the creation of meeting minutes to improve efficiency in documentation workflows.  - Automating responses for customer service inquiries or generating template-based outputs for routine tasks.  - Organizing thoughts and prioritizing information to aid in decision-making    Creative and Technical Problem Solving:  - Brainstorming ideas for project development and strategy formulation.  - Assisting with technical problems such as understanding PowerShell scripting or SQL configuration settings.  - Designing website layouts, drafting emails with complex content, and conceptualizing Power apps    Research Aid and Learning Tool:  - Gathering information on specific subjects like VA public information or medical guidelines.  - Finding synonyms or generating ideas for naming conventions in research contexts.  - Seeking deep insights into subject matter for personal knowledge enhancement or educational purposes    Amongst other similar tasks"
VA-3119,Lyssn for Mental Health,VA,VHA: Veterans Health Administration,"To improve fidelity to evidence based practices in Behavioral Health, such as Motivational Interviewing. ","Lyssn uses AI algorithms to automatically generate clinical quality metrics from a recording (or  transcript) of a provider-patient session or appointment. Metrics range from general counseling  and patient-centered communication to fidelity to evidence-based counseling, including  Motivational Interviewing and Cognitive Behavioral Therapy."
VA-3131,SOMATOM go.Up; SOMATOM go.Now; SOMATOM go.All; SOMATOM go.Top; SOMATOM go.Sim; SOMATOM go.Open Pro; SOMATOM X.cite; SOMATOM X.ceed,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K233650.pdf).
VA-3164,"HCD User Feedback Summary, Analysis, and Design",VA,VHA: Veterans Health Administration,"The Human-Centered Design (HCD) team uses Large Language Models (LLMs) and custom agents to enhance user experience (UX) research. The primary purpose is to improve the usability, accessibility, and clarity of user feedback, providing a better understanding of the needs of Veterans and healthcare providers.","The AI system generates insights, such as user stories, personas, and workshop summaries, which are used to inform design decisions."
VA-3205,3M/Solventum 360 Encompass Computer Assisted Coding - Auto Suggestion,VA,VHA: Veterans Health Administration,"The intended purpose is to provide medical coder end users with suggested ICD 10, CPT, and HCPCS codes to select to be assigned/associated to an outpatient, inpatient or surgery encounter based on the provider's clinical documentation.  The expected benefit for the medical coder to gain efficiency in the medical coding process that results in more accurate and timely coding of encounters.","Suggested ICD 10 CM, ICD 10 PCS, CPT, and HCPCPS codes to a medical coder end user based on the clinical documentation the AI system reads."
VA-3213,Vivid iq,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K221148.pdf)
VA-3254,Vivid E80/ Vivid E90/ Vivid E95,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220882.pdf).
VA-3291,Payment Redirect Fraud (PRF) Model,VA,VBA: Veterans Benefits Administration,"Criminals make direct deposit (DD) changes to steal Veterans’ benefit payments. Most direct deposit changes are safe, but 1-2 out of 1,000 (.1% - .2%) are fraudulent. The goal of the Payment Redirect Fraud (PRF) model is to identify which DD changes are likely to be fraudulent and refer them to team investigators for review and remediation.",The model identifies referrals (Veterans) with the highest scores indicating likely fraudulent activity. The outputs include Veteran PII and associated direct deposit bank account information.  These outputs are in the form of an R data file and an Excel file.
VA-3295,"EchoPAC Software Only, EchoPAC Plug-In",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220940.pdf).
VA-3320,Using Partially Observed Markov Decision Process to Implement a Response to Intervention Framework for Veterans with Post-Traumatic Stress Disorder ,VA,VHA: Veterans Health Administration,The Partially Observed Markov Decision Process (POMDP) model will be eligible to help clinicians to provide more personalized treatment to minimize or eliminate the PTSD symptoms in a short amount of time (thus costing less) and enable veterans to return to civilian life more quickly than the current practice,
VA-3324,Microsoft Power Automate and AI  ,VA,VHA: Veterans Health Administration,"To retrieve information from external facilities (SNF, CNH) in order to allow our facility (Veterans Transport Program) to facilitate scheduling of transport of eligible veterans to and from our facility or to community care appointments.","The AI program extracts information from a request form (pdf) attached to an email. The information is then populated in an Excel spreadsheet.  The data points include the date of request, date transport needed, name of requesting facility, person completing the form, Veteran's last name, first name and last 4, attendance needed, trip type, pick up time, appointment time, facility pick up address, appt location, destination address, oxygen needed, weight of patient."
VA-3365,IVC Access Transformation Transformative Care Modalities VA Health Connect Using Machine Learning to Evaluate First Contact Resolution (FCR),VA,VHA: Veterans Health Administration,For analytics purposes to generate performance metrics on First Contact Resolution for the Clinical Triage core service. Does not influence medical or critical decisions and does not use any sensitive Veteran data.,"The output of the model allows us to classify each clinical triage as resolved or not resolved, so that we can generate performance metrics on First Contact Resolution for the Clinical Triage core service."
VA-3369,ECG system software,VA,VHA: Veterans Health Administration,Commercially available software to assist with electrocardiogram interpretation,Produces an ECG tracing and provides reading on ECG parameters
VA-3373,Avicenna ICH ,VA,VHA: Veterans Health Administration,The function of the AI is to detect possible intracranial hemorrhage (ICH) on CT head exams to aid and expedite diagnosis.,The input is DICOM format CT head image data from VHA facilities that submit the exam to VHA National Teleradiology Program (NTP) for interpretation.  The output is DICOM object written to the NTP Picture Archive Communication System (PACS) for review by an interpreting VHA NTP Diagnostic Radiologist.  Future output will also include a DICOM structured report to the VHA NTP PACS Powerscribe dictation software.
VA-3414,Densitas Density AI,VA,VHA: Veterans Health Administration,"The function of the AI is to incorporate quantitative mammographic density with the qualitative 4-category (A, B, C, D) breast density scale that aligns with the ACR BI-RADS Atlas 5th edition breast density scale.  The AI accounts for both the degree of mammographic density and the presence of localized areas of dense breast tissue to aid and expedite mammographic diagnosis.",The input is DICOM mammography image data from VHA facilities that submit digital mammogram exams to VHA National Teleradiology Program (NTP) for interpretation.  The output is DICOM object written to the NTP Picture Archive Communication System (PACS) for review by an interpreting VHA NTP Diagnostic Radiologist.  Future output will also include a DICOM structured report to the VHA NTP PACS Powerscribe dictation software.
VA-3418,CLARUS,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf19/K191194.pdf).
VA-3455,Riverain ClearRead CT,VA,VHA: Veterans Health Administration,"The function of the AI is to analyze CT chest exams and support identification and characterization of pulmonary nodules of all types (sold, part-solid, ground glass), especially for lung cancer screening exams.  The CT Vessel Suppress produces a secondary series of CT images, suppressing vessels and other normal structures within the lungs to improve conspicuity of pulmonary nodules.  ClearRead CT Compare extends detection by automatically matching nodules found in the current exam to the same nodule on a prior exam.

The AI is managed by VHA National Teleradiology Program (NTP) and is hosted in VA Enterprise Cloud (VAEC) or on-premise servers depending on the individual VISN/facility. ","The input is DICOM CT chest image data.   The output is DICOM object written to the PACS for review by an interpreting Diagnostic Radiologist.   Future output will also include a DICOM structured report to the voice recognition dictation software.  The AI is deployed by NTP for the use of the individual VISN and facility Radiologists interpreting the exam, or for NTP Radiologist use."
VA-3488,Clinical Key | Elsevier ,VA,VHA: Veterans Health Administration,A search platform that clinicians can use when searching for current evidence- based medical practices. ,Summary of medical literature or answers to medical questions based on a search prompt.
VA-3492,ACS NSQIP Risk Score,VA,VHA: Veterans Health Administration,Clinical decision support by providing surgical risk assessment,Provides a surgical risk assessment for a patient based on a set of values input by a provider.
VA-3496,Avicenna LVO,VA,VHA: Veterans Health Administration,"The function of the AI is to detect large vessel occlusion in the anterior intracranial circulation (distal Internal Carotid Artery, M1 and proximal M2 Middle Cerebral Artery) on Head CT Angiography exams to aid and expedite diagnosis.",The input is DICOM Head CT image data from VHA facilities that submit the exam to VHA NTP for interpretation.   The output is DICOM object written to the NTP Picture Archive Communication System (PACS) for review by the interpreting VHA NTP Diagnostic Radiologist.  Future output will also include a DICOM structured report to the VHA NTP PACS Powerscribe dictation software.
VA-3500,Ysio Max,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf13/K133259.pdf).
VA-3537,Transpara Breast Care,VA,VHA: Veterans Health Administration,"The function of the AI is to analyze digital mammograms to identify and characterize patterns of breast tissue suspicious for breast cancer, potentially identifying cancers more quickly and at an earlier stage.",The input is DICOM mammography image data from VHA facilities that submit mammography exams to VHA National Teleradiology Program (NTP) for interpretation.  The output is DICOM object written to the NTP PACS for review by an interpreting VHA NTP Diagnostic Radiologist.  Future output will also include a DICOM structured report to the VHA NTP PACS Powerscribe dictation software.
VA-3541,"XIDF-AWS801, Angio Workstation (Alphenix Workstation), V9.5",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K232526.pdf).
VA-3574,BlackBox Code research,VA,VHA: Veterans Health Administration,"We do a lot of coding in various languages java, SQL, Mquery, DAX, Fx, python and R.  While being able to use this product and other products like ASkSage and ChatGPT.  It has had a lot of use in identifying code errors, improving performance of code to better load data in other systems in VA and providing insights on new ways to code in many programs. ","The AI system's outputs can be categorized into several types, depending on the task or question being addressed. Here are some examples:  Math and Logic Problems  Step-by-step solutions to math problems, including algebra, geometry, calculus, and other branches of mathematics Logical explanations and derivations for logic problems, including propositional and predicate logic Coding and Programming  Code snippets in various programming languages, such as Python, Java, C++, and JavaScript, with clear explanations and comments Detailed code reviews and suggestions for improvement Algorithmic solutions to programming challenges and problems Creative Writing and Role-Play  Original creative writing pieces, such as short stories, poems, or dialogues, in response to prompts or requests Engaging role-play scenarios, including character development and interactive storytelling Analysis and Discussion  In-depth analysis of topics, including scientific concepts, historical events, and cultural phenomena Well-structured and coherent arguments, with evidence and supporting examples Engaging discussions and debates on various topics, with respectful and open-minded dialogue Teaching and Explanation  Clear and concise explanations of complex concepts, broken down into manageable parts Step-by-step tutorials and guides for learning new skills or subjects Patient and supportive feedback, with suggestions for improvement and further learning General Discussion and Q&A  Concise and accurate answers to factual questions, with sources and references when available Engaging and respectful conversations on various topics, with active listening and thoughtful responses Overall, the AI system's outputs are designed to be informative, engaging, and helpful, with a focus on clarity, accuracy, and respect for the user's time and interests"
VA-3578,Synthetic Data Creation,VA,VBA: Veterans Benefits Administration,"Synthetic (non-PII) test data creation, using Generative AI, at the scale and representation of the diverse characteristics of the beneficiary population necessary to support EDU UAT.  ",Synthetic beneficiary population data
VA-3619,Billie GPT,VA,VBA: Veterans Benefits Administration,Generative AI knowledge portal to support School Certifying Officials in addressing questions regarding VA education benefits and use of the Enrollment Manager System.,Generative AI response to the user query
VA-3623,X100HT with Slide Loader with Full Field Peripheral Blood Smear (PBS) Application,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220013.pdf).
VA-3664,WRDensity by Whiterabbit.ai,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf20/K202013.pdf).
VA-3705,Workflow Box,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K181572.pdf).
VA-3738,BTSSS 3542 Review,VA,VHA: Veterans Health Administration,"The intended purpose of the AI model is to streamline the claims processing workflow by automatically extracting relevant information from patient-filled paper forms and organizing the corresponding scans chronologically. This automation eliminates the tedious task of manually renaming and sorting files, significantly reducing the time staff spend on these activities. The expected benefits include a marked decrease in manual labor hours, leading to lower operational costs and minimizing the need for overtime. Ultimately, this efficiency allows staff to focus more on patient care and other critical tasks, improving overall workflow productivity.","The AI model outputs a renamed version of the original file, moving it to a designated SharePoint folder with the relevant information extracted from the patient form. Additionally, specific columns in the file are updated with data to facilitate easy sorting by dates. This streamlined process ensures quick access to organized claims information and enhances overall efficiency."
VA-3746,Withings Scan Monitor 2.0,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K230812.pdf).
VA-3775,HTM-LLM,VA,VHA: Veterans Health Administration,RAG chatbot using technical service manuals to aid Healthcare Technology Management staff in medical device maintenance and troubleshooting,Chatbot responses
VA-3783,Clinician-Administered PTSD Scale for DSM-5 (CAPS-5) Clinician Training Simulator,VA,VHA: Veterans Health Administration,"The CAPS-5 Clinician Training Simulator comprises three online courses, available in TMS and TRAIN, that provide instruction in the administration and scoring of the CAPS-5. The courses use voice recognition, 3-D technology, and artificial intelligence to create an immersive learning experience. The courses are intended for clinicians, trainees, researchers, and examiners in VA and in the community. They use AI in the following ways: 1. In the three current CAPS-5 virtual patient courses, learners have the option to speak the prompts, with their spoken prompts transformed to text using speech recognition. 2. The learners’ prompts, whether spoken or typed, are programmatically compared to the required prompts in the CAPS-5. The system analyzes whether the prompts were delivered exactly (“verbatim”), with slight variations (“paraphrased”), or with unacceptable variations (“off-script”). 3. One of the courses analyzes learner prompts in order to trigger comments –corrections or praise -- from a virtual coach. 4. We’re currently revising one of the courses to use generative AI. Here’s how the vendor described it in their response to our solicitation: “This new design will also leverage a separate backend to handle AI multi-agency and retrieval augmented generation (RAG) to ensure large language models (LLMs) used will always operate as designed.” This will be a closed system that does not pull information from or input information to publicly-available platforms (e.g., GPT-4, Bard). More information about the three courses and access to them is available at https://www.ptsd.va.gov/professional/continuing_ed/caps5_clinician_training.asp.

","The AI system outputs, narrowly defined, are the virtual patients' responses to the learners' prompts. More broadly, the system is designed to help learners learn to more accurately administer and score the CAPS-5. Learners receive a summary document describing their performance at the conclusion of each course."
VA-3787,WellDoc BlueStar,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf19/K190013.pdf).
VA-3824,Electronic Virtual Assistant (e-VA),VA,VBA: Veterans Benefits Administration,"The electronic Virtual Assistant (e-VA) information system is a product acquired from SaraWorks (formerly The Career Index (TCI)) by the Veterans Benefits Administration (VBA) Veteran Readiness & Employment (VR&E) Business Line. e-VA is a breakthrough digital assistant that does most of the work a human assistant can do in terms of client follow-up, data entry, and documentation. The primary objective for implementing e-VA is to provide virtual support services that will alleviate administrative tasks from Vocational Rehabilitation Counselors (VRCs), which enable them to focus their time on the Veterans’ needs, fulfilling VR&E’s mission of guiding Veterans to successful outcomes. e-VA is the only digital assistant focused on applying these autonomous capabilities to the complex field of human services. The e-VA system will create reminders for appointments, grades, receipts, etc. and accept documents and images, in addition to connecting program participants directly to their Counselor. The application also enables automated routine electronic communication with program participants through either text message and/or e-mail. Participants can interact with the e-VA application via text or email to schedule and reschedule appointments, respond to reminders, and submit supporting documents and receipts related to their VR&E case. The e-VA information system is single-tenant, which resides in SaraWorks private AWS GovCloud. It is not a public-facing system. The SARA Sync windows executable will receive information from the e-VA system, such as supporting documents, receipts, etc., case notes, or updating of status on their case. This information are transmitted to the VA database of record for storage.","Allow VRCs to focus on providing world-class service to our Veterans. The e-VA system will create reminders for appointments, grades, receipts, etc. and accept documents and images, in addition to connecting program participants directly to their Counselor. The Case Manager ID will be used to identify case managers and assigned caseload which will determine the location of the requested appointment. The application will also enable automated routine electronic communication with program participant through either text message and/or e-mail. Participants can interact with the e-VA application via text or email to schedule and reschedule appointments, respond to reminders, and submit supporting documents and receipts related to their VR&E case.  The SARA Sync windows will receive information from the e-VA system, such as supporting documents, receipts, etc., case notes, or updating of status on their case. This information are transmitted to the VA database of record for storage."
VA-3828,WAVE Clinical Platform,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf17/K171056.pdf).
VA-3869,"VX1, VX1+",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223516.pdf).
VA-3898,Sybil - Lung Cancer Prediction Model by MIT,VA,VHA: Veterans Health Administration,"To be used to personalize screening regime, calling high risk patients earlier to catch cancers in the early stages and potentially reducing screening burden for low risk patients.","It takes as input a lung low-dose CT scan, and produces a JSON return object with predictions of the odds of developing cancer within the next 6 years (one prediction for each year)."
VA-3906,eCaremanager (Philips),VA,VHA: Veterans Health Administration,"eCaremanager integrates clinical, physiological, and demographic data from all patients entered into the National TeleCC Program.  The data are presented graphically to users.  Additionally, the data are used to generate acuity scores to assess each patients acuity in comparison to all other patients.  Trend and threshold alerts are also generated to notify providers to take a closer look at those patients and initiate treatments to remediate derangements and facilitate return to homeostasis and health.",The outputs of eCaremanager are acuity scores and trend and threshold alerts.  The software also integrates and presents patient care information to enable providers to care for larger number of patients and provide critical care at a population level.
VA-3910,VUNO Med-DeepBrain,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K231398.pdf).
VA-3939,Policy AId,VA,VHA: Veterans Health Administration,"Policy lookup is a time-consuming task in the VA. This challenge was identified as an ideal candidate for generative AI product development. After completing AI engineering and product development training, our internal team developed a Retrieval-Augmented Generation (RAG) application that accepts policy-related questions and provides relevant answers based on Medical Center reference materials. 

Expected Benefits:
Time spent on finding/referencing facility policy decreases, increasing efficiency and employee satisfaction. 
Standardization of meeting minutes per Dayton governance structure.
",LLM produces feedback in text with links to the associated medical center publications.
VA-3951,"Voluson Expert 22, Voluson Expert 20, Voluson Expert 18",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K231965.pdf).
VA-3992,Volta AF-Xplorer,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K232616.pdf).
VA-4066,Biotronik Home Monitoring System,VA,VHA: Veterans Health Administration,"The Biotronik home monitoring system collects data transmitted by patients with implanted cardiac monitors from their homes for review by clinicians on a password protected Web page. Transmissions are made by the monitors when certain criteria are met suggesting an important heart rhythm abnormality is present. A proprietary industry-created AI system evaluates the transmitted data and classifies whether the findings that triggered the transmissions are true arrhythmias or false positives. The home monitoring system for BioMonitor IV implanted cardiac monitor uses AI to detect false positives for atrial fibrillation, bradycardia, tachycardia and pauses. These technologies leverage machine learning algorithms and vast datasets to provide more accurate diagnoses and patient care. The staff of the VA National Cardiac Device Surveillance program and the patients’ providers at local VA clinics use this AI when evaluating patient implanted cardiac monitor transmissions.",It filters possible arrhythmia events in to those that are false positive and those that are true positive.
VA-4099,"Synthetic Data Generation:  Experimenting with OpenSource, Third Party and GenAI ",VA,VHA: Veterans Health Administration,Improve agility of research and operational dev,Synthetic patient clinical and demographic data
VA-4107,CareLink Home Monitoring,VA,VHA: Veterans Health Administration,The CareLink home monitoring system collects data transmitted by patients with implanted cardiac monitors from their homes for review by clinicians on a password protected Web page. Transmissions are made by the monitors when certain criteria are met suggesting an important heart rhythm abnormality is present. A proprietary industry-created AI system evaluates the transmitted data and classifies whether the findings that triggered the transmissions are true arrhythmias or false positives. The home monitoring system for Carelink Reveal Linq and Linq II uses AI deep learning algorithms flowing into the CareLink network to remove false AFib and false pause episodes. The staff of the VA National Cardiac Device Surveillance program and the patients’ providers at local VA clinics use this AI when evaluating patient implanted cardiac monitor transmissions.,It eliminates false positive atrial fibrillation and pause events recorded by Medtronic implanted loop recorders when you are reviewing data from these devices on the Medtronic Carelink web page.
VA-4148,Nuance Dragon Medical One (DMO),VA,VHA: Veterans Health Administration,Documentation is entered into the electronic health record leveraging voice to text technology,Voice-generated content and turn it into clinical documentation
VA-4152,Stratification Tool for Opioid Risk Mitigation (STORM) predictive model ,VA,VHA: Veterans Health Administration,"The STORM model is a predictive model to estimate risk of a suicide or overdose-related health care event or death in the next year.  The model uses patient level predictors extracted from the patient’s medical records (into the VA’s Corporate Data Warehouse), such as diagnoses, prescriptions, and health care utilization, etc.  
This predictive model is used for three purposes. (1) Primary use case is to identify patients at elevated risk of suicide or overdose-related events for referral to an interdisciplinary team for clinical case review.  This team makes treatment recommendations to share with treating providers and documents them in the medical record. The STORM algorithm is used to identify patients to refer to this program at each facility.  Assignment to this case management program has been shown to reduce all-cause mortality in patients estimated at “very high” risk on the STORM predictive model by 22% in the next 4 months. (2) Secondary use case is to help risk stratify patients based on prior health care interactions to support augmentation of risk mitigation interventions and treatments for patients with patterns of care associated with risk of suicide or overdose events. Risk estimates are provided as a sorting/filtering and informational feature on the STORM clinical decision support system.  This decision support system enables population management of patients prescribed opioids or with opioid use disorders, as well as providing curated information to support treatment planning for individual patients. (3) The last use case is to meet the requirements of the Comprehensive Addiction Recovery Act (CARA) mandating that clinicians use VA decision support tools to review patient risks prior to initiating opioid therapy for pain.  Direct synchronized links from the VISTA medical record to the STORM report integrate this decision support summary information into clinician workflows as a support for risk assessment before writing and initial opioid prescription.  Each of these use cases is built into existing clinical workflows completed by overlapping, but different health care providers. For use case 1, designated interdisciplinary risk review teams at each health care system use the risk estimates to determine which patient require risk review.  For use case 2, VA health care providers (e.g., opioid prescribers) and teams (e.g., primary care and general mental health teams) use the risk estimates in combination with decision support recommendations of interventions to consider facilitate and augment risk assessment and treatment planning for their patients on opioid analgesics or being treated for opioid use disorder.  For use case 3, VA medication prescribers or their delegated team members use the categorized risk scores in the context of curated descriptive data from the patient’s medical record to review risk factors and consider risk and benefits of treatment options for pain management before prescribing opioids.  Risk considerations are documented in a clinical note for tracking.   Use of STORM is expected to improve decision-making about opioid prescribing and treatment of patients with opioid use disorders, as well as consistency of use of clinical practice guideline recommended treatment practices for safe management of patients exposed to opioids.  STORM also focuses on ensuring recognition of patient risks and facilitating care coordination across treatment providers for complex patients with multiple interacting disorders. By improving use of risk mitigation practices and treatment interventions, we expect STORM will reduce adverse outcomes for patients exposed to opioids.  Program evaluations support this expectation, finding that implementation of the targeted interdisciplinary review requirements associated with use case 1 significantly reduced all cause mortality in the targeted patient population. 

Links: https://psycnet.apa.org/buy/2017-03732-004
https://www.tandfonline.com/doi/10.1080/08897077.2018.1540376
https://link.springer.com/article/10.1007/s11606-022-07622-1
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10698768/","The STORM predictive model estimates the risk of having an overdose or suicide-related event in next year for all patients currently receiving a VA opioid analgesic prescription with nightly updates.  For all other active VHA patients, the STORM predictive model estimates the hypothetical risk of having an overdose or suicide-related event in next year, if the patient was prescribed or otherwise had access to low, medium, or high dose opioid analgesics.  These risk estimates are provided to clinicians on a family of dashboards, both as percentage likelihood of an event in the next year, and as a categorical grouping of estimated low, medium, high or very high risk.   Paired with this risk estimate is a summary of all risk factors identified and considered in generating the risk estimate for that patient, and recommendations for risk mitigation and treatment options to consider.  These recommendations are tailored based on patient characteristics identified in the medical record (e.g. Medications for opioid use disorder are recommended for patients seen for an opioid use disorder diagnosis) and patient receipt of these interventions is tracked and displayed on the dashboard.  The STORM dashboards are used by clinicians as an informational tool to summarize and organize medical record information to support risk reviews during treatment planning (e.g. when considering an opioid prescription), for management of patients prescribed opioids or treated for opioid use disorder, and for interdisciplinary case reviews of very high risk patients to ensure safe and effective care coordination and treatment planning across health care providers."
VA-4156,Vitrea CT Brain Perfusion,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K181247.pdf).
VA-4193,Deep-Learning approaches to develop candidate lists of terms for use in text searches ,VA,VHA: Veterans Health Administration,"The intended use is to increase the comprehensiveness of term lists to be used in text-matching approaches to identifying concepts of interest in free-text medical record notes. Text-matching approaches are an efficient method for identifying text of interest in medical notes.  The success of text-matching approaches depends on the quality of term lists used to search for a concept of interest.  While humans can generate word lists for text-matching approaches, the generated word lists are likely to be limited and biased by the vocabulary, language habits, population exposure, and local dialects of the human generating the list.  Deep learning methods can help to augment candidate term lists to help overcome some of these challenges.  Once generated these augmented candidate terms are reviewed by subject matter experts for appropriateness and accuracy of the suggested terms for the concept and use case of interest.  Here we (1) query pre-trained large language models (e.g., ChatGPT or Llama) through a user interface that allows prompting (such as the OpenAI API or CodeLlama) and/or (2) query word and phrase “embedding” models (e.g., Word2Vec and Phrase2Vec) to expand candidate term lists for review by subject matter experts.  Our team has found both approaches effective for expediting the generation of more comprehensive term to concept mappings for use in text-matching algorithms that increase the accuracy of clinical concept extraction.   We expect this use of AI to improve initial brainstorming of terms related to a given concept, resulting in a more sensitive approach to finding information of interest in free-text clinical notes. ","The outputs of this use of AI is a candidate list of terms related to a concept of interest.  This candidate list is combined with suggestions generated by human experts and then these are reviewed by a subject matter expert to generate a final list of terms for use in text-matching algorithms to extract medical record free text mentions of interest. For the pre-trained Large Language model approach, the input is a query prompting for synonyms of terms related to the concept of interest.  The output is the answer provided by the LLM, including the suggested candidate terms and the original terms that were stated in the query.  For the word and phrase embedding models, the input is an initial list of terms that are relevant to the concept of interest and the output are the suggested candidate terms, ranked by their statistical similarity to the original terms, based on the transformation of a clinical corpus into vector space or an “embedding model”.  Regardless of the type of model used, all suggested candidate terms are reviewed by subject matter experts to ensure quality term lists are used in all text searches."
VA-4197,Vereos PET/CT,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf21/K211764.pdf).
VA-4234,Recovery Engagement and Coordination for Health – Veterans Enhanced Treatment (REACH VET) 1.0 predictive model,VA,VHA: Veterans Health Administration,"The REACH VET 1.0 model is a predictive model using predictors extracted from the patient’s medical records (into the VA’s Corporate Data Warehouse), such as diagnoses, prescriptions, and health care utilization, to estimate statistical risk of a suicide death in the next month.  
This predictive model is used for two purposes. (1) Primary use case is to support identification of patients at elevated statistical risk of suicide in the next month for referral to a clinical case review and outreach program. Staffing guidance to ensure each health care system is staffed to conduct the case review and outreach protocol is established per clinical policy. To date, the population recommended to the clinical case review program has been limited to a number equivalent to 0.1% of the total treated patient population at each facility each month; the number of patients in the program may be modified based on guidance from the Office of Suicide Prevention. The REACH VET 1.0 statistical risk estimates contribute to an algorithm used to identify patients to refer to this program at each facility. (2) Secondary use case is to help risk stratify patients based on prior health care interactions to support augmentation of clinical attention and interventions for patients with patterns of care associated with high suicide risk. This is used, for example, to support clinical review of relevant health care history during triage of Veteran Crisis Line calls and during risk assessment of patients in mental health care.
For use case 1, REACH VET coordinators and REACH VET providers use the list and supporting information to guide execution of the targeted prevention program. For use case 2, Veterans Crisis Line responders and VHA health care providers use the categorized risk scores in the context of curated descriptive data from the patient’s medical record to review risk factors towards optimizing assessment and clinical follow-up.   
The REACH VET 1.0 model is expected to identify a population of patients at elevated risk of suicide and other negative outcomes for review by clinicians; clinicians conduct telephone outreach to identified patients when they deem such outreach appropriate.  This model and targeted prevention in which it is used (i.e. the REACH VET program) is used to augment VHA's extensive clinical suicide prevention program. While VHA conducts universal screening for suicide risk by asking patients structured questions regarding suicidality, this screening process does not identify all patients who go on to die of  suicide. The REACH VET model is intended to identify patients who might be missed in clinical assessment or whose risk may have changed since their last assessment. Here, the REACH VET model identifies patients at statistical risk of suicide, that is they share similarities in their health care data to patients who did die of suicide in the past.  The patients at highest statistical risk are highlighted to mental health providers for additional review. This targeted prevention program has been nationally implemented in VHA health care systems since 2017 and an evaluation of the effects of the REACHVET program was conducted. This evaluation found that REACH VET implementation was associated with greater treatment engagement and new safety plan documentation and fewer mental health admissions, emergency department visits, and suicide attempts. Full findings of this program evaluation are available at:  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8524305/","The REACH VET predictive model estimates the likelihood of dying of suicide in the next month for each active patient in VHA. This estimate is used as part of an algorithm that considers factors such as the size of the health care system, current patient treatment engagement, and whether the patient has had previous engagement with the REACH VET program to generate a dashboard with patients at high statistical risk of suicide for review by a REACH VET coordinator and identified clinicians at each health care system. The REACH VET dashboard provides information about identified risk factors for the included patients and supports a coordinated case review and, where applicable, clinical outreach process to support identification of care gaps and offer additional services as appropriate."
VA-4238,Venue; Venue Fit; Venue Go,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPMN/pmn.cfm?ID=K180599).
VA-4279,Velacur,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223287.pdf).
VA-4316,2268 Next Generation (2268NextGen),VA,OSVA: Office of the Secretary,"We receive information via a PDF VA Form. AI builder, a Microsoft product, “reads” the PDF VA Form and the information is transferred to a D-365 CRM database. This transfer of information from the PDF document to the database minimizes the need for human intervention and typographical errors.  ",The AI Builder provides digital data from a PDF Document.
VA-4320,Syngo Application Software,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf17/K170747.pdf).
VA-4349,Operationalizing Coronary Artery Calcium Computer Vision Model,VA,VHA: Veterans Health Administration,This AI model's purpose is to screen Chest CT scans for coronary artery calcification and notify physicians of patients with increased cardiovascular risk. This will help physicians detect cardiovascular disease earlier and better treat their patients.,The model will output a coronary artery calcium score and also output image masks showing physicians where the model detected coronary artery calcium on the patients chest images.
VA-4353,Rapid AI,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K233582.pdf).
VA-4361,"Spine Planning (2.0), Elements Spine Planning, Elements Planning Spine",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223553.pdf).
VA-4390,VRS Employment Support,VA,VHA: Veterans Health Administration,We are using ChatGPT to support veterans in resume development as well as mock interview question if the veteran is interested.,The output is resumes and mock interview questions.
VA-4431,Classifying the reportability of and extracting cancer diagnosis information from pathology reports or other clinical documents ,VA,VHA: Veterans Health Administration,"The intended purpose is to highlight and show the extracted information by the system along with the original context for review by the nurse coordinators, within the health informatics tools currently in production, in the National Oncology Program Office. This will decrease the nurse coordinators’ information gathering time and improving their information efficiency. Information may also help identify Veterans with diagnoses of interest for review by the coordinator allowing for additional resources to be activated to support the Veteran if they meet program criteria. 
We do not anticipate this AI to be either safety impacting or rights impacting. The output does not serve as a principal basis for a decision. Coordinators are expected to review the output and corroborate its veracity using source information obtained from the EHR. The system resides completely within approved VA IT boundaries that are fully compliant with FISMA and HIPAA rules with availability and reliability set by OI&T. The information that the algorithm uses for input and its output relates to patient and disease features related to cancer diagnoses and therefore are unlikely to perpetuate inequalities related to protected characteristics. They are unrelated to educational benefits, housing grants, loans, risk assessment for insurance, job training programs, employment services, vocational rehabilitation, or hiring. It does not impact claims and benefits processing.
While the system is envisioned to increase the efficiency of coordinators identifying information elements related the Veteran’s cancer diagnoses, these elements are not envisioned to be related to race, nor creating or promoting disparities. On the contrary, by improving coordinator efficiency, we believe the system will allow more Veterans to be supported; decreasing any existing inequities. It will also allow Coordinators be spend less time gathering information and more time interacting with Veterans, improving their ability to connect with the Veteran, learn about them, and provide Veteran-centric support, including care coordination, tracking, providing access to clinical trials if the Veteran is interested per standard of care policy set by the National Oncology Program Office, or provide other types of support. The system will make it easier for Coordinators to locate information about Veterans related to their diagnoses, however it will not be used for diagnosing disease, recommending treatment plans nor as a tool to monitor a patient’s health. It will not be used for health assessments or interventions, manage or dispense medications, or to automate labs. It will not make any decisions for the provider, but will make it easier for the provider to identify information elements of interest in the course of supporting Veterans. The system will also be entirely redundant, meaning Coordinators will still use information from the EHR to perform their workflows, both to find information about Veterans and to document their interactions. Coordinators will be able to fall back to EHR workflows should the system is unavailable for any reason.  
","Binary label of reportability, i.e. if there is cancer diagnosis in the report. This will be highlighted in the original context and output along with the original context for nurse coordinators to review.  Cancer diagnosis information including histology, site, and subsite. This will be highlighted in the original context and output along with the original context for nurse coordinators to review."
VA-4435,Post discharge 30-day readmission or death prediction model to select patients for expedited postdischarge clinic follow-up.,VA,VHA: Veterans Health Administration,"The purpose of this AI is to act as an aid not a replacement for clinical decision-making about whether a patient should have clinical follow-up in the week following discharge (an accelerated timeframe) or follow-up in 2-4 weeks (the regular timeframe). The AI will consider dozens of factors to which a clinician does not have ready access or time to review during a typical discharge process. Patients that are predicted to have an adverse outcome will be recommended a quick follow-up but this will not be mandated, similarly patients not predicted to have an adverse outcome can still be scheduled for quick post discharge follow-up. Predicting which patients will die or be readmitted after discharge is a famously difficult unsolved clinical problem, and this tool will be one more data point for clinicians to aid but not replace clinical judgment during the discharge process.

The AI’s intended benefit is to make our healthcare system more systematic and accurate in identifying high-risk patients at discharge as a primary goal. An aspirational benefit is that this process of more systematic more accurate follow-up for high risk patients will lead to decreased re-admissions and mortality after discharge.",The XG boost system outputs a 0 and 100% probability of readmission or death within 30 days.
VA-4439,Using Artificial Intelligence to Predict Suicide,VA,VHA: Veterans Health Administration,"Prevention of Veteran suicide is VHA’s top clinical priority. We use AI to identify patients with two key risk factors for death by suicide: 1) having access to a gun, and 2) having an active opioid use disorder. This project is funded by and developed with input from the Office of Suicide Prevention.

THREE REASONS KNOWING ABOUT ACCESS TO GUNS IS CRITICAL TO SUICIDE PREVENTION
First, when a person attempts suicide using a gun, the death rate is about 85%. For the most common method of attempting suicide—drug overdose—the death rate is less than 5%. Second, Veterans are more likely to own a gun and know better how to use it than other patients, so Veterans’ death rate when attempting suicide using a gun is even higher. Third, there are things clinicians can do to protect Veterans from their guns while they are suicidal, such as counselling them to give the guns or the ammunition to friends or family until they feel better.  This is always voluntary, but Veterans very often agree to it, because they see and fear the risk. 

WHY KNOWING WHICH PATIENTS HAVE ACTIVE OPIOID USE IS CRITICAL TO SUICIDE PREVENTION
Patients who die by suicide almost always have a prior history of emotional and mental health difficulties. When they die by suicide, it’s usually not due to that history, but rather because some bad life event (such as breaking up with their spouse) happens and then they have an overwhelming impulse to end their lives. 

Opioid use disorder (OUD) contributes to suicide risk in two ways. First, it makes bad life events much more common. It’s hard to keep a job or have good relationships with OUD. Second, OUD also increases impulsivity. That is, among patients who have just lost their jobs, those with OUD are more likely to have the impulse to end their lives. (Among substance use disorders, we focus on OUD because it is very common and there are good treatments available.)


WHY USE AI TO DETERMINE ACCESS TO GUNS?
The need for AI arise from how information is stored in an electronic health record. For historical reasons, when a clinician sees a patient, there are codes they can use to record what diseases (e.g., diabetes) the patient has, but there is no code for having access to a gun. VHA has considered asking all patients during intake for each visit whether they have access to a gun, but this is time consuming and can cause concern among patients about why they’re always being asked about guns. 

AI, specifically natural language processing (NLP) of clinical notes, offers another way to know which patients have guns. We have developed NLP algorithms that are very good at assessing from notes whether a patient owns or has access to a gun. But we use only notes already written by clinicians, any mention of gun access came voluntarily from the patient. However, to find this information, we need a method that can go through notes quickly, and NLP provides that method. 

WHY USE AI TO ASSESS WHETHER PATIENTS HAVE SUBSTANCE USE DISORDERS?
OUD is a disease, and there are disease codes available to record it. However, because there are many different states you can be in with OUD (e.g., actively using vs in rehab vs sober for years), there are over 100 possible ways to code OUD. Most clinical settings (like outpatient clinics and ERs) have short list of commonly used codes for clinicians to pick from, but that may not offer up much specificity. So most clinics will only put on their list a single code, “opioid use, unspecified” and leave off all the more specific codes. Thus, typical coding practice does not differentiate between a patient who is currently using opioids or one who is 10 years sober (and, if you live along time with OUD, it is usually because you spend much of that time sober). That differentiation is important because the increase in impulsivity with OUD is only during active opiate use.

NLP can again be useful, because descriptions of OUD in clinical notes are likely to be much more specific than the codes used","OUR INPUT, OUTPUT, AND INTENDED USER In the “Please add anything else you would like to share” box below we describe in more detail why it is necessary to use AI to find information about gun access or OUD (versus either not having the information or getting that information without using AI). We also describe how we build and test AI models to determine whether a patient has gun access or is actively using opioids. First, however, we think it is important to describe how human clinicians in VHA will use our AI.   The INPUT to our AI models is simply the notes that have already been written on patients. These only contain information volunteered by the patient. The OUTPUT of our models will be simply indicators that a patient **may** have access to a gun or **may** have an active substance use disorder, along with a presentation of the text that leads the AI algorithm to reach its conclusion.   However, the INTENDED USE of the output is that a human mental health clinician be notified about patients at risk, then read the note or notes that led to the determination that the patient was at risk. The clinician may conclude that the AI was incorrect (this occurs about 12-16% of the time with our current models) and drop the issue. Alternatively, the clinician may decide that the patient does have the risk factor and that the risk factor needs to be addressed.   There is no planned interaction between the AI and the patient, nor does the AI make any clinical decisions. Rather, it is a tool to help point clinicians to potentially critical information that they might not otherwise have been aware of.   OUR AI METHOD We begin by creating a list of common terms centered around gun access or OUD. We then pull thousands of pieces of clinical text with these terms in them, and have physicians determine whether the risk factor is present or not. (A term can be present, but the patient can still not have the risk factor in a variety of ways. It could be that “the patient’s brother has a gun” or “the patient has NO gun” or “the patient used to use Fentanyl, but quit”.) The text that has been assessed by physicians is called “labeled data”. We then give our NLP models some of the labeled data, so they can learn what positive and negative examples look like.   For each risk factor, we develop 4 non-neural AI text classification models: random forest, bagging, gradient boosting, and logistic regression with ridge penalization. We also implement two large language models, BioBERT and Bio-ClinicalBERT.   Subsequently, we test each algorithm on other data for which we have (but don’t give the algorithm) the label and ask each algorithm to produce its own labels. We then compare each algorithm’s conclusions to the physicians’ conclusions. That is how we know that our algorithms so far, will be incorrect about 12-16% of the time. Over time, we hope to improve the performance of these algorithms. For example, the large language models are relatively new additions to the AI toolkit and perform better than the non-neural models. We expect further advances over time. However, the current level of accuracy is already higher than many commonly used diagnostic tests, such as mammograms or erythrocyte sedimentation rates.   WHERE DO WE DO THIS WORK? Our team currently uses the Summit Data Platform (SDP) – formerly called the Health Data and Analytics Platform (HDAP) – maintained by the VA Office of Information Technology. This is an Azure Machine Learning environment."
VA-4443,RayStation 11B,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220141.pdf).
VA-4472,Identify access to genetic testing in Veterans with breast cancer. ,VA,VHA: Veterans Health Administration,"Stakeholders in the National Oncology Program that are required to understand quality of standard of care access provided by VA to Veterans with cancer to germline genetic testing. Veterans who have not been provided standard of care access may be provided additional support in the form of care coordination services to ensure they receive standard of care access. 
The AI use case is intended to help the Stakeholders in the National Oncology Program understand quality of standard of care access provided by VA to Veterans with cancer to germline genetic testing.
This will help stakeholders be able to identify which veterans have not been provided with germline genetic testing access more efficiently and at almost real time, thus being able to provide additional support in the form of care coordination services to ensure they receive standard of care access. 
   We do not anticipate this AI to be either safety impacting or rights impacting. The output does not serve as a principal basis for a decision. Coordinators are expected to review the output and corroborate its veracity using source information obtained from the EHR. The system resides completely within approved VA IT boundaries that are fully compliant with FISMA and HIPAA rules with availability and reliability set by OI&T. The information that the algorithm uses for input and its output relates to patient , disease features, and whether genetic testing is offered are related to cancer diagnoses and therefore are unlikely to perpetuate inequalities related to protected characteristics. They are unrelated to educational benefits, housing grants, loans, risk assessment for insurance, job training programs, employment services, vocational rehabilitation, or hiring. It does not impact claims and benefits processing.
While the system is envisioned to increase the efficiency of coordinators identifying information elements related the Veteran’s cancer diagnoses, and whether standard of care access to genetic testing was offered to Veterans, these elements are not envisioned to be related to race, nor creating or promoting disparities. On the contrary, by improving coordinator efficiency and awareness of whether Veterans received the care adherent to VA NOP guidelines, we believe the system will allow more Veterans to be supported in adherence with NOP guidelines; decreasing any existing inequities. It will also allow Coordinators be spend less time gathering information and more time interacting with Veterans, improving their ability to connect with the Veteran, learn about them, and provide Veteran-centric support, including facilitating access to genetic testing per NOP guidelines. The system will make it easier for Coordinators to locate information about Veterans related to their diagnoses, however it will not be used for diagnosing disease, recommending treatment plans nor as a tool to monitor a patient’s health. It will not be used for health assessments or interventions, manage or dispense medications, or to automate labs. It will not make any decisions for the provider but will make it easier for the provider to identify information elements of interest in the course of supporting Veterans. The system will also be entirely redundant, meaning Coordinators will still use information from the EHR to perform their workflows, both to find information about Veterans and to document their interactions. Coordinators will be able to fall back to EHR workflows should the system is unavailable for any reason.  

","Binary output of Yes or no on if the patients have access to germline genetic testing, and the reason of the output. This will be highlighted in the original context and output along with the original context for nurse coordinators to review."
VA-4513,Classify clinical pathway for cancer patients,VA,VHA: Veterans Health Administration,"The VA National Oncology Program has invested in creating clinical pathways that guide providers to provide high quality evidence-based standard of care treatments to Veterans with cancer. However at this time, it is unclear how many or how often providers are ‘on pathway’ or are concordant with this recommendation. Work will focus on leveraging AI to assess degree of adoption of various pathways. For example:  To assess care quality across the VA in regards to genetic testing in Veterans with prostate cancer, and provide the needed information to engage in quality improvement efforts, the VA NOP proposes to develop, evaluate and implement an informatics workflow that is capable of extracting information regarding whether a Veteran with prostate cancer has been offered access to germline and somatic genetic testing. Work will follow the framework NOP developed to assess germline genetic testing in Veterans with breast cancer in response to the Advances in Mammography and Medical Options (MAMMO) for Veterans Act of 2022. Briefly, Veterans receiving care for prostate cancer in VA will be identified using electronic health information in the VA Corporate Data Warehouse, and their latest relevant clinical notes will be retrieved. Data from VistA CPRS prostate cancer pathway templates will provide a gold standard for developing and evaluating the feasibility of using an open-source generative large language model to determine whether a Veteran has been offered genetic testing according to clinical notes. Earlier work has been successful using zero-shot (or few-shot) prompt development. Model fine tuning can be considered should these approaches fail. Upon achieving acceptable accuracy, the model will then be implemented for near real time determination of access to genetic testing at scale, especially in sites where this information is not available. 
This work will allow assessment of quality of care as it relates to adherence to VA endorsed clinical pathways on genetic testing in Veterans with prostate cancer. It will also facilitate efforts for improving care delivered through identification of sites that can be supported through existing efforts such as the National Tele-oncology Office, or cancer care navigation and tracking initiatives.
We do not anticipate this AI to be either safety impacting or rights impacting. The output does not serve as a principal basis for a decision. Stakeholders are expected to review the output at the population level, increasing their awareness of how the system as a whole is attending to Veteran needs per program office policy. Any use of the system to address needs at the site level or Veteran level will involve human review and corroboration of the output veracity using source information obtained from the EHR. The system resides completely within approved VA IT boundaries that are fully compliant with FISMA and HIPAA rules with availability and reliability set by OI&T. The information that the algorithm uses for input and its output relates to documentation of patient, disease, and prior treatment features related to cancer diagnoses and therefore are unlikely to perpetuate inequalities related to protected characteristics. They are unrelated to educational benefits, housing grants, loans, risk assessment for insurance, job training programs, employment services, vocational rehabilitation, or hiring. It does not impact claims and benefits processing.
While the system is envisioned to increase the effectiveness and efficiency of stakeholders identifying information elements related the Veteran’s cancer diagnoses and treatment, these elements are not envisioned to be related to race, nor creating or promoting disparities. On the contrary, by improving identification of off pathway care, we believe the system will offer the opportunity for stakeholders to identify areas where Veterans, or systems in need more support, decreasing any existing inequities. It will not be used for diagnosing disease","Class for clinical pathway, i.e., which clinical pathway the cancer patient is on. This will be highlighted in the original context and output along with the original context for nurse coordinators to review."
VA-4521,Enterprise Command Center - Generative AI ,VA,OIT: Office of Information & Technology,The benefit of this use case is to provide plain English alert messages to service owners. The current alert language has proven suboptimal and results in a inordinate volume of alerts not being actioned. By feeding alerts into an LLM the message can be reconfigured to be understood by a human who in turn can take appropriate steps to resolve the alert.,Human readable alert messages
VA-4554,Extract patients’ diagnosis information and map the diagnosis to oncotree,VA,VHA: Veterans Health Administration,"Patients’ diagnosis information has only been extracted in the format of ICD0 code, although clinicians are only able to use the diagnosis information that is described according to the oncotree in situations such as clinical trial matching. We aim to use the AI system to identify the diagnosis information according to oncotree. 

This will help highlight the diagnosis information according to oncotree on the clinical documents that the nurse navigators could review more quickly, therefore help the document review more efficiently. 
We do not anticipate this AI to be either safety impacting or rights impacting. The output does not serve as a principal basis for a decision. Coordinators are expected to review the output and corroborate its veracity using source information obtained from the EHR. The system resides completely within approved VA IT boundaries that are fully compliant with FISMA and HIPAA rules with availability and reliability set by OI&T. The information that the algorithm uses for input and its output relates to patient and disease features related to cancer diagnoses and therefore are unlikely to perpetuate inequalities related to protected characteristics. They are unrelated to educational benefits, housing grants, loans, risk assessment for insurance, job training programs, employment services, vocational rehabilitation, or hiring. It does not impact claims and benefits processing.
While the system is envisioned to increase the efficiency of coordinators identifying information elements related the Veteran’s cancer diagnoses, these elements are not envisioned to be related to race, nor creating or promoting disparities. On the contrary, by improving coordinator efficiency, we believe the system will allow more Veterans to be supported; decreasing any existing inequities. It will also allow Coordinators be spend less time gathering information and more time interacting with Veterans, improving their ability to connect with the Veteran, learn about them, and provide Veteran-centric support, including care coordination, tracking, providing access to clinical trials if the Veteran is interested per standard of care policy set by the National Oncology Program Office, or provide other types of support. The system will make it easier for Coordinators to locate information about Veterans related to their diagnoses, however it will not be used for diagnosing disease, recommending treatment plans nor as a tool to monitor a patient’s health. It will not be used for health assessments or interventions, manage or dispense medications, or to automate labs. It will not make any decisions for the provider, but will make it easier for the provider to identify information elements of interest in the course of supporting Veterans. The system will also be entirely redundant, meaning Coordinators will still use information from the EHR to perform their workflows, both to find information about Veterans and to document their interactions. Coordinators will be able to fall back to EHR workflows should the system is unavailable for any reason.  

","Patients’ diagnosis according to oncotree, and this will be highlighted in the original context and output along with the original context for nurse coordinators to review."
VA-4562,Adobe Creative Cloud ,VA,VHA: Veterans Health Administration,Develop nursing education presentations ,Used to make animations or to populate AI art.
VA-4566,QLAB Advanced Quantification Software,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf20/K200974.pdf).
VA-4595,"Identify cancer patients symptom burden, including symptoms supported by embedded mental health.  ",VA,VHA: Veterans Health Administration,"Mental Health is important for cancer patients and could be barrier for effective and timely cancer care. Approximately one-third of persons with cancer will develop a mood or anxiety disorder. Mental health of Veterans with cancer is a priority for the VA National Oncology Program. We have been tasked to develop and implement a health information technology tool that will facilitate the effectiveness and efficiency of mental health providers embedded in cancer clinics, such as the one embedded in the Oncology clinic in the Durham VA. One of the challenges he faces is to identify patients that are most likely to benefit from the intervention. We aim to use AI to extract patients’ symptom burden information including the symptoms related to mental health needs from clinical notes and surface them for the embedded mental health provider. 
National oncology program embedded mental health specialists and nurse coordinators will review the information, allowing them to efficiently identify Veterans that may benefit from additional support for symptom management or mental health. This could allow embedded mental health specialists to monitor cancer patients among veterans at a higher risk level more closely and provide the most appropriate level of care. It could also potentially help veterans have increased cancer treatment engagement and quality of care, which are essential for cancer patients’ disease prognosis.  
","Information on patient symptom burden including symptoms related to mental health needs of cancer patients, this will be highlighted and output along with the clinical documents that are used to extract the information for the nurse coordinators to review. We do not anticipate this AI to be either safety impacting or rights impacting. The output does not serve as a principal basis for a decision. Coordinators are expected to review the output and corroborate its veracity using source information obtained from the EHR. The system resides completely within approved VA IT boundaries that are fully compliant with FISMA and HIPAA rules with availability and reliability set by OI&T. The information that the algorithm uses for input and its output relates to patient and disease features related to cancer diagnoses as well as descriptions of symptom burden and therefore are unlikely to perpetuate inequalities related to protected characteristics. They are unrelated to educational benefits, housing grants, loans, risk assessment for insurance, job training programs, employment services, vocational rehabilitation, or hiring. It does not impact claims and benefits processing. While the system is envisioned to increase the efficiency of providers identifying information elements related the Veteran’s cancer diagnoses and symptom burden documented in the EHR, these elements are not envisioned to be related to race, nor creating or promoting disparities. On the contrary, by improving efficiency, we believe the system will allow more Veterans to be supported, decreasing any existing inequities. It will also allow providers spend less time gathering information and more time interacting with Veterans, improving their ability to connect with the Veteran, learn about them, and provide Veteran-centric support. The system will make it easier for providers to locate information about Veterans related to their symptom burden, however it will not be used for diagnosing disease, recommending treatment plans nor as a tool to monitor a patient’s health. It will not be used for health assessments or interventions, manage or dispense medications, or to automate labs. It will not make any decisions for the provider but will make it easier for the provider to identify information elements of interest while supporting Veterans. The system will also be entirely redundant, meaning providers will still use information from the EHR to perform their workflows, both to find information about Veterans and to document their interactions. Providers will be able to fall back to EHR workflows should the system is unavailable for any reason."
VA-4599,Ambulatory heart rhythm monitoring,VA,VHA: Veterans Health Administration,AI is used to analyze 14 days of heart rhythm to narrow down periods of abnormalities and identify such rhythms.,Its a report with various abnormalities identified and listed for the clinician to interpret and make recommendations.
VA-4603,Insights Engine,VA,VEO: Veterans Experience Office,"The Insights Engine provides a human-language interface to query aggregate-level / anonymized customer experience and operational metrics and data in support of VA research and design initiatives. This tool leverages large language model interpretation and agents to write queries for structured and unstructured data, and articulate responses based on relevant source review or Retrieval Augmented Generation (RAG).

This tool will serve as a research librarian to empower research and design teams across the VA enterprise to identify and leverage past-relevant learnings that reduce redundant research initiatives and build on prior work and knowledge. Staff can inquire about what has been done / is known about x, y, z and receive answers in plain language.","Prior research findings, qualitative and quantitative insights."
VA-4607,"Philips EPIQ Diagnostic Ultrasound System, Philips Affiniti Diagnostic Ultrasound System",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf21/K212704.pdf).
VA-4640,Glassbeam Clinsights ,VA,VHA: Veterans Health Administration,"The benefits of this AI is to gather medical device data, and use machine knowledge to attempt prediction of when medical equipment may fail. ","Gathers medical device hardware information and compares the data that was gathered to determine if it is in normal range, declining, or failed to alert the technicians as soon as possible to repair/replace faulty parts before they are used in a medical procedure."
VA-4644,VX Insights Hub Agent,VA,VEO: Veterans Experience Office,"The VX insights hub provides a human-language interface to query aggregate-level / anonymized customer experience and operational metrics and data in support of VA performance improvement and decision-making. This tool leverages large language model interpretation and agents to write queries for structured and unstructured data, and articulate responses based on relevant source review or Retrieval Augmented Generation (RAG).

This tool will empower VA staff in decision-making and performance improvement roles, who may not have a background in data science, statistics or analytics, to inquire about performance and experience and receive answers in plain language.","Natural language responses to CX and operations questions + validation information about the query that was written and run, etc."
VA-4689,"OPTIS Mobile Next Imaging System, OPTIS Integrated Next Imaging System",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf21/K210458.pdf).
VA-4722,Automated Decision Support,VA,VBA: Veterans Benefits Administration,"Intake of VA Claims materials as well as other Veteran, VSO, and stakeholder submissions results in contentions which are prescribed as eligible.  The platform ingests and takes initial actions on claims and contentions (largely those impacted by the PACT Act) which include medical record retrieval, review of the VBMS eFolder, generates a summary review document, drafting or submitting contract examination requests via robotics process automation (RPA), and/or changing the claim status to Ready For Decision (RFD).  
","Utilizing prescribed machine learning and Natural Language Processing (NLP), ADS utilizes Intelligent Form Recognition (IFR), Optical Character Recognition (OCR), Intelligent Character Recognition (ICR), and NLP to extract an average of 95 fields on over 1500 form layouts within VA’s purview.  The system generates a summary review document, drafting or submitting contract examination requests via robotics process automation (RPA), and/or changing the claim status to Ready For Decision (RFD)."
VA-4726,Compliance Made Easy (CME) Cloud Optimization,VA,OIT: Office of Information & Technology,"The purpose is to provide automated review of official communications against the approved VA style guide, tone, and other key elements to making communications to the public effectively. The goal is to reduce the amount of time needed to create and review the documents leading to saved time and money. The benefits of using AI include more intelligent control over a rule based system, low/no code updates to the model through direct NLP prompts to update the approved style guides, leveraging machine learning to improve communications and tone over time, less reliance on human intervention to review and edit communications. ","AI outputs will include updated communications style and formatting based on the style guide, suggested language to improve tone, readability and conciseness of communications, and data based on the model running."
VA-4730,O-arm O2 Imaging System,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf24/K240465.pdf).
VA-4763,Mail Automation Services,VA,VBA: Veterans Benefits Administration,"Mail Automation Services (MAS) is a ITTT service for intake of VA Claims materials as well as other Veteran, VSO, and stakeholder submissions.  The platform ingests and reviews 25k to 40k packets of information per day, primarily derived from the Centralized Mail Portal.  Utilizing prescribed machine learning and Natural Language Processing (NLP), MAS utilizes Intelligent Form Recognition (IFR), Optical Character Recognition (OCR), Intelligent Character Recognition (ICR), and NLP to extract an average of 95 fields on over 1500 form layouts within VA’s purview.",VBA End-Product establishment and correct business line orientation for ingested submissions are the most common outcomes and outputs for the MAS platform which runs under Veterans Benefits Administration Automation Platform (VBAAP).
VA-4771,NeuroQuant,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf17/K170981.pdf).
VA-4804,Master Claims Assistance Tool (M-CAT),VA,VBA: Veterans Benefits Administration,"Function of the system is generative AI use and derivatives to assist VA personnel. Inputs to the model include policy, procedure, and other knowledge management documents such as CFR database knowledge and user entered inquiries. ",Outputs include RAG model results from chatbot. Intended users are VA or VBA staff as directed by SES.
VA-4812,MAGNETOM Vida; MAGNETOM Lumina; MAGNETOM Aera; MAGNETOM Skyra; MAGNETOM Prisma; MAGNETOM Prisma fit,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPMN/pmn.cfm?ID=K231560).
VA-4923,3D Quorum ,VA,VHA: Veterans Health Administration,Mammography. AI-powered analytics - Generates 6mm 'SmartSlices' from the original high-resolution 3D data. Identifies clinically relevant regions of interest through overlapping slices (3mm) to ensure no loss of 3D data. Reduces the number of 3D images to be reviewed by the Radiologist by 2/3. ,Produces 6mm 'SmartSlices' from native 3D data to highlight clinically relevant or potentially clinically relevant regions of interest. Augments the decision making process of Board Certified or Board Eligible Radiologists. Interpreting Radiologists retain the ability to 'accept' or 'reject' the suggested outputs.
VA-4935,INtuition-Structural Heart Module,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPMN/pmn.cfm?ID=K191585).
VA-4964,Intelligent 2D ,VA,VHA: Veterans Health Administration,"Mammography - Produces synthetic 2D images from 3D mammography data to improve the detection of breast lesions while reducing radiation dose. Reduces the 'noise' if the images, helping to eliminate random elements that may distort the image. Provides Interpreting Radiologists improved detection ability through reduction of artifacts that may reduce visibility of lesions - ultimately providing a clearer picture of breast tissue. FDA Approved. ",Provides synthetic 2D image to augment the Interpreting Radiologist's ability to detect breast lesions.
VA-5005,QV CAD,VA,VHA: Veterans Health Administration,Automated Breast Ultrasound (ABUS) solution from QView Medical. Aids Radiologists with interpreting screening procedures for women who have negative mammograms but have had a 3D breast ultrasound due to dense breast tissue. Receives input images via standard DICOM format. Native imaging from the ABUS together with the output of the QVCAD images are displayed on the viewer. QVCAD engine uses several image patter recognition processes and artificial neural networks to detect suspicious areas in the breast with the objective to distinguish potential breast lesions from normal breast tissue. ,Detects suspicious or potentially suspicious areas in the breast.  Augments the decision making process of Board Certified or Board Eligible Radiologists. Interpreting Radiologists retain the ability to 'accept' or 'reject' the suggested outputs.
VA-5009,FlexLine: Detect patterns and make corrective action recommendations in application and dependency time to mitigation data. ,VA,VHA: Veterans Health Administration,"Within the FlexLine materials management application, this AI capability would look at patterns across the time-to-mitigation data and potentially other scans for application vulnerabilities. If teams are not resolving vulnerabilities within the 30, 45, 60 day periods, then it could expose our products and degrade Veteran care. The goal would be to connect the duration to mitigate to other available data trends and recommend actions to the application teams that could help them resolve the issues faster.",Will provide detailed text data hat combines/correlates scan results for the app team and what might be causing the inability to resolve. This additional intelligence and recommended resolution(text) could be provided to the app team through automated Jira tickets to help them understand a way to resolve the issue.
VA-5013,Medical Imaging Auto-segmentation,VA,VHA: Veterans Health Administration,To make the process of drawing regions of interest more efficient ,Rather than a physician manually outlining a lesion or organ such as the liver the AI system uses imaging data and anatomic atlas information to create a proposed outline that the physician can then adjust or approve for use
VA-5017,FFRangio,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf19/K192442.pdf).
VA-5046,Quantra ,VA,VHA: Veterans Health Administration,Mammography. Uses multi-class support vector machine (SVM) based classification technique to segregate breast types into four categories based on breast parenchymal tissue pattern and texture representation to assist Radiologists in interpretations and reduce intra- and inter-reader variability. ,Classifies breast type. Augments the decision making process of Board Certified or Board Eligible Radiologists. Interpreting Radiologists retain the ability to 'accept' or 'reject' the suggested outputs.
VA-5050,VSTOne – AI-Driven Patient Monitoring and Care Delivery,VA,VHA: Veterans Health Administration,"Supporting Care Through AI

The healthcare industry is at a critical juncture due to the convergence of rising patient demands and severe staffing shortage, specially in nursing. According to the U.S Bureau of Labor Statistics projection in 2022, American hospitals will be hiring 1,100,00 registered nurse positions. In response to this challenge AI driven patient monitoring care delivery can proactively assist nurses.
The integration of artificial intelligence into healthcare presents a unique opportunity to enhance patient outcomes while supporting clinical staff in an increasingly challenging environment. With the looming shortage of nursing staff and the growing demand for patient care, there is an urgent need for technological solutions that support nurses in their roles. Today, I present VSTOne, an innovative AI solution designed to assist nurses, prevent patient falls, and improve care quality through continuous monitoring and real-time alerts.","Supporting Care Through AI VSTOne leverages advanced AI to provide comprehensive monitoring solutions that address several critical areas of patient care: • Assisting Nurses: Automated monitoring allows nurses to focus on higher-level care tasks. • Preventing Falls: The system predicts potential falls 30-65 seconds in advance, allowing timely intervention. • Preventing Pressure Ulcers: Early detection of pressure ulcer risks through continuous monitoring of patient movement. • Telemetry and Telehealth: Vitals are tracked via wearable patches, providing real-time data to clinicians, and enabling telehealth consultations."
VA-5054, Surveillance and Reporting of Suicidal Ideation Assessment in PTSD Specialty Care Clinical Notes using Natural Language Processing (NLP),VA,VHA: Veterans Health Administration,We endeavor to surveil and monitor nationally both the conduct and quality of suicide ideation (SI) assessment during treatment in PTSD specialty care. We hope eventually to increase the consistency and quality of SI assessment in PTSD care to enhance clinical management of suicide risk. ,"Our methods entail the use of natural language processing (NLP) of progress note documentation of treatment within the PTSD Clinical Team (PCT) specialty care clinics, to identify SI mentions, to quantify SI assessment documentation, and to classify SI mention clinical quality. We will provide reports of consistency and quality and the national, VISN, and medical center levels."
VA-5058,"FastStroke, CT Perfusion 4D",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf19/K193289.pdf).
VA-5087,Koios,VA,VHA: Veterans Health Administration,Used with Automated Breast Ultrasound (ABUS). Classifies breast ultrasound lesions and automates reporting for improved efficiency and streamlined workflows. Increased sensitivity and specificity with reduced variability. Reduces unnecessary treatments (existing BI-RADS 3's can be accurately and safely downgraded) and provides probability of malignancy aligned to BI-RADS categorization. ,Classifies breast ultrasound lesions. Augments the decision making process of Board Certified or Board Eligible Radiologists. Interpreting Radiologists retain the ability to 'accept' or 'reject' the suggested outputs.
VA-5095,Evaluation of Autonomous Assistive Feeding System in Spinal Cord Injury Patients,VA,VHA: Veterans Health Administration,"The AI use is to improve autonomous bite acquisition by robotic arm as well as to improve transfer to the participant's mouth.  Inputs include video analysis of caretakers administering/transferring bite to participants, as well as a web interface where feedback from stakeholders will be collected to improve the robotic arm's actions and to provide additional contextual information for bite acquisition and transfer.  This information will be used by the AI to improve the robotic arms autonomous functions of bite acquisition and transfer.

The ultimate goal of the robotic arm function is to provide autonomous or semi-autonomous support to improve functional independence for patients with upper extremity weakness from spinal cord injury or other causes."," Inputs and Outputs: Our experimental setup will consist of bite acquisition trials under two settings. In the autonomous setting, the robot will acquire the food autonomously. In the shared autonomy setting, the robot may acquire the food autonomously, but during certain times, may query the end-user or an expert research assistant based on its confidence about its manipulation actions and use their feedback to complete the bite acquisition process. For both the settings, the robot will use our online learning framework to design its behaviors. In the shared autonomy setting, we will develop an accessible web interface that the stakeholders can use to provide feedback on what actions to use or what additional contexts may be useful for bite-acquisition"
VA-5136,Using AI to read PDFs and parse the information to SharePoint list,VA,VHA: Veterans Health Administration,"The AI will read PDFs from the TPA, and parse the data into a sharepoint list, reducing the employees processing time by 20%","SharePoint, and will be used in Power BI."
VA-5140,Discovery MI Gen2,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf21/K211846.pdf).
VA-5169,Genius AI,VA,VHA: Veterans Health Administration,Mammography. Assists the Radiologist in locating lesions likely representing breast cancer by searching each slice of the tomosynthesis image set. Lesions are marked on the appropriate slices that can be overlaid on a synthesized 2D image and on 3DQuorum SmartSlices. These 2D overlays augment Radiologists by providing an overview image with suspicious areas indicated with quick navigation to the tomosynthesis slice that the mark was originally identified on. ,Lesions are marked on identified imaging slices with reference back to corresponding tomosynthesis slice.
VA-5173,Implementation of a Severe COVID-19 Risk Prediction Tool,VA,VHA: Veterans Health Administration,"The project seeks to implement a Severe COVID-19 Risk Prediction Tool to effectively identify Veterans at higher risk of developing severe COVID-19 symptoms through a machine-learning model to address one of the key barriers to increased vaccination offerings identified, i.e., the lack of tools for assessing risk of severe disease progression and potential vaccination benefit. It is expected by facilitating the estimated risk for severe COVID-19 progression, as well as a patient's current vaccine eligibility, that these patients can be outreached to and offered the vaccine in a more timely manner to improve vaccination rates and ultimately health outcomes.","The model will output a relative risk score for currently hospitalized patients based on their COVID-19 progression severity risk, and will generate a task notification to clinical teams to notify them of patients within that cohort output who also currently meet eligibility for receiving the COVID vaccine based on CDC guidelines (i.e. no recent history of already receiving vaccine, or recent COVID-19 infection)."
VA-5181,CVI42,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf14/K141480.pdf).
VA-5214,Discharge Predictive Model,VA,VHA: Veterans Health Administration,"Implementation of a predictive model that can identify acute inpatients likely to discharge within 24 hours can facilitate communication across clinical and ancillary staff teams who are otherwise currently reliant on a manual process that requires clinical teams to enter a Pre-Discharge order, a process which can be inconsistent due to trainee turnover. The expectation of this project is increased awareness and communication of the hospital's anticipated aggregate discharge volume resulting in potentially improved visibility on hospital throughput for bed coordination, including improved capability and flexibility to accommodate additional hospital admissions and transfers.",The model estimates the overall clinical readiness of inpatient patients using fundamental parameters including vital signs and lab result trends and then produces an output that aggregates the total anticipated number of patients across the facility that would be expected to be ready for discharge within 24 hours based on basic clinical criteria.
VA-5218,HSRD IIR 19-069 Optimizing Renin Angiotensin System Blocker Use among Veterans with Kidney Disease,VA,VHA: Veterans Health Administration,"Intended purpose: clinical summarization of narrative clinical notes within the electronic health records among patients with CKD to give providers a summary of relevant terms (side effects, adverse events) noted in those notes (exact phrase matches, pointer to document) along with medication and chronic condition information (not using AI) delivered to primary care providers before a clinic encounter to assist in clinical decision making.","Narrative note that goes into the patient's record with the PCP as an additional signer with a summary of why they qualify for the clinical summarization (CKD), when the ACE/ARB was stopped, documentation of notes and phrases/sentences that are relevant to decision making (exact text from note)."
VA-5222,CT CoPilot,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf16/K161322.pdf).
VA-5263,"Cranial Navigation, Navigation Software Cranial, Navigation Software Craniofacial, Cranial EM System, Automatic Registration iMRI",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223288.pdf).
VA-5333,Aquilion ONE (TSX-305A/6) V8.9 With AiCE,VA,VHA: Veterans Health Administration,AI Deep Learning CT Reconstruction,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K183046.pdf).
VA-5427,CellaVision DM1200 with the body fluid application,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf10/K102778.pdf).
VA-5464,Nediser reports QA,VA,VHA: Veterans Health Administration,"Nediser is a continuously trained artificial intelligence “radiology resident” that assists radiologists in drafting their reports. Using computer vision/ML, Nediser selects normal templates (for example, the knee, shoulder joint), detects absence or presence of hardware in the image, evaluate patella alignment and leg length and angle discrepancy, measure Cobb angles, and evaluate hip exams for osteoarthritis. The output is directed to a QC field in the report that the Radiologist may use. The output helps standardize reports and improve accuracy of reporting.","The system classifies arthritis grade and performs measurements which are output to a QC field in dictation software as a draft that the Radiologist may or may not incorporate into their report templates. This is similar to a Radiology resident who provides draft reports that the Attending Radiologist reviews. The system can also detect objects and landmarks to assist in making measurements and identify abnormality. The output are landmark annotations and measurements. However, these outputs are not sent to the production PACS. They are stored in a secure directory which the Radiologists can refer to and do not become part of the medical record. All original production DICOM images are deleted after processing. Nediser saves de-identified JPG images and reports (no PHI) for audit and review of system performance, and to further train the model is necessary."
VA-5468,"CARTO 3 EP Navigation System Software V8.0 (FG-5400-00, FG-5400-00U)",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K231207.pdf).
VA-5501,Care Assessment Needs (CAN) Score,VA,VHA: Veterans Health Administration,CAN is a set of risk-stratifying logistic regression models run on Veterans receiving health care through VHA.,90-day hospitalization or 90-day death
VA-5509,Cartesion Prime (PCD-1000A/3) V10.15,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K231748.pdf).
VA-5542,VA CART Percutaneous Coronary Intervention SYNTAX Score ,VA,VHA: Veterans Health Administration,The VA CART SYNTAX risk model predicts 30-day post-PCI mortality using a combination of clinical and anatomic variables. The model is available to facilitate personalized informed consent discussions and appropriate preparation for high-risk PCI cases.,"The calculated score indicates a risk of major adverse cardiovascular events (death, MI, stroke, and repeat revascularization) over time."
VA-5550,Cardiac CT Function Software Application,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf24/K241038.pdf).
VA-5579,Falls Prediction Tool,VA,VHA: Veterans Health Administration,"Background: Pact Act Co-Pay exemption determination is currently a manual process, and some veterans may not know if they had toxic exposure and may be eligible for co-pay exemption.
Objective: Develop an algorithm for the PACT Act to predict if patients are eligible for co-pay exemption.
",Automatically generate a binary output that indicates whether a veteran is eligible for Pact Act Co-Pay exemption.
VA-5583,VA CART Percutaneous Coronary Intervention Mortality Model ,VA,VHA: Veterans Health Administration,The VA CART mortality risk model is based on logistic regression using baseline clinical and procedural variables to predict post-PCI 30-day mortality. The model is available to facilitate risk stratification at the point of care., Post-PCI 30-day mortality
VA-5620,Pact Act Co-Pay Exemption Prediction Tool,VA,VHA: Veterans Health Administration,"Background: Pact Act Co-Pay exemption determination is currently a manual process, and some veterans may not know if they had toxic exposure and may be eligible for co-pay exemption.
Objective: Develop an algorithm for the PACT Act to predict if patients are eligible for co-pay exemption.",Automatically generate a binary output that indicates whether a veteran is eligible for Pact Act Co-Pay exemption.
VA-5624,VA CART Percutaneous Coronary Intervention Nephropathy Model ,VA,VHA: Veterans Health Administration,The VA CART nephropathy risk model is based on logistic regression using baseline clinical and procedural variables to predict. The model is available to facilitate risk stratification at the point of care.,Post-PCI acute kidney injury
VA-5628,Purchase Order Filing,VA,VHA: Veterans Health Administration,"We use Microsoft Power Automate's AI builder to file our purchase orders on Sharepoint, as well as documents connected with them (invoices, returns, amendments, packing slips, etc). This saves staff time and makes it easy to respond to audits because all of the required documents are in 1 place with a consistent naming convention.","The AI puts the document into a PDF on Sharepoint and names it according to the Purchase Order Number and document type (538Q407568Amendment1, for example). The AI makes a folder for each PO number and all documents connected to that PO number go in the same folder."
VA-5632,"Brainlab Elements Image Fusion, Contouring (4.5);Image Fusion (4.5);Fibertracking (2.0);BOLD MRI Mapping (1.0);Image Fusion Angio (1.0)",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223106.pdf).
VA-5665,VA CART Myocardial Ischemia NLP,VA,VHA: Veterans Health Administration,Extracts myocardial ischemia information in VistA using Natural Language Processing (NLP) of Radiology report. ,"Results of the NLP contain 0 indicating negative stress test result, 1 indicating positive stress test result, and -1 indicating inconclusive stress test result."
VA-5706,VA CART Ejection Fraction NLP,VA,VHA: Veterans Health Administration,Extracts ejection fraction (EF) information in VistA using Natural Language Processing (NLP) of Echocardiogram TIU report text,"Results of the NLP are separated by EF determination method including Human Observation, Biplane, 4-Chamber, and 2-Chamber, with the Best EF Value following that hierarchy in order.  A NULL Best EF Value indicates that the LLM did not find an ejection fraction in the text."
VA-5714,BioPlex 2200 ANA Screen with Medical Decision Support Software for Use with BioPlex 2200 Multi-Analyte Detection System,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf4/K043341.pdf).
VA-5788,VA CART Percutaneous Coronary Intervention Bleeding Risk Model,VA,VHA: Veterans Health Administration,The VA CART bleeding risk model is based on logistic regression using baseline clinical and procedural variables to predict post-PCI in-hospital bleeding events. The model is available to facilitate risk stratification at the point of care.,Post Percutaneous Coronary Intervention bleed prior to hospital discharge
VA-5796,"Biograph Vision, Biograph MCT Family Of PET/CTs",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf19/K193248.pdf).
VA-5825,Rythm Express,VA,VHA: Veterans Health Administration,Predict potassium levels from ECG.,Potassium levels from ECG evaluation.
VA-5837,AutoContour Model RADAC V3,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K230685.pdf).
VA-5874,A computer vision framework (CVF) for the image classification in the Veteran Health Administration (VHA),VA,VHA: Veterans Health Administration,"Intended purpose: To develop a computer vision framework (CVF) to classify medical test images in the VHA.
Benefits: Disease related decision generation from the medical test image.","The CVF can provide a decision for the given image (e.g., the patient has a disease or not)."
VA-5903,Github Copilot,VA,OIT: Office of Information & Technology,"The intended purpose of GitHub Copilot is to assist developers by providing intelligent code suggestions and completions, thereby enhancing their productivity and efficiency.

Increased Productivity: By suggesting code snippets and completions, Copilot reduces the amount of time developers spend writing boilerplate code and looking up syntax or API usage.
Improved Code Quality: Copilot can suggest best practices and common patterns, helping developers write more robust and maintainable code.
Learning Aid: It serves as a learning tool for developers by providing examples and explanations of how to implement certain functionalities.
Reduced Cognitive Load: By handling repetitive coding tasks, Copilot allows developers to focus more on the logic and design of their applications.
Faster Prototyping: Developers can quickly generate code for new features or prototypes, accelerating the development process.
Overall, GitHub Copilot aims to streamline the coding process, making it faster and more efficient for developers to build high-quality software.","The AI system's outputs in this context would be:  Code Suggestions: The AI might suggest alternative ways to securely handle sensitive information like the master_key. For example, it could recommend using environment variables or secret management services instead of hardcoding the key. Security Warnings: The AI could provide warnings about potential security risks, such as the exposure of sensitive information in the code. Best Practices: The AI might suggest best practices for managing configuration settings, such as using a configuration file or a dedicated secrets management tool. Documentation: The AI could generate comments or documentation strings explaining the purpose of the master_key and how it should be used securely."
VA-5919,aPROMISE X,VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K220590.pdf).
VA-5956,AI coding,VA,VHA: Veterans Health Administration,"Increased Productivity: By automating routine tasks, both coders and designers can work faster and more efficiently.
Improved Quality: AI can enhance the quality of code and designs through intelligent analysis and suggestions.
Accessibility: It can make coding and design more accessible to non-experts, democratizing creative processes.
Innovation: By offering new perspectives and solutions, AI can drive innovation in both fields.
Overall, the integration of AI into coding and creative design aims to enhance human capabilities, foster creativity, and improve overall outcomes in both areas.","Code Snippets: Automatically generated blocks of code based on user prompts or requirements. Bug Reports: Detailed analyses of code with identified issues and suggestions for fixes. Documentation: Automatically generated documentation for codebases, explaining functions, classes, and usage. Refactored Code: Improved versions of existing code that enhance readability, efficiency, or performance. Test Cases: Suggested test cases or automated tests generated to ensure code functionality and reliability."
VA-5960,"Aplio i900, Aplio i800 and Aplio i700 Software V8.1 Diagnostic Ultrasound System",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf23/K233195.pdf).
VA-6001,"Alignment System Cranial, Alignment Software Cranial, Cirq Alignment Software Cranial Biopsy, Cirq Alignment Software Cranial sEEG, Varioguide Alignment Software Cranial",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf22/K223864.pdf).
VA-6030,Dental - Dentsply Sirona CERE,VA,VHA: Veterans Health Administration,Intelligent automation enables a fast proposed dental reconstruction proposal based on the scan. ,Dental reconstruction proposal.
VA-6038,Fusion 2024 (JAWS/ZoomText),VA,OIT: Office of Information & Technology,"Allows blind and low vision employees to gain information from charts, graphs, tables and other images on the screen to provide comparable access in support of legal requirements of Section 508.","Detailed descriptions and details of charts, graphs, tables and other images on the screen. It also allows for follow on questions to obtain additional information such as trends, specific details, etc."
VA-6042,"Acumen Hypotension Prediction Index - EV1000 Clinical Platform, Acumen Hypotension Prediction Index - Hemosphere Advanced Monitoring Platform, Acumen Hypotension Prediction Index, Hemosphere Advanced Monitoring Platform - Pressure",VA,VHA: Veterans Health Administration,FDA-cleared medical device to assist clinicians and improve healthcare outcomes.,Described in FDA documentation for this device (https://www.accessdata.fda.gov/cdrh_docs/pdf18/K183646.pdf).
VA-6067,Xtract WDS - OSSO,VA,VHA: Veterans Health Administration,Heat map detection for weapon detection software.,Areas of interest for a heat map that include objects that would produce heat indicators aligned with heat signatures of known types of different weapons.
4,GovChat,Environmental Protection Agency,Office of Mission Support,The purpose of this application is to provide a generative AI chatbot tool to EPA staff. It is materialized as a web site user interface which users interact with on their web browser when on the EPA network.,"The Use Case produces a variety of output depending on what users use it for internally which can range from content, code, and other uses of ChatGPT. A rules of behavior requires that users do not use it for final decisions or recommendations. Additionally, users will potentially use this environment for a broad set of general AI uses. Individual use cases may be described if the system becomes widely adopted and patterns of use are determined."
12,Transitioning historical help desk knowledge to new help desk software ,Environmental Protection Agency,Office of Air and Radiation,The program has 20 years of help requests and responses in a customized open source help desk tool. We are mapping out a transition to Jira Service Desk but are not able to easily import 20 years of knowledge and answers to common questions. The project team plans to use generative AI to categorize questions and summarize responses. These outputs would serve as the knowledge base for the new help desk. ,"Knowledge base to populate the new help desk system:
- Common questions
- Categories of questions
- Responses"
13,Emission monitoring program knowledge management system search and summary,Environmental Protection Agency,Office of Air and Radiation,"Provide a chatbot to respond to EPA monitoring system analyst questions about the emission monitoring programs, including historical regulatory changes and the reasons for those changes. ","Using preambles and regulatory text, respond to questions such as:
- What is the grace period for performing a relative accuracy QA test?
- In what year were the monitoring performance criteria last updated and what was the justification?
- What monitoring options are available for an oil-fired power plant?"
19,Identification of lead service lines in drinking water distribution systems using bioindicators/biomarkers,Environmental Protection Agency,Office of Reseach and Development,Explore the potential of predictive tools to identify lead service lines (LSLs). Alternative approach using bioindicators/biomarkers obtained from high-resolution microbiome profiles to identify LSLs without excavation.,Predict LSLs in DWDSs . Two outcomes (binary): LSL or non-LSL.
21,Living Literature Review: Semi-automated Literature Screening,Environmental Protection Agency,Office of Reseach and Development,Reduce the time required to screen literature for inclusion for chemical assessments and related research activities.,Output is a predicted binary class indicating relevance of a reference to a chemical assessment or topic of interest.
23,Generative AI for Study Evaluation and Document Chat,Environmental Protection Agency,Office of Research and Development,Reduce the time required to complete study evaluation and make it easier to find/recall information found in documents.,"The outputs are generated text based upon a prompt. The text is intended to help the user answer questions about a document, specifically about the quality of the information reported."
24,Natural Gas STAR Videos ,Environmental Protection Agency,Office of Air and Radiation,"This is a commercial product that is not reflected in the list in the previous column. The purpose of using this AI tool was to simply create realistic audio narration files, without having to go through the lengthy and more expensive process of hiring a voice actor to read our scripts. The tool turns text into speech.

","The AI tool did not make any of the decisions or predictions.  It only sounded out text that we created and supplied the tool.
"
26,Agency Records Management System (ARMS),Environmental Protection Agency,Office of Mission Support,"purpose: to improve accuracy of Records schedule prediction
expected benefit: reduce administrative burden on EPA staff ",the machine learning model predicts records schedules 
31,Use of Microsoft CoPilot within the M365 Purview Security Suite,Environmental Protection Agency,Office of Mission Support,"Purview is one of the Agency’s tools to protect our Microsoft cloud data and endpoint devices.  Several potential use cases are possible with the addition of CoPilot into the product which is anticipated in upcoming releases within our GCC tenant.  Our proposed use of AI tools is limited in scope the Agency’s existing security boundary, data and ATO.

The expected benefits are faster answers to common questions about the nature of EPA's security and IT infrastructure environment.  We will be able to more effectively leverage the voluminous amount of data currently collected by Purview, Microsoft Security Center, and Defender agents to make decision in a more expedited fashion.  We will be able to act on results more quickly to help reduce security vulnerabilities and weaknesses.

","a.	Security and infrastructure analysts will be able to use CoPilot to better understand and report on existing security vulnerabilities on Microsoft Windows devices. Purview currently delivers canned reports in our dashboard which shows existing vulnerabilities.  CoPilot can be queried to ask specific questions about the vulnerabilities, such as which computers are impacted and the potential mitigation strategy for specific vulnerabilities.
b.	CoPilot can be used to analyze and report on installed software, reporting on potential vulnerabilities and versions for each package.
c.	CoPilot can describe and summarize Data Loss Prevention (DLP) alerts that require Agency attention and help analysts to understand which types of sensitive data are triggering alerts and to improve our models.
d.	CoPilot can quickly respond to common questions about the environment without writing custom reports:  how many Windows 22H2 computers are in the environment?  How many systems are missing the latest Microsoft System Center Configuration Manager (SCCM) client?  How many computers are still unpatched for the Log4J vulnerability?  What is the last login for the workstation name: R07Smith123?"
32,Use of AI tools within the Agency’s instance of ServiceNow,Environmental Protection Agency,Office of Mission Support,"ServiceNow is used as the Agency’s primary service desk management system for resolving incidents, problems, change controls, knowledge management, inventory of systems and software including the central Configuration Management Datbase (CMDB).  Employees and IT professionals rely on this platform to obtain service, submit incidents, obtain reports and trends, and plan workloads and priorities to solve problems.  Our proposed use of AI tools is limited in scope the Agency’s existing security boundary, data and Authority to Operate (ATO).  The expected benefits are reduced numbers of service tickets and calls which will have a direct cost reduction.  Help desk and IT professionals throughout the agency will be able to leverage the vast trove of knowledge articles, asset inventory and history of hundreds of thousands of service tickets to find answers to challenging (and common) IT issues facing our workforce.","Several use cases have emerged to leverage ServiceNow's upcoming AI tools for employees to engage with an AI agent to ask technical questions to solve specific technical issues.  

For example:
b.	An employee may ask, how do I reset my password; the answer will provide a written response with steps based on our existing internal knowledge articles and a link to the Agency’s self-service password management page at pss.epa.gov.  This could divert thousands of calls away from service desk agents each year.
c.	A service desk agent may ask, how do I troubleshoot a problem a customer reports with the error message at Windows login, “domain not found.”  The response would be a list of steps both the technician and employee will need to preform to resolve the error.  This will save the technician a significant amount of time to search the ServiceNow knowledge articles, read the contents and relay instructions to the customer.
d.	A manager may ask the AI agent, how many computers in Region 10 require updates to the latest version of Windows 11 23H2?  How many installations of Adobe Acrobat (pro) are installed in HQ?  How many Dell Latitude 5340 computer have expired warranties agency-wide, provide a detailed list including service tags? 
"
50,Machine learning-assisted literature screening,Environmental Protection Agency,Office of Reseach and Development,"The purpose is to help scientists in screening references by using machine learning to rank references by title and abstract based on relevance as determined from a set of ""on topic"" and ""off topic"" references. The benefits are that scientists will more efficiently identify relevant references for consideration in the development of scientific assessments. ","The machine learning tools support scientists in screening references by providing those references in a ranked order. That ranked order may or may not be based on seed references that are ""on topic"" and/or ""off topic. The screening tools build a model based on what the screener identifies for ""inclusion"" and ""exclusion"". This ranked set of references allows scientists to more quickly identify relevant references. Some of these tools also provide an estimate or recall, or the percentage of relevant references identified. "
54,Data Management and Analytics Platform (DMAP) Operations and Governance AI Use Cases,Environmental Protection Agency,Office of Mission Support,"Improve data quality, operational efficiency, and improved use of data to support mission outcomes","Proposed use of AI and ML to enhance DMAP mission needs and operational excellence in the following areas:

Automated Data Quality Assessment
•	AI-augmented data profiling
•	Auto-detect data anomalies, missing values, outliers
•	Generate comprehensive data quality reports
•	Recommend data cleaning and transformation strategies
•	Provide statistical insights about dataset characteristics
AI-Augmented Data Documentation Generation
•	AI to aid in creating human-readable data dictionaries
•	Generate insights into semantic relationships between data elements
•	AI-augmented data lineage and provenance tracking documentation
AI-Driven Data Enrichment Recommendations
•	Suggest potential external data sources for enrichment
•	Recommend feature engineering techniques
•	Identify potential data joins and correlations
•	Flag opportunities for data augmentation
Workflow and Pipeline Automation
•	AI to aid in Extract Transform Load/Extract Load Transform (ETL/ELT) pipeline configurations
•	Create reproducible data transformation scripts
•	Develop dynamic data routing and processing workflows
•	Implement intelligent error handling and recovery mechanisms
Intelligent Onboarding Assistant
•	Guide users through data and project onboarding processes and workflows
•	Provide contextual recommendations during onboarding process
•	Validate/audit project requirements and compliance needs
•	Offer interactive tutorials and best practices
Predictive Data Governance
•	Recommend data access controls
•	Detect potential compliance risks
•	Augment analysis/validation/auditing and recommendations for data sensitivity levels
•	Suggest data anonymization and masking strategies
Feature Engineering for ML and Analysis
•	Auto-generate initial machine learning features
•	Identify potential model training datasets
•	Recommend preprocessing techniques
•	Highlight dataset suitability for specific ML tasks
Semantic Data Discovery
•	Create semantic knowledge graphs
•	Enable natural language querying of datasets
•	Aid in identifying and recommending data relationships across disparate sources
•	Support data catalogue generation
"
60,Intelligent Superfund Search & Chatbot capabilities,Environmental Protection Agency,Office of Land and Emergency Management,"The intended purpose of this AI use case is to modernize and enhance the EPA's Superfund Enterprise Management System (SEMS) document search and processing system through intelligent automation. Key expected benefits include:

1. Dramatic improvement in operational efficiency by reducing search time from months/weeks to minutes
2. Enhanced accuracy in document retrieval and information extraction
3. Better user experience through intuitive natural language search capabilities
4. Cost reduction through automated document processing
5. Improved compliance and quality control in environmental site management
6. Increased ability to process and derive insights from millions of technical documents
7. Better decision support for EPA staff managing contaminated sites
","The AI system will generate the following outputs:

1. Intelligent Document Processing Results:
   - Extracted key entities (site locations, contaminants, responsible parties)
   - Document classifications and metadata
   - Automated summaries of technical reports

2. Search and Retrieval Outputs:
   - Relevant document recommendations based on natural language queries
   - Direct answers to specific questions with source citations
   - Cross-document insights and connections

3. Analysis and Decision Support:
   - Site contamination pattern analysis
   - Related case recommendations
   - Risk assessment summaries

4. Quality Assurance Outputs:
   - Confidence scores for extracted information
   - Source attribution for all provided information
"
66,Resource Conservation and Recovery Act (RCRA) Predictive Analytics,Environmental Protection Agency,Office of Enforcement and Compliance Assurance,"Risk scoring of Large Quantity Generators (LQGs) to support RCRA inspections
","Risk scoring (integers 0 to 4, inclusive) for LQGs
"
67,Clean Water Act (CWA)Predictive Analytics,Environmental Protection Agency,Office of Enforcement and Compliance Assurance,"Identify high risk National Pollution Discharge Elimination System (NPDES) facilities that don't submit Discharge Monitoring Reports (DMRs)
","Risk scoring (Ranking from lowest to highest risk) for NPDES facilities that don't submit DMR's
"
68,Clean Air Act (CAA) Predictive Analytics,Environmental Protection Agency,Office of Enforcement and Compliance Assurance,"Risk scoring of Majors and Synthetic Minor Facilities to support CAA inspections
","Decimal score between 0 and 1 for Major and Synthetic Minor CAA Facilities
"
82,Extracting references from technical documents,Environmental Protection Agency,Office of the Administrator,"In response to OMB interest—which we agree with—in giving researchers more visibility when we cite their work, National Center for Environmental Economics (NCEE) is investigating various methods to document citations in economic analysis and other regulatory documents. We have explored using GovChat to extract references from regulatory documents. 
","Output would be lists of unique references by document, which can then be combined into a list with counts. The list could then be used to acknowledge researchers whose work is used by EPA. "
83,Streamflow Duration Assessment Modeling,Environmental Protection Agency,Office of Water,"Streams exhibit a diverse range of hydrologic regimes, and the hydrologic regime strongly influences the physical, chemical, and biological characteristics of active stream channels and their adjacent riparian areas. One important aspect of the hydrologic regime is streamflow duration—the length of time that a stream sustains flowing surface water. Determining streamflow duration class can help support a variety of regulatory and non-regulatory water resource management decisions. This random forest modeling supports prediction of the appropriate streamflow duration classification across a range of geographies. Full information is available at: https://www.epa.gov/streamflow-duration-assessment/random-forest-modeling","Prediction of whether a streamflow is “perennial,” “intermittent,” or “ephemeral”"
DHS-2414,3rd Party Traveler Identity Verification Services,DHS,CBP,"The TVS Biometric Air Exit solution is a cloud-based facial biometric matching service that enables CBP, External Partners, and Other Government Agencies (OGA) to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification.
","The TVS Biometric Air Exit solution is a cloud-based facial biometric matching service that enables CBP, External Partners, and Other Government Agencies (OGA) to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification.


3rd Party Traveler Identity Verification Services is part of CBP’s Traveler Verification Service (TVS), a biometric system leveraging facial recognition technology (FRT). This system confirms traveler identities at various exit points, including airports, seaports, and land borders, as part of CBP’s Biometric Exit Program.  These services operate under strict privacy guidelines to protect travelers’ personal information, aligning with CBP’s mission of balancing security and convenience., The TVS Biometric Air Exit solution is a cloud-based facial biometric matching service that enables CBP, External Partners, and Other Government Agencies (OGA) to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification, Leverages DHS facial matching technologies to provide a match or no match response."
DHS-314,Advance RPM Maintenance Operating Reporter (ARMOR),DHS,CBP,"ARMOR will shorten time to service/repair/maintenance of radiation portal monitors by two weeks. ARMOR will allow better distribution of resources (travel, spare parts, etc.) and expected cost decrease could be 25-50%. Through decreased outage time, and prediction of equipment degradation, ARMOR will increase radiological/nuclear (R/N) security on US borders.","ARMOR will shorten time to service/repair/maintenance of radiation portal monitors by two weeks. ARMOR will allow better distribution of resources (travel, spare parts, etc.) and expected cost decrease could be 25-50%. Through decreased outage time, and prediction of equipment degradation, ARMOR will increase radiological/nuclear (R/N) security on US borders.

Utilizing AI and physical modeling, the Advance Radiation Portal Monitor (RPM) Maintenance Operating Reporter (ARMOR) project provides predictive maintenance of RPMs, detecting issues with the equipment before the issue causes the screening lane to be inoperable. The system will provide a listing of malfunctioning RPMs categorized by issue severity and predicted date of failure, which will be used to create service tickets. ARMOR will shorten time to service/repair/maintenance of RPMs by two weeks. ARMOR will allow better distribution of resources (travel, spare parts, etc.) with a potential cost decrease of 25-50%. Through decreased outage time, and prediction of equipment degradation, ARMOR will increase radiological/nuclear (R/N) security on U.S. borders. "
DHS-313,Advanced Analytics for X-ray Images (AAXI),DHS,CBP,"AAXI aims to address the problem of anomaly detection in empty commercial vehicles entering the United States at land border ports of entry. The AI models achieve this goal by encoding past X-Ray images of vehicular border crossings in a semantically meaningful way and comparing the current crossing to detect differences amongst the images to identify anomalies. Benefits include enhancement of the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States, and increased clearance rate at border crossings so that vehicles operating safely and lawfully may pass through the border faster.","AAXI aims to address the problem of anomaly detection in empty commercial vehicles entering the United States at land border ports of entry. The AI models achieve this goal by encoding past X-Ray images of vehicular border crossings in a semantically meaningful way and comparing the current crossing to detect differences amongst the images to identify anomalies. Benefits include enhancement of the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States, and increased clearance rate at border crossings so that vehicles operating safely and lawfully may pass through the border faster.

Advanced Analytics for X-ray Images (AAXI) aims to address the problem of anomaly detection in empty commercial vehicles entering the U.S. at land border ports of entry. The AI models achieve this goal by encoding past x-ray images of vehicular border crossings in a semantically meaningful way and comparing the current crossing to detect differences amongst the images to identify anomalies. The system produces bounding boxes around an anomaly or unidentifiable object(s) within an image or any portion of the image that cannot be identified or explained. Benefits include enhancement of the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States, and increased clearance rate at border crossings so that vehicles operating safely and lawfully may pass through the border faster. "
DHS-162,Agent Portable Surveillance,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The agent portable surveillance system is a backpack mobile unit meant for single agent deployments. The system identifies border activities of interest by using AI/ML to analyze data from Electro-Optical/Infra-Red cameras and radar. When an activity is detected, the system sends the information to agents through the Team Awareness Kit (TAK). Detections are shared with CBP TAK users to enhance efficiency and agent/officer safety."
DHS-86,Agriculture Commodity Model (AGC) Model,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

Agriculture Programs and Trade Liaisons (APTL) use AGC to leverage statistical sampling and supervised AI/ML models for risk-based inspection of selected agricultural commodities. The AGC Model maximizes CBP’s limited resources by prioritizing inspection of containers deemed high-risk. The AI output is a predicted risk result level for cargo shipments to identify agricultural pest risk. The predicted risk is integrated into the Automated Targeting System (ATS) - Import Cargo and utilized in APTL’s targeting workflow for agriculture pest risk analysis. If a cargo shipment is identified as high-risk for pest infestation, it is prioritized for inspection. "
DHS-31,AI Curated Synthetic Data,DHS,CBP,The availability of rare event/outlier data or labeled data that can be used to train and automate detection is severely limited. The technology enhances available libraries of true positives and normal scans from CBP Non-Intrusive Inspection (NII) systems and supports development of Automated Threat Recognition (ATR) algorithms designed to quickly identify items of interest.,"The availability of rare event/outlier data or labeled data that can be used to train and automate detection is severely limited. The technology enhances available libraries of true positives and normal scans from CBP Non-Intrusive Inspection (NII) systems and supports development of Automated Threat Recognition (ATR) algorithms designed to quickly identify items of interest.

AI Curated Synthetic Data creates synthetic data for computer vision to enable more capable and ethical AI when detecting anomalies in complex environments.  Specifically, it creates an emulated X-ray sensor that can produce visually realistic synthetic X-ray scan images similar to real X-ray scan images, and virtual 3D assets of vehicles and narcotics containers. These images will be used to enhance the development of Anomaly Detection Algorithms for Non-Intrusive Inspection (NII), incorporating Artificial Intelligence/Machine Learning (AI/ML) for the detection of narcotics and other contraband in conveyances and cargo. The availability of rare event/outlier data or labeled data that can be used to train and automate detection is severely limited. The technology enhances available libraries of true positives and normal scans from CBP NII systems and supports development of Automated Threat Recognition (ATR) algorithms designed to quickly identify items of interest. Through the technology, the end user will have access to enhance existing, deployed algorithms to increase detection performance. "
DHS-194,AI Enabled Autonomous Underwater Vehicle,DHS,CBP,"Customs and Border Patrol (CBP) Office of Field Operations (OFO) has identified significant potential for parasitic loads on vessels entering and exiting ports of entry. The current identification method is using dive teams or borrowing larger ROV units from Local, State, or Federal partners. Through autonomous systems, OFO can more efficiently and safely identify anomalies/items of interest. 
","Customs and Border Patrol (CBP) Office of Field Operations (OFO) has identified significant potential for parasitic loads on vessels entering and exiting ports of entry. The current identification method is using dive teams or borrowing larger ROV units from Local, State, or Federal partners. Through autonomous systems, OFO can more efficiently and safely identify anomalies/items of interest. 


Advanced sonar, navigation, and communications system subsea vehicle is a fully integrated, hand-portable, low detection threshold system that has the small footprint and maneuverability to inspect underwater infrastructure.  It integrates Doppler Velocity Log (DVL), Ultra-Short Baseline (USBL), Inertial Navigation System (INS), and acoustic and optical modems. This enables highly reliable, fully autonomous underwater missions and provides obstacle detection and collision avoidance.  The system will be developed to assist in the detection of parasitic smuggling attempts on the outer hull of maritime vessels. Office of Field Operations (OFO) has identified significant potential for smuggling of narcotics attached to the outer hull of marine vessels entering and exiting ports of entry. The current identification method is using dive teams or borrowing larger Remotely Operated Vehicle (ROV) units from Local, State, or Federal partners. Through autonomous systems, OFO can more efficiently and safely identify anomalies/items of interest.  The technology allows for increased shared situational awareness in real time for OFO and strategic partners and improves mission planning and agent and officer safety, while reducing reactionary gaps. "
DHS-P2,AI for Autonomous Situational Awareness,DHS,CBP,"The AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. The system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination, to allow for more active monitoring of remote camera feeds that prompt operators to review the items of interest once detected.  This will reduce the overall operator burden of camera monitoring and allow users to accomplish other tasks or system management. 

","The AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. The system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination, to allow for more active monitoring of remote camera feeds that prompt operators to review the items of interest once detected.  This will reduce the overall operator burden of camera monitoring and allow users to accomplish other tasks or system management. 



The AI for Autonomous Situational Awareness System is intended to use Internet of Things IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations.  The system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination. It will also incorporate a motion sensor that, when triggered, wakes up a high-resolution camera to capture a series of pictures, with additional sensors providing confirmation prior to camera capture. Images captured will be processed by Artificial Intelligence models to classify objects, determine vehicle direction at intersections, and provide imagery sufficient for re-identification. Ultimately, the system is intended to create a low footprint, low cost, low power system to provide situational awareness and covert detection., detection and identification of objects at or near the U.S. border, and possibly classification. "
DHS-2369,AI for Software Delivery,DHS,CBP,The initial use case is to integrate AI into the development process to assist developers with code reviews so that when a request to modify code in a baseline is made by a developer AI is integrated into the continuous integration pipeline to examine the code for potential problems and inefficiencies.  By reducing code review time and identifying potential issues earlier in the development CSPD expects to reduce the time to deliver changes and increase initial software quality.,"The initial use case is to integrate AI into the development process to assist developers with code reviews so that when a request to modify code in a baseline is made by a developer AI is integrated into the continuous integration pipeline to examine the code for potential problems and inefficiencies.  By reducing code review time and identifying potential issues earlier in the development CSPD expects to reduce the time to deliver changes and increase initial software quality.

The Automated Commercial Environment (ACE) is the system through which the trade community reports imports and exports, and the government determines admissibility. This system is developed and maintained by the Cargo Systems Program Directorate (CSPD) within the Office of Information Technology (OIT) in Customs and Border Protection (CBP). ACE is a large system consisting of hundreds of applications with new capabilities added regularly. CSPD is seeking to incorporate AI into the software delivery process to reduce delivery time as well as increase the quality and security of the ACE system. The initial use case is to integrate AI into the development process to assist developers with code reviews so that when a request to modify code in a baseline is made by a developer AI is integrated into the continuous integration pipeline to examine the code for potential problems and inefficiencies.  The AI model will identify coding errors and recommend fixes as well as make recommendations for improvement and optimization which the request reviewer will assess and determine what, if any, changes need to be made before the code is approved to go into the baseline. By reducing code review time and identifying potential issues earlier in the development CSPD expects to reduce the time to deliver changes and increase initial software quality. "
DHS-2362,AI/LLM to generate testable synthetic data,DHS,CBP,The purpose of using AI to generate test data for trade partners is to create more realistic data for trade partners to use for testing their systems before releasing new ACE capabilities.  Currently there are many data issues where test data does not accurately reflect real production data which results in unrealistic failures when testing which result in wasted time and resources tracking down false positive errors during testing.  By providing trade partners with more realistic test data the expectation is that testing times will be shorter and enhancements and capabilities can be delivered quicker.,"The purpose of using AI to generate test data for trade partners is to create more realistic data for trade partners to use for testing their systems before releasing new ACE capabilities.  Currently there are many data issues where test data does not accurately reflect real production data which results in unrealistic failures when testing which result in wasted time and resources tracking down false positive errors during testing.  By providing trade partners with more realistic test data the expectation is that testing times will be shorter and enhancements and capabilities can be delivered quicker.

he Automated Commercial Environment (ACE) is the system the trade community reports imports and exports, and the government determines admissibility. This system is developed and maintained by the Cargo Systems Program Directorate (CSPD) within the Office of Information Technology (OIT) in Customs and Border Protection (CBP). ACE is a large system consisting of hundreds of applications with new capabilities added regularly. CSPD is seeking to incorporate AI to generate more realistic synthetic data without Personally Identifiable Information (PII) for trade partners to utilize in testing new data formats and APIs before releasing new ACE capabilities.  By using synthetic data, the system does not risk any PII spillages. Currently, there are many data issues where test data does not accurately reflect real production data, which results in unrealistic failures when testing and wasted time and resources tracking down false positive errors during testing.  By providing trade partners with more realistic test data, the expectation is that testing times will be shorter and enhancements and capabilities can be delivered quicker., The AI capability would generate test data without PII or other trade sensitive data and allow for more accurate simulation of production data."
DHS-65,Aircraft Landing Location Predictor (KESTREL),DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

CBP uses Kestrel in CBP’s Air & Marine Operations Surveillance System (AMOSS) to aid in predicting where an aircraft will likely land based on historical flight paths. After an aircraft radar track has been declared suspect by the officer evaluating the track of interest through other research, Kestrel employs AI/ML to predict where the aircraft is most likely to land. The output results in a display of the top three final locations as displayed on AMOSS using green, yellow, and red lines to depict most to least probable outcomes."
DHS-188,Airship Outpost for Cross Border Conveyance  Identification,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

Part of CBP’s mission is the monitoring of cross border activity at and between our nation’s Ports of Entry. This requires maintaining awareness of cross border conveyances such as automobiles, boats, and airplanes. Airship Outpost allows CBP to accurately identify conveyances (aircraft, vessels, automobiles) by ingesting images and then leveraging AI to identify the type of conveyance and to know where to read the alpha numeric values used to identify them (tail number, hull number, license plate). Standards and regulations for the external identification of various types of conveyances vary significantly. For instance, an aircraft tail number, a vessel hull number, and an automobile license plate number. Once a conveyance is identified, the system focuses on the appropriate location to capture the alphanumeric values used for identification. The software then assigns a confidence score to the accuracy of each capture, which is attached to the files transmitted by the array to a database on cross border activity.  AI is solely used to identify the type of conveyance and then document the associated identification number."
DHS-2363,Anomaly Detection COV Structure,DHS,CBP,Anomaly Detection COV Structure is an AI algorithm solution to assist CBP officers in adjudicating  large-scale Non-Intrusive Inspection (NII) x-ray images. The solution will identify regions of interest within the structure of Commercially Owned Vehicles (COV) and detect anomalies within these regions. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication ultimately reducing overall review time for NII images.,"Anomaly Detection COV Structure is an AI algorithm solution to assist CBP officers in adjudicating  large-scale Non-Intrusive Inspection (NII) x-ray images. The solution will identify regions of interest within the structure of Commercially Owned Vehicles (COV) and detect anomalies within these regions. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication ultimately reducing overall review time for NII images.

CBP is seeking anomaly detection algorithm (ADA) models that can run on U.S. government systems for rapid screening of passenger and cargo vehicles. The desired end state is a suite of algorithms that supports CBP's non-intrusive inspection (NII) image analysis for detecting anomalies and interdicting contraband to assist CBP officers’ image review with specific interest on algorithms that facilitate screening for contraband and anomaly detection in passenger vehicles and cargo conveyances. This solution will assist CBP officers in adjudicating large-scale NII x-ray images. The solution will identify regions of interest within the structure of commercially owned vehicles (COVs) and detect anomalies within these regions. It will place bounding boxes around an anomaly or unidentifiable object(s) within an image or any portion of the image that cannot be identified or explained. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication, ultimately reducing overall review time for NII images.  It is expected that this will enhance the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States and increase clearance rate at border crossings, so that vehicles operating safely and lawfully may pass through the border faster.  "
DHS-2364,Anomaly Detection Homogenous Cargo,DHS,CBP,Anomaly Detection Homogenous Cargo is an AI algorithm solution to assist CBP officers in adjudicating large scale Non-intrusive Inspection (NII) x-ray images. The solution will identify anomalies within homogenous cargo contained in commercially owned vehicles (COVs). The algorithm will support the review and analysis conducted by CBP image analysts during NII x-ray image adjudication ultimately reducing overall review time for NII images.,"Anomaly Detection Homogenous Cargo is an AI algorithm solution to assist CBP officers in adjudicating large scale Non-intrusive Inspection (NII) x-ray images. The solution will identify anomalies within homogenous cargo contained in commercially owned vehicles (COVs). The algorithm will support the review and analysis conducted by CBP image analysts during NII x-ray image adjudication ultimately reducing overall review time for NII images.

CBP is seeking anomaly detection algorithm (ADA) models that can run on U.S. government systems for rapid screening of passenger and cargo vehicles. The desired end state is a suite of algorithms that supports CBP's non-intrusive inspection (NII) image analysis for detecting anomalies and interdicting contraband to assist CBP officers’ image review with specific interest on algorithms that facilitate screening for contraband and anomaly detection in passenger vehicles and cargo conveyances. This solution will assist CBP officers in adjudicating large scale NII x-ray images. The solution will identify anomalies within homogenous cargo contained in commercially owned vehicles (COVs). Bounding boxes around an anomaly or unidentifiable object(s) within an image or any portion of the image that cannot be identified or explained. The algorithm will support the review and analysis conducted by CBP image analysts during NII x-ray image adjudication ultimately reducing overall review time for NII images. It is expected that this will enhance the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States and increase clearance rate at border crossings, so that vehicles operating safely and lawfully may pass through the border faster.  "
DHS-312,Anomaly Detection in Non-Intrusive Inspection,DHS,CBP,"The model will identify irregularities or deviations from expected patterns that may indicate concealed contraband or threats while reducing overall review time.
","The model will identify irregularities or deviations from expected patterns that may indicate concealed contraband or threats while reducing overall review time.


CBP intends to procure, develop, and implement solutions that leverage advanced algorithms and machine learning to analyze data to assist CBP personnel in automating analysis of non-intrusive inspection (NII) images used in cargo and vehicle inspections. The model will identify irregularities or deviations from expected patterns that may indicate concealed contraband or threats by displaying specific areas within scanned images that show anomalies, that possibly needing further screening. It is expected to reduce overall review time. "
DHS-2365,Anomaly Detection POV Structure,DHS,CBP,Anomaly Detection POV Structure is an AI algorithm solution to assist CBP officers in adjudicating large-scale Non-Intrusive Inspection (NII) x-ray images. The solution will identify regions of interest within the structure of Privately Owned Vehicles (POV) and detect anomalies within these regions. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication  ultimately reducing overall review time for NII images while facilitating legitimate trade and travel.,"Anomaly Detection POV Structure is an AI algorithm solution to assist CBP officers in adjudicating large-scale Non-Intrusive Inspection (NII) x-ray images. The solution will identify regions of interest within the structure of Privately Owned Vehicles (POV) and detect anomalies within these regions. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication  ultimately reducing overall review time for NII images while facilitating legitimate trade and travel.

CBP is seeking anomaly detection algorithm (ADA) models for rapid screening of passenger and cargo vehicles. The desired end state is a suite of algorithms that supports CBP's non-intrusive inspection (NII) image analysis for detecting anomalies and interdicting contraband to assist CBP officers’ image review with specific interest on algorithms that facilitate screening for contraband and anomaly detection in passenger vehicles and cargo conveyances. This solution will assist CBP officers in adjudicating large-scale NII x-ray images. The solution will identify regions of interest within the structure of privately owned vehicles (POVs) and detect anomalies within these regions. Bounding boxes around an anomaly or unidentifiable object(s) within an image or any portion of the image that cannot be identified or explained. The algorithm will support the review and analysis conducted by image analysts during NII x-ray image adjudication  ultimately reducing overall review time for NII images while facilitating legitimate trade and travel. It is expected that this will enhance the capability of humans to consistently detect items of interest/concern present (and possibly concealed) in vehicles crossing into the United States and increase clearance rate at border crossings, so that vehicles operating safely and lawfully may pass through the border faster. "
DHS-2444,API Security Vulnerability Technology,DHS,CBP,"With the necessity of leveraging application programing interfaces (APIs) for applications across the enterprise, this AI technology is intended to run thousands of custom attack scenarios against APIs on a continuous basis. This will help to identify potential security vulnerabilities prior to production level deployments, and enable the enterprise to develop essential remediations, if required.  Additionally, the techonlogy is intended to provide continuous monitoring on APIs to provide real-time alerts on new potential vulnerabilities.
","With the necessity of leveraging application programing interfaces (APIs) for applications across the enterprise, this AI technology is intended to run thousands of custom attack scenarios against APIs on a continuous basis. This will help to identify potential security vulnerabilities prior to production level deployments, and enable the enterprise to develop essential remediations, if required.  Additionally, the techonlogy is intended to provide continuous monitoring on APIs to provide real-time alerts on new potential vulnerabilities.


Enabling user-access to a secure environment and robust cybersecurity posture is critical to CBP operations. In order to support these objectives, CBP is intending to leverage application programing interface (API) testing technology which machine learning (ML) coupled with natural language processing (NLP) and automated software testing techniques. This platform is intended to automatically scan and continuously monitor APIs to detect potential risks like unauthorized access, data leaks, or weaknesses. Once tests are conducted on APIs, a comprehensive vulnerability report will identify security risks such as broken authentication, exposed data, or misconfigurations. The software is also intended to provide clear remediation guidance based on the applications, environment, data, and tests conducted for end-users, offering step-by-step solutions to fix these vulnerabilities. Additionally, this capability will assign a risk score to help prioritize the most critical issues and ensures APIs comply with industry standards and regulations through detailed compliance checks. With continuous security monitoring, the platform also delivers real-time alerts for new vulnerabilities, empowering teams to maintain robust API security throughout the development and deployment lifecycle. "
DHS-37,Automated Item of Interest Detection,DHS,CBP,"The software analyzes images and video that are taken by operationally deployed equipment, which are then fed into CBP systems for review by USBP agents and personnel. It provides quick identification of people either crossing into the U.S. at a time and place other than designated for entry or those already inside the U.S. trying to elude capture, as well as the ability for human operators to quickly determine if subjects in an image are, in fact, human.","The software analyzes images and video that are taken by operationally deployed equipment, which are then fed into CBP systems for review by USBP agents and personnel. It provides quick identification of people either crossing into the U.S. at a time and place other than designated for entry or those already inside the U.S. trying to elude capture, as well as the ability for human operators to quickly determine if subjects in an image are, in fact, human.

CBP uses software to analyze field imaging in monitored areas and to provide alerts when it detects the presence of an Item of Interest (IoI) that the AI model was trained to detect (i.e., persons, vehicles, animals) in the image frame. The software outputs include a superimposed outline surrounding of the IoI within the image or live feed. Each outline is color-coded based on the degree of certainty that the detection is the item it was trained to detect. The software allows the user to filter based on preferences for detections of IoI. This filtering allows for quick and efficient review and adjudication of the detection(s). After the alert of a detection, a trained CBP agent or user, reviews the image to identify and classify the activity taking place. "
DHS-23,Autonomous Aerostat,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Aerostat capability that uses three tethers instead of the traditional single tether, coupled with advanced weather sensors, analytic capabilities, and powerful winches. The AI/ML model is used to detect the need to launch and land based on weather. It also leverages AI and robotics to autonomously launch and recover the aerostat during inclement weather events without the need for on-site staffing, allowing the aerostat to operate autonomously, saving time and manpower. "
DHS-P3,Autonomous Maritime Awareness,DHS,CBP,"The technology is equipped to operate in low temperatures, ice, and snow enable real-time surveillance for continuous monitoring of maritime activity, even in harsh conditions, while providing enhanced detection capabilities to identify threats such as unauthorized vessels or smuggling activities in difficult-to-navigate regions.
","The technology is equipped to operate in low temperatures, ice, and snow enable real-time surveillance for continuous monitoring of maritime activity, even in harsh conditions, while providing enhanced detection capabilities to identify threats such as unauthorized vessels or smuggling activities in difficult-to-navigate regions.


The Autonomous Maritime Awareness system combines surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to autonomously detect, identify, and track items of interest in a maritime environment. The towers are low-cost, customizable, and relocatable surveillance systems. They are equipped with a suite of radars and day/night camera sensors. The ASVs have been ruggedized for the open ocean and are powered by wind, solar, and/or onboard engine as required, allowing them to operate in an area of responsibility (AOR) for up to 12 months. Their sensor suite includes cameras and radar. Both systems use AI/ML to detect and identify objects, determine items of interest (IoI) and autonomously track those items using their sensor suites. Once identified, these systems can send alerts to monitoring agencies for at-sea interdiction of potential targets and/or intel collections. "
DHS-35,Autonomous Surveillance Tower (AST),DHS,CBP,"AST machine learning assisted system is augmenting the U.S. Border Patrol by enhancing the capabiltiies of individual users when carrying out the domain awareness mission. 
The expected benefit is to have ability of single person to monitor magnitude greater area than could be done with conventional CCTV or human surveillance. The ultimate outcome for the agency and the public is greater availability of the agents to solve and address more complex tasks and allow for better strategic/tactical deployment of existing resources and personnel.
","AST machine learning assisted system is augmenting the U.S. Border Patrol by enhancing the capabiltiies of individual users when carrying out the domain awareness mission. 
The expected benefit is to have ability of single person to monitor magnitude greater area than could be done with conventional CCTV or human surveillance. The ultimate outcome for the agency and the public is greater availability of the agents to solve and address more complex tasks and allow for better strategic/tactical deployment of existing resources and personnel.


The ASTs are lawfully deployed technologies used to support the U.S. Border Patrol mission between Ports of Entry.  ASTs alert when detecting the presence of an IoI that the AI model was trained to detect (i.e., persons, vehicles, animals) in the image frame. When an IoI is detected in monitored areas, the information is sent as a notification to the user interface which generates an audible alert, a pop-up, and highlights the IoI in a green rectangle on the picture or video. A trained CBP agent or user, reviews the image to identify and classify the activity taking place. The AI merely alerts to the presence of an item it was trained to detect. "
DHS-185,Babel,DHS,CBP,"CBP uses this tool to conduct targeted queries to aid CBP in open source research to monitor potential threats or dangers or identify travelers who may be subject to further inspection for violation of laws CBP is authorized to enforce or administer.
","CBP uses this tool to conduct targeted queries to aid CBP in open source research to monitor potential threats or dangers or identify travelers who may be subject to further inspection for violation of laws CBP is authorized to enforce or administer.


Babel is a commercially procured tool that helps CBP compile social media and open-source information on travelers who may be subject to further screening for potential violation of laws that CBP is authorized to enforce or administer. The tool searches and aggregates open-source information related to manually entered queries, which CBP can review and utilize to identify potential threats to the United States. CBP uses this tool to conduct targeted queries to aid CBP in open source research to monitor potential threats or dangers, or to identify travelers who may be subject to further inspection for violation of relevant laws . Babel utilizes AI modules for text detection and translation as well as object and image recognition to provide analysts with possible matches to manually review in a single interface, versus doing multiple manual queries. The output is not singly used for action or decision making. Rather, it is used to identify additional open source or social media content for a person or to identify additional selectors (such as phone and emails) that are previously unknown to CBP. These selectors are then compared by an analyst against Government systems to identify any additional derogatory information. These factors often eliminate additional screening for the traveler. "
DHS-2390,Cargo Counternarcotics,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

The Cargo Counternarcotics Model is integrated within the Automated Targeting System (ATS) and utilizes advanced data analytics and machine learning algorithms to identify and target shipments potentially involved in narcotics smuggling. By analyzing various data sources, including shipping details, historical information, and risk indicators the AI model enhances CBP’s ability to detect and prevent the trafficking of illicit substances and strengthens operational capabilities without compromising the efficiency of cargo processing., AI/ML models identify high risk shipments to aid CBP officers in detecting narcotics smuggling threats, identifying candidate shipments for review and referral for inspection at CBP Ports of Entry (POEs). High-risk model results are returned to users as a system rule hit. These rule hits are viewable in the associated system results window. From this window, CBP operational personnel review and assess result for next action, including possible shipment examination. "
DHS-95,Cargo Entity Risk Model,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

The project leverages an ensemble of supervised machine learning models that identifies risk of trade entities likely to have a seizure/violation.  These models are based on aggregated trade entity profiles as well as associative characteristics used to inform risk across  all cargo enforcement risk domains and cargo predictive threat models. The Cargo Entity Risk model/tool enhances cargo predictive threat models by providing a comprehensive risk profile that aggregates historical trade entity transactions, trading partner relationships, reviews, examinations, and violations (within CBP data holdings) to create quantifiable risk measures for all trade entities. The resulting risk measures can be utilized by larger AI/ML cargo risk targeting models to better assess cargo threats. The output of the Cargo Entity Risk (CER) model/tool is a calculated risk measure that supports standardization of trade entity risk for enhanced data and feature development for use in larger mode, or threat-specific cargo predictive risk models."
DHS-2366,CBP Careers Bot - Leo,DHS,CBP,"Visitors to the U.S. Customs and Border Protection (CBP) careers website can engage with a decision-tree based chat bot to help access CBP career related information and drive users to take the next action such as contacting a recruiter, attending a career event, or applying for a CBP career to help access CBP career related information and drive users to take the next action. The addition of Natural Language Processing (NLP)-driven responses will allow for more natural, conversational interactions to increase usability and accuracy in provided information.","Visitors to the U.S. Customs and Border Protection (CBP) careers website can engage with a decision-tree based chat bot to help access CBP career related information and drive users to take the next action such as contacting a recruiter, attending a career event, or applying for a CBP career to help access CBP career related information and drive users to take the next action. The addition of Natural Language Processing (NLP)-driven responses will allow for more natural, conversational interactions to increase usability and accuracy in provided information.

Visitors to careers.cbp.gov can engage with a decision-tree based chat bot to help access CBP career related information and drive users to take the next action such as contacting a recruiter, attending a career event, or apply for a CBP Career. This bot will be enhanced over the next year to include responses driven by natural language processing (NLP) for predetermined intents. "
DHS-2373,CBP Employee Experience,DHS,CBP,"CBP Employee Experience is intended to ingest, interpret, and operationalize employee experience data originating from survey results and operational data to deliver real time insights related to the experience of USBP recruits, applicants, and employees. These metrics inform HRM leadership of opportunities for process improvement in order to meet congressionally mandated hiring targets and retain a qualified workforce.","CBP Employee Experience is intended to ingest, interpret, and operationalize employee experience data originating from survey results and operational data to deliver real time insights related to the experience of USBP recruits, applicants, and employees. These metrics inform HRM leadership of opportunities for process improvement in order to meet congressionally mandated hiring targets and retain a qualified workforce.

CBP Office of Human Resources Management leverages Medallia Employee Experience Management Software to ingest, interpret, and operationalize employee  survey results and operational data to deliver real time insights related to the experience of USBP recruits, applicants, and employees. Medallia offers Athena AI Text Analytics to analyze qualitative input and layer with quantitative data for holistic experience metrics. These metrics inform HRM leadership of opportunities for process improvement in order to meet congressionally mandated hiring targets and retain a qualified workforce.  
 
CBP HRM has launched the following solutions that leverage Medallia Athena Artificial Intelligence (AI) Text Analytics:  (1)  Digital feedback survey on the public facing CBP Careers Site for visitors interested in a CBP Career to provide feedback on experience finding and applying for a CBP Career 
 (2) Post-Application Survey and Dashboard - provides opportunity for USBP applicants who receive tentative select to provide feedback on the Careers Site, Application Process, and Recruiter Experience.  (3) Withdraw Survey and Dashboard - provides opportunity for USBP applicants who voluntarily withdraw from the hiring process to provide feedback on their reason for discontinuing and opportunities for future process improvement.  (4) Medical Exam Survey - provides opportunity for USBP applicants who have completed medical exam step to provide feedback on preparation and experience interacting with vendor staff. (5) eQIP Survey - provides opportunity for USBP applicants who have completed eQIP to provide feedback on preparation and experience using the vendor software. (6) Exit Survey - provides opportunity for departing employees to provide feedback on their experience as a CBP employee to inform opportunities for improved retention., To ingest, interpret, and operationalize employee experience data originating from survey results and operational data, Real time insights related to the experience of USBP recruits, applicants, and employees. "
DHS-381,CBP One,DHS,CBP,"TVS uses facial recognition to compare live or uploaded images with CBP's database, enabling real-time identity verification. This automation streamlines border processes, enhances accuracy, and reduces fraud.","TVS uses facial recognition to compare live or uploaded images with CBP's database, enabling real-time identity verification. This automation streamlines border processes, enhances accuracy, and reduces fraud.

CBP One is a mobile application developed by CBP to streamline and enhance various border management processes. It allows users, including travelers and border agents, to access multiple CBP services through a single, user-friendly platform. The Traveler Verification System (TVS) is an AI-driven facial recognition technology integrated into CBP One. TVS uses facial recognition to compare live or uploaded images with CBP's database, enabling real-time identity verification. This automation streamlines border processes, enhances accuracy, and reduces fraud. The system outputs include identity match confirmation, fraud alerts, and traveler status updates for clearance in processes like boarding or border crossing."
DHS-2388,CBP Translate,DHS,CBP,"CBP Translate is used to facilitate clear communication between officers and non-English-speaking individuals during border interactions. The AI enhances efficiency by reducing language barriers, supports diverse languages for greater inclusivity, and ensures accurate communication to minimize misunderstandings during critical procedures.
","CBP Translate is used to facilitate clear communication between officers and non-English-speaking individuals during border interactions. The AI enhances efficiency by reducing language barriers, supports diverse languages for greater inclusivity, and ensures accurate communication to minimize misunderstandings during critical procedures.


CBP Translate is a mobile and web application designed to assist CBP officers in communicating with travelers who speak diverse languages during inspections at U.S. ports of entry. It supports real-time, multilingual translation for interviews, inspections, and other interactions, improving efficiency and accessibility at ports of entry and during border processes., CBP Translate is used to facilitate clear communication between officers and non-English-speaking individuals during border interactions. The AI enhances efficiency by reducing language barriers, supports diverse languages for greater inclusivity, and ensures accurate communication to minimize misunderstandings during critical procedures. The system provides real-time translations of spoken or written communication, detects individuals' languages for accurate translation, and generates logs of interactions for review. The output is used to support necessary interpretation but sworn statements and official communications for law-enforcement purposes are moved to standard translation services for formal documentation and questioning. "
DHS-165,Automated Data Annotation,DHS,CBP,"The Automated Data Annotation system is used to manage training data, collaborate on internal annotation strategies, and to process vast amounts of raw data for AI/ML applications collected from several CBP missions.The intended purpose of the AI is used to generate domain specific training data to facilitate model training for specific mission use cases. The expected benefit would be increased accuracy and confidence in model development.","The Automated Data Annotation system is used to manage training data, collaborate on internal annotation strategies, and to process vast amounts of raw data for AI/ML applications collected from several CBP missions.The intended purpose of the AI is used to generate domain specific training data to facilitate model training for specific mission use cases. The expected benefit would be increased accuracy and confidence in model development.

The Automated Data Annotation system simplifies and enhances data annotation for machine learning by providing tools to efficiently label datasets across various formats, such as images, text, and videos. It supports both manual labeling with an intuitive web interface and automated labeling powered by machine learning to accelerate the process. Human annotation is offered to verify and validate the automated annotations. The intended purpose of the AI is to generate domain specific training data to facilitate model training for specific mission use cases. The expected benefit is increased accuracy and confidence in model development and high-quality, labeled datasets in JavaScript Object Notation (JSON) format ready for machine learning. It also provides metadata, including annotation metrics and quality insights, to ensure accuracy and support model training workflows."
DHS-69,Commodity Detection Model (Cargo Insights Team),DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

This project leverages computer vision with object detection and a neural network to analyze X-Ray images and predict the commodity code of detected objects. It analyzes X-Ray images and predicts the commodity code of detected objects, reducing the need for users to manually enter codes for all commodities presented. The model provides a commodity code prediction label with bounding boxes on the image. "
DHS-2367,Computer Vision for Aerial Detection of Land and Open Water Items of Interest,DHS,CBP,"This capability will automate cross-border maritime threat detection, classification and tracking, enabling more efficient maritime border security surveillance.   ","This capability will automate cross-border maritime threat detection, classification and tracking, enabling more efficient maritime border security surveillance.   

Current detection, classification (determining intention and/or threat level of each detection), and tracking of potential, cross-border maritime threats mostly rely on human operators monitoring radar tracks on a screen and scanning the maritime environment with surveillance camera systems.  This capability leverages high fidelity cameras on airborne platforms along with computer vision machine learning (CV/ML) models to automate the detection, classification, and tracking of potential cross-border maritime threats. This capability will automate cross-border maritime threat detection, classification and tracking by providing alerts and tracks of detected/classified maritime threats to system operators, enabling more efficient maritime border security surveillance. "
DHS-310,Customs Broker License Exam - Proctor Support,DHS,CBP,"The model supports remote proctoring of the exam and ensure the integrity of the testing process, by ensuring the exam is conducted under secure conditions, preventing cheating or fraud, while also verifying the identity of exam takers to confirm they meet the necessary requirements.
","The model supports remote proctoring of the exam and ensure the integrity of the testing process, by ensuring the exam is conducted under secure conditions, preventing cheating or fraud, while also verifying the identity of exam takers to confirm they meet the necessary requirements.


CBP uses AI technology during the remote Customs Broker License Exam (CBLE) to alert exam proctors to activities that may need review (i.e., alerting the proctor when a candidate leaves or when a second person is present). The output of the AI is a box that highlights the examinee’s tile on the proctor’s screen, drawing the proctor’s attention to the examinee’s behavior. Proctors can use the third-party vendor portal to review the alerts.  The examinee’s computer webcam and audio will be used to capture a video and audio recording of the examination by the vendor. After the alert, the proctor reviews the video and audio and determines if there is any potential violation of exam rules. If the proctor determines there is a potential violation, the proctor will create an incident report to describe the concern. Upon request, CBP will have access to the third-party vendor’s audio and video files to review along with any incident report.    "
DHS-399,Cyber Threat Analysis (Recorded Future),DHS,CBP,"Cyber Threat Analysis quickly populates query results when searching against adversary tactics, techniques, and procedures, establishing a threat scorecard. This service can also provide cyber risk scorecards for third party vendors, companies, and organizations.","Cyber Threat Analysis quickly populates query results when searching against adversary tactics, techniques, and procedures, establishing a threat scorecard. This service can also provide cyber risk scorecards for third party vendors, companies, and organizations.

Recorded Future data query enables CBP Cyber Threat Intelligence (CTI) analysts to focus on investigating recently observed relevant cyber threat activity rather than manually identifying, formatting, and searching for such information in multiple locations. Enables these analysts to quickly view known cyber threat activity targeting known vulnerabilities, which will reduce the time to identify risks to the vulnerabilities that exist in CBP’s information technology environment. AI/ML is employed several ways on this platform: For representation of structured knowledge of the world, using ontologies and events; for transforming unstructured text into a language-independent, structured representation, using natural language processing; for classifying events and entities, primarily to help decide if they are important enough to require a human analyst to perform a deeper investigation; to forecast events and entity properties by building predictive models from historic data. This service can also provide cyber risk scorecards for third party vendors, companies, and organizations. "
DHS-2446,Cyber Threat Detection,DHS,CBP,"The technology will provide premise and/or behind the firewall deployments to support all cloud environments. The technology will establish a decoy file sharing capability such as SharePoint, Shared Drive, etc. with tailored decoy products or reports and monitor and alert on the access and interactions with the decoys.
","The technology will provide premise and/or behind the firewall deployments to support all cloud environments. The technology will establish a decoy file sharing capability such as SharePoint, Shared Drive, etc. with tailored decoy products or reports and monitor and alert on the access and interactions with the decoys.


Cyber Threat Detection is a cyber platform that enables CBP to detect, engage, and respond to malicious activity across hybrid cloud deployments, protecting both IT and networks. It uses generative AI (GenAI) to create decoys, lures, baits, and breadcrumbs, to detect threats and allows for more proactive threat identification and associated mitigation. The technology will establish a decoy file sharing capability such as SharePoint, Shared Drive, etc. with tailored decoy products or reports and monitor and alert on the access and interactions with the decoys. The technology enables the accurate detection of malicious activity in the cyber environment for actionable insights so that leadership can identify threats and efficiently mitigate them while reducing the cost of other security defenses. With the technology, the user will be alerted of detected compromise, evaluation of the creation of decoys, and the monitoring/analysis of interaction with the decoys from the adversary.  "
DHS-32,Data and Entity Resolution,DHS,CBP,Entity resolution for ES multiple independent valid requirements that may be similar or able to be consolidated.,"Entity resolution for ES multiple independent valid requirements that may be similar or able to be consolidated.

Product uses ML modeling to ingest multiple data sources and evolve models that associate disparate records to identify probable entities and/or identify commonalities between multiple independently submitted records. The automation of entity resolution within the models is supported by a tool that enables non-technical end users to continuously train models through a user-friendly interface."
DHS-68,Empty Container Detection Model (Cargo Insights Team),DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

CBP's Empty Container Detection Model uses machine learning to identify and track empty containers in cargo shipments. By analyzing shipping data and container movements, the model helps detect potential discrepancies, such as empty containers being incorrectly labeled as full, improving the accuracy and efficiency of cargo management and inspections. This enhances border security and optimizes resource allocation for inspections. The model is designed to accurately identify and track empty containers in cargo shipments, preventing errors and fraud in cargo declarations. The AI improves accuracy, enhances efficiency by prioritizing legitimate containers for inspection, and strengthens security by detecting potential smuggling risks. The system applies a prediction label alongside a bounding box on record.  Officers use this information along with all information provided to determine what, if any, further steps are required."
DHS-24,Entity Resolution,DHS,CBP,Detection research of force labor within supply chain utilizing analytical AI platform.,"Detection research of force labor within supply chain utilizing analytical AI platform.

CBP uses Altana to compile a vast amount of public and lawfully obtained private data regarding cross-board trade. These data elements can include bills of lading, manifests, invoices, and open-source information, as well as elements available only through the Altana subscription. Altana assists in researching supply chain information related to various trade enforcement topics areas such as forced labor and anti-dumping/countervailing duty evasion to better assess trade flow and risk associated with cross-border trade. The data elements provide an illustration for both supply chain and the flow of trade. The AI is used in the background to pull together disparate pieces of information from incompatible data sets to illustrate the supply chains. The illustration is used by the analysts to determine high risk areas for trade targeting in the forced labor mission set. "
DHS-315,ERNIE,DHS,CBP,"The model enhances threat detection and prioritizes high-risk targets, improving operational efficiency and national security.","The model enhances threat detection and prioritizes high-risk targets, improving operational efficiency and national security.

ERNIE is used to analyze Radiation Portal Monitor (RPM) data to enhance the detection of radioactive materials. The system assesses potential threats, improving the accuracy and speed of identifying illicit or hazardous materials, thereby prioritizing high-risk detections, reducing false alarms and ensuring more efficient security and risk management at ports of entry. The model enhances threat detection and prioritizes high-risk targets, improving operational efficiency and national security. The model provides real-time risk assessments and alerts for potential threats detected by the Radiation Portal Monitors. It also provides prioritized recommendations for further screening based on the analysis of radiation data. "
DHS-186,Fivecast ONYX,DHS,CBP,"The system enhances CBP's capability to monitor, analyze, and assess threats related to border security by processing vast amounts of open-source data, CBP aims to detect potential risks, monitor emerging trends, and uncover connections between individuals, organizations, or networks involved in illegal activities such as human trafficking, smuggling, or terrorism. Thereby streamlining operations and bolster security measures while maintaining a proactive approach to emerging threats
","The system enhances CBP's capability to monitor, analyze, and assess threats related to border security by processing vast amounts of open-source data, CBP aims to detect potential risks, monitor emerging trends, and uncover connections between individuals, organizations, or networks involved in illegal activities such as human trafficking, smuggling, or terrorism. Thereby streamlining operations and bolster security measures while maintaining a proactive approach to emerging threats


Fivecast is a technology platform accessed through an internet-based user interface that provides insight into a variety of social media platforms including, but not limited to, Facebook, Instagram, Telegram, and Twitter.  Fivecast analyzes the strength of connections between social media users and collects both media and activity information from targeted profiles. It also enables the identification of usernames and profiles using individual names, telephone numbers, age, email address, and location.  Fivecast has proven to be one of the most valuable tools in the OSINT technology stack as it enables advanced search, collection, and analysis of publicly available information through a single user interface, facilitating the collection of information regarding people, places, and things across social media platforms, as well as general information held on the surface, deep, and dark web to inform situational awareness. CBP uses Fivecast ONYX to analyze open-source data, including social media and other public platforms, to identify potential threats, monitor illegal activities, and assess risks to national security.  The system enhances CBP's capability to monitor, analyze, and assess threats related to border security by processing vast amounts of open-source data. CBP aims to detect potential risks, monitor emerging trends, and uncover connections between individuals, organizations, or networks involved in illegal activities such as human trafficking, smuggling, or terrorism, thereby streamlining operations and bolstering security measures.  "
DHS-27,Geospatial Imagery Utilizing Annotation,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Leverages a commercial constellation of Synthetic Aperture Radar (SAR) satellites with readily available data, capable of imaging any location on Earth, day, and night, regardless of cloud cover. Utilizes AI, including machine vision, object, detection, object recognition, and annotation to detect airframes, military vehicles, and marine vessels, as well as built-in change detection capabilities for disaster response missions."
DHS-94,HTS Classifier,DHS,CBP,"CBP’s HTS Classifier improves trade compliance and enhances cargo risk assessment by streamlining the classification of goods, enabling better integration with machine learning systems, and refining entity risk evaluations. It identifies potential threats linked to specific cargo types and prior violations by categorizing goods based on their descriptions and attributes. These improvements contribute to faster, more accurate classification and risk-based targeting, which strengthens security and facilitates trade.","CBP’s HTS Classifier improves trade compliance and enhances cargo risk assessment by streamlining the classification of goods, enabling better integration with machine learning systems, and refining entity risk evaluations. It identifies potential threats linked to specific cargo types and prior violations by categorizing goods based on their descriptions and attributes. These improvements contribute to faster, more accurate classification and risk-based targeting, which strengthens security and facilitates trade.

CBP’s HTS Classifier employs AI Natural Language Processing (NLP) and text analytics to analyze product descriptions and predict appropriate Harmonized Tariff Schedule codes. These capabilities align with cargo threat evaluation by integrating unsupervised learning to classify goods efficiently, reducing human error and enhancing compliance. CBP’s HTS Classifier improves trade compliance and enhances cargo risk assessment by streamlining the classification of goods, enabling better integration with machine learning systems, and refining entity risk evaluations. It identifies potential threats linked to specific cargo types and prior violations by categorizing goods based on their descriptions and attributes. These improvements contribute to faster, more accurate classification and risk-based targeting. The HTS Classifier produces outputs that map cargo commodity descriptions to their most probable tariff codes, enhancing classification accuracy. These outputs integrate seamlessly into broader threat-specific risk models, providing features to support predictive risk assessments in cargo security"
DHS-424,I4 Viewer Matroid Image Analysis,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Matroid is a software that enables CBP end users to create and share vision detectors. Matroid detectors are trained computer vision models that recognize objects, people, and events in any image and in video streams. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. Users can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through Matroid’s powerful developer Application Programming Interface and language-specific clients, so CBP applications can be integrated with the power of computer vision. "
DHS-2391,Illicit Trade,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

CBP leverages an advanced AI and machine learning (AI/ML) model to enhance risk assessment in inbound cargo, focusing on critical areas like Intellectual Property Rights (IPR) violations and compliance with the Uyghur Forced Labor Prevention Act (UFLPA). The tools include text analytics and predictive modeling to assist personnel to identify suspicious shipments and flag potential violations of trade laws for further examination. These efforts help CBP prioritize enforcement actions in maritime cargo, targeting counterfeit goods and forced-labor-related imports through data-driven insights. The model identifies high risk shipments to aid CBP personnel in workload associated with detecting threats, identifying candidate shipments for review and referral for further screening. The model analyzes historical data, examination outcomes, and high-risk attributes to identify shipments likely to involve Intellectual Property Rights (IPR) violations or breaches of the Uyghur Forced Labor Prevention Act (UFLPA).  The model results are sent to the Automated Targeting System for review and assessment by operational personnel, who may conduct additional screening if necessary. "
DHS-311,Integrated Defense and Security Solutions (IDSS),DHS,CBP,"The systems improves the screening efficiency and accuracy of contraband detection in international express consignment and mail inspection.
","The systems improves the screening efficiency and accuracy of contraband detection in international express consignment and mail inspection.


CBP employs computed tomography x-ray systems with automated recognition technology for the inline screening of high-volume parcels to detect contraband. The system integrates AI-driven analytics into non-intrusive inspection systems, enhancing screening efficiency and accuracy by identifying anomalies for CBP personnel to review and, if necessary, conduct additional screening. The systems improve the screening efficiency and accuracy of contraband detection in international express consignment and mail inspection. The system provides a segmented image, highlighting anomalies for further inspection by CBP personnel. "
DHS-29,Integrated Digital Environment,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Integrated Digital Environment provides managers with a better understanding of end user workflows, most and least used applications, and opportunities for improvement. The AI/ML model applies to end user activity data (e.g., use of applications, flow between applications) to help CBP identify opportunities for more efficient or effective configuration of interfaces, use of resources, or development and deployment of CBP’s applications. It tailors analytics and insight generation to allow metrics gathering, usage recording/observation, dashboarding, and workflow experimentations/suggestions to support analysts utilizing the entire suite of agency and open-source data systems. It also customizes existing capabilities to allow the exact automations needed for agency applications and systems, creating an integrated digital environment for greater connectivity and security between applications, and better ability for CBP administrators to manage and optimize use of applications by end users. "
DHS-2415,Mobile Traveler Identity Verification,DHS,CBP,"The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification","The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification

CBP uses facial recognition technology for process efficiency under the Visa Waiver system, using Electronic System for Travel Authorization (ESTA) Mobile, and in identifying arriving travelers at airports of entry, using Mobile Passport Control. ESTA Mobile is an application and screening system used to determine whether citizens and nationals from countries participating in the Visa Waiver Program (VWP) are eligible to travel to the United States. ESTA Mobile extends the functionality to mobile platforms. The ESTA Mobile application captures a live photo from the traveler to perform a liveness test, and permit CBP’s TVS to conduct a 1-to-1 comparison of the traveler’s captured photo against the traveler’s passport e-Chip photo. ESTA mobile app users may either be an applicant, or third-party affiliates may complete an ESTA authorization on behalf of the traveler. If the ESTA Mobile output does not find liveness or cannot determine an identity match, the application can move forward through the ESTA website, simply treating it as filed by a third-party applicant. Mobile Passport Control captures lives photos of a traveler to permit CBP’s TVS to compare the photo to verified identifies compiled in flight galleries. This allows traveler to verify their identity using their mobile device. If a traveler is unsuccessful with mobile passport control, the traveler is simply processed in the regular customs line. "
DHS-2449,Multi-media Insight Tool,DHS,CBP,"The system enhances CBP's ability to monitor and analyze surveillance footage from existing USBP camera technology, enabling real-time detection of anomalies, and tracking of Items of interest within the video frame. It improves situational awareness, streamlines the identification process, and supports faster, more accurate decision-making, ultimately enhancing security and operational efficiency.","The system enhances CBP's ability to monitor and analyze surveillance footage from existing USBP camera technology, enabling real-time detection of anomalies, and tracking of Items of interest within the video frame. It improves situational awareness, streamlines the identification process, and supports faster, more accurate decision-making, ultimately enhancing security and operational efficiency.

The capability will leverage multimodal AI models and a cloud-native application programing interface (API) platform to find similar videos, or to search within videos for objects, spoken language, or sounds through recognition. The platform will provide users the ability to more efficiently search within videos for objects, spoken language, or sounds and the ability to rapidly ingest and extract insights for visual and audio data. With the technology, CBP will be able to more easily track and search for individuals, things, events (such as activated lights/sirens) in video, expanding to searching for an entity or event from one video file across multiple. The technology will integrate multimedia (audio and video) from multiple sources and sensors to generate by-source timelines and provide geospatial reference. With the extracted insights from visual and audio data, users will be able to detect simultaneous events across multiple video files and identify common key events where event times are known, inferring timestamps in linked or subsequent videos. Ultimately, the technology will allow for more efficient investigations. "
DHS-163,Non-Intrusive Inspection (NII) 3D Imaging Tool,DHS,CBP,"Utilizes AI/ML to generate high resolution, rapid imaging of objects behind occlusions; create 3D images for existing processes without significant slowdowns; and provide a novel narcotics detection capability for the inspection of packages.","Utilizes AI/ML to generate high resolution, rapid imaging of objects behind occlusions; create 3D images for existing processes without significant slowdowns; and provide a novel narcotics detection capability for the inspection of packages.

CBP is responsible for the processing of imported mail, which includes, but is not limited to, the examination of commercial and personal parcels to detect contraband while assuring compliance with applicable laws and regulations. CBP uses a 3D imaging tool for border and transportation security. This system generates high resolution, rapid imaging of objects behind occlusions; creates 3D images for existing processes without significant slowdowns; and provides a novel narcotics detection capability for the inspection of packages. The system uses supervised ML-trained algorithms to accelerate identification of anomalies and objects of interest within the output images by CBP officers. Based on the output images, officers are able to triage incoming mail more effectively and make a faster determination of whether to apply additional screening., The solution utilizes AI/ML to generate high resolution, rapid imaging of objects behind occlusions; create 3D images for existing processes without significant slowdowns; and provide a novel narcotics detection capability for the inspection of packages. The system creates detection alerts for Items of Interest."
DHS-171,Open-Source News Aggregation,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The platform enables users to make better decisions faster by identifying and forecasting emerging events on a global scale to mitigate risk, recognize threats, greatly enhance indications and warnings, and provide predictive intelligence capabilities. The AI/ML models enable rapid access to automated intelligence assessments by fusing, processing, exploiting and analyzing open sources of data (including news, social media, economic indicators, governance indicators, travel warnings, weather and other sources). This system is an immediate and substantial force multiplier that shifts the traditional approach of monitoring and assessing the operational environment to focus on the forecast of the future geopolitical, socio, and economic environment. "
DHS-2371,Optical Counter - UAS Detection,DHS,CBP,"This capability will automate cross-border air & ground threat detection, classification and tracking, enabling more efficient border surveillance.","This capability will automate cross-border air & ground threat detection, classification and tracking, enabling more efficient border surveillance.

Current detection, classification [determining intention and/or threat level of each detection], and tracking of potential, cross-border air and ground threats mostly rely on human operators scanning the border environment with surveillance camera systems.  This capability leverages 360-degree rotating, high fidelity cameras on stationary towers along with computer vision machine learning (CV/ML) models to automate the detection, classification, and tracking of potential cross-border air and ground threats. This capability will automate cross-border air and ground threat detection, classification, and tracking, enabling more efficient border surveillance. It will provide alerts and tracks of detected/classified air & ground threats to system operators on a workstation user interface. "
DHS-2389,Passenger Counternarcotics,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

The Passenger Counternarcotics Model uses AI to detect potential narcotics-related threats in passenger baggage, particularly focusing on high-risk indicators. The model is designed to assist CBP personnel in identifying narcotics shipments quickly, ensuring border security and safety. The model enhances the decision-making process of CBP personnel at ports of entry by providing real-time risk assessments related to narcotics smuggling indicators by leveraging data not typically accessible during primary processing, allowing for a rapid and comprehensive evaluation of inbound travelers and vehicles. The benefit is improved detection, enabling personnel to quickly identify high-risk individuals or shipments, which leads to more efficient narcotics interdiction. The output generates risk assessments and recommendations, which are integrated into the primary passenger processing systems, such as the Automated Targeting System (ATS). These notifications provide CBP personnel with actionable insights to identify potential narcotics threats in real-time."
DHS-80,Passenger Targeting and Vetting,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

he Passenger Targeting and Vetting Model enhances identity verification by comparing traveler data against government records to identify individuals who may require additional scrutiny before travel. The model also analyzes passenger information, such as travel patterns and historical records, to assess risk levels, enabling the prioritization of higher-risk travelers for further inspection by CBP personnel who are always the final decision-makers in the process. This approach enhances both security and operational efficiency by ensuring that resources are focused on the highest-risk individuals, streamlining the overall process of border security.  The AI model assesses traveler data such as travel patterns and historical records, allowing CBP personnel to prioritize higher-risk individuals for further screening. This streamlines the vetting process and allows CBP personnel to focus resources on the most high-risk travelers, thereby improving border security and reducing the burden of manual screening. The outputs are integrated into the Automated Targeting System (ATS), which generates notifications to recommend further inspection or follow-up actions. These recommendations assist CBP personnel in making real-time decisions about which travelers to prioritize for further screening. CBP personnel retain the final authority in the decision-making process, ensuring that human judgment remains central to border security operations. "
DHS-2380,Passive Body Scanner,DHS,CBP,"PBS is intended to enhance situational awareness in pedestrian traveler processing to aid  CBP officers in observing potentially dangerous objects or contraband in a timely manner and pursuant to CBP’s border search authority.
","PBS is intended to enhance situational awareness in pedestrian traveler processing to aid  CBP officers in observing potentially dangerous objects or contraband in a timely manner and pursuant to CBP’s border search authority.


Passive Body Scanner's (PBSs), deployed at various CBP pedestrian border crossings, use an algorithm to identify anomalies in body heat, assisting CBP officers to detect concealed weapons and contraband, allowing for efficient processing of travelers while flagging anomalies for further screening. While the AI provides these recommendations, CBP officers retain the final decision-making authority, reviewing any flagged areas to determine whether additional inspection is necessary. PBS is intended to enhance situational awareness in pedestrian traveler processing to aid CBP officers in observing potentially dangerous objects or contraband in a timely manner pursuant to CBP’s border search authority. This algorithm highlights areas on a person where potential objects may be blocking the subject's expected body heat and displays these areas on live video image, monitored by a CBP officer. The highlighted areas may show the locations of carried objects, which could be potential weapons or contraband. "
DHS-81,Passport Anomaly Model (ODIN ESTA),DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

As there is no requirement to notify the U.S. when a country issues a new passport series or an old series expires, Online Document Information Network (ODIN) is an important on-demand passport analysis tool used by officers to identify passport anomalies based on historical passport issuing trends. ODIN is a tool available to CBP officers for confirming the validity of a passport. Should officers send a passport to ODIN for validation, ODIN returns an assessment of passport validity, which includes normal or inconsistent/abnormal passport patterns. This result is used to notify the CBP officer that a passport may require review, as it may be part of a newly released sequence, may be invalid, or even possibly fraudulent. The CBP officer’s review of a passport may involve conducting additional research and scrutiny to determine whether a passport may be a new foreign country sequence, may have been altered, or may even be counterfeit. "
DHS-343,Port of Entry Risk Assessments,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

CBP utilizes AI to develop, inform, and augment risk assessment processes that evaluate trade and travel data in real-time.  AI methods are applied to CBP data holdings, and the results are used to inform decision making.  These tools are continuously evaluated to ensure accuracy and precision, and support CBP’s core mission as part of the layered risk assessment strategy. "
DHS-2451,Position Description Generation and Evaluation,DHS,CBP,"Faster and more accurate creation of PDs, reducing admin burden on field and HQs as well as HR specialists, allowing agency to get more done with less staff.","Faster and more accurate creation of PDs, reducing admin burden on field and HQs as well as HR specialists, allowing agency to get more done with less staff.

Incorporation of large langue models (LLMs) into the position description (PD) classification process, will enable accurate, speedy classification services delivery, increase uniformity in the classification process, and enable more robust PD language, leading to a more accurate assessment and ultimately a better applicant pool and candidate. Accurate PDs will also reduce the risk of PD based litigation or grievance against the agency. The system- created accurate PDs will be verified by Human Resources Specialist while reducing the administrative burden, allowing the agency to accomplish more with less staff."
DHS-2417,Process Efficiency Traveler Identity for Airline Check-in and Bag Drop,DHS,CBP,This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.,"This use case is Law Enforcement Sensitive. Some information about this use case is not shared because it would be inconsistent with applicable law and government wide policy. Please review the provided Use Case Summary for information about this Use Case.

This use case utilizes facial comparison technology, Traveler Verification Service (TVS), for identity verification at check-in or bags drop for air travel.  For bag drop, the Transportation Security Agency (TSA) has an established process under 49 U.S.C. § 114.1 for carriers to request an alternate procedure for identity verification. For these technical demonstrations, CBP’s TVS may serve as the requested alternate procedure. Air carriers, in voluntary partnership with CBP, may purchase camera equipment in order to capture photos at check-in and again at baggage drop for transmission to CBP. The TVS matching service creates a biometric template of each international traveler’s photo and compares it against templates of existing DHS holdings (i.e., U.S. passports, U.S. visas, and/or other DHS encounters) in order to provide identity verification on behalf of the CBP partner.  In the event of a positive match, the TVS returns a unique identifier and matching results to the air carrier, and the traveler may proceed to finish the check-in/bag drop process. The matching result can be used by airlines (1) to meet their CBP regulatory requirement to verify specific passenger information and (2) their TSA regulatory requirement to accurately verify traveler’s identities. This is a voluntary opt-in process efficiency option provided to travelers. "
DHS-183,Public Information Compilation for Travel Threat Analysis (Dataminr),DHS,CBP,"This tool significantly reduces the amount of time it takes for users to collect and compile commercially available open-source information when attempting to identify  possible threats related to national security, border violence, CBP facilities, CBP employee safety and other topics with a CBP-nexus involving air, sea, and land travel to and/or from the U.S.
","This tool significantly reduces the amount of time it takes for users to collect and compile commercially available open-source information when attempting to identify  possible threats related to national security, border violence, CBP facilities, CBP employee safety and other topics with a CBP-nexus involving air, sea, and land travel to and/or from the U.S.


CBP uses Dataminr, a commercially available open-source alerting tool, which compiles publicly available information to provide alerts for possible threats related to national security, border violence, CBP facilities, CBP employee safety, and other topics with a CBP-nexus involving air, sea, and land travel to and/or from the U.S.  This tool significantly reduces the amount of time it takes for users to collect and compile this data.  CBP manually enters parameters related to these topics into Dataminr.  The results provide a summary of complied information, citation to information sources, and the possible threat (e.g., facility disruption, border violence, natural disaster, or terrorism).  CBP employees review these results, including the source information, to further research the information to determine if there is a possible threat.  "
DHS-317,RAPTOR (Rapid Tactical Operations Reconnaissance),DHS,CBP,"RAPTOR will significantly increase domain awareness and the agency’s ability to engage in intelligence-driven operations.  The AI capability acts as a force multiplier and saves personnel from analyzing video feed from a stationary camera and manually noting all boat identifiers, improving their ability to respond quickly to potential threats and gather critical intelligence for law enforcement and border control operations.","RAPTOR will significantly increase domain awareness and the agency’s ability to engage in intelligence-driven operations.  The AI capability acts as a force multiplier and saves personnel from analyzing video feed from a stationary camera and manually noting all boat identifiers, improving their ability to respond quickly to potential threats and gather critical intelligence for law enforcement and border control operations.

Rapid Tactical Operations Reconnaissance (RAPTOR) provides real-time surveillance and reconnaissance capabilities to enhance border security by integrating advanced technologies, such as radar, infrared sensors, and video surveillance, to detect and track suspicious activities along U.S. borders. This use case involves testing the capabilities of a vessel hull reader with AI capabilities that produces a test transcription of vessel registration/documentation data and photographs of the vessel. This system will significantly increase domain awareness, the agency’s ability to engage in intelligence-driven operations and enhance officer safety and capabilities to meet operational mission requirements. "
DHS-234,Relocatable Multi-Sensor System,DHS,CBP,"The system uses advanced sensor technology to differentiate valid items of interest (IOI), such as unmanned aircraft systems and humans, from other detections such as animals or other environmental objects. By integrating radar and other sensor data, the system filters out false alarms, ensuring more accurate identification of potential IOI. This capability enhances CBP's ability to focus on legitimate risks while minimizing the time spent on non-threatening activities, improving operational efficiency at border and security checkpoints.
","The system uses advanced sensor technology to differentiate valid items of interest (IOI), such as unmanned aircraft systems and humans, from other detections such as animals or other environmental objects. By integrating radar and other sensor data, the system filters out false alarms, ensuring more accurate identification of potential IOI. This capability enhances CBP's ability to focus on legitimate risks while minimizing the time spent on non-threatening activities, improving operational efficiency at border and security checkpoints.


MDF correlates sensor data of different types into an integrated operational picture, allowing the user to see simplified, single entity tracks in highly complex scenarios.  The system prioritizes items of interest (IOI) automatically based upon user intent and automatically cues sensors.  MDF also classifies detections into groups it is trained for, including aircraft, humans, and vehicles.  This does not include any nexus to biometric detection or image processing. The system uses advanced sensor technology to differentiate valid IOI, such as unmanned aircraft systems and humans, from other detections such as animals or environmental objects. By integrating radar and other sensor data, the system filters out false alarms, ensuring more accurate identification of potential IOI. This capability enhances CBP's ability to focus on legitimate risks while minimizing the time spent on non-threatening activities, improving operational efficiency at border and security checkpoints. The outputs include real-time data identifying and categorizing potential IOI while filtering out false or non-relevant IOI like animals. These outputs are used to provide situational awareness and support decision-making for CBP personnel. "
DHS-138,RVSS Legacy Overhauled System Project,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Video Computer Aided Detection (VCAD) (also known as Matroid AI) is software that enables CBP end users to create and share vision detectors. VCAD detectors are trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. Users can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through VCAD's powerful developer Application Programming Interface (API) and language specific clients, so CBP applications can be integrated with the power of computer vision."
DHS-2413,Semi-Supervised Traveler Identity Verification Services (Traveler Initiated),DHS,CBP,"The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification.","The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification.

The Semi-Supervised Traveler Identity Verification Services (Traveler Initiated) leverages biometric facial recognition to streamline identity verification at border crossings. Travelers submit images through self-service kiosks or mobile platforms, which are then compared against government databases, such as previous inspection records and travel documents, for identity confirmation and approval. This system enhances border efficiency and security by expediting processing while ensuring CBP officers maintain oversight to verify matches and address discrepancies. The TVS Biometric matching service is a cloud-based service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification."
DHS-2452,Source Code Development Tool,DHS,CBP,"This capability will enable end users to develop software faster and more efficiently through the use of a generative artificial intelligence coding assistant.  
","This capability will enable end users to develop software faster and more efficiently through the use of a generative artificial intelligence coding assistant.  


Current software development usually requires many hours of human coding labor.  This capability accelerates software development by providing a generative artificial intelligence coding assistant.  The coding assistant is based on large language models (LLM) and coding foundation models.  End users may prompt the assistant to code, refine and complete a software project through natural language commands and queries. This capability will enable end users to develop software faster and more efficiently through the use of a generative artificial intelligence (GenAI) coding assistant and which will create functional software code for end users.  "
DHS-2412,Supervised Traveler Identity Verification Services (Officer Initiated),DHS,CBP,"The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification","The TVS Biometric matching service is a cloud-based facial biometric matching service that enables CBP to match a passenger’s identity against a trusted source, throughout the travel continuum which improves traveler facilitation and reduces manual identity verification

Supervised Traveler Identity Verification Services (Officer Initiated) leverages facial recognition/comparison technology (FR/FC) to confirm the identity of travelers during traditional officer-led processing. In this system, a CBP officer uses FR/FC to compare a traveler's face to a gallery of stored images from prior government records, such as passports, visas, and previous border crossings. This technology supports officers in validating identities efficiently and accurately while maintaining oversight throughout the verification process. Officers remain responsible for making final determinations based on the results of the FR/FC and their observations, ensuring security and compliance., The TVS Biometric matching service is a cloud-based service that enables CBP to match a passenger’s identity against a trusted source, which improves traveler facilitation and reduces manual identity verification. "
DHS-101,Advanced Trade Analytics Platform (ATAP),DHS,CBP,"To create efficiencies and unlock key insights in CBP's trade mission execution through the application of data analytics, machine learning, and AI.","To create efficiencies and unlock key insights in CBP's trade mission execution through the application of data analytics, machine learning, and AI.

ATAP uses data analytics, machine learning, and AI to aggregate and analyze vast amounts of historical trade data and current activity data to identify patterns and trends in the trade environment that allow for greater data-driven insights into the threats and opportunities in CBP’s trade mission execution. The output of ATAP’s various analysis is typically provided through data visualizations and dashboards, allowing CBP personnel to examine the information as part of detecting and deterring non-compliance throughout the trade environment. CBP personnel use ATAP to aggregate information, visualize and display activity and patterns, and to assist the user in locating relevant information to a research query."
DHS-2375,Thermal Power Generation with Geoseismic IoI Detection and Classification,DHS,CBP,Utilize seismic sensor data to determine Item of Interest traffic in deployed locations. Increases situational awareness in austere environments and reduces need for battery replacement since the devices are self-charging.,"Utilize seismic sensor data to determine Item of Interest traffic in deployed locations. Increases situational awareness in austere environments and reduces need for battery replacement since the devices are self-charging.

The Thermal Power Generation and Geoseismic Item of Interest (IoI) detection and classification is able to convert surface heat fluctuations into electrical energy in order to power a seismic sensor. The data generated from the seismic sensor is then paired with a machine learning (ML) algorithm which is able to identify and classify Items of Interest (IoIs), noting the confidence interval that the detected seismic activity is correctly classified. Once an IoI is identified, users will receive alert notifications within their systems and determine the appropriate response in that area. Increases situational awareness in austere environments and reduces need for battery replacement since the devices are self-charging."
DHS-2416,Traveler Identity Verification Services (Vetting),DHS,CBP,CBP's Traveler Identity Verification Services (Vetting) utilizes facial recognition technology to enhance threat identification by matching travelers' biometrics against records of concern. ,"CBP's Traveler Identity Verification Services (Vetting) utilizes facial recognition technology to enhance threat identification by matching travelers' biometrics against records of concern. 

The Traveler Identity Verification Services (Vetting) uses biometric facial comparison technology to match traveler photographs with existing photographs in CBP’s holdings. These holdings include images captured during prior CBP inspections, U.S. passport and visa records, immigration records, and photographs from DHS encounters. This process is designed to complement the existing biographic vetting processes, enhancing identity verification and ensuring accurate assessments for travel and security purposes . CBP’s Traveler Identity Verification Services (Vetting) utilizes facial recognition technology to enhance threat identification by matching travelers’ biometrics against records of concern. When the system identifies a potential match to concerning records, CBP personnel conduct a manual facial comparison to determine whether the record is likely associated with the individual."
DHS-344,Traveler Verification Service (TVS),DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Traveler Verification Service (TVS) provides CBP a biometric entry/exit system to record arrivals and departures to and from the United States. CBP uses TVS as its backend matching service for all biometric entry and exit operations that use Facial Comparison. CBP creates localized photo ""galleries"" from images captured during previous entry inspections, photographs from U.S. passports and U.S. visas, and photographs from other DHS encounters. The images are converted into templates and the actual photograph is discarded. The templates are securely stored, and are what make up the TVS gallery. The templates are then used by the Facial Comparison system to verify a traveler's identity when they arrive or depart the U.S. When the traveler presents him or herself for entry, or for exit, the traveler will encounter a camera connected to TVS. This camera matches live images with the existing photo templates from passenger travel documents. Once the camera captures a quality image and the system successfully matches it with historical photo templates of all travelers from the gallery associated with that particular manifest, the traveler proceeds to inspection for admissibility by a CBP Officer, or exits the United States. For more information, please read the DHS/CBP/PIA-056 - Privacy Impact Assessment for the Traveler Verification Service."
DHS-2377,Underwater ROV,DHS,CBP,The expected benefit of the system is that users will be able to more quickly identify potential threats and contraband on maritime vessels. This identification will allow for the streamlined investigations of a ship's hull without the need for a dive team.,"The expected benefit of the system is that users will be able to more quickly identify potential threats and contraband on maritime vessels. This identification will allow for the streamlined investigations of a ship's hull without the need for a dive team.

The Underwater Remotely Operated Vehicle (ROV) is a submersible drone capable of conducting inspections of maritime vessel hulls to detect underwater threats and contraband. The systems utilize supervised machine learning (ML) to assist in the identification of items of interest on a maritime ship’s hull. Outputs from the system will be the identification of threats and contraband. Users will use the output, an informed decision on if a potential threat or contraband is present on a hull, to determine if additional actions are required, The expected benefit of the system is that users will be able to identify potential threats and contraband on maritime vessels quickly. This identification will allow for the streamlined investigations of a ship’s hull without the need for a dive team. "
DHS-398,Unified Processing/Mobile Intake,DHS,CBP,The purpose is to facilitate the biometric identification of individuals as they are encountered by CBP for the purpose of expedited processing.,"The purpose is to facilitate the biometric identification of individuals as they are encountered by CBP for the purpose of expedited processing.

The Unified Processing/Mobile Intake system integrates with the Traveler Verification Service (TVS) to enhance border security operations. The system enables CBP personnel to match detainees' facial biometrics against CBP's photo galleries and derogatory image repositories. This process aids in identifying individuals with prior apprehensions and security concerns. The purpose is to facilitate the biometric identification of individuals as they are encountered by CBP for the purpose of expedited processing. "
DHS-2383,Unmanned Aircraft Collision Avoidance (Skydio),DHS,CBP,The platform operates on video feed only which in turn activates the obstacle avoidance on the aircraft where the AI capabilities are housed.  The system supports the streamlined intake process while maintaining the accuracy and reliability of identity verification.,"The platform operates on video feed only which in turn activates the obstacle avoidance on the aircraft where the AI capabilities are housed.  The system supports the streamlined intake process while maintaining the accuracy and reliability of identity verification.

Skydio X2D Small Unmanned Aircraft System (sUAS) platform operates on video feed only which in turn activates the obstacle avoidance on the unmanned aircraft where the AI capabilities are housed. The obstacle avoidance capability assists the pilot on the ground to avoid colliding the unmanned aircraft with objects such as man-made structures, vehicles, trees, wires, or other objects in the projected flight path. The pilot receives a visual alert on the hand controller, indicating a possible collision and in some cases the aircraft will slow down, change direction to avoid the obstacle, or stop."
DHS-28,Use of technology to identify proof of life,DHS,CBP,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Mobile applications rely on product for liveness detection to avoid use of spoofed or fraudulent images by bad actors. Being able to accept submitted data with confidence that the submitting individual is who and where they claim to be is critical to the functionality of the app within the agency environment."
DHS-401,Vault Access Log (SPVAA),DHS,CBP,"The system will enhance monitoring and minimizes the risk of unauthorized access, contributing to stronger security protocols for handling seized property.","The system will enhance monitoring and minimizes the risk of unauthorized access, contributing to stronger security protocols for handling seized property.

CBP uses the facial recognition technology in Seized Property Vault Activity Automation (SPVAA) to create a log of access to a seized property vault. Photos of the CBP personnel accessing the vault are loaded into the application and the application logs the entrance request, the case number associated with the entrance request, and the individual’s activity in the vault. "
DHS-38,Vessel Detection,DHS,CBP,"Current surveillance technology does not have machine assisted classification of targets on screen, making it harder for human operators to decipher legitimate from illegitimate traffic in times of high volumes of legitimate traffic.  Project intends to support human operator identification and classification of potential illicit vessels.  Benefits would be more efficient detection and resolution of IOIs, especially during times of high-volume traffic.        ","Current surveillance technology does not have machine assisted classification of targets on screen, making it harder for human operators to decipher legitimate from illegitimate traffic in times of high volumes of legitimate traffic.  Project intends to support human operator identification and classification of potential illicit vessels.  Benefits would be more efficient detection and resolution of IOIs, especially during times of high-volume traffic.        

Integrated technologies and analytics enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking allow for improved illicit vessel detection in areas with high volumes of legitimate trade and recreational water vessel traffic by increasing situational awareness and responsiveness to threats.  Vessel Detection allows an agent to set a search area with criteria (e.g., people, drones, vehicles) and transmit those criteria to the sensors.  Images detected by the sensors are automatically recognized using Artificial Intelligence. The AI algorithms filter, detect, and recognize objects, dividing them into Items of Interest (IoI) and other objects.  Detections of IoI are shared with other detection systems while detections of other objects (e.g., animals) are not shared. IoIs can be tracked and maintained across multiple sensors seamlessly. "
DHS-2378,Wellness and Physical Fitness Application ,DHS,CBP,"This is an internal  AI powered personal workout coach for Customs and Border Patrol Staff. 

Wellness and Physical Fitness Application uses AI to provide increased user awareness of physical status and associated remedial actions, if necessary. Health and wellness awareness intends to mitigate human capital costs.
","This is an internal  AI powered personal workout coach for Customs and Border Patrol Staff. 

Wellness and Physical Fitness Application uses AI to provide increased user awareness of physical status and associated remedial actions, if necessary. Health and wellness awareness intends to mitigate human capital costs.


The use case helps service members build strength and durability by delivering structured, personalized workout plans to perform at their highest level. Coaches and users can start from a periodized base program built by Tactical Strength and Conditioning (TSAC) certified strength and conditioning specialists to optimize operational readiness — then customize it as much (or as little) as needed. The system will produce personalized physical fitness assessments and programs with real-time AI fitness monitoring and program adjustments, including metrics, graphs, and a display for group and/or individual trends analyses. This will increase user awareness of physical status and associated remedial actions, if necessary, with the ultimate goal of mitigating human capital costs through health and wellness awareness. "
DHS-104,Advanced Analytic Enabled Forensic Investigation,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

CISA deploys forensic specialists to analyze cyber events at Federal Civilian Executive Branch (FCEB) departments and agencies, as well as other State, Local, Tribal, Territorial, and Critical Infrastructure partners. Forensic analysts can utilize advanced analytic tooling, in the form of Artificial Intelligence (AI) implementations, to better understand anomalies and potential threats. This can be further supported by the development of AI-assisted agents. Analysts can interact with such agents in a conversational manner to produce the input needed for complex search queries for behaviors or patterns in traffic that the agent then rapidly creates. Such tooling allows forensic specialists the capabilities to comb through event data in an automated fashion with mathematically and probabilistically based models to ensure high-fidelity anomalies are detected in a timely manner. "
DHS-105,Advanced Network Anomaly Alerting,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of data from the National Cybersecurity Protection System's (NCPS’s) Einstein sensors. Manually developed detection alerts and automatic correlation via off the shelf tooling are common, but not comprehensive. Many network attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and backed in subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high-fidelity anomalies are detected in a timely manner. "
DHS-43,AI Security and Robustness,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Frameworks, processes, and testing tools are developed to govern the acquisition, development, deployment, and maintenance of AI technologies. Technology integrators within CISA, as well as the rest of the federal enterprise, use AI-enhanced tools to ensure the trustworthy, robust, and secure operation of their AI systems. These tools use machine learning (ML) and Natural Language Processing (NLP) to enhance the assessment of AI technology within the agency by speeding up data processing."
DHS-4,Automated Detection of Personally Identifiable Information (PII) in Cybersecurity Data,DHS,CISA,"Automated PII Detection and Review Process uses analytics to identify and manage potential PII in submissions. If PII is flagged, the submission is sent to CISA analysts, who are guided by AI to review and confirm or reject the detection, redacting information if necessary. Privacy experts monitor the system and provide feedback. The system learns from this feedback, ensuring compliance with privacy regulations and improving efficiency by reducing false positives. Regular audits ensure the process remains trustworthy and effective.
","Automated PII Detection and Review Process uses analytics to identify and manage potential PII in submissions. If PII is flagged, the submission is sent to CISA analysts, who are guided by AI to review and confirm or reject the detection, redacting information if necessary. Privacy experts monitor the system and provide feedback. The system learns from this feedback, ensuring compliance with privacy regulations and improving efficiency by reducing false positives. Regular audits ensure the process remains trustworthy and effective.


The Automated Indicator Sharing (AIS) service allows public and private-sector organizations to voluntarily share real-time cyber threat information with CISA. Although the purpose of this service is to collect information directly related to potential cyber threats, there is a possibility that Personally Identifiable Information (PII), such as names or addresses, could be incidentally included in submission notes. To enhance privacy, this AI tool uses Natural Language Processing (NLP) to automatically flag potential PII for review and removal by CISA analysts. The Automated PII Detection and Review Process uses analytics to identify and manage potential PII in submissions. If PII is flagged, the submission is sent to CISA analysts, who are guided by AI to review and confirm or reject the detection, redacting information if necessary. Privacy experts monitor the system and provide feedback. The system learns from this feedback, ensuring compliance with privacy regulations and improving efficiency by reducing false positives. Regular audits ensure the process remains trustworthy and effective. "
DHS-2306,CISAChat,DHS,CISA,"Currently, multiple CISA program offices are using contractor staff to review pre-production content and other internal materials to develop summaries, key themes, and improve clarity. Leveraging a Generative AI solution improves internal agency Customer Experience (CX) and saves staff time. ","Currently, multiple CISA program offices are using contractor staff to review pre-production content and other internal materials to develop summaries, key themes, and improve clarity. Leveraging a Generative AI solution improves internal agency Customer Experience (CX) and saves staff time. 

CISAChat is a custom generative AI solution that enables authorized CISA personnel to interact with, summarize, and search agency-created materials and internal content. Once prompted, the tool searches through relevant CISA files and delivers a focused response based on the inputs. As established in required employee AI training, personnel using the tool will validate the accuracy of the information and use it in accordance with applicable law and policy. This AI capability streamlines the process of finding information and improves CISA personnel’s internal customer experience. Currently, multiple CISA program offices use contractor staff to review pre-production content and other internal materials to develop summaries, key themes, and improve clarity. Leveraging CISAChat improves internal agency Customer Experience (CX) and saves staff time."
DHS-5,Confidence Scoring for Cybersecurity Threat Indicators,DHS,CISA,"The confidence scores produced by this use case via an AI-driven decision tree process allow CISA's Automated Indicator Sharing (AIS) partners to contextualize the indicator information they are receiving so that they can ingest the data accordingly on their systems.
","The confidence scores produced by this use case via an AI-driven decision tree process allow CISA's Automated Indicator Sharing (AIS) partners to contextualize the indicator information they are receiving so that they can ingest the data accordingly on their systems.


The Automated Indicator Sharing (AIS) service allows public and private-sector organizations to voluntarily share real-time cyber threat information with CISA. The Confidence Scoring for Cybersecurity Threat Indicators capability, a feature of the AIS service, uses an AI-driven decision tree process to assign a confidence score to a submission. The scoring algorithm evaluates factors such as whether technical details within the submission have been previously observed or verified by CISA analysts. The score represents the reliability and completeness of the information submitted, and helps analysts prioritize which information to review first. A set of confidence scores is included along with the other fields in the indicator data set. The confidence scores allow CISA's AIS partners to contextualize indicator information for improved data system ingest. "
DHS-106,Critical Infrastructure Network Anomaly Detection,DHS,CISA,"This use case delivers improved internal government tools for hunting and detection of malicious threat actors on critical infrastructure networks. It automates manual data fusion and correlation processes and highlights potential anomalies, allowing CISA analysts to focus more  time on hunting adversaries.
","This use case delivers improved internal government tools for hunting and detection of malicious threat actors on critical infrastructure networks. It automates manual data fusion and correlation processes and highlights potential anomalies, allowing CISA analysts to focus more  time on hunting adversaries.


CISA is responsible for providing timely technical assistance, risk management support, and incident response capabilities to federal and non-federal critical infrastructure partners. In support of this responsibility, critical infrastructure partners can opt-in to the CyberSentry program, which monitors critical infrastructure networks. The CyberSentry program uses a suite of analytical tools and methods, including unsupervised machine learning algorithms that analyze unlabeled datasets to identify trends, patterns, and anomalies in network data. This AI capability automates manual data fusion and correlation processes, highlighting potential anomalies for CISA analyst review. Analysts are provided with an interface to query cybersecurity data and dashboards that display potential cybersecurity alerts, including anomalies detected through predictive models and rule-based heuristics. This use case delivers improved government tools for CISA analysts to hunt and detect malicious threat actors on critical infrastructure networks. "
DHS-41,Cyber Incident Reporting,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Cyber incident handling specialists utilize advanced automation tools to process data received through various threat intelligence and cyber incident channels. These tools leverage machine learning (ML) and Natural Language Processing (NLP) to increase the accuracy and relevance of data filtered and presented to human analysts and decision-makers. ML techniques also assist in aggregating the information in reports for presentation and further analysis, including data received through covered Cyber Incident Reporting for Critical Infrastructure Act (CIRCIA) entities. Such tools can leverage current dashboards and reports to cluster vulnerabilities by entity and sector, identifying trends in exposure and remediation. These solutions can also correlate vulnerabilities to existing frameworks (such as MITRE Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK)) and other incidents to understand attackers’ techniques and improve modeling. "
DHS-40,Cyber Threat Intelligence Feed Correlation,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Cyber Data Feed Correlation uses AI enabled capabilities to provide accelerated correlation across multiple incoming information feeds. This enables more timely enrichment to improve the externally shared information feeds. AI allows the algorithm to use the information items and results to learn the most efficient ways to perform the task. Additionally, tailored algorithms could be created to provided sustained surveillance of threat actor Tactics, Techniques, and Procedures (TTPs). "
DHS-42,Cyber Vulnerability Reporting,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Vulnerability analysts require advanced automation tools to process data received through various vulnerability reporting channels, as well as aggregate the information for automated sharing. These tools leverage machine learning (ML) and Natural Language Processing (NLP) to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. ML techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data in the Known Exploited Vulnerabilities (KEV) and Common Vulnerabilities and Exposures (CVE) databases. "
DHS-2335,Draft Tailored Summaries of Media Materials for Different Publication Channels,DHS,CISA,The Large Language Models (LLMs) will summarize information from historical publications and pre-production documents intended for external publication.,"The Large Language Models (LLMs) will summarize information from historical publications and pre-production documents intended for external publication.

CISA personnel draft product summaries for information sharing with federal and non-federal critical infrastructure partners. This is a custom generative AI solution that leverages a Large Language Model (LLM), augmented by Retrieval-Augmented Generation (RAG), to extract key themes from approved CISA products and automatically generate tailored summaries using approved templates. As established in required employee AI training, personnel using the tool will validate the accuracy of information and use it in accordance with applicable law and policy. The drafts are reviewed, edited, and coordinated by authorized CISA personnel prior to publication. This AI capability accelerates the process of drafting summarized content for CISA’s published products."
DHS-107,Malware Reverse Engineering,DHS,CISA,"This use case delivers improved internal government tools for reverse engineering of malware and speeding the development of cyber threat intelligence that can be shared across the government and with CISA partners.  Threat actors can leverage the same malware for long periods of time, so having the ability to improve analysis and generation of shareable cyber threat intelligence forces threat actors to spend more resources generating new malware. Machine learning and other analytical tools are leveraged to guide malware analysts and automate elements of the manual reverse engineering process. Automation of tasks such as triage and indicator extraction allow threat hunting analysts to meet high demand and focus more on adversary response.
","This use case delivers improved internal government tools for reverse engineering of malware and speeding the development of cyber threat intelligence that can be shared across the government and with CISA partners.  Threat actors can leverage the same malware for long periods of time, so having the ability to improve analysis and generation of shareable cyber threat intelligence forces threat actors to spend more resources generating new malware. Machine learning and other analytical tools are leveraged to guide malware analysts and automate elements of the manual reverse engineering process. Automation of tasks such as triage and indicator extraction allow threat hunting analysts to meet high demand and focus more on adversary response.


CISA receives information about computer security vulnerabilities and threats in the form of malicious code samples (malware) from its federal civilian and critical infrastructure partners. These malware samples require manual reverse engineering to find actionable insights, such as indications of potential compromise or adversary-operated command and control. This AI capability uses deep learning to assist CISA analysts with understanding the content of malware samples, automating tasks such as triage and indicator extraction. This improves internal government tools for reverse engineering of malware, speeding the development of cyber threat intelligence that can be shared across the government and with CISA partners.  

By enhancing the analysis and generation of shareable cyber threat intelligence, CISA forces threat actors to spend more resources generating new malware.  A report is generated from malware samples submitted to the analysis pipeline, which is then used by human analysts to facilitate the malware triage process. Additional recommendations are displayed via plugins to reverse engineering tools. "
DHS-44,Operational Activities Explorer,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The integration of an AI tool into a dashboard to analyze cyber and physical incidents affecting critical infrastructure from all-source reporting could assist with maintaining operational clarity and centralized situational awareness. However, CISA decided not to move forward from the conceptual phase due to the nuances of event data and resource constraints. "
DHS-103,Security Information and Event Management (SIEM) Alerting Models,DHS,CISA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

CISA Threat hunting and Security Operations Center (SOC) analysts are provided with terabytes of log data per day. Manually developed detection alerts and automatic correlation in Security Information and Event Management (SIEM) tools are common, but not comprehensive. Many cyber attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and curated subject matter expertise. This can be further supported by the development of AI-assisted agents. Analysts can interact with such agents in a conversational manner to produce the input needed for complex search queries for behaviors or patterns in traffic that the agent then rapidly creates. This tooling allows CISA analysts to comb through security data in an automated fashion with mathematically and probabilistically based models to ensure high-fidelity anomalies are detected in a timely manner. "
DHS-2403,Security Operation Center (SOC) Network Anomaly Detection,DHS,CISA,"This use case delivers improved internal government tools for hunting and detection of malicious threat actors on federal civilian networks. It automates manual data fusion and correlation processes and highlights potential anomalies, allowing CISA analysts to focus more on hunting adversaries.
","This use case delivers improved internal government tools for hunting and detection of malicious threat actors on federal civilian networks. It automates manual data fusion and correlation processes and highlights potential anomalies, allowing CISA analysts to focus more on hunting adversaries.


CISA Threat hunting and Security Operations Center (SOC) analysts process terabytes of daily network log data from the Cyber Analytic and Data System (CADS) Einstein network traffic sensors. CADS is a sensor grid that monitors network traffic for malicious activity to and from participating government departments and agencies. This AI capability uses methods such as unsupervised machine learning (algorithms that analyze unlabeled datasets) to detect trends, patterns, and anomalies in network data. It automates manual data fusion and correlation processes and highlights potential anomalies, allowing CISA analysts to narrow the scope of analysis and prioritize data for review. An interface is provided for analysts to query cybersecurity data, and dashboards display potential cybersecurity alerts, including anomalies detected through predictive models and rule-based heuristics. This use case delivers improved government tools for CISA analysts to hunt and detect malicious threat actors on federal civilian agency networks. "
DHS-406,Report Analysis and Archive System (RAAS),DHS,CWMD,"To assist users of the Test and Evaluation document archive in locating documents and portions of document that are relevant for their needs by specifying individual queries as natural language questions, responding with detailed, natural language answers, and facilitating attainment of related or more precise information through follow-up questions.","To assist users of the Test and Evaluation document archive in locating documents and portions of document that are relevant for their needs by specifying individual queries as natural language questions, responding with detailed, natural language answers, and facilitating attainment of related or more precise information through follow-up questions.

 RAAS is an information management system for the retention and dissemination of test reports, test data, and evaluations of Chemical, Biological, Radiological, and Nuclear (CBRN) detection equipment. RAAS simplifies the ability for human analysts to search for documents and phrases using natural language. RAAS is being developed to assist users of the Test and Evaluation document archive in locating documents and portions of document that are relevant to their needs. Users can specify individual queries as natural language questions and receive detailed answers. The system also facilitates the attainment of related or more precise information through follow-up questions. RAAS is funded by CWMD Test & Evaluation (T&E) and is developed and maintained by Argonne National Lab (ANL).  

Intermediate outputs will include context summaries to facilitate indexing of document passages. Output to the user will include summarization of content relevant to the questions and interests indicated by the conversation with the user. "
DHS-373,Commercial Generative AI for Code Generation,DHS,DHS,DHS employees are permitted to use commercially available generative AI for code generation in day-to-day work. These tools are able to dynamically create usable code through plain-language prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce code in many different programming languages and for a variety of tasks.,"DHS employees are permitted to use commercially available generative AI for code generation in day-to-day work. These tools are able to dynamically create usable code through plain-language prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce code in many different programming languages and for a variety of tasks.

DHS employees are permitted to use commercially available generative AI for code generation in day-to-day work. These tools can dynamically create usable code through plain-language prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce code in many different programming languages and for a variety of tasks. "
DHS-369,Commercial Generative AI for Image Generation,DHS,DHS,"DHS employees are permitted to use commercially available generative AI for image generation in day-to-day work. These tools are able to dynamically create graphical content through text prompts submitted by the user. They use Natural Language Processing (NLP), in conjunction with other Machine Learning techniques such as Generative Adversarial Networks (GANs) and Diffusion Models, to produce images in a wide variety of contexts and styles.","DHS employees are permitted to use commercially available generative AI for image generation in day-to-day work. These tools are able to dynamically create graphical content through text prompts submitted by the user. They use Natural Language Processing (NLP), in conjunction with other Machine Learning techniques such as Generative Adversarial Networks (GANs) and Diffusion Models, to produce images in a wide variety of contexts and styles.

DHS employees are permitted to use commercially available generative AI for image generation in day-to-day work. These tools can dynamically create graphical content through text prompts submitted by the user. They use Natural Language Processing (NLP), in conjunction with other machine learning techniques, such as Generative Adversarial Networks (GANs) and Diffusion Models, to produce images in a wide variety of contexts and styles."
DHS-368,Commercial Generative AI for Text Generation (AI Chatbot),DHS,DHS,"DHS employees are permitted to use commercially available generative AI for text generation in day-to-day work. Commonly referred to as AI Chatbots, these tools are able to dynamically create written content through text prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce natural sounding language in a wide variety of contexts and styles.

Approved applications of commercial Gen AI tools to DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information, and developing briefing materials or preparing for meetings and events.","DHS employees are permitted to use commercially available generative AI for text generation in day-to-day work. Commonly referred to as AI Chatbots, these tools are able to dynamically create written content through text prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce natural sounding language in a wide variety of contexts and styles.

Approved applications of commercial Gen AI tools to DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information, and developing briefing materials or preparing for meetings and events.

DHS employees are permitted to use commercially available generative AI for text generation in day-to-day work. Commonly referred to as AI chatbots, these tools can dynamically create written content through text prompts submitted by the user. They use Natural Language Processing (NLP) and Large Language Models (LLM) to produce natural sounding language in a wide variety of contexts and styles. Approved applications of commercial generative AI tools for DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information, and developing briefing materials or preparing for meetings and events. "
DHS-33,RelativityOne,DHS,DHS,"RelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary. It is currently in use across several different DHS Components and Offices.","RelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary. It is currently in use across several different DHS Components and Offices.

Relativity One is a document review platform used to gain efficiencies in document review for litigation, Freedom of Information Act (FOIA) requests, and other arenas where large-scale document review and production are necessary. It is currently in use across several different DHS Components and Offices. Review Center tailors the review process by predicting the categorization of documents based on the reviewer's inputs."
DHS-2442,Digital Processing Procedure Manual (D-PPM),DHS,FEMA,"The AI addresses the inefficiency in the current manual search process, where agents spend significant time navigating static documents like PDFs (2000+ pages/70 documents) to answer survivor questions. As policies can change frequently, especially during disasters, it is crucial that agents access the most up-to-date information quickly and accurately.

Expected Benefits and Positive Outcomes:
Faster Response Times: The AI will enable agents to retrieve information quickly, reducing the overall time spent on each call.
Improved Answer Accuracy: By providing more accurate and relevant search results, the AI will help agents deliver consistent, correct responses.
Cost Savings: Reducing the time spent per call will improve operational efficiency, leading to potential cost savings.
Reduced Escalations: By empowering agents with the correct information, the tool will lower the frequency of escalations to supervisors, allowing them to focus on more complex cases.
Increased Capacity for Complex Casework: The time saved through the AI tool will allow agents to handle more complex queries, ultimately improving service quality and survivor satisfaction.
Scalability: As the AI tool is rolled out, it will provide a scalable solution that can grow with the agency’s needs during large-scale disaster responses.","The AI addresses the inefficiency in the current manual search process, where agents spend significant time navigating static documents like PDFs (2000+ pages/70 documents) to answer survivor questions. As policies can change frequently, especially during disasters, it is crucial that agents access the most up-to-date information quickly and accurately.

Expected Benefits and Positive Outcomes:
Faster Response Times: The AI will enable agents to retrieve information quickly, reducing the overall time spent on each call.
Improved Answer Accuracy: By providing more accurate and relevant search results, the AI will help agents deliver consistent, correct responses.
Cost Savings: Reducing the time spent per call will improve operational efficiency, leading to potential cost savings.
Reduced Escalations: By empowering agents with the correct information, the tool will lower the frequency of escalations to supervisors, allowing them to focus on more complex cases.
Increased Capacity for Complex Casework: The time saved through the AI tool will allow agents to handle more complex queries, ultimately improving service quality and survivor satisfaction.
Scalability: As the AI tool is rolled out, it will provide a scalable solution that can grow with the agency’s needs during large-scale disaster responses.

The Digital Processing Procedures Manual (D-PPM) technology is an AI-based search that will be implemented in call centers and remote field services locations to enhance agent support, encourage proper utilization of guidance and procedures, and ensure a consistent, empathic survivor experience. Leveraging this intelligent retrieval technology does not rely on extensive application changes and offers substantial benefits in providing round-the-clock support while prioritizing complex inquiries. This initiative aims to enhance survivor satisfaction and call center efficiency by reducing call handle times and maintaining or improving answer quality.  The current applications for handling agent inquiries for processing applications are resource-intensive, leading to high operational costs and inefficiencies, especially during peak periods immediately following presidential-declared disasters. Currently, FEMA has a repository on SharePoint called the Processing Procedures Manual (PPM) that houses more than 70 documents that make up over 2,000 pages worth of content and guidance. Agents search this content and guidance with find function and keyword search, first having to find the right document, and then using keyword-based search and find functionality, negatively impacting efficiency and quality and leading to increases in escalations to higher tiers of agents/support who are no longer freed up to work on more complex situations.  Implementation of a 24/7 digital, interactive application will expedite guidance comprehension and discovery to provide better support to disaster survivors during active disasters. The system would use AI and search capabilities to intelligently analyze FEMA policies and guidance and assist the agents through the assistance review and award process.  

The AI will enable agents to retrieve information quickly, reducing the overall time spent on each call.  By providing more accurate and relevant search results, the AI will help agents deliver consistent, correct responses.  Reducing the time spent per call will improve operational efficiency, leading to potential cost savings.  By empowering agents with the correct information, the tool will lower the frequency of escalations to supervisors, allowing them to focus on more complex cases.  The time saved through the AI tool will allow agents to handle more complex queries, ultimately improving service quality and survivor satisfaction.  As the AI tool is rolled out, it will provide a scalable solution that can grow with the agency’s needs during large-scale disaster responses. "
DHS-250,FEMA OCFO GPT,DHS,FEMA,"FEMA OCFO GPT - B is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions for the record and providing a preliminary response to the Program Office to use in their formal response to the request. It provides draft responses reducing the data gathering stage and providing additional time for analysis, response, and approval.  This has reduced the analyst initial level of effort versus individual research by 80% on initial surveys.""","FEMA OCFO GPT - B is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions for the record and providing a preliminary response to the Program Office to use in their formal response to the request. It provides draft responses reducing the data gathering stage and providing additional time for analysis, response, and approval.  This has reduced the analyst initial level of effort versus individual research by 80% on initial surveys.""

FEMA Office of the Chief Financial Officer Generative Pre-trained Transformer (OCFO GPT) is an internal facing Generative AI (GenAI) tool to augment the FEMA workforce in generating initial responses to questions for the record and providing preliminary responses to questions for the record and providing preliminary responses for the Program Office. The tool leverages public facing and internal deliberative documents (e.g., hearing testimony, answers sent to previous questions) to assist in answering questions the Agency receives. It generates draft responses that are then refined before formal submission. This tool is used in the data gathering stage and does not replace the work of analysts or the review by Agency leadership.  It reduces the analyst initial level of effort versus individual research."
DHS-346,Geospatial Damage Assessments,DHS,FEMA,"We will integrate these automated tools for imagery-based damage assessments into RGO processes and systems to inform FEMA geospatial analysts.  FEMA geospatial analysts will review output and develop recommendations, so FEMA can quickly detect and characterize damaged and undamaged buildings, identify the concentrations of damage, identify and detect debris, and to support rapid response and recovery activities.","We will integrate these automated tools for imagery-based damage assessments into RGO processes and systems to inform FEMA geospatial analysts.  FEMA geospatial analysts will review output and develop recommendations, so FEMA can quickly detect and characterize damaged and undamaged buildings, identify the concentrations of damage, identify and detect debris, and to support rapid response and recovery activities.

The Response Geospatial Office (RGO) is exploring the use of AI to assist in the prioritization of structural and debris assessments. RGO reviews satellite, aerial, and radar imagery to expedite damage assessments in the aftermath of a disaster. RGO is utilizing several AI techniques, including computer vision, machine learning, and deep learning, to help prioritize imagery exploitation by identifying areas likely having damage or debris. Areas indicated as likely having damage or debris are prioritized for imagery exploitation by analysts, reducing the time required for visual damage assessments. FEMA will integrate these automated tools for imagery-based damage assessments into RGO processes and systems to inform FEMA geospatial analysts. FEMA geospatial analysts will review output and develop recommendations, so FEMA can quickly detect and characterize damaged and undamaged buildings, identify concentrations of damage, detect debris, and support rapid response and recovery activities. AI models generate points or polygons over areas where damage or debris is likely. This output is a recommendation meant to trigger investigation by human analysts via traditional damage assessments. In large-scale incidents, imagery collection can be comprised of hundreds of thousands of miles of land and millions of structures. AI automation allows for the prioritization of imagery exploitation where damage is likely to have occurred, reducing the time required to identify impacts and summarize damage sustained. "
DHS-2439,Hazard Mitigation Assistance Chatbot,DHS,FEMA,"The intended purpose is to deploy an AI-powered internal chatbot that serves as a centralized, intuitive user interface for staff across all FEMA regions and headquarters. The intended outcomes include: Improving Efficiency and Consistency by providing quick access to accurate information, the chatbot streamlines work processes, reduces redundancy, and ensures consistent procedures across regions. Accelerate Onboarding of new hires become competent more quickly, reducing the time to full productivity and strengthening the workforce. Ensure Compliance and Accountability by being Transparent and accurate guidance promotes adherence to HMA policies, reducing errors and enhancing program integrity. Enhancing Decision-Making by providing access to precise citations and real-time data improves the quality of decisions, benefiting program outcomes. Supporting FEMA's mission by empowering staff to perform effectively, the chatbot enhances overall efficiency and service delivery, aligning with FEMA's goal of improving program delivery and serving the whole community.","The intended purpose is to deploy an AI-powered internal chatbot that serves as a centralized, intuitive user interface for staff across all FEMA regions and headquarters. The intended outcomes include: Improving Efficiency and Consistency by providing quick access to accurate information, the chatbot streamlines work processes, reduces redundancy, and ensures consistent procedures across regions. Accelerate Onboarding of new hires become competent more quickly, reducing the time to full productivity and strengthening the workforce. Ensure Compliance and Accountability by being Transparent and accurate guidance promotes adherence to HMA policies, reducing errors and enhancing program integrity. Enhancing Decision-Making by providing access to precise citations and real-time data improves the quality of decisions, benefiting program outcomes. Supporting FEMA's mission by empowering staff to perform effectively, the chatbot enhances overall efficiency and service delivery, aligning with FEMA's goal of improving program delivery and serving the whole community.

The Hazard Mitigation Assistance (HMA) Chatbot, will be developed for Internal Stakeholders Navigating HMA Grant Applications with Benefit-Cost Analysis (BCA) Assistance, Project Scoping, and Feasibility Support to serve as a centralized, intuitive user interface for staff across all Federal Emergency Management Agency (FEMA) regions and headquarters. The AI-powered chatbot will utilizing Natural Language Processing (NLP) to provide tailored, context-specific guidance to assist FEMA HMA staff, including new hires, who face significant challenges in accessing and processing vast amounts of information related to applications and grants. Benefits include accelerating onboarding of new hires, reducing the time to full productivity, ensuring compliance and accountability through transparency and accuracy, reducing errors, enhancing decision-making by providing access to precise citations and real-time data, and improving the quality of decisions which benefit program outcomes. The chatbot aims to enhance overall efficiency and service delivery, aligning with FEMA's goal of improving program delivery and serving the whole community. 

The chatbot will provide accurate, uniform answers with citations, ensuring everyone is aligned and reducing the risk of misinterpretation of publicly available HMA data sourced from FEMA.gov. The chatbot will provide clear, plain-language explanation, highlighting eligibility criteria, funding priorities, and application processes for each HMA program. The chatbot will quickly retrieve relevant HMA policy documents, provides precise citations, and summarizes key points. The chatbot will compile publicly available HMA data sourced from FEMA.gov, perform analyses, and present it in a clear report with visualizations."
DHS-248,Incident Management Workforce Deployment Model (depmod),DHS,FEMA,"The model is able to extract patterns from big data, combine these patterns in a way that mirrors a real-world process, and simulate likely outcomes to yield predictions in the form of relatable, mission-centric, metrics.","The model is able to extract patterns from big data, combine these patterns in a way that mirrors a real-world process, and simulate likely outcomes to yield predictions in the form of relatable, mission-centric, metrics.

The Incident Management Workforce Deployment Model helps predict how FEMA's incident management team might respond to disasters. It uses historical data to plan staffing needs but does not directly decide who gets staffed.  The model is used to make predictions about how the incident management (IM) workforce could respond to the Stafford Act incidents. A key area of application is the setting of IM workforce staffing levels (i.e., force structure). The model was constructed in R and delivered as an R package. The model uses various kinds of statistical inference and machine learning methods (i.e., multinomial regression, Bayesian multi-level modeling, etc.).  This use case leverages historic data on the deployment of FEMA personnel to anticipate requirements for disaster staffing and supporting assessments for overall readiness. It does not leverage demographic data, nor is it used to directly inform staffing decisions.  It is purely used for planning and assessment purposes.  

The model is able to extract patterns from big data, combine these patterns in a way that mirrors a real-world process, and simulate likely outcomes to yield predictions in the form of relatable, mission-centric metrics. 

The system primarily outputs predictions that can then (optionally) be summarized and communicated as recommendations. "
DHS-251,Individual Assistance (IA) & Public Assistance (PA) Projections,DHS,FEMA,"The purpose of these supervised learning models is two-fold:

1.	For informational purposes: the models will produce predictions for to-be-determined quantities of interest. These quantities are often of interest to Agency personnel in the field, region, and headquarters, as well as DHS, OMB, NSC, and the Whitehouse.
2.	For decisional purposes: in addition to being informative, the model’s predictions are likely to be used for decision making. This may include implicit use (e.g., seeing that there are a large number of households that require assistance may motivate FEMA CFO to consider requesting additional funding for the Disaster Relief Fund) or explicit use (e.g., the number of estimated housing units required may be used to determine the number of housing units to order just-in-time).

Anticipated benefits of using supervised learning models include:
1.	Increased predictive performance: supervised learning models offer means of quantifying and choosing models with the best possible predictive performance.
2.	Timely prediction: supervised learning models can produce reasonably high performance predictions based on limited data.
3.	Quantification of uncertainty: supervised learning models are able to provide prediction intervals and predictive distributions in addition to point predictions to give users a sense of how uncertainty is inherent in the prediction.
4.	Rigor: supervised learning models are well founded on statistical learning theory and provide a level of mathematical rigor that speaks to the reliability and limitations of methods.","The purpose of these supervised learning models is two-fold:

1.	For informational purposes: the models will produce predictions for to-be-determined quantities of interest. These quantities are often of interest to Agency personnel in the field, region, and headquarters, as well as DHS, OMB, NSC, and the Whitehouse.
2.	For decisional purposes: in addition to being informative, the model’s predictions are likely to be used for decision making. This may include implicit use (e.g., seeing that there are a large number of households that require assistance may motivate FEMA CFO to consider requesting additional funding for the Disaster Relief Fund) or explicit use (e.g., the number of estimated housing units required may be used to determine the number of housing units to order just-in-time).

Anticipated benefits of using supervised learning models include:
1.	Increased predictive performance: supervised learning models offer means of quantifying and choosing models with the best possible predictive performance.
2.	Timely prediction: supervised learning models can produce reasonably high performance predictions based on limited data.
3.	Quantification of uncertainty: supervised learning models are able to provide prediction intervals and predictive distributions in addition to point predictions to give users a sense of how uncertainty is inherent in the prediction.
4.	Rigor: supervised learning models are well founded on statistical learning theory and provide a level of mathematical rigor that speaks to the reliability and limitations of methods.

Individual Assistance (IA) and Public Assistance (PA) Projections predicts recovery program quantities of interest using supervised learning models. These models include, but not limited to, predicting the number of households that will register for the Individuals and Households Program (IHP), the number of households that will require direct housing assistance, the number of temporary transitional housing units needed, the number of applicants for Public Assistance, the number of PA projects that applicants will submit, the number of sites that will need to be inspected per PA project, and the cost of delivering assistance.  Supervised learning models include sample statistics, generalized linear models, decision trees, and deep neural networks. 

The purpose of these supervised learning models is for informational purposes, to produce predictions for to-be-determined quantities of interest and for decisional purposes that may include implicit use (e.g., seeing a large number of households requiring assistance may motivate FEMA Chief Financial Officer (CFO) to consider requesting additional funding for the Disaster Relief Fund) or explicit use (e.g., the number of estimated housing units required may be used to determine the number of housing units to order just-in-time). Anticipated benefits of using supervised learning models include increased predictive performance, timely predictions, quantification of uncertainty, and rigor. 

These supervised learning models produce predictions, not recommendations or decisions (though they can inform human users in making recommendations and decisions). At minimum, these models will produce point predictions for the different quantities of interest for disaster declarations. Additionally, they may produce prediction intervals or predictive distributions as feasible and appropriate for the given prediction problem. Often these outputs will be shared via business intelligence tools (e.g., Tableau or PowerBI) for wide internal FEMA use. Some predictions may be shared with a more restricted audience through simpler means (e.g., an excel workbook) as appropriate. "
DHS-2441,OCFO Code Assist GPT,DHS,FEMA,"1) Code Assist GPT is an internal facing GenaAI tool to augment the FEMA workforce in generating and troubleshooting existing queries in established query languages.  

2) The tool provides improved queries and rapid iteration to produce desired scripts/query language saving the end user 80-90% of the time versus custom query development.  The tool also opens other computer languages, as required, to support our data analytics community.""
","1) Code Assist GPT is an internal facing GenaAI tool to augment the FEMA workforce in generating and troubleshooting existing queries in established query languages.  

2) The tool provides improved queries and rapid iteration to produce desired scripts/query language saving the end user 80-90% of the time versus custom query development.  The tool also opens other computer languages, as required, to support our data analytics community.""


Code Assist Generative Pre-trained Transformer (GPT) is an internal facing Generative AI (GenAI) tool to augment the FEMA workforce in generating and troubleshooting existing queries in established query languages (e.g., SQL, Java, COBOL). Users enter the language they are querying, and the Code Assist GPT then provides a proposed query based on the elements provided.  If the query is unsuccessful, the tool maintains the session, allowing users to prompt for enhancements until expected results are achieved.  At the end of the session, all prompts and queries are removed, and no data is stored outside of the active session. 

The tool provides improves query generation and rapid iteration, saving users 80-90% of the time compared to custom query development.  It also supports various computer languages to assist the data analytics community. "
DHS-2296,OCFO Response Augmentation Suite,DHS,FEMA,"1) FEMA OCFO GPT - B is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions for the record and providing a preliminary response to the Program Office to use in their formal response to the request. 
2) FEMA OCFO GPT provides draft responses reducing the data gathering stage and providing additional time for analysis, response, and approval.  This has reduced the analyst initial level of effort versus individual research by 80% on initial surveys.

1) Travel Policy GPT is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions regarding FEMA/DHS Travel Policy, including the JTR, and providing a preliminary response to the travel specialist to use in their formal response to the queries. 
2) The tool provides improved responses saving the end user 80-90% of the time versus regular engagement with the Travel Service Center.  The tool also allows travelers to ask specific questions that require Travel Service Center engagement, limiting the needed triage and speeding resoultion times.

1) Fiscal Policy GPT is an internal facing GenAI tool to augment the FEMA workforce in providing preliminary responses to questions regarding FEMA/DHS Fiscal Policy.
2) The tool provides improved responses saving the end user 80-90% of the time versus regular engagement with the DHS/FEMA OCFO Policy.  The tool also allows internal users to ask specific questions that require Fiscal Policy engagement, limiting the needed triage and speeding resoultion times.","1) FEMA OCFO GPT - B is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions for the record and providing a preliminary response to the Program Office to use in their formal response to the request. 
2) FEMA OCFO GPT provides draft responses reducing the data gathering stage and providing additional time for analysis, response, and approval.  This has reduced the analyst initial level of effort versus individual research by 80% on initial surveys.

1) Travel Policy GPT is an internal facing GenAI tool to augment the FEMA workforce in generating initial responses to questions regarding FEMA/DHS Travel Policy, including the JTR, and providing a preliminary response to the travel specialist to use in their formal response to the queries. 
2) The tool provides improved responses saving the end user 80-90% of the time versus regular engagement with the Travel Service Center.  The tool also allows travelers to ask specific questions that require Travel Service Center engagement, limiting the needed triage and speeding resoultion times.

1) Fiscal Policy GPT is an internal facing GenAI tool to augment the FEMA workforce in providing preliminary responses to questions regarding FEMA/DHS Fiscal Policy.
2) The tool provides improved responses saving the end user 80-90% of the time versus regular engagement with the DHS/FEMA OCFO Policy.  The tool also allows internal users to ask specific questions that require Fiscal Policy engagement, limiting the needed triage and speeding resoultion times.

FEMA Office of the Chief Financial Officer Generative Pre-trained Transformer (OCFO GPT), Travel Policy GPT and Fiscal Policy GPT are internal Generative AI (GenAI) tools designed to support the FEMA workforce by generating initial responses to various queries. These tools leverage relevant public and internal documents to draft preliminary responses, which are then refined prior to formal submission. They assist in the data gathering stage, but do not replace the critical review and judgement of FEMA analysts and leadership.  FEMA OCFO GPT generates initial responses to questions for the record, leveraging public and internal documents, and provides a preliminary response to the Program Office to use in their formal response to the request. It reduces the data gathering stage, saving analysts 80% of the initial effort.  Travel Policy GPT generates initial responses to questions regarding FEMA/DHS Travel Policy, including the JTR, and provides a preliminary response to the travel specialist to use in their formal response to the queries.  It improves response times, saving users 80-90% of the time compared to regular engagement with the Travel Service Center.  Fiscal Policy GPT provides preliminary responses to questions regarding FEMA/DHS Fiscal Policy and will generate a draft response with references to assist FEMA internal workforce in compliance with established policy.  It saves users 80-90% of the time compared to regular engagement with DHS /FEMA OCFO policy and speeds up resolution times.  These tools do not replace analysts’ work or leadership review, but enhance efficiency in data gathering and preliminary response stages. "
DHS-254,Planning Assistant for Resilient Communities (PARC),DHS,FEMA,"Hazard mitigation plans are not only a foundational step that communities can take to build their resilience but can be lengthy to produce and challenging for communities that lack resources to do so. PARC will specifically support State, Local, Tribal, and Territorial (SLTT) governments’ understanding of how to craft a plan that identifies risks and mitigation strategies as well as generate draft plan elements—from publicly-available, well-researched sources — that governments could customize to meet their needs. This capability could provide planners more time to allocate toward community engagement and stakeholder collaboration, and lead to more communities having the ability to submit grant applications for funding to become more resilient and reduce disaster risks.","Hazard mitigation plans are not only a foundational step that communities can take to build their resilience but can be lengthy to produce and challenging for communities that lack resources to do so. PARC will specifically support State, Local, Tribal, and Territorial (SLTT) governments’ understanding of how to craft a plan that identifies risks and mitigation strategies as well as generate draft plan elements—from publicly-available, well-researched sources — that governments could customize to meet their needs. This capability could provide planners more time to allocate toward community engagement and stakeholder collaboration, and lead to more communities having the ability to submit grant applications for funding to become more resilient and reduce disaster risks.

The proposed Generative AI (GenAI) solution, Planning Assistant for Resilient Communities (PARC) will create efficiencies for the hazard mitigation planning process for local governments, including underserved communities. Hazard mitigation plans are not only a foundational step that communities can take to build their resilience but can be lengthy to produce and challenging for communities that lack resources to do so. PARC will specifically support State, Local, Tribal, and Territorial (SLTT) governments’ understanding of how to craft a plan that identifies risks and mitigation strategies as well as generate draft plan elements—from publicly available, well researched sources—that governments could customize to meet their needs. This capability could lead to more communities having the ability to submit grant applications for funding to become more resilient and reduce disaster risks. 

The Beta Release GenAI Plan Generator (OpenAI GPT-4o) is a Large Language Model (LLM) that generates sections of the Hazard Mitigation Plans based on user inputs. It processes prompts and user responses to create detailed, regulatory-compliant Hazard Mitigation Plan sections.  Beta Release PARC Assistant (OpenAI GPT-4o) produces responses through an interactive chat assistant. The Assistant helps planners by answering questions related to the Hazard Mitigation Plan process, offering explanations of policy guidelines, and guiding users through the Federal Emergency Management Agency’s (FEMA’s) regulatory requirements. "
DHS-2440,Recovery and Resilience Resource (RRR) Portal,DHS,FEMA,"The AI-layer (currently unfunded) would include a smart matching wizard functionallity via AI large language model (LLM) to connect SLTT partners with the resources that meet their unique needs. Increasing access and improving navigation of federal resources will benefit a wide array of stakeholders across all sectors, including private and public. The primary stakeholders are SLTTs that are looking to support recovery and/or resilience in communities. This includes 50 States, DC, and 5 US Territories, about 80,000 local governments (including special districts), 574 Federally recognized Tribal governments, and their partners. Additional stakeholders include the 25+ federal departments and agencies that are members of the Mitigation Framework Leadership Group (MitFLG), who have equity in the availability of comprehensive resources, best practices, or tools for SLTTs to recover from or increase resilience to disasters.
","The AI-layer (currently unfunded) would include a smart matching wizard functionallity via AI large language model (LLM) to connect SLTT partners with the resources that meet their unique needs. Increasing access and improving navigation of federal resources will benefit a wide array of stakeholders across all sectors, including private and public. The primary stakeholders are SLTTs that are looking to support recovery and/or resilience in communities. This includes 50 States, DC, and 5 US Territories, about 80,000 local governments (including special districts), 574 Federally recognized Tribal governments, and their partners. Additional stakeholders include the 25+ federal departments and agencies that are members of the Mitigation Framework Leadership Group (MitFLG), who have equity in the availability of comprehensive resources, best practices, or tools for SLTTs to recover from or increase resilience to disasters.


The Recovery and Resilience Resource (RRR) Portal aims to simplify the process of finding and using disaster recovery and resilience resources and information for State, Local, Tribal, and Territorial (SLTT) decision-makers as well as the communities they serve. The RRR Portal brings together technical, financial, and information assistance into one easy-to-use platform to reduce the time it takes to navigate the wide range of available resources. The non-AI layers (currently funded) will provide an intuitive user interface, a business intelligence reporting tool, and an expansive data library. The AI-layer (currently unfunded) would include a smart matching wizard functionality via AI Large Language Model (LLM) to connect SLTT partners with the resources that meet their unique needs. 

Increasing access and improving navigation of federal resources will benefit a wide array of stakeholders across all sectors, including private and public. The primary stakeholders are SLTTs that are looking to support recovery and/or resilience in communities. This includes 50 states, Washington D.C., 5 U.S. territories, about 80,000 local governments (including special districts), 574 federally recognized tribal governments, and their partners. Additional stakeholders include the 25+ federal departments and agencies that are members of the Mitigation Framework Leadership Group (MitFLG), who have equity in the availability of comprehensive resources, best practices, or tools for SLTTs to recover from or increase resilience to disasters. 

The smart matching wizard will be an AI LLM that analyzes user search behavior and matches recommended resources from across the expansive data library that will include resources from federal, state, local, nonprofit sectors. "
DHS-2424,AI Assisted Compromise Email Detector (AACED),DHS,ICE,"The use case was developed to assist ICE SOC in reviewing a collection of emails between ICE personnel and Microsoft that were part of ED 24-02.  The use case provides a faster mechanism to the SOC analysts to determine indicators of compromise, reducing the level of effort for these individuals’ analysis exponentially.  To assist the analysts, Named Entity Recognition (NER) was used to detect PII and other associated keywords to increase analyst productivity, and reduce time required to analyze emails.
","The use case was developed to assist ICE SOC in reviewing a collection of emails between ICE personnel and Microsoft that were part of ED 24-02.  The use case provides a faster mechanism to the SOC analysts to determine indicators of compromise, reducing the level of effort for these individuals’ analysis exponentially.  To assist the analysts, Named Entity Recognition (NER) was used to detect PII and other associated keywords to increase analyst productivity, and reduce time required to analyze emails.


The AI Assisted Compromise Email Detector (AACED) helps prioritize which emails human security analysts should investigate first to identify cyber compromise ICE. This use case reports AI-enabled analysis on a one-time export of emails between ICE and Microsoft relevant to Cybersecurity and Infrastructure Security Agency (CISA) Emergency Directive 24-02. This use case does not perform live email analysis and only includes emails sent to/from ICE email accounts. 

The Information Assurance Division (IAD) within ICE is responsible for providing Cybersecurity Services to ICE, including operating the ICE Security Operations and Computer Security Incident Response Center through its Cyber Defense & Intelligence Branch. The Branch performs information assurance mitigation, responds to (and reports on) Information Technology (IT) security incidents, performs systems vulnerability testing, and monitors and evaluates the security performance on sensitive enterprise systems. CISA published Emergency Directive (ED) 24-02: Mitigating the Significant Risk from Nation-State Compromise of Microsoft Corporate Email System in which all Federal Government Agencies were required to review the stored email metadata from Microsoft to determine if they were affected from the breach. This requires the investigation of tens of thousands of emails to determine if there were any signs of compromise or Personally Identifiable Information (PII) leakage. 

The use case was developed to assist ICE Security Operations Center (SOC) in reviewing a collection of emails between ICE personnel and Microsoft that were part of ED 24-02.  It provides a faster mechanism for SOC analysts to determine indicators of compromise, reducing the level of effort for these individuals’ analysis exponentially.  To assist the analysts, Named Entity Recognition (NER) was used to detect PII and other associated keywords while a locally running Large Language Model (LLM), with no external connections, answers questions about selected emails.  The LLM also answers preset questions formulated from Standard Operating Procedures (SOP). The analysts use the outputs to expedite the detection of PII and key language within emails, reducing the time needed to analyze the total collection of emails.  If the use case detects PII or key language, then those emails are ranked as higher risk and prioritized by the analyst. The analyst then inspects the email at that location for presence of the data and logs it manually allowing for specified actions based on the results of the analysts’ review.  Ultimately, all emails are manually inspected and depending on the circumstance of the investigation the ICE Privacy Office may be contacted notifying them of the PII that was exposed, or the analyst will provide the information to the SOC Leadership to initiate the incident response process to perform remediation actions needed.  The use case only provides ranking for prioritized processing to the SOC analysts. "
DHS-407,Biometric Check-in for ATD-ISAP (SmartLINK),DHS,ICE,"ISAP Biometric Monitoring App is a technology option that allows participants to report in using a smartphone. This app verifies a participant’s identity, determine their location, and quickly collect status change information. The app adds functionality not available with telephonic and is less intrusive than a GPS unit. ISAP monitoring app limits in-person interactions of routine check-ins, allowing more time to be allocated to non-compliant participants, complex removal proceedings cases and docket management.","ISAP Biometric Monitoring App is a technology option that allows participants to report in using a smartphone. This app verifies a participant’s identity, determine their location, and quickly collect status change information. The app adds functionality not available with telephonic and is less intrusive than a GPS unit. ISAP monitoring app limits in-person interactions of routine check-ins, allowing more time to be allocated to non-compliant participants, complex removal proceedings cases and docket management.

The Intensive Supervision Appearance Program (ISAP) Monitoring App includes unique facial verification technology that allows participants to capture their photo during ICE Alternatives to Detention (ATD) enrollment for future verification purposes (e.g., during check-in). Unlike facial identification or recognition, the facial verification function uses a one-to-one matching approach of the individual presenting to the Monitoring App during their check-in by comparing it against the ATD participant’s photograph captured upon enrollment to determine whether the person is who they declare themselves to be. The Monitoring App can be launched from either an ICE ATD-issued mobile device or from the participant’s personal mobile device.  It takes a series of photos of the participant during enrollment, which are stored in the ISAP ATD case management system. During subsequently checks in, an automatic 1:1 verification image of the individual in front of the phone’s camera is matched against the stored profile images to enable the ICE ATD Case Manager to verify the participant’s identity, using a proprietary algorithm. The technology also recognizes if a “live” person is in front of the camera, as opposed to a representation or image of a person. There is a visual ICE ATD Case Manager review if there is no match or if the matching attempt generates an error alert. The photos are only used for the described verification purpose and are not shared for any other purpose or with any other entity or database. Any pictures taken during the facial template capture are immediately deleted from the device and only the facial measurements are captured. 

The ISAP Biometric Monitoring App is a technology option that allows participants to report in using a smartphone. This app verifies a participant’s identity, determines their location, and quickly collects status change information. It adds functionality not available with telephonic methods and is less intrusive than a global positioning system unit. The ISAP Monitoring App limits in-person interactions for routine check-ins, allowing more time to be allocated to non-compliant participants, complex removal proceedings cases, and docket management. 

There are two outputs related to using ISAP Biometric Monitoring App: either a participant passes the biometric match, or the photo is moved to a pending review status.   "
DHS-2436,Burlington Finance Center Voice Bot,DHS,ICE,"Identify and verify the caller, retrieve the status of the bond, and share the bond status with the requester and/or answer administrative FAQs.","Identify and verify the caller, retrieve the status of the bond, and share the bond status with the requester and/or answer administrative FAQs.

The Bond Management Information System (BMIS) supports the lifecycle of an immigration bond, from posting to disposal.  The Burlington Finance Center (BFC) Voice Bot will be a public-facing multilingual chatbot that uses voice recognition to understand and respond to suer inquiries over the phone. It employes Natural Language Understanding (NLU) and Natural Language Processing (NLP) for voice-to-text and text-to-voice translations, enabling it to recognize voices and interpret meaning.  The BFC Voice Bot will be deterministic and will not use Generative AI.  The BFC Voice Bot will identify and verify callers, providing or retrieving and sharing bond status information. It will support English, Spanish, and French/Haitian Creole.  The current bond inquiry workflow is entirely manual; automating the process will improve efficiency and reduce the burden of the Bonds Management team. "
DHS-2426,"Cybersecurity Threat Management, Detection, and Response",DHS,ICE,"Machine Learning (ML) is used to analyze historical ICE cybersecurity data, create activity baselines, and detect anomalous behaviors for alerting. By integrating ML with other advanced analytics and correlation rules, AI identifies patterns indicative of security incidents, enabling SOC analysts to detect and respond to threats more quickly than previously possible.","Machine Learning (ML) is used to analyze historical ICE cybersecurity data, create activity baselines, and detect anomalous behaviors for alerting. By integrating ML with other advanced analytics and correlation rules, AI identifies patterns indicative of security incidents, enabling SOC analysts to detect and respond to threats more quickly than previously possible.

The Information Assurance Division (IAD) within ICE is responsible for providing internal Cybersecurity Services to ICE. Within IAD is the Cyber Defense & Intelligence (CD&I) Branch whose mission is operating the ICE Security Operations and Computer Security Incident Response Center. The Branch performs information assurance mitigation, responds to and reports on Information Technology (IT) security incidents, performs systems vulnerability testing, and monitors and evaluates the security performance on sensitive enterprise systems. The CD&I Branch performs monitoring and analysis on aggregate ICE cybersecurity data to identify and respond to anomalous and malicious activity. This data is limited to IT security operations and is not used to conduct AI-enabled workplace surveillance or automated personnel management. CD&I uses several AI-enabled cybersecurity tools to analyze this data. Machine learning (ML) models, such as classification and regression models, are used to analyze historical data and detect emerging threats through pattern recognition. Additional capabilities include the identification of real-time threats by using algorithms and ML from a vast database of known threats and patterns during continuous monitoring of ICE cybersecurity data. This includes recognizing phishing patterns, malware signatures, or abnormal network traffic patterns across a variety of tools. This provides security analysts with modern tools to identify and respond to threats much more quickly than previously possible, minimizing potential damage to systems and data."
DHS-416,Data Tagging and Classification,DHS,ICE,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Homeland Security Investigations (HSI) Innovation Lab is developing an analytical platform called the Repository for Analytics in a Virtualized Environment (RAVEn). RAVEn facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables users to develop new tools to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for the Repository for Analytics in a Virtualized Environment (RAVEn).  RAVEn leverages data tagging and classification to do the following: The Email Analytics Tool streamlines how special agents and criminal analysts search, filter, translate, and report on electronic communications evidence and will help investigators more effectively determine the structure and organization of criminal enterprises. The RAVEn - Lead Tracker is a centralized system where agents can send and receive leads and enter outcomes such as arrests and seizures. The goal is for all leads in the agency to be found in one place, rather than in various email inboxes. The overarching goal of Mobile Device Analytics is to improve the efficiency of agents and analysts in identifying pertinent evidence, relationships, and criminal networks from data extracted from mobile devices. "
DHS-2423,Digital Records Manager (DRM) User Assistance Chatbot,DHS,ICE,"This is an AI records search tool to help investigators more efficiently search and gather information. 

The Digital Records Manager (DRM) User Assistance Chatbot is intended to increase user efficiency by providing answers to commonly asked question without the need to manually refer to documentation or submit a help desk ticket.  A reduction in the volume of submitted help desk tickets is expected as a result.","This is an AI records search tool to help investigators more efficiently search and gather information. 

The Digital Records Manager (DRM) User Assistance Chatbot is intended to increase user efficiency by providing answers to commonly asked question without the need to manually refer to documentation or submit a help desk ticket.  A reduction in the volume of submitted help desk tickets is expected as a result.

The Digital Records Manager (DRM) User Assistance Chatbot is an AI tool designed to help investigators efficiently search and gather information. Homeland Security Investigations (HSI), a component DHS, is responsible for investigating, disrupting, and dismantling transnational criminal organizations and terrorist networks that threaten or seek to exploit the customs and immigration laws of the United States. HSI uses the Investigative Case Management (ICM) system to document its investigative activities and has integrated the DRM with ICM to manage digital media associated with investigations. Together, ICM and DRM serve as HSI’s official system of record for investigative case data, ensuring compliance with the National Archives and Records Administration’s mandate for fully electronic records. The HSI DRM User Assistance Chatbot provides users with a consistent location in the DRM interface to pose natural language questions about using the application for case and media management.  It uses a Retrieval Augmented Generation (RAG) approach to augment natural language responses from a Large Language Model (LLM) with a custom Knowledge Base containing DRM documentation. The Chatbot outputs natural language responses to user questions, guiding them to accomplish specific tasks within the system. This immediate, on-demand assistance emulates help desk support, reducing time-to-completion for many DRM functions and easing the burden on help desk staff. "
DHS-48,Email Analytics for Investigative Data,DHS,ICE,"HSI personnel encounter large volumes of legally acquired, multilingual email data that must be prepared (ingested, triaged, translated, searched and filtered) before it can be analyzed to support investigations. The Email Analytics application eliminates manual data preparation processes, and leverages machine learning to conduct spam message classification, translation, and entity extraction, including names, organizations, or locations. It also utilizes HSI's AI-enabled translation capabilities (see related use case “Translation and Transcription for Investigative Data”) for translation of emails in other languages to English. The output reduces time and resources spent preparing data, increases the analytic utility of the data, and allows HSI personnel to more quickly conduct analysis on the information.","HSI personnel encounter large volumes of legally acquired, multilingual email data that must be prepared (ingested, triaged, translated, searched and filtered) before it can be analyzed to support investigations. The Email Analytics application eliminates manual data preparation processes, and leverages machine learning to conduct spam message classification, translation, and entity extraction, including names, organizations, or locations. It also utilizes HSI's AI-enabled translation capabilities (see related use case “Translation and Transcription for Investigative Data”) for translation of emails in other languages to English. The output reduces time and resources spent preparing data, increases the analytic utility of the data, and allows HSI personnel to more quickly conduct analysis on the information.

Homeland Security Investigations (HSI) is a critical component ICE, responsible for investigating a wide range of crimes that threaten national security, public safety, and the economy. HSI targets transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. To achieve this mission, HSI uses on advanced technologies to analyze and process vast amounts of data, including audio and video evidence. HSI personnel handle significant amounts of legally acquired, multilingual email data, which must be prepared (ingested, triaged, translated, searched and filtered) before analysis. The Email Analytics application automates this process, using machine learning (ML) for spam classification, translation, and entity extraction (such as names, organizations, or locations). The Translation and Transcription Tool translates emails into English, reducing the time and resources needed for data preparation. This increases the analytic utility of the data, allowing HSI personnel to conduct quicker analysis. HSI uses this tool to generate leads, with further actions taken by investigators and analysts as part of the full investigative process before any action is taken against an individual."
DHS-362,Facial Recognition for Investigations of Child Sexual Exploitation and Abuse,DHS,ICE,This tool is being used to identify children who would not be otherwise identified and rescued by traditional investigative methods. This tool is also used to identify offenders who produce CSAM.,"This tool is being used to identify children who would not be otherwise identified and rescued by traditional investigative methods. This tool is also used to identify offenders who produce CSAM.

The Homeland Security Investigations (HSI) Child Exploitation Investigations Unit (CEIU) handles cases involving the production, distribution, and possession of child sexual exploitation materials.  It works to identify and rescue victims using advanced forensic technology and investigative techniques. CEIU employs an “image recognition neural network” to help identify unknown victims and offenders depicted in child sexual abuse material (CSAM). HSI personnel receive specific training to use this technology, examining newly discovered and unidentified images of CSAM. The technology generates leads on the possible identities of victims and offenders, but no enforcement action is taken based on these leads alone.  Potential identifications must be further investigated and validated. CEIU ensures the tool’s use complies with all policy and privacy standards as set forth in the Privacy Impact Assessment. This technology has been proven effective in identifying and rescuing children who might not have been found through traditional methods and in preventing further victimization by arresting otherwise undetected offenders. The tool provides visually similar photos of individuals, serving as a starting point for further investigation by analysts. No enforcement action is permitted on these leads alone. "
DHS-54,Facial Recognition Service,DHS,ICE,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Facial Recognition Service is used during investigations conducted by Homeland Security Investigations (HSI) agents and analysts for identification of known individuals, as well as extracting faces for further investigations from perpetrators including child exploitation offenses, human rights atrocities, and war criminals.  This is a DHS HSI Innovation Lab/RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn. "
DHS-2408,Hurricane Score,DHS,ICE,"The Immigration and Customs Enforcement (ICE) Enforcement and Removal Operations (ERO) division would like to explore technology that could help lead to time savings and eliminate human error due to overburdened officers.  An AI generated hurricane score could also minimize the risk that a factor is overlooked due to officers being overburdened.  The hurricane score may be one factor that is used to inform the decision-making process. The “Hurricane Score” models the potential risk (1-5) that a noncitizen who is released from detention with the requirement to check in with ICE through monitoring will abscond from the program, with a higher number indicating a higher risk of absconding.","The Immigration and Customs Enforcement (ICE) Enforcement and Removal Operations (ERO) division would like to explore technology that could help lead to time savings and eliminate human error due to overburdened officers.  An AI generated hurricane score could also minimize the risk that a factor is overlooked due to officers being overburdened.  The hurricane score may be one factor that is used to inform the decision-making process. The “Hurricane Score” models the potential risk (1-5) that a noncitizen who is released from detention with the requirement to check in with ICE through monitoring will abscond from the program, with a higher number indicating a higher risk of absconding.

ICE Enforcement Removal Operations’ Alternatives to Detention (ATD) program exists to ensure compliance with release conditions and provides important case management services for non-detained noncitizens. ATD consists of the Intensive Supervision Appearance Program (ISAP), which utilizes case management and technology tools to support noncitizens compliance with release conditions, court hearings, and final orders of removal, while allowing them to remain in their communities as they move through the immigration process or prepare for departure from the United States. Once individuals are in the ATD-ISAP program, officers periodically perform case reviews to determine if current levels of case management and technology assignment are appropriate for the noncitizen in the program or if they need to be adjusted. During the case review, the officer will consider numerous factors to include, but not limited to, current immigration status, supervision and compliance history, pending benefits, being a care giver or care provider, current immigration stage, pending criminal history and/or convictions, the hurricane score, and other factors. The factor known as the Hurricane Score is a quasi-binomial, binary classification machine learning (ML) model that is given information by an analyst that is known about an individual (factors from case management details and participant actions) and determines the probability that the individual will abscond based on absconding patterns the model has learned from inactive ATD-ISAP case data. The model returns a score from 1-5, with the higher number equating to a higher risk. The officer may use this score as one of the many factors previously described when deciding the appropriate level of case management and technology for noncitizens enrolled in the ATD-ISAP program. Because the hurricane score can quickly evaluate an enormous amount of information on thousands of noncitizens in the ATD-ISAP program, it provides officers with additional insight that they would not have otherwise had when performing a case review. "
DHS-2409,ICE Mobile Check-in Application,DHS,ICE,"The Check-In App is an opt-in capability that allows for low-risk adult noncitizens to securely check-in via an ICE Verified user account, verify their identity, identify their location, and satisfy check-in requirements thereby reducing in-person office visits and reducing manual processing work. AI-enabled capabilities within the ICE Check-In application give ICE the ability to scale its interactions to a greater number of noncitizens and reduce in-office presence at ICE facilities.","The Check-In App is an opt-in capability that allows for low-risk adult noncitizens to securely check-in via an ICE Verified user account, verify their identity, identify their location, and satisfy check-in requirements thereby reducing in-person office visits and reducing manual processing work. AI-enabled capabilities within the ICE Check-In application give ICE the ability to scale its interactions to a greater number of noncitizens and reduce in-office presence at ICE facilities.

ICE is authorized under the Immigration and Nationality Act (INA) to set terms of supervision on non-citizens who are in immigration proceedings or who have completed proceedings and were not granted a status or relief of any kind. The ICE Check-In application is a mobile application where low-risk adult noncitizens can check-in using location and photo capabilities on user owned mobile devices (iOS and Android application stores). The Check-In App is an opt-in capability that allows for low-risk adult noncitizens to securely check-in via an ICE Verified user account, verify their identity, identify their location, and satisfy check-in requirements thereby reducing in-person office visits and reducing manual processing work. The app requires users to follow several randomly prompted actions and leverages programmatic logic-based heuristics to infer liveness based upon facial-tracking feedback from user interaction. AI and machine learning (ML) are used for this face detection and tracking. Once captured, the photo is verified with a 1:1 verification using the Customs and Border Protection (CBP) Traveler Verification Service. Verification of all requirements will satisfy check-in requirements. A failed verification will result in a review by an officer. The officer can request the user try again or request the user use the default in-person check-in process by making an appointment with their local ICE office. AI-enabled capabilities within the ICE Check-In application give ICE the ability to scale its interactions to a greater number of noncitizens and reduce in-office presence at ICE facilities. "
DHS-53,Identification Card and Travel Document Code Detection,DHS,ICE,"The Identification Card and Travel Document Code Detection service leverages mobile phone cameras to quickly and accurately read 2D Data Matrix Codes on US Driver's Licenses and ID cards, as well as Machine Readable Zones (MRZ) on travel documents like Passports and Passport cards. This innovative solution utilizes machine learning to enhance the detection of these codes, allowing for seamless scanning and automatic population of detected information into corresponding text fields within HSI mobile apps. By streamlining the code recognition process, the service significantly reduces the time required for users to read cards or documents, eliminating the need for manual data entry and resulting in more efficient, in-person interactions with individuals.","The Identification Card and Travel Document Code Detection service leverages mobile phone cameras to quickly and accurately read 2D Data Matrix Codes on US Driver's Licenses and ID cards, as well as Machine Readable Zones (MRZ) on travel documents like Passports and Passport cards. This innovative solution utilizes machine learning to enhance the detection of these codes, allowing for seamless scanning and automatic population of detected information into corresponding text fields within HSI mobile apps. By streamlining the code recognition process, the service significantly reduces the time required for users to read cards or documents, eliminating the need for manual data entry and resulting in more efficient, in-person interactions with individuals.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating crimes that threaten national security, public safety, and the economy. HSI’s mission is to protect the United States from transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. To achieve this mission, HSI uses advanced technologies to analyze and process vast amounts of data, including audio and video evidence. The Identification Card and Travel Document Code Detection service leverages mobile phone cameras to read 2D Data Matrix Codes on U.S. driver's licenses and identification cards, as well as Machine Readable Zones (MRZ) on travel documents like passports and passport cards. This service uses machine learning (ML) to enhance code detection, allowing for seamless scanning and automatic population of detected information into corresponding text fields within HSI mobile apps. By streamlining the code recognition process, this service reduces the time required for users to read cards or documents, eliminating the need for manual data entry, and resulting in more efficient in-person interactions with individuals."
DHS-2425,Intelligent Document Processing for Workflow Automation,DHS,ICE,"Business units within ICE leverage these services to automate repeatable, time-consuming processes such as invoice processing, and form entry validation and extraction. This platform will provide Optical Character Recognition and machine learning models to verify, extract, and classify information from ICE forms. Using AI to provide information extraction for these processes saves ICE personnel a significant amount of time while improving data quality and enabling automation.
","Business units within ICE leverage these services to automate repeatable, time-consuming processes such as invoice processing, and form entry validation and extraction. This platform will provide Optical Character Recognition and machine learning models to verify, extract, and classify information from ICE forms. Using AI to provide information extraction for these processes saves ICE personnel a significant amount of time while improving data quality and enabling automation.


ICE processes forms of all types across its Program Offices, requiring a significant amount of time to manually validate and extract form data and enter it into a variety of systems. ICE uses a Commercial Off-The-Shelf (COTS) platform and cloud services to provide Robotic Process Automation (RPA) and AI-based intelligent document processing capabilities to the enterprise. Business units within ICE leverage these services to automate repeatable, time-consuming processes such as invoice processing, and form entry validation and extraction. This platform will provide Optical Character Recognition and machine learning models to verify, extract, and classify information from ICE forms such as contract invoices, the Disability Accommodation Notification (DAN) form, Notices to Appear (NTA), email inquiries to the Office of the Inspector General, the Sexual Abuse or Assault Incident Review form, Student and Exchange Visitor Program (SEVP) system access requests, the Notice to Student or Exchange Visitor (I-515) form, and the Training Plan for STEM OPT Students (I-983) form. AI is used during these automations to verify and extract information from the forms only and does not change data or make decisions based on the data. Additional workflow automations will use this data for follow-on actions such as processing an invoice, creating a case, or entering data into another system, depending on the purpose of the automation. The platform also includes the ability to create a feedback loop to continuously improve the model's accuracy by retraining it with new, relevant data. Using AI to provide information extraction for these processes saves ICE personnel a significant amount of time while improving data quality and enabling automation.  "
DHS-125,Investigative Prioritization Aggregator,DHS,ICE,"The sheer volume of data associated with investigations often overwhelms human capabilities, making it challenging for HSI personnel to analyze evidence and identify key players in criminal networks. Currently, there is no effective mechanism to quantify the level of evidence related to a particular subject or entity, or to determine which actors within a network are the most influential. This is particularly critical in the context of the counter-opioid/fentanyl mission, where timely and accurate intelligence is essential.

To address this challenge, this project utilizes machine learning to assign point values to data, enabling the scoring of information associated with a given selector, such as a phone number or legal name. This scoring system helps to understand the importance of an entity to investigations and the potential consequences of removing or neutralizing that entity. By doing so, HSI personnel can focus on high-priority targets and associated criminal networks, ultimately enhancing their ability to disrupt and dismantle these threats.","The sheer volume of data associated with investigations often overwhelms human capabilities, making it challenging for HSI personnel to analyze evidence and identify key players in criminal networks. Currently, there is no effective mechanism to quantify the level of evidence related to a particular subject or entity, or to determine which actors within a network are the most influential. This is particularly critical in the context of the counter-opioid/fentanyl mission, where timely and accurate intelligence is essential.

To address this challenge, this project utilizes machine learning to assign point values to data, enabling the scoring of information associated with a given selector, such as a phone number or legal name. This scoring system helps to understand the importance of an entity to investigations and the potential consequences of removing or neutralizing that entity. By doing so, HSI personnel can focus on high-priority targets and associated criminal networks, ultimately enhancing their ability to disrupt and dismantle these threats.

Homeland Security Investigations (HSI) is a critical component ofICE, responsible for investigating crimes that threaten national security, public safety, and the economy. HSI’s mission is to protect the United States from transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. HSI relies on advanced technologies and innovative solutions to analyze and process vast amounts of data, including audio and video evidence. The sheer volume of data often overwhelms human capabilities, making it challenging for HSI personnel to analyze evidence and identify key players in criminal networks. Currently, there is no effective mechanism to quantify the level of evidence related to a particular subject or entity, or to determine the most influential actors within a network. This is particularly critical in the counter-opioid/fentanyl mission, where timely and accurate intelligence is essential. To address this challenge, HSI has developed a project that uses machine learning (ML) to assign point values to data, enabling the scoring of information associated with a given selector, such as a phone number or legal name. This scoring system helps to understand the importance of an entity to investigations and the potential consequences of removing or neutralizing that entity. By doing so, HSI personnel can focus on high-priority targets and associated criminal networks, enhancing their ability to disrupt and dismantle these threats. HSI uses this tool to generate leads, with further actions taken by investigators and analysts as part of the full investigative process before any action is taken against an individual"
DHS-197,Machine Learning Translation Technology Initiative,DHS,ICE,"The solution will be used to facilitate non-critical communications only. When deployed to production, the solution should not be used alone, absent human quality control, when materials are vital to an individual’s rights or benefits, or when the source materials contain non-literal language (e.g., slang, metaphor), lack clear grammar or structure, contain abbreviations or acronyms, or are overly complex, technical, or wordy. If any interactions indicate the presence of legal or medical issues or a need for greater accuracy, ERO personnel are required to seek additional language assistance via bilingual staff or a professional language line. The solution was first spearheaded by U.S. Coast Guard for maritime usage with the support of DHS Science and Technology Directorate through the Silicon Valley Innovation Program (SVIP). ICE ERO received FY22 funding to initiate the proof of concept with the vendors vetted by USCG and DHS S&T through an interagency agreement. Solutions, in the form of mobile phone applications, are being developed under research and development phases and projected to completely meet ERO’s requirements by January 2026.","The solution will be used to facilitate non-critical communications only. When deployed to production, the solution should not be used alone, absent human quality control, when materials are vital to an individual’s rights or benefits, or when the source materials contain non-literal language (e.g., slang, metaphor), lack clear grammar or structure, contain abbreviations or acronyms, or are overly complex, technical, or wordy. If any interactions indicate the presence of legal or medical issues or a need for greater accuracy, ERO personnel are required to seek additional language assistance via bilingual staff or a professional language line. The solution was first spearheaded by U.S. Coast Guard for maritime usage with the support of DHS Science and Technology Directorate through the Silicon Valley Innovation Program (SVIP). ICE ERO received FY22 funding to initiate the proof of concept with the vendors vetted by USCG and DHS S&T through an interagency agreement. Solutions, in the form of mobile phone applications, are being developed under research and development phases and projected to completely meet ERO’s requirements by January 2026.

ICE’s Enforcement and Removal Operations (ERO) is developing a real-time translation tool to assist staff in communicating with noncitizens who have limited English proficiency. This tool, intended for non-critical conversations, will supplement existing language services contracts by providing real-time capabilities during various touch points in the ICE process. ERO personnel, who regularly interact with individuals who speak little or no English, currently rely on professional interpretation and translation services, which can be slow to secure. The new machine learning (ML) solution aims to facilitate informal communication quickly and efficiently. When deployed, it will not be used alone for materials vital to an individual’s rights or benefits, or when the source materials contain non-literal language, lack clear grammar, or are overly complex.  In such cases, ERO personnel must seek additional language assistance via bilingual staff or professional language lines. 

The initiative, first spearheaded by the U.S. Coast Guard for maritime usage with support from the DHS Science and Technology Directorate through the Silicon Valley Innovation Program (SVIP), received Fiscal Year 2022 funding for proof of concept. Solutions, in the form of mobile phone applications, are being developed under research and development phases and are projected to meet ERO’s requirements by January 2026. The Machine Learning Translation Technology Initiative will offer real-time communication and translation services, providing voice-to-text, text-to-voice, and voice-to-voice translations in at least 21 languages. This technology will enhance the ability of ICE ERO personnel to provide meaningful access to programs and services for limited English proficient (LEP) noncitizens. "
DHS-9,"Machine Translation
(Previously Language Translator)",DHS,ICE,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Rapid Analysis and Visualization Engine for Reporting (RAVEn) platform provides capabilities to upload data that may contain text in languages other than English. To support the agent/analyst analysis of the ingested data as well as to provide for the means to standardize searches across RAVEn data sources, RAVEn provides language translation capabilities to create text conversions between the original language and English. Data translation can be performed on ingest or on an ad hoc basis. Solution will provide translation support of, at minimum, plain text, word documents, and portable document formats using Natural Language Processing and machine learning. "
DHS-49,Mobile Device Analytics for Investigative Data,DHS,ICE,"Mobile device analytics capabilities were developed to meet the growing need for investigators to quickly and effectively review and analyze the massive amounts of data extracted from mobile devices obtained in court-ordered seizures through a warrant or other investigative due process. The solution empowers investigators and analysts to identify and extract critical evidence, relationships, and networks from mobile device data, leveraging machine learning capabilities to determine locations of interest. Present capabilities are limited to the use of an algorithm for clustering of geo-location data, allowing investigators to identify 'stops' and 'overlaps' of locations from lawfully seized phones, where a 'stop' is a location a phone may have remained for a period of time and an 'overlap' is a location where multiple phones may have visited. By streamlining the analysis process, these capabilities aim to enhance the efficacy of HSI agents and analysts by providing advanced data processing to identify the most relevant information for lead generation in a shorter amount of time than manually processing, ultimately contributing to the disruption and dismantling of criminal networks and the protection of national security.","Mobile device analytics capabilities were developed to meet the growing need for investigators to quickly and effectively review and analyze the massive amounts of data extracted from mobile devices obtained in court-ordered seizures through a warrant or other investigative due process. The solution empowers investigators and analysts to identify and extract critical evidence, relationships, and networks from mobile device data, leveraging machine learning capabilities to determine locations of interest. Present capabilities are limited to the use of an algorithm for clustering of geo-location data, allowing investigators to identify 'stops' and 'overlaps' of locations from lawfully seized phones, where a 'stop' is a location a phone may have remained for a period of time and an 'overlap' is a location where multiple phones may have visited. By streamlining the analysis process, these capabilities aim to enhance the efficacy of HSI agents and analysts by providing advanced data processing to identify the most relevant information for lead generation in a shorter amount of time than manually processing, ultimately contributing to the disruption and dismantling of criminal networks and the protection of national security.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating a wide range of crimes that threaten national security, public safety, and the economy. With a mission to protect the United States from transnational crime and terrorism, HSI works to disrupt and dismantle complex organizations that engage in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. To achieve this mission, HSI relies on advanced technologies and innovative solutions to analyze and process vast amounts of data, including audio and video evidence. Mobile device analytics capabilities were developed to meet the growing need for investigators to quickly and effectively review and analyze the massive amounts of data extracted from mobile devices obtained in court-ordered seizures through a warrant or other investigative due process. The solution empowers investigators and analysts to identify and extract critical evidence, relationships, and networks from mobile device data, leveraging machine learning capabilities to determine locations of interest. Present capabilities are limited to the use of an algorithm for clustering of geo-location data, allowing investigators to identify 'stops' and 'overlaps' of locations from lawfully seized phones, where a 'stop' is a location a phone may have remained for a period and an 'overlap' is a location where multiple phones may have visited. By streamlining the analysis process, these capabilities aim to enhance the efficacy of HSI agents and analysts by providing advanced data processing to identify the most relevant information for lead generation in a shorter amount of time than manually processing, ultimately contributing to the disruption and dismantling of criminal networks and the protection of national security. HSI uses this tool to generate leads, and further action is required by investigators and analysts as part of the full investigative process before any action is taken against an individual. "
DHS-P1,Normalization Services,DHS,ICE,"HSI utilizes artificial intelligence to enhance data accuracy and efficiency by verifying, validating, correcting, and normalizing various types of information, including addresses, phone numbers, names, and ID numbers. This process helps to eliminate data entry errors, detect intentional misidentification, and connect related information across multiple datasets, ultimately reducing the time and resources required for investigations. The machine learning-powered normalization services offered by HSI include converting ambiguous addresses into usable formats, identifying ID types from partial information, categorizing names with complex suffixes and family names, and standardizing phone numbers to the E164 format, including determining their originating county. By normalizing and improving the quality of investigative datasets, HSI is able to use more advanced tools to find correlations and leads that would have otherwise gone undetected without extensive manual effort.","HSI utilizes artificial intelligence to enhance data accuracy and efficiency by verifying, validating, correcting, and normalizing various types of information, including addresses, phone numbers, names, and ID numbers. This process helps to eliminate data entry errors, detect intentional misidentification, and connect related information across multiple datasets, ultimately reducing the time and resources required for investigations. The machine learning-powered normalization services offered by HSI include converting ambiguous addresses into usable formats, identifying ID types from partial information, categorizing names with complex suffixes and family names, and standardizing phone numbers to the E164 format, including determining their originating county. By normalizing and improving the quality of investigative datasets, HSI is able to use more advanced tools to find correlations and leads that would have otherwise gone undetected without extensive manual effort.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating a wide range of crimes that threaten national security, public safety, and the economy. With a mission to protect the United States from transnational crime and terrorism, HSI works to disrupt and dismantle complex organizations that engage in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. To achieve this mission, HSI relies on advanced technologies and innovative solutions to analyze and process vast amounts of data, including audio and video evidence. 

HSI utilizes machine learning to enhance data accuracy and efficiency by verifying, validating, correcting, and normalizing various types of information, including addresses, phone numbers, names, and identification numbers. This process helps to eliminate data entry errors, detect intentional misidentification, and connect related information across multiple datasets, ultimately reducing the time and resources required for investigations. The machine learning-powered normalization services offered by HSI include converting ambiguous addresses into usable formats, identifying identification types from partial information, categorizing names with complex suffixes and family names, and standardizing phone numbers to the E164 format, including determining their originating county. By normalizing and improving the quality of investigative datasets, HSI is able to use more advanced tools to find correlations and leads that would have otherwise gone undetected without extensive manual effort. "
DHS-208,Policy Analyst Assistant,DHS,ICE,"The Student and Exchange Visitor Program (SEVP) uses AI to help policy analysts quickly find and summarize information about visa rules for students and schools. This saves time and helps analysts respond faster to questions.

This project is intended purpose is to enable SEVP Policy staff to provides responses to policy related inquiries and conduct policy research and analysis: It will be a tool embedded in workflow processes. The processes augmented by the AI includes responses for questions asked by SEVP internal staff and responses given to schools and students by SEVP personnel. For this process, the source of information for the responses will be from authoritative, pre-vetted documents. This reduces the workload on the Policy staff and allows them to focus on more complex policy and guidance issue. For these processes, the AI will assist with researching internal documents and information from regulations, applicable legislation, and other federal guidance. It will assist the policy analyst with summaries, citations, and initial drafts. The benefits includes faster, more consistent responses from Policy and the ability to handle additional work without adding staff.","The Student and Exchange Visitor Program (SEVP) uses AI to help policy analysts quickly find and summarize information about visa rules for students and schools. This saves time and helps analysts respond faster to questions.

This project is intended purpose is to enable SEVP Policy staff to provides responses to policy related inquiries and conduct policy research and analysis: It will be a tool embedded in workflow processes. The processes augmented by the AI includes responses for questions asked by SEVP internal staff and responses given to schools and students by SEVP personnel. For this process, the source of information for the responses will be from authoritative, pre-vetted documents. This reduces the workload on the Policy staff and allows them to focus on more complex policy and guidance issue. For these processes, the AI will assist with researching internal documents and information from regulations, applicable legislation, and other federal guidance. It will assist the policy analyst with summaries, citations, and initial drafts. The benefits includes faster, more consistent responses from Policy and the ability to handle additional work without adding staff.

The Student and Exchange Visitor Program (SEVP) uses AI to help policy analysts quickly find and summarize information about visa rules for students and schools, saving time and enabling faster responses to questions. SEVP is responsible for a wide variety of functions focusing on visa holders including F and M nonimmigrants and schools certified to admit them. The SEVP Regulation and Guidance Team performs research on large volumes of immigration policies, regulations, and other guidance for nonimmigrants to generate responses to data calls and queries from schools and students. Current methods for generating responses are manual and time-intensive. SEVP plans to leverage AI by developing a semantic search and LLM-based summarization tool using Retrieval Augmented Generation (RAG) to allow policy analysts to research and generate an initial analysis of applicable material more quickly and effectively. The generated output will be used as a starting point to assist policy analysts in completing their tasks, who will further refine, modify, vet, and review the response as part of their process. The source information provided to the tool is either in the public domain or is internal, non-sensitive data, with no Sensitive Personally Identifiable Information (SPII), Personally Identifiable Information (PII), nor Security Sensitive Information (SSI) used. This enhanced search capability will save hours of manual work per request, allowing analysts to respond more quickly with the most relevant information and focus on more complex policy and guidance issues. "
DHS-175,RAVEn Compliance Automation Tool (CAT),DHS,ICE,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Repository for Analytics in a Virtualized Environment (RAVEn) Compliance Automation Tool (CAT) is being developed as part of an effort to modernize HSI’s Form I-9 Inspection Process. The goal is to uses machine learning (ML) and automation to increase the speed and efficiency of ingesting and processing Forms I-9 data. Easy to use front-end interface workflow that increases work productivity and reduces manual entry. RAVEn CAT currently employs an Optical Recognition Service (OCR) model and software (Tesseract OCR) to identify pixel coordinates of handwritten and read/extract computer typed characters from ingested forms for processing. Additional research into opensource ML Object Detection models is being made to help further augment accuracy of text identification and extraction of ingested forms into the pipeline. "
DHS-204,Semantic Search and Summarization for Investigative Reports,DHS,ICE,"Effective investigations require querying large volumes of unstructured reports to extract and summarize contextually-relevant information. Current lexical search methods are insufficient for finding such information. Semantic Search and Summarization enables contextually-relevant information extraction and summarization from large volumes of unstructured investigative reports. The output will enhance and optimize investigative analysis by accelerating person-of-interest identification, surfacing trends, and improving network or fraud detection.","Effective investigations require querying large volumes of unstructured reports to extract and summarize contextually-relevant information. Current lexical search methods are insufficient for finding such information. Semantic Search and Summarization enables contextually-relevant information extraction and summarization from large volumes of unstructured investigative reports. The output will enhance and optimize investigative analysis by accelerating person-of-interest identification, surfacing trends, and improving network or fraud detection.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating crimes that threaten national security, public safety, and the economy. HSI’s mission is to protect the United States from transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. HSI relies on advanced technologies to analyze and process vast amounts of data, including audio and video evidence. Effective investigations depend on the ability to extract relevant information quickly and accurately from large volumes of unstructured reports. Traditional lexical search methods often fall short in this regard. Semantic Search and Summarization technology bridges this gap by leveraging large language models (LLM) to allow investigators to submit natural language queries.  These queries are analyzed to identify the most relevant information in reports, accelerating investigative analysis by rapidly identifying persons of interest, surfacing trends, and detecting networks or fraud. Furthermore, the system allows investigators to build reports by entering raw notes and leveraging LLM to generate a draft report that adheres to the Report of Investigation (ROI) manual's formatting and style guidelines. This saves time and produces more articulate and accurate reports. Once reviewed, validated, and approved by supervisors, the final report is uploaded to a case management system. HSI uses this tool to generate leads, with further action required by investigators and analysts as part of the full investigative process before any action is taken against an individual."
DHS-2402,SEVP Response Center Chatbot - SID (SEVIS Interactive Dialog),DHS,ICE,"AI provides SID the ability to understand voices and its deterministic question and answer workflow (1) enables SID to answer routine caller questions without a help desk agent, and (2) when a help desk agent is required, SID will create a ticket with a caller transcript to reduce the burden on the agent. This frees up the human agents to deal with more complex cases and issues with specific records.","AI provides SID the ability to understand voices and its deterministic question and answer workflow (1) enables SID to answer routine caller questions without a help desk agent, and (2) when a help desk agent is required, SID will create a ticket with a caller transcript to reduce the burden on the agent. This frees up the human agents to deal with more complex cases and issues with specific records.

The Student and Exchange Visitor Program (SEVP) has a response center that answers questions about policy, procedures, and issues with Student and Exchange Visitor Information System (SEVIS). To provide faster answers, SEVP uses a chatbot named SEVIS Interactive Dialog (SID) to handle common questions from students and officials. If SID cannot help, it connects the caller to a human agent and shares the conversation to save time. Callers include visa holders (F, M, and J nonimmigrants), school and program officials, government users, and members of the public. Many questions are routine inquiries about established policies and procedures. SID is a conversational chatbot that uses voice recognition and Natural Language Understanding to understand and reply to users’ questions with scripted answers. SID is deterministic and does not use generative AI. It answers frequently asked questions but SEVP will not be programmed SID to answer safety- and/or rights-impacting questions. If SID cannot answer a question, it transfers the caller to an agent in the response center. The chatbot captures the interaction with the caller and sends the information via an API to Student and Exchange Visitor Program Automated Management System (SEVPAMS). SEVPAMS creates a tickets, either for calls completed by SID or those handed over to an agent. This allows agents to see the dialog between SID and the caller, reducing the need to repeat information. This frees up the human agents to handle  more complex cases and specific record issues."
DHS-206,Title III Semantic Search and Summarization for Translated Content,DHS,ICE,"The Title III Semantic Search and Summarization functionality will augment translation and transcription services by extracting relevant data using machine learning and natural language processing for correlation and semantic search. Results can then be summarized using a large language model, giving users a tool to target relevant data only. This capability accelerates investigative analysis by rapidly identifying persons of interest, surfacing trends, and detecting networks or fraud, saving hundreds of man hours in manual analysis. HSI will use this tool to generate leads, and further action will be required by investigators and analysts as part of the full investigative process before any action is taken against an individual.","The Title III Semantic Search and Summarization functionality will augment translation and transcription services by extracting relevant data using machine learning and natural language processing for correlation and semantic search. Results can then be summarized using a large language model, giving users a tool to target relevant data only. This capability accelerates investigative analysis by rapidly identifying persons of interest, surfacing trends, and detecting networks or fraud, saving hundreds of man hours in manual analysis. HSI will use this tool to generate leads, and further action will be required by investigators and analysts as part of the full investigative process before any action is taken against an individual.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating a wide range of crimes that threaten national security, public safety, and the economy. With a mission to protect the United States from transnational crime and terrorism, HSI works to disrupt and dismantle complex organizations that engage in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. During an investigation, HSI collects large volumes of legally obtained evidentiary data, often in languages other than English. Once this data has been translated using translation and transcription services, agents and analysts need a better way to search through the vast amounts of data. The Title III Semantic Search and Summarization functionality will augment translation and transcription services by extracting relevant data using machine learning (ML) and Natural Language Processing (NLP) for correlation and semantic search. Results can then be summarized using a Large Language Model (LLM), giving users a tool to target relevant data only. This capability accelerates investigative analysis by rapidly identifying persons of interest, surfacing trends, and detecting networks or fraud, saving hundreds of hours in manual analysis. HSI will use this tool to generate leads, and further action will be required by investigators and analysts as part of the full investigative process before any action is taken against an individual. "
DHS-2427,Translation and Transcription for Investigative Data,DHS,ICE,"HSI investigators often encounter data from various sources, including legal and administrative processes, enforcement actions, and open-source materials, in languages other than English. To unlock the value of this data, it must be translated into English before further analysis can be conducted. The Translation and Transcription Service leverages neural machine translation (NMT) models for text translation and automatic speech recognition (ASR) and deep neural network (DNN) models with normalization for voice-to-text transcription. This innovative approach enables users to quickly triage large datasets and identify key information relevant to investigations. Any data deemed critical for court proceedings is then submitted to certified human translators for final review, ensuring that government resources are allocated efficiently and only used for necessary translations and transcriptions.
","HSI investigators often encounter data from various sources, including legal and administrative processes, enforcement actions, and open-source materials, in languages other than English. To unlock the value of this data, it must be translated into English before further analysis can be conducted. The Translation and Transcription Service leverages neural machine translation (NMT) models for text translation and automatic speech recognition (ASR) and deep neural network (DNN) models with normalization for voice-to-text transcription. This innovative approach enables users to quickly triage large datasets and identify key information relevant to investigations. Any data deemed critical for court proceedings is then submitted to certified human translators for final review, ensuring that government resources are allocated efficiently and only used for necessary translations and transcriptions.


Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating a wide range of crimes that threaten national security, public safety, and the economy. With a mission to protect the United States from transnational crime and terrorism, HSI works to disrupt and dismantle complex organizations that engage in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. To achieve this mission, HSI relies on advanced technologies and innovative solutions to analyze and process vast amounts of data, including audio and video evidence. HSI investigators often encounter data from various sources, including legal and administrative processes, enforcement actions, and open-source materials, in languages other than English. To unlock the value of this data, it must be translated into English before further analysis can be conducted. The Translation and Transcription Service leverages neural machine translation (NMT) models for text translation and automatic speech recognition (ASR) and deep neural network (DNN) models with normalization for voice-to-text transcription. This innovative approach enables users to quickly triage large datasets and identify key information relevant to investigations. Any data deemed critical for court proceedings is then submitted to certified human translators for final review, ensuring that government resources are allocated efficiently and only used for necessary translations and transcriptions. HSI uses this tool to generate leads, and further action is required by investigators and analysts as part of the full investigative process before any action is taken against an individual. "
DHS-172,Video Analysis Tool (VAT),DHS,ICE,"The Video Analysis Tool (VAT) is used to investigate human rights violations, fraud detection and countering transnational organized crime involved in synthetic opioids. Machine learning algorithms to identify a human face and crop the image from media. VAT leverages model-based matching and developed algorithms indifferent to subject pose, illumination, and expression. The output is a collection of relevant facial images of perpetrators to create a database of suspects. Then images are used to query and compare with relevant Federal biometric and biographical databases through connections to VAT, or share these images with other agency partners, where the images are compared against those partners’ holdings using facial matching methodologies.","The Video Analysis Tool (VAT) is used to investigate human rights violations, fraud detection and countering transnational organized crime involved in synthetic opioids. Machine learning algorithms to identify a human face and crop the image from media. VAT leverages model-based matching and developed algorithms indifferent to subject pose, illumination, and expression. The output is a collection of relevant facial images of perpetrators to create a database of suspects. Then images are used to query and compare with relevant Federal biometric and biographical databases through connections to VAT, or share these images with other agency partners, where the images are compared against those partners’ holdings using facial matching methodologies.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating crimes that threaten national security, public safety, and the economy. HSI’s mission is to protect the United States from transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. HSI relies on advanced technologies to analyze and process vast amounts of data, including audio and video evidence. The Video Analysis Tool (VAT) is used to investigate human rights violations, detect fraud, and counter transnational organized crime involved in synthetic opioids. Machine learning (ML) algorithms identify human faces and crop the image from media. VAT leverages model-based matching and developed algorithms that are indifferent to subject pose, illumination, and expression. The output is a collection of relevant facial images of perpetrators, which are used to create a database of suspects. These images are then used to query and compare with relevant Federal biometric and biographical databases through connections to VAT, or shared with other agency partners, where the images are compared against those partners’ holdings using facial matching methodologies. HSI uses this tool to generate leads, with further action taken by investigators and analysts as part of the full investigative process before any action is taken against an individual. "
DHS-2307,Virtual Agent Chatbot for Human Capital,DHS,ICE,"The intended purpose of the ServiceNow Virtual Agent natural language understanding (NLU) is to facilitate seamless interactions between users and the chatbot. It aims to provide automated support for common Human Capital related questions and inquiries, enhancing efficiency and user experience.  By understanding natural language, the virtual agent can provide relevant and accurate responses, making it easier for users to get the help they need.  Reduce the amount of submitted inquiries that need to be manually processed by OHC. Reduce the amounts of clicks it takes for the user to find the information they are looking for.","The intended purpose of the ServiceNow Virtual Agent natural language understanding (NLU) is to facilitate seamless interactions between users and the chatbot. It aims to provide automated support for common Human Capital related questions and inquiries, enhancing efficiency and user experience.  By understanding natural language, the virtual agent can provide relevant and accurate responses, making it easier for users to get the help they need.  Reduce the amount of submitted inquiries that need to be manually processed by OHC. Reduce the amounts of clicks it takes for the user to find the information they are looking for.

ICE’s Human Capital Virtual Agent “Alice” is a chatbot available to all ICE employees focused on delivering answers and resources for Human Capital related inquiries through conversation. The chatbot will be enhanced through the implementation of Natural Language Understanding (NLU) within ServiceNow, a type of AI focused on understanding and processing human language to enable effective interactions between the chatbot and users. Understanding natural language will enhance user experience by providing a way for the chatbot to comprehend what the employee is asking for and provide relevant and accurate responses, making it easier for users to get the help they need. By providing ICE employees information fast and efficiently at any time through Virtual Agent NLU, the chatbot aims to reduce the amount of time spent by Human Capital Specialists responding to the inquiries. "
DHS-123,Voice Analytics for Investigative Data,DHS,ICE,"While conducting investigations, Homeland Security Investigations (HSI) encounters a significant volume of live and recorded content, requiring human language to be extracted and analyzed. Currently, this is achieved through manual processes that are extremely labor-intensive and expensive. To address this challenge, HSI has developed Voice Analytics, a cutting-edge technology that leverages machine learning and advanced speech processing techniques to perform multilingual speech transcription and translation on user-supplied audio files. This innovative solution enables HSI personnel to quickly identify new investigative leads and analyze the outputs against other law enforcement datasets, significantly improving the efficiency and effectiveness of their investigations compared to manual voice analytics processes.","While conducting investigations, Homeland Security Investigations (HSI) encounters a significant volume of live and recorded content, requiring human language to be extracted and analyzed. Currently, this is achieved through manual processes that are extremely labor-intensive and expensive. To address this challenge, HSI has developed Voice Analytics, a cutting-edge technology that leverages machine learning and advanced speech processing techniques to perform multilingual speech transcription and translation on user-supplied audio files. This innovative solution enables HSI personnel to quickly identify new investigative leads and analyze the outputs against other law enforcement datasets, significantly improving the efficiency and effectiveness of their investigations compared to manual voice analytics processes.

Homeland Security Investigations (HSI) is a critical component of ICE, responsible for investigating crimes that threaten national security, public safety, and the economy. HSI’s mission is to protect the United States from transnational crime and terrorism by disrupting organizations involved in human trafficking, narcotics smuggling, cybercrime, and other illicit activities. During investigations, HSI encounters significant volumes of live and recorded content that require language extraction and analysis. Currently, this is done manually, which is labor-intensive and costly. To address this challenge, HSI has developed Voice Analytics, a cutting-edge technology that uses machine learning (ML) and advanced speech processing techniques for multilingual speech transcription and translation of audio files. This system outputs transcribed and translated audio files, enabling HSI personnel to quickly identify new investigative leads and analyze the outputs against other law enforcement datasets, significantly improving the efficiency and effectiveness of their investigations compared to manual processes. HSI uses this tool to generate leads, with further actions taken by investigators and analysts as part of the full investigative process before any action is taken against an individual. "
DHS-419,AdaptiveMFA,DHS,MGMT,"Adaptive Multi-factor Authentication (AMFA) introduces additional intelligence into Identity flows by taking into account the authentication context data during the authentication. Using the data, DHS is able to adapt security and authentication policies to enhance the security to DHS systems.","Adaptive Multi-factor Authentication (AMFA) introduces additional intelligence into Identity flows by taking into account the authentication context data during the authentication. Using the data, DHS is able to adapt security and authentication policies to enhance the security to DHS systems.

Adaptive Multi-Factor Authentication (AMFA) will collect DHS user behavior data to better understand how users’ access DHSAuthPortal applications. By considering the authentication context data during the authentication process, AMFA introduces additional intelligence into identity flows. Using this data, DHS can detect anomalies and adapt security and authentication policies to enhance the security to DHS systems. The data will be visible to the Department's centralized Security Information and Event Management (SIEM), which can be used for larger correlation with other identity systems.  

The outputs are risk ratings HIGH, MEDIUM, and LOW for each authentication attempt, which can be configured to require stricter access control policies. "
DHS-2343,CFO Companion,DHS,MGMT,"Provides authorized staff with an intuitive, conversational interface to query and analyze DHS CFO financial data and reports.
Benefits: Democratizes access to financial information, reduces time spent searching through documents, and enables quick self-service analytics without specialized database knowledge.","Provides authorized staff with an intuitive, conversational interface to query and analyze DHS CFO financial data and reports.
Benefits: Democratizes access to financial information, reduces time spent searching through documents, and enables quick self-service analytics without specialized database knowledge.

This project develops an internal chatbot that assists authorized DHS personnel in accessing and understanding DHS Chief Financial Officer (CFO) data. The chatbot uses advanced natural language processing (NLP) to interpret and respond to user queries related to DHS financial matters. Its knowledge base is built upon the DHS CFO publicly available data set, including financial reports, budgets, and expenditures. Authorized users interact with the chatbot through a secure interface, asking questions about DHS financial operations. The chatbot analyzes the user's input, identifies key financial terms, retrieves relevant information from the DHS CFO data set, and generates human-like responses using NLP. This specialized internal chatbot provides authorized personnel with an intuitive, conversational interface to query and analyze DHS CFO financial data and reports. It democratizes access to financial information, reduces the time spent searching through documents, and enables quick self-service analytics without requiring specialized database knowledge. "
DHS-2406,Climate Change Assessment Tool,DHS,MGMT,"Our Nationis already experiencing the adverse impacts from climate change, from sea-level rise, extreme heat, flooding, and drought, to changes in migration patterns and harmful effects on workforce health. DHS needs to be able to better understand and predict where extreme weather conditions will affect DHS assets, including our facilities and our workforce, in the near and long-term. In support of the DHS Climate Action Plan, this AI pilot will enable the detection and streamliinng the assessment of cost/benefit data driven decisions like the location of facilities, prioritization of O&M projects and the health and safety of the DHS workforce. 

Benefits include cost savings, time savings and improved access to critical data and ability to make decisions, improved health and safety of the workforce.","Our Nationis already experiencing the adverse impacts from climate change, from sea-level rise, extreme heat, flooding, and drought, to changes in migration patterns and harmful effects on workforce health. DHS needs to be able to better understand and predict where extreme weather conditions will affect DHS assets, including our facilities and our workforce, in the near and long-term. In support of the DHS Climate Action Plan, this AI pilot will enable the detection and streamliinng the assessment of cost/benefit data driven decisions like the location of facilities, prioritization of O&M projects and the health and safety of the DHS workforce. 

Benefits include cost savings, time savings and improved access to critical data and ability to make decisions, improved health and safety of the workforce.

The Climate Change Assessment Tool is a protype that explores how AI can be used to inform decisions in the Real Properties and Sustainability and Environmental Protection functional areas. For Phase 1 of this climate prototype, traditional machine learning (ML) will be leveraged to do anomaly detection. Multiple ML algorithms will be explored and evaluated. The prototype will use AI to detect anomalies in climate projections, weather data, and extreme weather event damage costs, identifying patterns and considerations for facility managers from a resiliency perspective. The outputs of the model will be numerical values corresponding to an anomaly score, visualized in a dashboard along with geolocation data. These outputs will be refined through user engagement with POCs from the Real Properties group. A key benefit of using AI/ML for this project is AI’s ability to process vast amounts of data for pattern detection in climate change exposure assessment and sustainability planning, taking advantage of data processing and model scalability/latency. In support of the DHS Climate Action Plan, this AI pilot will enable the detection and streamlining the assessment of cost/benefit data driven decisions like the location of facilities, prioritization of projects and the health and safety of the DHS workforce. "
DHS-2433,DHS-Chat,DHS,MGMT,"This is a chatbot based on a Large Language Models (LLM) for internal DHS employee use - It's like chat-GPT for DHS but approved for use with non-classified but internal information (this includes FOUO (For Official Use Only) CUI (Controlled Unclassified Information) due to its improved security compared to publicly available chatbots. 

This tool is able to dynamically create written content through text prompts submitted by the user. Approved applications of this tool to DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information and internal documents, and developing briefing materials or preparing for meetings and events.","This is a chatbot based on a Large Language Models (LLM) for internal DHS employee use - It's like chat-GPT for DHS but approved for use with non-classified but internal information (this includes FOUO (For Official Use Only) CUI (Controlled Unclassified Information) due to its improved security compared to publicly available chatbots. 

This tool is able to dynamically create written content through text prompts submitted by the user. Approved applications of this tool to DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information and internal documents, and developing briefing materials or preparing for meetings and events.

This is a chatbot based on a Large Language Model (LLM) for internal DHS employee use with non-classified but internal information, including For Official Use Only (FOUO) and Controlled Unclassified Information (CUI), due to its improved security compared to publicly available chatbots. DHS employees are permitted to use an internally available generative AI for text generation in day-to-day work leveraging internal documents. This tool can dynamically create written content through text prompts submitted by the user. It uses Natural Language Processing (NLP) and Large Language Models (LLMs) to produce natural sounding language in a wide variety of contexts and styles. Approved applications of this tool to DHS business include generating first drafts of documents that a human would subsequently review, conducting and synthesizing research on open-source information and internal documents, and developing briefing materials or preparing for meetings and events. "
DHS-2342,JES and Appropriations Insight,DHS,MGMT,"Purpose: Converts scanned financial tables from PDFs into structured, machine-readable data while maintaining multi-year spending relationships.
Benefits: Eliminates manual data entry, reduces errors, and significantly speeds up the process of consolidating historical financial data from legacy documents.","Purpose: Converts scanned financial tables from PDFs into structured, machine-readable data while maintaining multi-year spending relationships.
Benefits: Eliminates manual data entry, reduces errors, and significantly speeds up the process of consolidating historical financial data from legacy documents.

This system for internal financial efficiency converts scanned financial tables from PDFs into structured, machine-readable data while maintaining multi-year spending relationships. It processes scanned PDF documents containing financial tables to extract and reconstruct funding tables. The system employs computer vision techniques to identify and extract relevant tabular data from the scanned images. Natural Language Processing (NLP) and Large Language Models (LLMs) are then utilized to analyze the extracted text and numerical data, identifying, and linking related multi-year spending amounts across different tables and sections of the document. The output includes a comprehensive, structured funding table that consolidates the multi-year spending information, enabling users to quickly access and analyze the financial data spanning multiple years. This automated approach streamlines the process of gathering and organizing financial information from scanned PDF documents, reducing manual effort, and improving the efficiency of financial analysis tasks. "
DHS-159,Sentiment Analysis and Topic Modeling (SenTop),DHS,MGMT,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The initial purpose of the Sentiment Analysis and Topic Modeling (SenTop) project was to analyze survey responses for DHS’s Office of the Chief Procurement Officer related to contracting. However, it has evolved to be a general-purpose text analytics solution that can be applied to any domain or area. It has also been tested and used for HR topics. SenTop is a DHS-developed Python package for performing descriptive text analytics, specifically, sentiment analysis and topic modeling on free-form, unstructured text. SenTop uses several methods for analyzing text, including combining sentiment analyses and topic modeling into a single capability, permitting identification of sentiments per topic and topics per sentiment. Other innovations include the use of polarity and emotion detection, fully automated topic modeling, and multi-model/multi-configuration analyses for automatic model/configuration selection. The code has been established, performs an analysis, and provides a report, but it is only accessed and run by one person per customer request. "
DHS-418,Spending Analysis and Budget Execution Risk (SABER) Model,DHS,MGMT,"Purpose: Predicts potential budget execution issues by analyzing historical spending patterns across various Treasury accounts and classifications.
Benefits: Early identification of spending anomalies allows proactive budget management and reduces the risk of under/overspending.","Purpose: Predicts potential budget execution issues by analyzing historical spending patterns across various Treasury accounts and classifications.
Benefits: Early identification of spending anomalies allows proactive budget management and reduces the risk of under/overspending.

This model analyzes historic Treasury Information Executive Repository (TIER) data reported under the DATA Act to identify past spending trends for Treasury Account Symbols (TAS), object classes, Programs, Projects, Activities (PPA), and Disaster Emergency Fund Codes (DEFC).  It predicts accounts at risk of being severely under-spent or overspent. The outputs include the degree to which current spending patterns match prior trends for all accounts, the likelihood that spending will not reach budgeted amounts, and accounts at risk of reaching budgetary ceilings too quickly."
DHS-45,Text Analytics for Survey Responses (TASR),DHS,MGMT,"The intended purpose of the AI is to perform topic modeling,  sentiment analysis, or other text classification tasks on responses provided to internal staff DHS Pulse Survey questions.

Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS Office of the Chief Human Capital Officer (OCHCO) to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees’ basic needs and improve job satisfaction","The intended purpose of the AI is to perform topic modeling,  sentiment analysis, or other text classification tasks on responses provided to internal staff DHS Pulse Survey questions.

Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS Office of the Chief Human Capital Officer (OCHCO) to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees’ basic needs and improve job satisfaction

Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on internal staff survey responses. It is currently being applied by DHS Office of the Chief Human Capital Officer (OCHCO) to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees’ basic needs and improve job satisfaction. "
DHS-2434,User and Entity Behavior Analytics (UEBA),DHS,MGMT,"Enhanced Threat Detection: Identify patterns in user behaviors that deviate from normal baselines, signaling potential insider threats or security risks. Continuous Risk Assessment: Move from static vetting to a continuous vetting process by monitoring real-time activities and interactions with secure information.
Improved Incident Response: Enable rapid responses to high-risk behaviors, escalating alerts for timely intervention by security personnel.""
","Enhanced Threat Detection: Identify patterns in user behaviors that deviate from normal baselines, signaling potential insider threats or security risks. Continuous Risk Assessment: Move from static vetting to a continuous vetting process by monitoring real-time activities and interactions with secure information.
Improved Incident Response: Enable rapid responses to high-risk behaviors, escalating alerts for timely intervention by security personnel.""


As part of the personnel security vetting process for continuous vetting-eligible employees, employees provide information and authorize access to information about themselves, including criminal history, credit reports, and other information. This information is collected and collated on an ongoing basis. UEAB presents aggregated information in a structured manner to help prioritize staffing.  Additionally, pursuant to and as authorized by Executive Order 13467, “Reforming Processes Related to Suitability for Government Employment, Fitness for Contractor Employees, and Eligibility for Access to Classified National Security Information,” employees must be enrolled in a continuous vetting program.   

UEBA enhances the efficiency, accuracy, and effectiveness of personnel security processes by aggregating information provided by or authorized to be collected by an employee about the employee.   

The AI output is the collated information is a risk matrix for human review. The AI output uses a hard coded scoring system to provide alerts for collated information that presents greater risk in the vetting process.  Staff reviews the risk matrix and uses the collated information in the matrix as background information for the personnel security vetting process. The collated information supports decisions about staffing priorities. "
DHS-2453,ESEC Inquiry (STORM) Summarization,DHS,MGMT,"ESEC-STORM AI employs Generative Artificial Intelligence (Gen-AI) technology to automate the creation of document summaries. This advanced system facilitates the automatic integration of these summaries into the System of Tracking, Operations, and Record Management (STORM), thereby optimizing the management of correspondence and information requests. ","ESEC-STORM AI employs Generative Artificial Intelligence (Gen-AI) technology to automate the creation of document summaries. This advanced system facilitates the automatic integration of these summaries into the System of Tracking, Operations, and Record Management (STORM), thereby optimizing the management of correspondence and information requests. 

The Executive Secretariat (ESEC) receives a substantial number of inquiries from members of Congress and the Senate seeking information on various subjects. To enhance efficiency and streamline the process, ESEC-STORM AI employs Generative Artificial Intelligence (Gen-AI) technology to automate the creation of document summaries. This advanced system facilitates the automatic integration of these summaries into the System of Tracking, Operations, and Record Management (STORM), thereby optimizing the management of correspondence and information requests. Upon receipt of correspondence, the Executive Secretariat (ESEC) initiates a work-package within the STORM - a sophisticated Microsoft Dynamics CRM system integrated with SharePoint for document storage. Each file uploaded to STORM is consequently stored in SharePoint, adhering to the organizational structure of the relevant work-package. When a user creates a new work package and uploads a letter, it activates a Power Apps workflow that creates a summary. The workflow is designed to process the incoming letter efficiently and accurately. "
DHS-2419,MiX Indicators,DHS,OHS,"Online news and other open-source media can be used to quickly detect and respond to emerging health security threats. However, it is not practical for people to read and scan all online news stories every day for key terms. AI/ML makes it possible to read, digest and organize news stories to look for key threat terms. AI/ML will also be used to predict normal trends in news stories. This makes it possible to detect when an unusual number of health security threat terms are found in the news. This use of AI/ML helps prepare for, respond to, and protect from potential health security threats.","Online news and other open-source media can be used to quickly detect and respond to emerging health security threats. However, it is not practical for people to read and scan all online news stories every day for key terms. AI/ML makes it possible to read, digest and organize news stories to look for key threat terms. AI/ML will also be used to predict normal trends in news stories. This makes it possible to detect when an unusual number of health security threat terms are found in the news. This use of AI/ML helps prepare for, respond to, and protect from potential health security threats.

The goal for this proof-of-concept project is to quickly detect unusual trends in online news stories related to health security threats. Open-source media are pulled from the internet, and key search terms such as pathogen or chemical names are identified and tallied across articles. AI/ML makes it possible to read, organize, and predict normal trends in news stories, making it possible to quickly detect any unusual trends (anomalies). This capability helps us to better prepare for, respond to, and protect from health security threats. 

The main AI system output will be anomaly detection, which represents two elements: 1) AI/ML predictions for usual trends in news story key terms, and 2) the actual daily number of mentions for key terms in the news. When the actual number of mentions for key terms exceeds the modeled predictions, these instances will be detected as anomalies. "
DHS-2420,MiX MedINT (Medical Intelligence Dashboard and Canvas),DHS,OHS,"Health security visuals will be created using a broad variety of data pulled from online sources. AI/ML will make it possible to translate this information into machine-readable data. AI/ML will also find relevant terms in these online articles, such as for locations and diseases of interest, label articles accordingly, and rank articles for relevance to topics of interest. These necessary steps cannot practically be performed by people. AI/ML will then support MedINT Canvas to  visualize connections between topics of interest, such as the presence of key symptoms and disease diagnoses in certain locations. Given the wide variety of potential health security threats, wholistic visual tools are needed to allow analysts to broadly monitor the health security landscape.","Health security visuals will be created using a broad variety of data pulled from online sources. AI/ML will make it possible to translate this information into machine-readable data. AI/ML will also find relevant terms in these online articles, such as for locations and diseases of interest, label articles accordingly, and rank articles for relevance to topics of interest. These necessary steps cannot practically be performed by people. AI/ML will then support MedINT Canvas to  visualize connections between topics of interest, such as the presence of key symptoms and disease diagnoses in certain locations. Given the wide variety of potential health security threats, wholistic visual tools are needed to allow analysts to broadly monitor the health security landscape.

The goal for this proof-of-concept project is to create wholistic visuals of a wide variety of health security data. These data will be pulled from online open sources to broadly include, for example, news on societal conflicts, scientific literature, and reports on weather and aggregated (not individual level) information on disease for humans and wildlife. Visuals will be created using two different approaches. One approach (MedINT Dashboard) is to view global mapping of the health security events, where each event is tagged on the map to its reported location. The map can be modified to view different health security layers and zoomed in/out to locations of interest. The second approach (MedINT Canvas) is to build a data visualization of interest by selecting topics, such as a disease, symptom, and location, and then observing if and how these topics connect through recent health security events. AI/ML will make this project possible by streamlining the pull of openly available online data into a machine-readable dataset. AI/ML will also support the MedINT Canvas visuals by finding relevant terms in online articles, labeling articles accordingly, and ranking them for relevance to topics of interest. These necessary steps cannot practically be performed by people. Allowing analysts to wholistically visualize health security data will enable identification of potential threats that should be further investigated. 

The main AI system output will be the translation of online information into a structured, machine-readable dataset. This includes language translation for non-English articles, labeling articles by health threat types, and ranking articles by relevance to health threats. This dataset will then be used to create the wholistic visuals in Canvas and Dashboard. 

MedINT will use only open-source and aggregated level data without personal identifiers.  It will not use individual medical data. "
DHS-2418,MiX Phenotyping,DHS,OHS,"Electronic medical records can provide key data for health security insights. AI/ML makes it possible to translate these records into machine-readable data, which is the first step to finding these health security insights. AI/ML will then be used to find clinical patterns across the data, such as patterns in symptoms over time and location. AI/ML will also be used to automate the process for detecting new trends (anomalies) in these clinical patterns. These health security insights can alert about potential threats, inform messaging, and provide decision support to medical and public health partners.","Electronic medical records can provide key data for health security insights. AI/ML makes it possible to translate these records into machine-readable data, which is the first step to finding these health security insights. AI/ML will then be used to find clinical patterns across the data, such as patterns in symptoms over time and location. AI/ML will also be used to automate the process for detecting new trends (anomalies) in these clinical patterns. These health security insights can alert about potential threats, inform messaging, and provide decision support to medical and public health partners.

The goal for this proof-of-concept project is to automate creation of health security insights from DHS electronic medical record data. Clinical notes taken during clinical medical provision will be parsed into key terms and phrases, organized into machine-readable data, and integrated with other data such as geographic location of relevant DHS facilities. AI/ML is used to automate this data processing and quickly identify new DHS clinical patterns. These patterns can provide key health security insights, such as emerging disease detection (anomaly detection), and provide decision support to medical and public health community partners. 

The main AI system outputs will include anomaly detection for emerging trends in clinical record patterns. AI/ML outputs will identify these clinical patterns by clustering, classification, and topic modeling. Finally, these clinical patterns will be presented as linear reference models that are simple enough to be interpreted and guided by human clinicians using human-in-the-loop collaboration. 

Phenotyping will use only de-identified medical data that is publicly available or such de-identified data in DHS care and custody whose use is authorized under a specific Information Exchange Agreement.  "
DHS-2421,One Health Threat Detection and Risk Assessment Platform (OH-TREADS) / Planner,DHS,OHS,"Visuals will be created using a broad variety of data pulled from open-source, public, and non-public sources. AI/ML will make it possible to ingest data from a variety of digital formats, and translate it to usuable information into machine-readable data. The volume of data, and lack of clear data collection standards, requires AI to help merge streams with different data ontologies while facilitating data interoperability with mis-paired data sets. Neither activity is, or can be, practically performed by people. AI/ML will be further used in Planner to generate risk and predictive scores in addtion to displaying relevant information and analyses that help analysts understand health security threats and broadly monitor the health security landscape. AI/ML is meant to provide comprehensive situational awareness for health surveillance and public health response, with target capabilities that: enable global situational awareness of current and potential health risks from a One Health perspective; assist in early warning of health threats by location, facility, and species; aid in rapid identification of health threats at population, facility, and greater geographic resolution; and support data-driven decision making to prevent, mitigate, and respond to health threats.","Visuals will be created using a broad variety of data pulled from open-source, public, and non-public sources. AI/ML will make it possible to ingest data from a variety of digital formats, and translate it to usuable information into machine-readable data. The volume of data, and lack of clear data collection standards, requires AI to help merge streams with different data ontologies while facilitating data interoperability with mis-paired data sets. Neither activity is, or can be, practically performed by people. AI/ML will be further used in Planner to generate risk and predictive scores in addtion to displaying relevant information and analyses that help analysts understand health security threats and broadly monitor the health security landscape. AI/ML is meant to provide comprehensive situational awareness for health surveillance and public health response, with target capabilities that: enable global situational awareness of current and potential health risks from a One Health perspective; assist in early warning of health threats by location, facility, and species; aid in rapid identification of health threats at population, facility, and greater geographic resolution; and support data-driven decision making to prevent, mitigate, and respond to health threats.

The goal for this proof-of-concept project is to create wholistic visuals for health surveillance from relevant data and information sourced (open and non-public) from  International, Federal, State, Local, Tribal, and Territorial (IFSLTT) partners and stakeholders in interdependent sectors, including but not limited to the Food & Agriculture and Healthcare & Public Health sectors. By combining human, animal, plant, and environmental data, with critical infrastructure data, we aim to generate an integrated One Health data landscape that can aid decision making, early warning, and enhanced situational awareness. This would improve detection, prevention, and mitigation of emerging threats to health, food, and agriculture  (such as Chemical, Biological, Radiological, and Nuclear (CBRN), climate, pests/vectors, invasive species, etc.) whether natural, intentional, or accidental, and promote health security, preparedness, and resilience across domains, disciplines, sectors, and stakeholders. OHTREADs will use a similar approach to Medical Intelligence (MedINT), employing a dashboard to present a telescoping global-to-local map that will highlight health incidents, cases, or other epidemiological relevant data that can be linked via geospatial or temporal factors. Upon clicking the map, the user will be able to achieve state or county level data visualization, or other relevant user-filtered information for active incidents involving pathogens/agents of interest, including risk and predictive transmission values. AI/ML makes this project possible by streamlining the pull of accessible data into machine-readable datasets from veterinary syndromic, clinical, diagnostic, or other surveillance data sets. AI/ML will also create the OH-TREADs/Planner visuals and allow for analytical interpretation. 

The volume of data, and lack of clear data collection standards, requires AI/ML to help merge streams with different data ontologies while facilitating data interoperability with mis-paired data sets. AI/ML will also be used to generate risk and predictive scores, displaying relevant information and analyses that help analysts understand health security threats and broadly monitor the health security landscape. This comprehensive situational awareness will support data-driven decision making to prevent, mitigate, and respond to health threats. 

The main AI system outputs will be anomaly detection following the translation of information into a structured, machine-readable datasets. AI/ML is then used for risk identification and disease prediction, which are overlayed on a map and displayed with other wholistic visuals. These visuals and analytics can be combined with critical infrastructure locations, resources, or capabilities (federal, state, local, tribal, and territorial) to aid response and decision making. 

OH-THREADS will use a combination of open source and public health data sets as well as animal health records.  It will not use individual medical data. "
DHS-132,Accessible Property Screening (APS) Checkpoint CT Prohibited Items (PI) Detection,DHS,TSA,"This AI helps airplane luggage checks by the TSA officers scanning bags to have a continuous always watching partner to alert them to anything suspicious. 

Currently, a Transportation Security Officer (TSO) who is assigned to every X-ray equipment at an airport checkpoint visually inspects each image. This officer resolves the system generated explosive alarms as well as visually inspecting the image for the presence of non-explosive prohibited items such as guns and sharp objects (see TSA Travel site).
TSA is working on developing new Artificial Intelligence/Machine Learning (AI/ML) algorithms to automate the search for the non-explosive prohibited items (e.g. guns, knives, etc.).  Once a threat is found, the algorithm displays bounding boxes around the suspect item for the operator to then investigate and adjudicate.  
These AI solutions benefit the public by providing a consistent and uninterrupted level of threat detection as an added layer of security. The ML algorithms allow the TSA officers to be more flexible and to better prioritize their attention on important items to improve security.","This AI helps airplane luggage checks by the TSA officers scanning bags to have a continuous always watching partner to alert them to anything suspicious. 

Currently, a Transportation Security Officer (TSO) who is assigned to every X-ray equipment at an airport checkpoint visually inspects each image. This officer resolves the system generated explosive alarms as well as visually inspecting the image for the presence of non-explosive prohibited items such as guns and sharp objects (see TSA Travel site).
TSA is working on developing new Artificial Intelligence/Machine Learning (AI/ML) algorithms to automate the search for the non-explosive prohibited items (e.g. guns, knives, etc.).  Once a threat is found, the algorithm displays bounding boxes around the suspect item for the operator to then investigate and adjudicate.  
These AI solutions benefit the public by providing a consistent and uninterrupted level of threat detection as an added layer of security. The ML algorithms allow the TSA officers to be more flexible and to better prioritize their attention on important items to improve security.

This AI helps airplane luggage checks by the TSA officers scanning bags to have a continuous always watching partner to alert them to anything suspicious. Accessible Property Screening (APS) uses AI to identify both non-explosive threats and prohibited items in carry-on baggage as the bags pass through the Computed Tomography (CT) scanners at airports. The AI algorithms are trained to identify likely non-explosive threat and prohibited items through image segmentation and object recognition.  

Currently, Transportation Security Officers (TSOs) assigned to scanners at airport checkpoints visually inspect each image.  The TSOs resolve the system generated explosive alarms as well as visually inspect the image for the presence of non-explosive prohibited items such as guns and sharp objects. TSA is working on developing new AI and Machine Learning ML algorithms to automate the search for the non-explosive prohibited items (e.g. guns, knives, etc.). These AI solutions benefit the public by providing a consistent and uninterrupted level of threat detection as an added layer of security. The ML algorithms allow the TSOs to be more flexible and to better prioritize their attention on important items to improve security. 

AI system output is a set of 3-dimentional bounding boxes that is displayed on the X-ray image. The bounding boxes are placed on top of objects or areas where the algorithm believes it has found a prohibited item (threat object)."
DHS-2432,Airport Throughput Predictive Model,DHS,TSA,This project was to create a predictive model for the passenger volume using the Security Operations throughput count from checkpoints to help with airport staffing.,"This project was to create a predictive model for the passenger volume using the Security Operations throughput count from checkpoints to help with airport staffing.

This use case is a predictive model for passenger volume to help with airport staffing.  The Airport Throughput Predictive Model is an A) model which ingests checkpoint screening throughput data to train the predictive model, to provide projections for future-date throughput. Once a month the data is ingested, the predictive model is trained, and predictions of airport checkpoint throughput are made for the airports. 

The projections produced by the model are incorporated into Business Intelligence dashboards for airport coordination centers to access. This model was designed to inform future operational planning, such as staffing needs projections, for all Transportation Security Administration (TSA) security checkpoints. "
DHS-2400,Answer Engine,DHS,TSA,"TSA aims to enhance its capabilities in managing and analyzing complex data, ultimately contributing to more effective and efficient security operations and optimizing the TSA's operational workflows and support capabilities.","TSA aims to enhance its capabilities in managing and analyzing complex data, ultimately contributing to more effective and efficient security operations and optimizing the TSA's operational workflows and support capabilities.

The TSA Answer Engine is an LLM AI running on a closed, internal system that is trained to generate human-like outputs to expedite employee workflows by answering questions and assisting with tasks. The initial scope of the Answer Engine will permit TSA employees to ask questions related to the screening procedures and receive an answer based on volumes of TSA regulations, guidance, and requirements data. This platform is anticipated to harness the power of AI to provide intelligent, context-aware responses and insights. 

TSA aims to enhance its capabilities in managing and analyzing complex data, ultimately contributing to more effective and efficient security operations and optimizing the TSA's operational workflows and support capabilities. "
DHS-2430,Automated Field Data Collection,DHS,TSA,"The AI will analyze screening environments via CCTV footage and extract passenger processing times of various steps within the screening processes. Enabling AI to extract and visualize this data will enable TSA to make data informed decisions while testing or deploying new screening equipment, identify anomalies, establish real-world rates and standards, and reduce or eliminate TSA’s need to deploy data collection teams, resulting in real-time data collection and significantly reduced computational time of findings.
","The AI will analyze screening environments via CCTV footage and extract passenger processing times of various steps within the screening processes. Enabling AI to extract and visualize this data will enable TSA to make data informed decisions while testing or deploying new screening equipment, identify anomalies, establish real-world rates and standards, and reduce or eliminate TSA’s need to deploy data collection teams, resulting in real-time data collection and significantly reduced computational time of findings.


Automated Field Data Collection technology leverages AI through machine vision, a technology that enables computers to interpret and understand visual information, to automatically collect, analyze and report observational field data of checkpoint and checked baggage screening operations. This solution provides the Transportation Security Administration (TSA) with near-real-time rates of passenger flows at various points in the checkpoint process to inform staffing resource allocation, reduce passenger wait times, and reduce the cognitive load on Transportation Security Officers (TSOs). 

The AI will analyze screening environments via closed circuit television (CCTV) footage and extract passenger processing times of various steps within the screening processes. Enabling AI to extract and visualize this data (including screening location performance, rates and standards of the end-to-end screening system, and passenger wait times) will enable TSA to make data-informed decisions while testing or deploying new screening equipment, identify anomalies, establish real-world rates and standards, and reduce or eliminate TSA’s need to deploy data collection teams, resulting in real-time data collection and significantly reduced computational time of findings. "
DHS-131,Automated Target Recognition (ATR) Developments for Standard Screening,DHS,TSA,"The purpose of this use case is to improve upon Automated Target Recognition (ATR) algorithms used to reduce privacy concerns because a TSO is no longer required to view Advanced Imaging Technology (AIT) images. The expected benefits are to increase detection, reduce false alarms, and improve efficiency and passenger experience.","The purpose of this use case is to improve upon Automated Target Recognition (ATR) algorithms used to reduce privacy concerns because a TSO is no longer required to view Advanced Imaging Technology (AIT) images. The expected benefits are to increase detection, reduce false alarms, and improve efficiency and passenger experience.

Automated Target Recognition (ATR) uses AI and machine learning to conduct real-time object recognition and anomaly, or target, detection on the Advanced Imaging Technology (AIT) machines to automatically detect possible prohibited items carried by passengers on their person through checkpoint. The system then reproduces the threat location on a representative human figure using a coordinate transform function (CTF) for resolution by Transportation Security Officers (TSOs). By using trained AI algorithms, TSA may display a potential threat location on a representative human figure to show TSOs visual outlines of suspected threat or prohibited items. The purpose of this use case is to improve upon ATR algorithms used to reduce privacy concerns because after this enhancement TSOs are no longer required to view AIT images. Operational systems do not continue to collect images or train the algorithm. The expected benefits are to increase detection, reduce false alarms, and improve efficiency and passenger experience. 

The system reproduces the threat location, which is viewed as a bounding box on a representative human figure, for TSO resolution. "
DHS-2399,Axon Capture Application,DHS,TSA,"The Transportation Security Administration (TSA) uses body-worn cameras that incorporate artificial intelligence (AI) technologies as a part of the underlying software which transcribes and translates video footage. The technology provides rapid access to LEO and Investigative data, through transcription.  This will cut investigative processing time significantly, while also increasing accuracy.","The Transportation Security Administration (TSA) uses body-worn cameras that incorporate artificial intelligence (AI) technologies as a part of the underlying software which transcribes and translates video footage. The technology provides rapid access to LEO and Investigative data, through transcription.  This will cut investigative processing time significantly, while also increasing accuracy.

The Transportation Security Administration (TSA) uses body-worn cameras that incorporate AI as a part of the underlying software. The tool is designed to provide rapid access to law enforcement and investigative data to assist Law Enforcement Officers (LEOs) and those reviewing evidence to quickly sort and categorize data. Once electronic evidence/video footage is transferred to the tool, AI provides rapid transcription and translation of audio recordings. The embedded translation tools use machine learning to convert speech from one language to another. The AI will transcribe audio/video data and provide a printable artifact. The embedded AI also categorizes video evidence to allow reviewers to quickly identify areas within the video that may need to be redacted if the data needs to be released (e.g., drivers licenses, passport, the faces of youth, license plates, monitor screens, etc.) This will cut investigative processing time significantly, while also increasing accuracy.  The AI only provides recommendations the final usable data is reviewed and certified by TSA staff. "
DHS-342,CDC Airport Hotspot Throughput (PageRank),DHS,TSA,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

TSA launched the “Stay Healthy. Stay Secure.” campaign, which details proactive and protective measures implemented at security checkpoints to make the screening process safer for passengers and our workforce by reducing the potential of exposure to the coronavirus. The campaign includes guidance and resources to help passengers prepare for the security screening process in the COVID environment. A big part of that campaign was the development of the Centers for Disease Control and Prevention's Airport Hotspot Throughput. This capability determines the domestic airports that have the highest rank of connecting flights during the holiday travel season to help mitigate the spread of COVID-19. This capability is a DHS-developed artificial intelligence model written in Spark/Scala that takes historical non-PII travel data and computes the highest-ranking airports based on the PageRank algorithm. TSA does not make decisions about flight cancellations or airport closures. These decisions are made locally, on a case-by-case basis, by individual airlines, airports, and public health officials. TSA will continuously evaluate and adapt procedures and policies to keep the public and our workforce safe as we learn more about this devastating disease and how it spreads. "
DHS-2428,Contract Requirement Automation,DHS,TSA,"Eliminates the manual burden and reduces errors in document creation, where staff previously spent excessive time writing requirements to meet specific procurement needs from scratch. Increases documentation accuracy, consistency and standardization. Improves management and verification of requirement documents. Cost savings represent another major benefit, as the platform reduces labor costs associated with manual document creation and management. By streamlining the procurement process, the agency can complete more procurement actions with existing resources, maximizing taxpayer dollars. The automated tool also reduces the time spent on repetitive tasks, allowing for better resource allocation.","Eliminates the manual burden and reduces errors in document creation, where staff previously spent excessive time writing requirements to meet specific procurement needs from scratch. Increases documentation accuracy, consistency and standardization. Improves management and verification of requirement documents. Cost savings represent another major benefit, as the platform reduces labor costs associated with manual document creation and management. By streamlining the procurement process, the agency can complete more procurement actions with existing resources, maximizing taxpayer dollars. The automated tool also reduces the time spent on repetitive tasks, allowing for better resource allocation.

The Transportation Security Administration (TSA) is testing a contract documentation platform, Carver, to streamline the creation, management, and generation of requirement documentation for purchase request documents. The tool leverages AI technologies like large language models (LLMs) and machine learning (ML) for automation. Based on user inputs, the system generates and manages standard language for key documents, such as Statements of Work (SOW), Performance Work Statements (PWS), and Statements of Objectives (SOO). 

The tool attempts to provide the TSA user with contextually accurate outputs (primarily in the form of automated document generation and recommendations for procurement documentation) tailored to specific requirements. The platform provides contextual recommendations during the document creation process to ensure completeness and compliance with procurement requirements. The tool provides recommendations and decision support to guide users through the proper documentation structure and content requirements. 

This will significantly reduce manual effort and errors in document creation while improving accuracy, consistency, compliance, and efficiency. By streamlining the procurement process, the agency can complete more procurement actions with existing resources, maximizing taxpayer dollars. The automated tool also reduces the time spent on manual or repetitive tasks (e.g., manual document creation and management), allowing for better resource allocation. The system's outputs always require human verification as part of the workflow, ensuring that all generated content is reviewed and approved by qualified personnel before being finalized in the procurement process."
DHS-2395,Conversation Training and Feedback Simulator,DHS,TSA,"TSA's Training and Development office is using an off-the-shelf, on-demand, employee learning/training platform which contains commercial training on many topics tailored to each user's interests and skill level to support their personalized training plans and goals. One available component of the platform uses a large language model (LLM) as part of an interactive, dialogue-style training functionality to communicate with and advise the learner to develop critical non-security sensitive soft skills such as customer service and communicating on difficult topics.","TSA's Training and Development office is using an off-the-shelf, on-demand, employee learning/training platform which contains commercial training on many topics tailored to each user's interests and skill level to support their personalized training plans and goals. One available component of the platform uses a large language model (LLM) as part of an interactive, dialogue-style training functionality to communicate with and advise the learner to develop critical non-security sensitive soft skills such as customer service and communicating on difficult topics.

TSA's Training and Development office is using an off-the-shelf, on-demand, employee learning/training platform which contains commercial training on many topics tailored to each user's interests and skill level to support their personalized training plans and goals. One available component of the platform uses a large language model (LLM) as part of an interactive, dialogue-style training functionality to communicate with and advise the learner to develop critical non-security sensitive soft skills such as customer service and communicating on difficult topics using this conversation simulation tool. This function, if enabled, is intended to augment, and not replace, professional training interventions and human interaction. "
DHS-327,Credential Authentication Technology with Camera System (CAT-2) and AutoCAT (CAT-2 in an e-gate form factor),DHS,TSA,"The Transportation Security Administration (TSA) uses AI-based, one-to-one (1:1) facial matching technologies at some checkpoints to assist human reviewers with traveler identity verification. The purpose and expected benefits of the technology include increased speed and accuracy of identity verification at the checkpoint while improving detection of imposters.","The Transportation Security Administration (TSA) uses AI-based, one-to-one (1:1) facial matching technologies at some checkpoints to assist human reviewers with traveler identity verification. The purpose and expected benefits of the technology include increased speed and accuracy of identity verification at the checkpoint while improving detection of imposters.

The Transportation Security Administration (TSA) uses one-to-one (1:1) facial matching technologies at some checkpoints to assist human reviewers with traveler identity verification. These systems temporarily capture an image of a traveler who chooses to use the screening method and then utilizes biometric technology to match the traveler to the identity document they have presented at the checkpoint. No images are retained by TSA, and the voluntary process increases speed and improves accuracy of identity verification by the human reviewer at the checkpoint. "
DHS-135,Low Probability of False Alarm (Low-Pfa) Algorithm for on-person screening.,DHS,TSA,"The purpose is to reduce alarm rates while providing gender neutral detection which would increase passenger throughput and experience.

Utilizes Machine Learning (ML) to improve detection performance while decreasing alarm rates and passengers touch rates. The algorithm is gender agnostic which no longer requires officers to select a passengers gender prior to being scanned. AIT throughput and AIT utilization have increased with this new algorithm. Note: Once the algorithm is trained, it is locked down and no longer learning.","The purpose is to reduce alarm rates while providing gender neutral detection which would increase passenger throughput and experience.

Utilizes Machine Learning (ML) to improve detection performance while decreasing alarm rates and passengers touch rates. The algorithm is gender agnostic which no longer requires officers to select a passengers gender prior to being scanned. AIT throughput and AIT utilization have increased with this new algorithm. Note: Once the algorithm is trained, it is locked down and no longer learning.

TSA uses Low Probability of False Alarm (Low-PFA) algorithms to train AI systems deployed for on-person screening.  It utilizes ML to improve detection performance while decreasing alarm rates and passengers touch rates. The algorithm is gender agnostic, no longer requiring officers to select a passenger’s gender prior to being scanned. AIT scanner throughput and utilization have increased with this new algorithm. Once the algorithm is trained, it is locked down and no longer learning."
DHS-417,Machine Learning Analysis Applied to Cyber Threat Hunt Data,DHS,TSA,"Cyber threat hunts typically involve a vast amount of data. Machine learning models can quickly and efficiently process this data as well as more effectively identify anomalous activity than humans. 
This could improve the efficiency and quality of cyber threat hunts by detecting suspicious behavior more quickly and increasing the amount of data that can be analyzed during a hunt.","Cyber threat hunts typically involve a vast amount of data. Machine learning models can quickly and efficiently process this data as well as more effectively identify anomalous activity than humans. 
This could improve the efficiency and quality of cyber threat hunts by detecting suspicious behavior more quickly and increasing the amount of data that can be analyzed during a hunt.

Cyber threat hunts typically involve a vast amount of data. Machine learning models can quickly and efficiently process this data as well as more effectively identify anomalous activity than humans. This could improve the efficiency and quality of cyber threat hunts by detecting suspicious behavior more quickly and increasing the amount of data that can be analyzed during a hunt.  TSA is using machine learning (ML) models to analyze large volumes of TSA network log data from various systems to detect patterns more quickly and accurately than humans, aiding in more rapid response to potential threats. This tool currently detects anomalies or outliers within the collected data and could be expanded to include classification and categorization in the future. The analysis is run to explore the data and identify items for an analyst to analyze further. The ML output is a list of results with details including why that result was identified by the model and the statistical likelihood that it is a positive result. An analyst would then review these results and determine if any of the patterns might be associated with unusual cyber activity. The analyst then continues to analyze further as during normal cyber threat hunt operations. "
DHS-2397,OTA Automated Passenger Screening Gate System,DHS,TSA,The purpose is to manage passenger flow while reducing human interaction by using AI to assess body positioning and automatically initiate the screening process when the passenger is in the optimum position.,"The purpose is to manage passenger flow while reducing human interaction by using AI to assess body positioning and automatically initiate the screening process when the passenger is in the optimum position.

The automated passenger screening system regulates and expedites traveler screening by guiding passengers though the queue to the Advanced Imaging Technology (AIT) scanners. The system uses machine vision, a technology that enables computers to interpret and understand visual information, to assess body positioning and automatically initiate the screening process when the passenger is in the optimum position. The purpose is to manage passenger flow while reducing human interaction by using AI to assess body positioning and automatically initiate the screening process when the passenger is in the optimum position. The AI system initiates an AIT scan when the passenger is in the optimum position. Depending on the results of the AIT scan, the passenger would be routed either for additional screening or to the re-composure area to claim their accessible property and transit into the sterile area."
DHS-2431,Plan of Day Staff Optimization,DHS,TSA,"Plan of Day will automate TSA screening staff optimization.
","Plan of Day will automate TSA screening staff optimization.


Plan of Day is the Transportation Security Administration’s (TSA’s) approach to modernize screening resource allocations, leverage data to inform decisions, and realize efficiencies. Plan of Day leverages AI to assist in checkpoint operational determinations and activities by conducting historical data analytics to help determine optimal screening lane hours and locations, predict necessary staffing requirements, and provide notifications to Transportation Security Officers (TSOs) when scheduling and leave requests are approved. 

Plan of Day will automate TSA screening staff optimization though models capable of prescribing when screening lanes should be opened/closed, determining when/where screening staff is required to absorb operational peaks, determining optimal gender and certification ratios, recommending when to schedule overtime/shift adjustments, drafting lane rotation plans, and informing national TSA staffing requirements, factoring in changes to both optimization plans airline schedules. "
DHS-345,PreCheck Touchless Identity Solution (TIS),DHS,TSA,"TSA is using Facial Comparison to verify a passenger’s identity at its security checkpoints and CMAP locations using the CBP Traveler Verification Service (TVS). This process streamlines passenger and crewmember identity verification, increasing the speed of security checks while maintaining a high degree of safety for all passengers and crewmembers.""","TSA is using Facial Comparison to verify a passenger’s identity at its security checkpoints and CMAP locations using the CBP Traveler Verification Service (TVS). This process streamlines passenger and crewmember identity verification, increasing the speed of security checks while maintaining a high degree of safety for all passengers and crewmembers.""

The Transportation Security Administration (TSA) uses one-to-many (1:n) facial identification technologies as an optional process at some checkpoints to assist human reviewers with traveler identity verification. This additional TSA PreCheck feature is voluntary, and passengers may opt-out of the process at any time and instead choose the standard identity verification by a Transportation Security Officer (TSO). These systems temporarily capture an image of a traveler who chooses to use the screening method and then cross references Customs and Border Protection’s (CBP’s) Traveler Verification Service (TVS) to compare the passenger’s live image to a gallery of pre-staged, enrolled reference photos. No images are retained by TSA, and the voluntary process increases speed and improves accuracy of identity verification by the human reviewer at the checkpoint."
DHS-134,Synthetic Data for Improved Automated Threat Recognition (ATR) in Checkpoint Screening,DHS,TSA,"To create synthetic data that can be used to improve Automated Threat Recognition (ATR) algorithm development. Synthetic data can be quicker to produce which will improve effectiveness by addressing and adapting to new threats quicker.

Accessible Property Screening (APS) and On-Person Screening (OPS) are working with vendors and evaluating AI-based synthetic data generation techniques to bolster the pool of training data available to develop machine learning algorithms in ATR applications.","To create synthetic data that can be used to improve Automated Threat Recognition (ATR) algorithm development. Synthetic data can be quicker to produce which will improve effectiveness by addressing and adapting to new threats quicker.

Accessible Property Screening (APS) and On-Person Screening (OPS) are working with vendors and evaluating AI-based synthetic data generation techniques to bolster the pool of training data available to develop machine learning algorithms in ATR applications.

Engineers in the Transportation Security Administration’s (TSAs) Accessible Property Screening (APS) and On-Person Screening (OPS) program offices are developing AI to create images of prohibited items (i.e., synthetic data), such as knives or guns. These images are then used to train Automated Threat Recognition (ATR) and other AI models and systems to detect prohibited items in the screening processes. 

Synthetic data can be quicker to produce which will improve effectiveness by addressing and adapting to new threats quicker. APS and OPS are working with vendors and evaluating AI-based synthetic data generation techniques to bolster the pool of training data available to develop machine learning algorithms in ATR applications. The AI will generate images that mimic the human body and various threats. "
DHS-2429,TSA Case Handling Platform,DHS,TSA,"The tool saves case workers manual time to download reports, order, and compile. The case workers can then use their time to work on cases rather than administrative tasks. Newton POC has the potential of streamlining collection processes related to cases, and creating custom reports from various materials during the case managers interview process, producing a centralized tool to manage and control all steps within each case.","The tool saves case workers manual time to download reports, order, and compile. The case workers can then use their time to work on cases rather than administrative tasks. Newton POC has the potential of streamlining collection processes related to cases, and creating custom reports from various materials during the case managers interview process, producing a centralized tool to manage and control all steps within each case.

The Transportation Safety Administration’s (TSA’s) Case Handling Platform is a custom case management platform developed for TSA’s Civil Rights and Civil Liberties Office that leverages AI technologies like large language models (LLMs) and machine learning (ML) to generate recommended language for common documents and reports for claims handlers working on Equal Employment Opportunity (EEO) claims by synthesizing the information collected about a case and input into the platform. Language recommendations are assessed by human reviewers before implementation. 

The tool saves case workers manual time to download, order, and compile reports. The case workers can then use their time to work on cases rather than administrative tasks. The use case has the potential of streamlining collection processes related to cases, creating custom reports from various materials during the case managers interview process, producing a centralized tool to manage, and controlling all steps within each case. "
DHS-374,TSA Contact Center Virtual Assistant,DHS,TSA,"The three goals for TSA’s virtual assistant are:  1) Improve Ease / Efficiency – deliver timely, accurate responses to customers within / outside of TCC operational hours; 2) Improve Effectiveness – collect new customer insights to help drive agency improvements; 3) Fiscal Responsibility – leverage automation to meet increasing demand without the need for additional resources.","The three goals for TSA’s virtual assistant are:  1) Improve Ease / Efficiency – deliver timely, accurate responses to customers within / outside of TCC operational hours; 2) Improve Effectiveness – collect new customer insights to help drive agency improvements; 3) Fiscal Responsibility – leverage automation to meet increasing demand without the need for additional resources.

The Transportation Security Administration (TSA) Contact Center Virtual Assistant is an AI chat-bot designed to improve customer experience and increase efficiency on the TSA.gov website. An AI-powered virtual assistant serves as the initial point of contact for customers, using predictive AI or natural language processing (NLP), to answer routine questions. Customer service agents will remain available and will not be replaced by the virtual assistant. 

The three goals for TSA’s virtual assistant are: (1) improve ease of access and increase efficiency be delivering timely, accurate responses to customers within and outside of the TSA Contact Center’s (TCC’s) operational hours; (2) improve effectiveness by collecting new customer insights to help drive agency improvements; and (3) improve fiscal responsibility by leveraging automation to meet increasing demand without the need for additional resources. 

TSA’s virtual assistant, as a predictive AI tool, will not be able to create and provide original content to customers. It will be limited to providing responses to customer inquiries based on the existing content in the TCC’s knowledge library. However, it will record transactional data related to these customer inquiries (e.g., customer inputs, assistant outputs, topic classifications, etc.). TSA’s virtual assistant will create transactional data regarding customer inquiries in a consistent manner to our existing email and phone channels. TSA uses this transactional data to guide customer experience improvement efforts. This data offers TSA insights into what is working well, where the pain points are, where to improve public information, and what services are most requested. "
DHS-133,Walk-Through Metal Detector (WTMD) Alternative Automated Target Recognition (ATR) Developments,DHS,TSA,Artificial intelligence (AI)-enhanced Millimeter wave (mmWave) detectors are used as an alternative to Walk-Through Metal Detectors (WTMDs) for passenger screening to detect both metallic and non-metallic threats and prohibited items on passengers at the security checkpoint. These detectors are an improvement over traditional walk-through metal detectors and provide increased security and a better passenger experience.,"Artificial intelligence (AI)-enhanced Millimeter wave (mmWave) detectors are used as an alternative to Walk-Through Metal Detectors (WTMDs) for passenger screening to detect both metallic and non-metallic threats and prohibited items on passengers at the security checkpoint. These detectors are an improvement over traditional walk-through metal detectors and provide increased security and a better passenger experience.

AI-enhanced Millimeter wave (mmWave) detectors are used as an alternative to Walk-Through Metal Detectors (WTMDs) for passenger screening to detect both metallic and non-metallic threats and prohibited items on passengers at the security checkpoint. These detectors are an improvement over traditional walk-through metal detectors and provide increased security and a better passenger experience. mmWave body scanners use safer, skin-sensitive, non-ionizing radiation to find concealed objects using pre-defined rule-based and deep learning algorithms to identify prohibited items and relay that information to the Transportation Safety Officers (TSOs) on duty at the checkpoint. An mmWave Automated Target Recognition (ATR) algorithm uses AI and machine learning (ML) to detect anomalies, or targets, on the body and reproduces the threat location on a representative human figure using a coordinate transform function (CTF) for TSO resolution. ATR algorithms are trained and then deployed. Operational systems do not continue to collect images or train the algorithm. "
DHS-178,Adaptive Risk Model for Inspected Small Passenger Vessels,DHS,USCG,"The Small Passenger Vessels (SPV) Safety Task Force leveraged machine learning and subject matter expert input to create an adaptable, quantitative analysis tool that reliably identifies the key drivers of marine casualties and calculates a risk score for each vessel within the largest segment of the U.S.-inspected fleet. A vessel risk score is computed with an analytic model which leverages logistic regression and basic machine learning. The effort directly improved marine inspector allocation, targeted risk and enhanced the governance necessary to increase passenger safety across the country.","The Small Passenger Vessels (SPV) Safety Task Force leveraged machine learning and subject matter expert input to create an adaptable, quantitative analysis tool that reliably identifies the key drivers of marine casualties and calculates a risk score for each vessel within the largest segment of the U.S.-inspected fleet. A vessel risk score is computed with an analytic model which leverages logistic regression and basic machine learning. The effort directly improved marine inspector allocation, targeted risk and enhanced the governance necessary to increase passenger safety across the country.

This AI system helps the USCG assign a numerical risk score for Small Passenger Vessels (SPV) relative to one another. The SPV Safety Task Force leveraged machine learning (ML) and subject matter expert (SME) input to create an adaptable, quantitative analysis tool that reliably identifies the key drivers of marine casualties and calculates a risk score for each vessel within the largest segment of the U.S.-inspected fleet. A vessel risk score is computed with an analytic model that leverages logistic regression and basic ML. The risk score is then combined with an SME-derived consequence score that considers the number of vessel passengers and operation distance from shore. The final combined number is used to categorize a vessel into one of three tiers: at the lowest risk tier, vessels will receive, at a minimum, mandated inspections as per Title 46 Code of Federal Regulations, while vessels in tiers 2 and 1 may receive more frequent or more thorough inspections by more experienced inspectors. Before an inspection recommendation is communicated to the vessel owner, an SME reviews and approves the vessel scores. Follow-on policy efforts set the required scope and frequency of inspection, the minimum competency of the lead inspector, and the level of accountability for each vessel. In addition to their modeling and policy efforts, this team conducted extensive education and outreach with the field, district, and area commands to aid adoption and foster implementation. Their efforts directly improved marine inspector allocation, targeted risk, and enhanced the governance necessary to increase passenger safety across the country. "
DHS-263,Silicon Valley Innovation Program (SVIP) Language Translator,DHS,USCG,"A handheld voice translator could be used to communicate the questioning of vessels in high-tension situations where a USCG vessel does not have a translator available, or they encounter different or multiple languages. In cases where a rescue is involved, being able to determine critical information such as the number of people aboard and status of life saving equipment is vital to commanders in their decision-making process. Once the USCG boarding team makes contact with the occupants of the boarded vessel, they must be able to communicate and give orders to the occupants of the vessel who may not speak English or in many cases speak multiple languages. The development of an offline language translator could enable accurate and swift translation of orders and directions which are critical to the safety and security of the boarding team and the occupants of the vessel.","A handheld voice translator could be used to communicate the questioning of vessels in high-tension situations where a USCG vessel does not have a translator available, or they encounter different or multiple languages. In cases where a rescue is involved, being able to determine critical information such as the number of people aboard and status of life saving equipment is vital to commanders in their decision-making process. Once the USCG boarding team makes contact with the occupants of the boarded vessel, they must be able to communicate and give orders to the occupants of the vessel who may not speak English or in many cases speak multiple languages. The development of an offline language translator could enable accurate and swift translation of orders and directions which are critical to the safety and security of the boarding team and the occupants of the vessel.

USCG personnel often interact with individuals who speak little or no English, making it very challenging to quickly assess and respond to a variety of situations. To better execute these responsibilities, the USCG needs a portable language translator that can rapidly and effectively communicate with non-English speakers. USCG boarding teams need a handheld, universal language translator that works at the speed of natural language and operates in disconnected environments. A handheld voice translator could be used to communicate the questioning of vessels in high-tension situations where a USCG vessel does not have a translator available encounters different or multiple languages. In cases involving a rescue, being able to determine critical information such as the number of people aboard and the status of life-saving equipment is vital to commanders in their decision-making process. Once the USCG boarding team makes contact with the occupants of the boarded vessel, they must be able to communicate and give orders to the occupants who may not speak English or may speak multiple languages. The development of an offline language translator could enable accurate and swift translation of orders and directions, which are critical to the safety and security of the boarding team and the occupants of the vessel. This use case is funded by DHS (S&T), Silicon Valley Innovation Program (SVIP)."
DHS-13,Asylum Text Analytics,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

USCIS oversees lawful immigration to the United States. As set forth in Section 451(b) of the Homeland Security Act of 2002, Public Law 107-296, Congress charged USCIS with administering the asylum program. USCIS, through its Asylum Division within the Refugee, Asylum & International Operations Directorate (RAIO), administers the affirmative asylum program to provide protection to qualified individuals in the United States who have suffered past persecution or have a well-founded fear of future persecution in their country of origin, as outlined under Section 208 of the Immigration and Nationality Act (INA), 8 U.S.C. § 1158 and Title 8 of the Code of Federal Regulations (C.F.R.), Part 208. Generally, an individual not in removal proceedings may apply for asylum through the affirmative asylum process regardless of how the individual arrived in the United States or his or her current immigration status by filing Form I-589, Application for Asylum and for Withholding of Removal. The ATA capability employs machine learning and data graphing techniques to identify plagiarism-based fraud in applications for asylum status and for the withholding of removal by scanning the digitized narrative sections of the associated forms and looking for common language patterns."
DHS-180,Automated Name and Date of Birth (DOB) Harvesting from Existing Records,DHS,USCIS,To reduce the amount of adjudicative time spent manually harvesting aliases and dates of birth (DOBs) from identity history summary (idHS) report attached to the ELIS case as part of the Manual Name Harvesting Task during case processing.,"To reduce the amount of adjudicative time spent manually harvesting aliases and dates of birth (DOBs) from identity history summary (idHS) report attached to the ELIS case as part of the Manual Name Harvesting Task during case processing.

Automated Name and Date of Birth (DOB) Harvesting is being developed to reduce the amount of adjudicative time spent manually harvesting aliases and DOBs from Identity History Responses (IdHS) text. The use case output draws from FBI Background Check System (BCS) source information and is provided to USCIS officers to consider during case processing. For aliases, this solution uses a named-entity recognition (NER) model trained to understand the specific context around where aliases appear—meaning it’s effective at locating true aliases, while at the same time avoiding other places where proper names may exist but are not aliases (e.g., county or street names). For DOBs, this solution uses pattern matching and conditional logic to harvest valid birth dates, while weeding out obvious placeholders and other non-birth dates found within the IdHS text.  This use case has been in production since 2022 and is enabled only for N400. The solution was developed as a Python library, and the encasing Flask application runs on Amazon EKS. Its primary function is to predict where aliases and dates of birth appear within unstructured IdHS text.  It uses a named-entity recognition (NER) model, trained using Spark NLP with a TensorFlow back end on thousands of systematically labeled IdHS records, and word-level embeddings. 

This use case reduces the amount of adjudicative time spent manually harvesting aliases and dates of birth (DOBs) from identity history summary (IdHS) report attached to the ELIS case as part of the Manual Name Harvesting Task during case processing. 

Eliminates need for manual review by extracting unique names and DOBs from IdHS documents and when names/DOBs are already in ELIS, ANH will not suggest any names. This is still a human in the loop process. The ELIS user performing MNH tasks is prompted to decide if the suggested names and DOBs are related to case hence can accept/reject the suggestions. "
DHS-181,Automated Realtime Global Organization Specialist (ARGOS) for Company Registration Submissions to E-Verify,DHS,USCIS,"ARGOS sentiment analysis produces a risk score and keyword extraction identifies the keword category of interest to the VAC MPAs (management and program analyst) for the aggregated open-source information to help quickly identify any pertinent information to aid the MPAs in their open-source investigation of company applications.  This saves potentially thousands of MPA man hours in open-source investigation and creates a single source-of-truth for each MPAs investigation of a company application.  This, in turn, allows for quicker application processing and, if risk of company fraud exists, much faster referral processing time quickening the next-step referral to FDNS for further investigations.","ARGOS sentiment analysis produces a risk score and keyword extraction identifies the keword category of interest to the VAC MPAs (management and program analyst) for the aggregated open-source information to help quickly identify any pertinent information to aid the MPAs in their open-source investigation of company applications.  This saves potentially thousands of MPA man hours in open-source investigation and creates a single source-of-truth for each MPAs investigation of a company application.  This, in turn, allows for quicker application processing and, if risk of company fraud exists, much faster referral processing time quickening the next-step referral to FDNS for further investigations.

ARGOS searches publicly available datasets (like a human would) to establish risk and potential fraud associated with a company using E-Verify. The use case output informs USCIS Verification Account Compliance (VAC) analysts' decisions regarding whether a company applying to register on E-Verify is fraudulent and should be referred for investigation. ARGOS searches a multitude of public datasets for information that is then ranked and scored based on text analysis and a risk and fraud model developed in collaboration with the USCIS VAC team. The ARGOS application then displays that information to the end-user, allowing them to view the possibilities of fraud and make an informed decision. The goal of the use case is to streamline the process and accelerate work for the individual who is researching a company that has submitted its information for registration to E-Verify. 

ARGOS sentiment analysis produces a risk score, and keyword extraction identifies the keyword category of interest to the VAC management and program analysts (MPAs) for the aggregated open-source information. This helps quickly identify any pertinent information to aid the MPAs in their open-source investigation of company applications. This process saves potentially thousands of MPA man-hours in open-source investigation and creates a single source of truth for each MPA's investigation of a company application. In turn, this allows for quicker application processing and, if the risk of company fraud exists, much faster referral processing time, expediting the next-step referral to Fraud Detection and National Security (FDNS) for further investigations. 

Responses are sent back to a user dashboard accessible internally only by VAC Management and Program Analyst (MPA) personnel. Keywords related to the MPA's work interests are extracted if present, and risk scores are assigned to the open source collected information. The data is presented to the MPA on the graphical user interface (GUI) dashboard. "
DHS-14,Biometrics Enrollment Tool (BET) Fingerprint Maximization,DHS,USCIS,"BET assists in determining if the fingerprint taken is good enough quality to pass the FBI fingerprint check process. It provides immediate feedback when a set of prints is likely to be rejected by the FBI by incorporating machine learning models into the BET application. The FBI will not disclose their quality grading criteria for fingerprints, leaving BET with the responsibility of determining quality to prevent unnecessary secondary encounters with applicants.","BET assists in determining if the fingerprint taken is good enough quality to pass the FBI fingerprint check process. It provides immediate feedback when a set of prints is likely to be rejected by the FBI by incorporating machine learning models into the BET application. The FBI will not disclose their quality grading criteria for fingerprints, leaving BET with the responsibility of determining quality to prevent unnecessary secondary encounters with applicants.

The Biometric Enrollment Tool (BET) is custom-built biometric enrollment software for both domestic and overseas USCIS biometric collections. BET is integrated with the National Appointment Scheduling System (NASS) and the Customer Profile Management System (CPMS). This improves data integrity as BET utilizes data already collected in USCIS systems, reducing the amount of data entry by the Biometric Technician and the risk of typographic errors. BET assists in determining if the fingerprint taken is good enough quality to pass the FBI fingerprint check process. It provides immediate feedback when a set of prints is likely to be rejected by the FBI by incorporating machine learning (ML) models into the BET application. The FBI will not disclose their quality grading criteria for fingerprints, leaving BET with the responsibility of determining quality to prevent unnecessary secondary encounters with applicants. Using even the simplest of models would catch 98% of rejected submissions, which could have potentially saved USCIS from scheduling 42,763 additional appointments in 2020. This would come at the cost of forcing recapture during 11% of encounters. This effort aims to maximize the number of successful FBI submissions while minimizing the number of fingerprint recaptures necessary. The output is a Numerical Fingerprint Quality score, which is compared against fingerprint quality thresholds (per finger and per set of fingerprints) to align with FBI specifications. "
DHS-182,Biometrics Enrollment Tool (BET) Fingerprint Quality Score,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Duplicate with BET Maximization. The Biometrics Enrollment Tool (BET) team has incorporated the National Institute of Standards and Technology (NIST) Fingerprint Image Quality 2 (NFIQ2) algorithm (a trained machine learning algorithm) for scoring fingerprints (https://www.nist.gov/services-resources/software/nfiq-2) into the BET application. This algorithm takes a fingerprint image and assigns a score between 0 and 100, with 100 indicating the best quality fingerprint image that could be obtained. The higher the score, the more likely it is that the fingerprint will match when captured again. "
DHS-17,Case Processing Improvements in FDNS-DS NexGen,DHS,USCIS,"In the future, USCIS may consider using artificial intelligence (AI) / machine learning (ML)  FDNS-DS NexGen or other systems  may data from other applications for FDNS-DS NexGen or other systems to aid in investigative work, enhance investigative case prioritization, and detect duplicate case work. USCIS may consider and explore investigating whether it would be useful to integrate AI/ML into the predictive modeling for potential future system enhancements, also integrate AI/ML into the predictive modeling for future system enhancements, working side-by-side with the business stakeholders to develop best practices. Fraud occurs in numerous ways; being able to discover and detect persons with multiple identities allows for more comprehensive investigations, reduces investigative cycle time, and improves performance.","In the future, USCIS may consider using artificial intelligence (AI) / machine learning (ML)  FDNS-DS NexGen or other systems  may data from other applications for FDNS-DS NexGen or other systems to aid in investigative work, enhance investigative case prioritization, and detect duplicate case work. USCIS may consider and explore investigating whether it would be useful to integrate AI/ML into the predictive modeling for potential future system enhancements, also integrate AI/ML into the predictive modeling for future system enhancements, working side-by-side with the business stakeholders to develop best practices. Fraud occurs in numerous ways; being able to discover and detect persons with multiple identities allows for more comprehensive investigations, reduces investigative cycle time, and improves performance.

USCIS created the Fraud Detection and National Security (FDNS) Directorate to strengthen the integrity of the nation’s immigration system and to ensure that immigration benefits are not granted to individuals who may pose a threat to national security and/or public safety. In addition, the FDNS Directorate is responsible for detecting, deterring, and combating immigration benefit fraud.  In 2005, USCIS developed a case management system, the Fraud Detection and National Security-Data System (FDNS-DS), to record, track, and manage the screening processes related to immigration applications, petitions, or requests with suspected or confirmed fraud, public safety, or national security concerns, and to identify vulnerabilities that may compromise the integrity of the legal immigration system.  In June 2023, FDNS-DS was replaced with a modernized case management system, FDNS-DS NexGen.  In the future, FDNS-DS NexGen may use artificial intelligence (AI) and machine learning (ML) data from other applications to aid in investigative work, enhance investigative case prioritization, and detect duplicate case work. USCIS may also integrate AI/ML into the predictive modeling for future system enhancements, working side-by-side with the business stakeholders to develop best practices. Fraud occurs in numerous ways; being able to discover and detect persons with multiple identities allows for more comprehensive investigations, reduces investigative cycle time, and improves performance. Future implementation of AI/ML techniques will speed up case and investigative processing by several magnitudes. For more information, please visit: https://www.dhs.gov/publication/dhsuscispia-013-01-fraud-detection-and-national-security-directorate  While FDNS-DS NexGen is in production, the AI/ML functionality is still in discovery stages. "
DHS-189,ELIS Card Photo Validation via myUSCIS,DHS,USCIS,"USCIS uses a system called ELIS to manage immigration requests, and it includes a Photo Validation Service to check if ID photos meet requirements. This helps ensure photos are correct before making ID cards, saving time and avoiding delays.

The photo validation service uses a combination of computer vision techniques and machine learning models to validate photographs and ensure they meet the requirements, so these photos can be used in card production.","USCIS uses a system called ELIS to manage immigration requests, and it includes a Photo Validation Service to check if ID photos meet requirements. This helps ensure photos are correct before making ID cards, saving time and avoiding delays.

The photo validation service uses a combination of computer vision techniques and machine learning models to validate photographs and ensure they meet the requirements, so these photos can be used in card production.

USCIS uses a system called ELIS to manage immigration requests, and it includes a Photo Validation Service to check if ID photos meet requirements. This helps ensure photos are correct before making ID cards, saving time and avoiding delays. USCIS is the component within DHS that oversees lawful immigration to the United States. USCIS receives immigration requests from individuals seeking immigration and non-immigration benefits. Once a benefit request form is submitted to USCIS, a series of processing and adjudication actions occur. One of the case management systems used to track and adjudicate certain immigration request forms is the Electronic Information System (ELIS). USCIS ELIS is an internal case management system composed of microservices to assist with performing complex adjudicative and processing tasks; one of those microservices is the Photo Validation Service. The card photo validation solution was originally designed for e-filed I-765 (c)(3)s — to be in direct support of the beneficiary as they apply via myUSCIS. In enabling e-filing for the (c)(3)s, one goal was to have everything captured digitally, including these ID photos, all while avoiding any new delays or complications for the applicant in the process. In other words, if we observed an issue with a photo upon upload, we wanted to address it up front — rather than waiting until a failed card production sequence.  Because the photo requirements themselves are fixed, this exact same functionality could also be plugged directly into ELIS, just prior to card production. As of late October 2021, an effort to do exactly this is underway. The primary difference is that an adjudicator would explicitly request that a case’s photo be validated, and if applicable, the service would return a recommendation to edit the photo before submission. 

The photo validation service uses a combination of computer vision techniques and machine learning models to validate photographs and ensure they meet the requirements, so these photographs can be used in card production. The output is Response back to user based on the pre-defined quality checks if the uploaded photo meets USCIS requirements. Users still have the option to ignore the warnings and upload the photo. "
DHS-16,ELIS Evidence Classifier Machine Learning (ML) Tagging Solution,DHS,USCIS,"To enable end users to navigate directly to the page(s) containing evidence documents of interest instead of sifting through large PDF documents. Evidence tagging intends to accelerate case processing by identifying specific types of documents (e.g., I-589, passport photo spread, marriage certificate) and applying a metadata tag to that document object in ELIS. This way, when a user opens a case with potentially hundreds of pages of evidence documents, rather than scrolling through them one at a time to find a specific document of interest, they have clickable ""bookmarks"" in the UI generated from these tags that will jump directly to the corresponding page.","To enable end users to navigate directly to the page(s) containing evidence documents of interest instead of sifting through large PDF documents. Evidence tagging intends to accelerate case processing by identifying specific types of documents (e.g., I-589, passport photo spread, marriage certificate) and applying a metadata tag to that document object in ELIS. This way, when a user opens a case with potentially hundreds of pages of evidence documents, rather than scrolling through them one at a time to find a specific document of interest, they have clickable ""bookmarks"" in the UI generated from these tags that will jump directly to the corresponding page.

The Evidence Classifier Service is a machine learning (ML) solution that reduces the time spent by adjudicators and contractors sifting through digital evidence. The solution systematically tags and surfaces critical evidence types for the adjudicators in Electronic Immigration System (ELIS). Until the Evidence Classifier ML solution's introduction, those working on cases and responsible for reviewing evidence documents would often have to sift through dozens, if not hundreds, of unlabeled pages to find one specific artifact. As a result, an ML solution was built to systematically tag individual pages with some of the highest-volume, highest-impact evidence types. 

The service enables end users to navigate directly to the page(s) containing evidence documents of interest, instead of sifting through large PDF documents. Evidence tagging intends to accelerate case processing by identifying specific types of documents (e.g., I-589, passport photo spread, marriage certificate) and applying a metadata tag to that document object in ELIS. When a user opens a case with potentially hundreds of pages of evidence documents they have clickable bookmarks from these tags that will jump directly to the corresponding page. 

The output is tagged evidence. The system inputs an image (scanned document from Lockbox) and outputs either a specific label, such as ""Border Crossing Card - Front,"" or no label if that document is not recognized as one of the classes. "
DHS-61,I-485 Family Matching,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

I-485 Family Matching is designed to create models to match family members to underlying I-485 petitions. The underlying immigrant petition defines if the I-485 is employment-based or family-based. It also has information about the visa classification and priority date which, when compared against the Department of State’s monthly Visa Bulletin, helps predict visa usage. It is difficult to match an I-485 to its underlying immigrant petition, because the only available field on which to match is the Alien-number (A-number). This number is not always present on the immigrant petition, and name/date of birth matching is not as reliable.  The goal of I-485 Family Matching is to leverage AI to create connections more confidently between petitioners and their families based on limited data.  Additionally, it was intended to help identify and group I485s filed by family members, as well as gather up the many ancillary forms they may have been pending (such as I765, I131). Similar to immigrant petition matching, it can be difficult to match up I485s filed by family members. In these cases, the only similar fields are a common address. Efforts have been made in the past to identify family members by address, but it is effective only to a point. This use case explored the technical feasibility of using an AI model to help make working with this data more reliable (as well as group individual petitioners, their families, and other helpful associated data together for faster and more accurate processing).  Work on this use case did not go beyond ideation and no AI model was built (and no output was rendered) after the proof-of-concept established that the desired end-state was infeasible with the technology available at that time. "
DHS-64,I-539 approval prediction,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Builds models that identify lists of topics and documents that are related to each topic. Topic modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering hidden themes in the collection. classifying the documents into the discovered themes."
DHS-414,I-765 - USCIS Face Capture Mobile App,DHS,USCIS,This will allow the user to complete the biometric verification requirement without having to attend an appointment at am Applicant Support Center. This reduces the burden on the beneficiary as well as reducing demands on USCIS Applicant Service Center resources.,"This will allow the user to complete the biometric verification requirement without having to attend an appointment at am Applicant Support Center. This reduces the burden on the beneficiary as well as reducing demands on USCIS Applicant Service Center resources.

Utilizing facial capture in the mobile application reduces the burden on both Application Support Centers and customers by providing an alternative method for capturing card-quality photographs used for document production. Application Support Center appointments are limited to work hours, often requiring applicants to take time off work. In some regions, applicants may need to travel long distances to reach an application support center and inclement weather can make attending appointments difficult. The mobile application enables photograph collection without the need for a biometrics appointment, enhancing processing efficiency for adjudicators and offering greater convenience for applicants. This will allow the user to complete the biometric verification requirement without having to attend an appointment at an Applicant Support Center. This reduces the burden on the beneficiary and decreases demands on USCIS Applicant Support Center resources. 

Face detection locates human faces in visual media such as digital images or video. When a face is detected, it has an associated position, size, and orientation; it can also be searched for landmarks such as the eyes and nose, which are returned as numerical values. The ELIS Photo Validation service sends a response back to the user based on predefined quality checks to determine if the uploaded photo meets USCIS requirements. The I-765 - USCIS Facial Recognition through IDENT (1:1 Face Recognition/Validation) returns a match or no match response from IDENT. "
DHS-413,I-765 - USCIS Facial Recognition through IDENT (1:1 Face Recognition/Validation),DHS,USCIS,This will allow the user to complete the biometric verification requirement without having to attend an appointment at am Applicant Support Center. This reduces the burden on the beneficiary as well as reducing demands on USCIS Applicant Service Center resources.,"This will allow the user to complete the biometric verification requirement without having to attend an appointment at am Applicant Support Center. This reduces the burden on the beneficiary as well as reducing demands on USCIS Applicant Service Center resources.

USCIS intends to leverage facial recognition for several reasons. Multiple court orders require the adjudication of employment authorization applications within 30 days. Currently, applicants must attend an Application Support Center to verify their identity and capture a photograph, which can take up to three weeks of the 30-day period. Using the facial verification service makes this process nearly instant and greatly enhances processing efficiency without compromising the effectiveness of current identity verification methods. Additionally, new rules created by the FBI’s Compact Council require biometric verification to perform fingerprint resubmissions for different filing reasons than the original fingerprint capture. Facial verification brings USCIS into compliance with this rule change. Furthermore, performing facial verification increases the integrity of information and identities by identifying conflicts early on, preventing issues from becoming pervasive across immigration systems. This will allow the user to complete the biometric verification requirement without having to attend an appointment at an Applicant Support Center. This reduces the burden on the beneficiary as well as reducing demands on USCIS Applicant Support Center resources. The output is a match or no match response from IDENT.  "
DHS-57,Identity Match Option (IMO) Tool for Record Compilation,DHS,USCIS,"USCIS uses the IMO tool to aid in person-centric research and analytics. More specifically, IMO is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS.","USCIS uses the IMO tool to aid in person-centric research and analytics. More specifically, IMO is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS.

USCIS uses the Identity Match Option (IMO) tool to aid in person-centric research and analytics. More specifically, IMO is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS. USCIS maintains a variety of systems to track specific interactions with individuals – benefits case management, appointment scheduling, background check validation, and customer service inquiries. Each system captures its own person-centric data attributes (e.g., Social Security Number (SSN), Alien number (A-number), name, date of birth (DOB), address, etc.) related to individuals interacting with the agency. The system is designed to handle different data formats and potential data quality issues present in the source data to identify duplicate identities in a data set or between two data sets. The derived identities are linked back to the original source records, enabling USCIS personnel to view an individual's comprehensive interaction history with the agency.  The output of this can be visualized through a report or dashboard to assist with case review, ensuring access to helpful and accurate records. 

A user-friendly dashboard is created to display results and shows the data pattern but does not allow for any prediction or decision making. IMO is a Commercial Off-The-Shelf (COTS) product offered by Informatica. The product has a variety of “transformations” that can be used together to build a workflow-based solution. There are several different algorithms (Soundex, Jaro, Hamming distance, etc.) which are available for use in performing identity resolution. "
DHS-2385,Intelligent Document Processing (IDP) for I-539 Form Digitization,DHS,USCIS,"IDP for the I-539 makes use of an AI-enhanced tool to identify, categorize, and create separate images for each document type submitted as part of the 539 benefit application. Prior to implementation of this use case, all pages of a 539 application were scanned and stored as a single document in the content management system.  The benefit is reduced case processing time for adjudicators by identifying and classifying supporting documents for ease of use. An additional benefit is to bring digital images into compliance with NARA standards.","IDP for the I-539 makes use of an AI-enhanced tool to identify, categorize, and create separate images for each document type submitted as part of the 539 benefit application. Prior to implementation of this use case, all pages of a 539 application were scanned and stored as a single document in the content management system.  The benefit is reduced case processing time for adjudicators by identifying and classifying supporting documents for ease of use. An additional benefit is to bring digital images into compliance with NARA standards.

Intelligent Document Processing (IDP) for the Application to Extend/Change Nonimmigrant Status Form I-539 uses an Artificial Intelligence (AI)-enhanced tool to identify, categorize, and create separate images for each document type submitted as part of the I-539 benefit application. Before the use case, all pages of a I-539 application were scanned and stored as a single document in the content management system, delaying adjudication and not meeting National Archives and Records Administration (NARA) standards. The tool uses a learning model to identify, classify, and separate individual documents into their component parts for storage. For example, a USCIS form, marriage license, passport, bank statement, etc., will be identified and stored in the content management system (CMS or Electronic Immigration System (ELIS)) as individual images and linked as supporting documents for the I-539 benefit application. This streamlines case processing by organizing supporting information for easy access and brings digitization of the I-539 benefit application into compliance with NARA standards. A human in-the-loop architecture resolves uncertain results from the system. 

IDP for the I-539 reduces case processing time for adjudicators by identifying and classifying supporting documents for ease of use and brings digital images into compliance with NARA standards. "
DHS-366,Large Language Models for an Officer Training Tool,DHS,USCIS,"The LLM for an Officer Training tool, will use GenAI to improve the way the agency trains immigration officer personnel. The tool will generate dynamic, personalized training materials that adapt to officers’ specific needs and ensure the best possible knowledge and training on a wide range of current policies and laws relevant to their jobs.","The LLM for an Officer Training tool, will use GenAI to improve the way the agency trains immigration officer personnel. The tool will generate dynamic, personalized training materials that adapt to officers’ specific needs and ensure the best possible knowledge and training on a wide range of current policies and laws relevant to their jobs.

The Large Language Model (LLM) for Officer Training tool will use Generative AI (GenAI) to improve the way the agency trains immigration officer personnel. The tool will generate dynamic, personalized training materials that adapt to officers’ specific needs and ensure the best possible knowledge and training on a wide range of current policies and laws relevant to their jobs. The goal is to enhance trainees’ understanding and retention of crucial information, increase the accuracy of their decision-making process, and limit the need for retraining over time. The AI outputs human-like conversation in a text format, like other AI chatbots, but is specially trained and tuned for Refugee, Asylum, and International Operations (RAIO) Officer training. "
DHS-55,Person-Centric Identity Services Deduplication Model,DHS,USCIS,"Using Machine Learning allows us to improve entity resolution as compared to rule based system.

PCIS offers the ability to see a person's immigration history organized in one place. Specific benefits do or will include: an organized summary view of the identity with the individual's latest photo from PCIS; full immigration history including receipts associated with the applicant, regardless of case management system; mailing, physical, and safe history of the individual organized in reverse chronological order, allowing users to easily find the most recent address; and all identifiers associated with the applicant, including A-Numbers, FINs, SSNs, SSNs, ELIS account numbers, passport numbers, etc.","Using Machine Learning allows us to improve entity resolution as compared to rule based system.

PCIS offers the ability to see a person's immigration history organized in one place. Specific benefits do or will include: an organized summary view of the identity with the individual's latest photo from PCIS; full immigration history including receipts associated with the applicant, regardless of case management system; mailing, physical, and safe history of the individual organized in reverse chronological order, allowing users to easily find the most recent address; and all identifiers associated with the applicant, including A-Numbers, FINs, SSNs, SSNs, ELIS account numbers, passport numbers, etc.

The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The de-duplication model ingests person-centric datasets from various source systems for model training and evaluation purposes. Our dataset includes biographic information (e.g., name, date of birth, alien number Social Security Number, passport number) as well as biographic information (e.g., fingerprint IDs, eye color, hair color, height, weight) for model training and matching purposes. Critical to the success of PCIS is the entity resolution and de-deduplication of individual records from various systems of records to create a complete picture of a person. Using machine learning (ML), the model can identify which case management records belong to the same unique individual with a high degree of confidence. This allows PCIS to compile a full immigration history for an individual without the need for time-consuming research across multiple disparate systems. The de-duplication model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The ML models are more resilient to fuzzy matches and handle varying data fill rates more reliably. 

Using Machine Learning allows us to improve entity resolution as compared to rule-based system. PCIS offers the ability to see a person's immigration history organized in one place. Specific benefits do or will include: an organized summary view of the identity with the individual's latest photo from PCIS; full immigration history including receipts associated with the applicant, regardless of case management system; mailing, physical, and safe history of the individual organized in reverse chronological order, allowing users to easily find the most recent address; all identifiers associated with the applicant, including Alien number, Social Security Number, passport number, etc.; and a numerical likelihood score which is used to determine if the record belongs to the individual, subjected to a high threshold (.98, maximum 1) to assess whether the record belongs to the individual. "
DHS-56,Person-Centric Identity Services A-Number Management Model,DHS,USCIS,"The aim of this use case is to leverage machine learning to test the accuracy of PCIS to identify and manage associations between individuals and their assigned A-numbers, which is a unique 7, 8, or 9 digit number assigned to a noncitizen by DHS.  The A-Number plays a critical role in surfacing of a person and all their associated records from across PCIS.","The aim of this use case is to leverage machine learning to test the accuracy of PCIS to identify and manage associations between individuals and their assigned A-numbers, which is a unique 7, 8, or 9 digit number assigned to a noncitizen by DHS.  The A-Number plays a critical role in surfacing of a person and all their associated records from across PCIS.

This use case verifies the ongoing accuracy of the Person-Centric Identity Services (PCIS) information compilation.  PCIS is the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between authorized services into an individual's comprehensive immigration history and status, with the purpose of providing DHS employees all needed information to review and process cases in a single system. The aim of this use case is to leverage machine learning (ML) to test the accuracy of PCIS to identify and manage associations between individuals and their assigned alien numbers (A-numbers), which is a unique 7-, 8-, or 9-digit number assigned to a noncitizen by DHS.  The A-number plays a critical role in surfacing of a person and all their associated records from across PCIS. The output of the use case is the numerical confidence score which is used to determine the validity of the A-number presented in search results. The confidence score identifies which records from within PCIS best match search criteria for an A-number. "
DHS-60,Predicted to Natzuralize,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

The Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize and attempts to provide a current address. This model could potentially be used to send correspondence to USCIS customers of their resident status and notify others of potential USCIS benefits."
DHS-59,Sentiment Analysis - ELIS Case Notes,DHS,USCIS,Survey results cosed to specify the sentiments as positive negative or neutral tone in a excel dashboard,"Survey results cosed to specify the sentiments as positive negative or neutral tone in a excel dashboard

Once a benefit request form is submitted to USCIS, it undergoes a series of processing and adjudication actions. One of the case management systems used for tracking and adjudicating certain immigration request forms is the Electronic Information System (ELIS). ELIS is an internal case management system composed of microservices designed to assist with complex adjudicative and processing tasks. One of these microservices is the Sentiment Analysis machine learning (ML) model. This model classifies the notes taken by adjudicative officers as either positive, negative, or neutral sentiment for a particular case. Although this use case is not yet in production, it has been in development and testing for less than a year. The model was enhanced using ML to improve reusability and performance.  For more information, please visit [LINK https://www.dhs.gov/publication/dhsuscispia-056-uscis-electronic-immigration-system-uscis-elis]. The sentiment analysis output is provided to officers to consider during subsequent case processing, helping to improve efficiency and streamline workflow. This could serve as a basis for deciding or providing risk assessments related to immigration, asylum, or detention status"" and/or ""emotion assessment. Survey results coded to specify the sentiments as positive negative or neutral tone in a excel dashboard."
DHS-58,Sentiment Analysis - Employee Satisfaction Surveys,DHS,USCIS,Survey results cosed to specify the sentiments as positive negative or neutral tone in a excel dashboard,"Survey results cosed to specify the sentiments as positive negative or neutral tone in a excel dashboard

The Sentiment Analysis - Surveys system provides a statistical analysis of quantitative results from survey results and then uses Natural Language Processing (NLP) modeling software to assign ""sentiments"" to categories ranging from strongly positive to strongly negative. This work has not gone beyond proof-of-concept and is not in use by any business unit. The goal of the use case was to determine whether sentiment analysis was technically feasible in the context of employee satisfaction surveys. While the technical capability was proven, potential privacy concerns were also identified. There were/are no plans to operationalize the technical capability proof-of-concept until/unless the privacy blockers are resolved. "
DHS-2386,Sentiment Analysis -FOD Field Offices Complaints and Reviews,DHS,USCIS,"This system indicates the positive or negative feelings people express in their feedback to the U.S. Citizenship and Immigration Services (USCIS).

Survey results categorized to specify the sentiments as positive negative or neutral tone in an excel dashboard.","This system indicates the positive or negative feelings people express in their feedback to the U.S. Citizenship and Immigration Services (USCIS).

Survey results categorized to specify the sentiments as positive negative or neutral tone in an excel dashboard.

The Sentiment Analysis - FOD Field Offices Complaints and Reviews system analyzes feedback received by USCIS to determine the positive or negative sentiments expressed. This system provides a statistical analysis of quantitative results from complaints, reviews the results, and then uses machine learning (ML) techniques to assign sentiments to categories ranging from strongly positive to strongly negative. This helps survey administrators to identify trends and glean valuable from both quantitative and qualitative data. This capability is currently available and under consideration by the Field Operations Directorate (FOD). FOD receives complaints from the public through the USCIS Office of Investigations (OI) via telephone, mail, email, and a dedicated website. These complaints contain detailed descriptions of the in-office experiences. FOD personnel read, research, and resolve these complaints on a case-by-case basis. FOD uses the Sentiment Analysis - FOD Field Offices Complaints and Reviews system for ML analysis to provide an extra layer of information that helps FOD identify and resolve issues generally (without changing the process of resolving complaints). Currently, FOD reports complaints counts by pending and resolved and general bins determined by FOD HQ. It’s this binning that FOD would like to improve because they may be missing key trends and/or early identification of general issues. FOD were looking for generalization, a summary of aggregated complaints. 

The system categorizes feedback sentiments into positive, negative, or neutral tones, displayed in a dashboard. This graphical representation helps visualize how customer service can be improved but does not provide specific recommendations or decisions. "
DHS-231,Testing Performance of ML Model using H2O,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

USCIS is the component within DHS that oversees lawful immigration to the United States. That means USCIS receives, processes, and maintains all applications for admission for Lawful Permanent Residents (LPRs), or adjustments to LPR status. Also known as “green card” holders, LPRs are non-citizens who are lawfully authorized to live permanently within the United States and are required to fill out Form I-90, Application to Replace Permanent Resident Card (Green Card). Since there has been a considerable influx of green card applications, USCIS used a combination of exploratory data analysis to determine the most used categories for applicants submitting I-90's, and machine learning to create predictions of workloads. USCIS used the H20 machine learning model to allow USCIS analysts to build and run several machine learning models on big data in an enterprise environment and identify the model that performs the best. It has already been successful in identifying the most accurate model for the I-90 Form Timeseries Analysis and Forecasting use case. "
DHS-130,Text Analytics Data Science Sentence Similarity Model,DHS,USCIS,"Text Analytics augments the tedious and time-consuming manual process to identify potential fraud, national security, and/or public safety concerns and enables the identification of such concerns across jurisdictional boundaries. It increases the integrity of immigration programs, strengthens officers’ confidence in their work, and contributes to the reduction in customer wait times.","Text Analytics augments the tedious and time-consuming manual process to identify potential fraud, national security, and/or public safety concerns and enables the identification of such concerns across jurisdictional boundaries. It increases the integrity of immigration programs, strengthens officers’ confidence in their work, and contributes to the reduction in customer wait times.

USCIS oversees lawful immigration to the United States. Through its Refugee, Asylum & International Operations Directorate (RAIO), USCIS administers programs to provide protection to qualified individuals who have suffered past persecution or have a well-founded fear of future persecution in their country of origin, as outlined in the Immigration and Nationality Act (INA) and Title 8 of the Code of Federal Regulations (C.F.R.). The Text Analytics capability employs machine learning and data graphing techniques to identify patterns that may indicate potential fraud, national security, and/or public safety concerns by scanning the digitized narrative sections of the associated applications and looking for common language patterns. The Text Analytics Data Science Sentence Similarity Model identifies similarity and relevancy in text to determine potential matches in documents submitted into the system. Text Analytics does not make any determinations or decisions but is instead utilized as a research tool by staff in the course of their duties. 

Text Analytics augments the tedious and time-consuming manual process of identifying potential fraud, national security, and/or public safety concerns and enables the identification of such concerns across jurisdictional boundaries. It increases the integrity of immigration programs, strengthens officers’ confidence in their work, and contributes to the reduction in customer wait times. 

Text Analytics does not make predictions, recommendations, or decisions. It is merely a research tool that identifies potential patterns while remaining agnostic as to whether those patterns indicate potential fraud, national security, and/or public safety concerns. Instead, trained staff evaluate the patterns to determine whether they identify potential concerns and then validate and/or invalidate those potential concerns through the course of their investigations or adjudications. "
DHS-20,Timeseries Analysis and Forecasting,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

USCIS is the component within DHS that oversees lawful immigration to the United States. That means USCIS receives, processes, and maintains all applications for admission for Lawful permanent residents (LPRs), or adjustments to LPR status. Also known as “green card” holders, LPRs are non-citizens who are lawfully authorized to live permanently within the United States and are required to fill out Form I-90, Application to Replace Permanent Resident Card (Green Card). Since there has been a considerable influx of green card applications, USCIS used a combination of exploratory data analysis to determine the most used categories for applicants submitting I-90's and machine learning to create predictions of workloads. As a follow-on, USCIS used Autoregressive Integrated Moving Average (ARIMA) models on the I-90 form, which allowed the prediction of the total number of forms for a 2-year period. ARIMA is one of the easiest and effective machine learning algorithms to perform time series forecasting. This capability has been deployed in production for more than a year. This model was eventually enhanced using ML model to have better reusability and performance."
DHS-63,Topic Modeling on Request For Evidence (RFE) Data Sets,DHS,USCIS,"This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.","This use case is no longer an Active Use Case. See the ""Summary of Use Case"" section for details.

Builds models that identify lists of topics and documents that are related to each topic. Topic modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering hidden themes in the collection. classifying the documents into the discovered themes."
DHS-365,USCIS  Consular Consolidated Database (CCD) Facial Recognition (FR) On Demand Report (VISA Only),DHS,USCIS,CCD is operated by the DoS Bureau of Consular Affairs. DHS works closely with DoS on risks and mitigations. Refer to DoS Bureau of Consular Affairs for additional information about this use case.,"CCD is operated by the DoS Bureau of Consular Affairs. DHS works closely with DoS on risks and mitigations. Refer to DoS Bureau of Consular Affairs for additional information about this use case.

USCIS uses the Facial Recognition (FR) on Demand report (Visa only) to combat fraud by benefit applicants whose fingerprints are not in IDENT but who may have photos in the Department of State's (DoS) Consular Consolidated Database (CCD) that predate the fingerprinting of visa applicants."
DHS-2305,USCIS Translation Service,DHS,USCIS,"Document Translation: Integrate AI and GenAI models trained on relevant subject matter (e.g., immigration law, visa/immigration applications, family/adoption certificates, and other sourced processing materials) to provide fast, accurate translation of written or other digital documents in various languages.
Real-time Interpretation: Utilizing AI and GenAI-powered speech-to-speech, speech-to-text translation tools for efficient communication, consultations, and other interactions within DHS. Across all DHS components the need to support language translation and transcription is crucial for operations and adjudications.","Document Translation: Integrate AI and GenAI models trained on relevant subject matter (e.g., immigration law, visa/immigration applications, family/adoption certificates, and other sourced processing materials) to provide fast, accurate translation of written or other digital documents in various languages.
Real-time Interpretation: Utilizing AI and GenAI-powered speech-to-speech, speech-to-text translation tools for efficient communication, consultations, and other interactions within DHS. Across all DHS components the need to support language translation and transcription is crucial for operations and adjudications.

USCIS is testing AI-powered tools to quickly and accurately translate documents and provide real-time interpretation, enhancing communication and processing for immigration services. The USCIS Translation Service assesses the effectiveness and security of GenAI-powered translation tools for document translation and real-time interpretation. AI and GenAI models trained on relevant subjects (e.g., immigration law, visa applications, family/adoption certificates) provide fast, accurate translation of written or other digital documents in various languages. AI and GenAI-powered speech-to-speech and speech-to-text translation tools enable efficient communication, consultations, and other interactions within DHS. Supporting language translation and transcription is crucial for operations and adjudications across all DHS components. One use case application involves United States Refugee Admissions Program (USRAP) document translation, a time-consuming task for Resettlement Support Center (RSC) caseworkers before USCIS interviews. Documents include passports, national identifications, birth certificates, and more complex documents. The goal is to reduce or eliminate RSC casework dedicated to document collection, translation, data extraction, and summarization by leveraging document translation services. This allows USCIS officers to translate documents ad hoc during interviews.  

USCIS Translation Service use case addresses 4 key problem areas: 1) Limited capacity: Traditional translation methods rely on a finite pool of human translators, causing bottlenecks and delays. 2) Accuracy variability: Consistency and nuance can vary with individual translator expertise, especially with the diversity of languages in the Western Hemisphere and at the Southern Border. AI services aim to enhance consistency and address unique dialects. 3) Cost constraints: Scaling multilingual services through traditional methods can be resource-intensive and expensive. 4) Accessibility limitations: Real-time, on-demand translations are often unavailable, delaying communication and processing."
DHS-372,User Entity and Behavior Analytics (UEBA) for Security Operations (SecOps) Anomaly Identification,DHS,USCIS,"UEBA's purpose is to review USCIS system logs to determine when an entity is performing actions that are anomalous. An entity can be classified as a workstation, server or an internal USCIS system account. The UEBA ingests logs from systems to perform analytics based off of models that are manually created and maintained. UEBA uses the models to apply a risk score to the entity which the risk score is then used to create a case (or ticket) for Security Operations analyst review. The AI reviews the action of the analyst to adjust the risk scoring for future events. Output would assist in prioritizing cyber events for further manual investigation.","UEBA's purpose is to review USCIS system logs to determine when an entity is performing actions that are anomalous. An entity can be classified as a workstation, server or an internal USCIS system account. The UEBA ingests logs from systems to perform analytics based off of models that are manually created and maintained. UEBA uses the models to apply a risk score to the entity which the risk score is then used to create a case (or ticket) for Security Operations analyst review. The AI reviews the action of the analyst to adjust the risk scoring for future events. Output would assist in prioritizing cyber events for further manual investigation.

User Entity and Behavior Analytics (UEBA) assists USCIS Security Operations (SecOps) in identifying behavioral anomalies that most likely indicate malicious intent or heightened risk associated with user identities and endpoint hosts accessing the USCIS network. The analytics provide risk scoring, which helps USCIS SecOps to prioritize highest risk incidents first. The tool identifies credential compromise, risky behavior, violations of the rules of behavior, and other user behavior anomalies that could indicate the presence of an advanced persistent threat. UBEA is enhanced by machine learning models that can adapt to its environment and identify relevant threats, thereby improving the productivity of the USCIS Security Operations Center (SOC). 

UEBA reviews USCIS system logs to determine when an entity, such as a workstation, server, or internal USCIS system account, is performing actions that are anomalous.  The UEBA ingests logs from systems to perform analytics based on manually created and maintained models. These models  apply a risk score to the entity, which is then used to create a case (or ticket) for SecOps analyst to review. The AI reviews the actions of the analysts to adjust the risk scoring for future events, assisting in prioritizing cyber events for further manual investigation. "
DHS-2384,Verification Match Model,DHS,USCIS,"Leveraging AI in the USCIS verification matching process of known records across systems is beneficial because it streamlines existing USCIS review by 1) improving associated system accuracy, 2) reducing human-error by automating person-and-record match scoring, and 3) matching at a higher volume than traditional tools or manual processes can capably achieve.","Leveraging AI in the USCIS verification matching process of known records across systems is beneficial because it streamlines existing USCIS review by 1) improving associated system accuracy, 2) reducing human-error by automating person-and-record match scoring, and 3) matching at a higher volume than traditional tools or manual processes can capably achieve.

The Verification Match Model utilizes machine learning (ML) to gather information from multiple systems and match it to known records by comparing names, dates of birth, and other identifiers. This supports two key USCIS Verification Division (VER) programs: the Employment Verification Program (E-Verify) and the Systematic Alien Verification for Entitlements (SAVE) Program.  The model streamlines verification data integration services by providing a ranked order of the best matches, expressed as confidence scores, between the identifiers used by the two programs. These improved matches increase the accuracy of E-Verify and SAVE, ensuring they use the most recent and accurate documents to determine benefit status. E-Verify handles approximately 250,000 requests per day and SAVE handles approximately 70,000 requests per day. Multiple data verification models for SAVE and E-Verify exist, complicating efficiency and performance. By consolidating these into a single, unified Verification Match Model within a separate microservice, the use case aims to improve the accuracy of responses and reduce the need for manual review. ML plays a key role in the continuous improvement of these models, ultimately reducing the need for manual case reviews. 

Leveraging AI in the USCIS verification matching process of known records across systems is beneficial because it streamlines existing USCIS reviews by 1) improving system accuracy, 2) reducing human error through automated person-and-record match scoring, and 3) handling a higher volume of matches than traditional tools or manual processes can achieve.  The ouput is a recommendation and score indicating person-and-record match probability, used by verification systems (E-verify and SAVE) to improve accuracy in initial system responses. "
DHS-415,Criminal Investigations (OBIM),DHS,USSS,"The intended purpose of this AI is so that USSS INV personnel may submit available photographs or video stills of these unknown persons as probe images (facial images or templates searched against the gallery of an FRS) to other government agencies for comparison against their image galleries. The agencies will query their image galleries of known persons and may provide lists of potential matches. USSS INV personnel may use the potential matches to produce investigative leads which will assist in the further identification of victims or suspects. Additionally, USSS INV personnel may request another government agency to conduct a one-to-one comparison of two photographs or video stills  for investigative use.","The intended purpose of this AI is so that USSS INV personnel may submit available photographs or video stills of these unknown persons as probe images (facial images or templates searched against the gallery of an FRS) to other government agencies for comparison against their image galleries. The agencies will query their image galleries of known persons and may provide lists of potential matches. USSS INV personnel may use the potential matches to produce investigative leads which will assist in the further identification of victims or suspects. Additionally, USSS INV personnel may request another government agency to conduct a one-to-one comparison of two photographs or video stills  for investigative use.

The investigative mission of the USSS is to detect and arrest those that engage in crimes that undermine the integrity of U.S. financial and payment systems. During criminal investigations, USSS Office of Investigations (INV) personnel may require the identification of potential victims of crimes (e.g., identity theft) or of individuals suspected of crimes. USSS INV personnel may submit available photographs or video stills of these unknown persons as probe images (facial images or templates searched against the gallery of a Facial Recognition Service [FRS]) to other government agencies for comparison against their image galleries.  

Additionally, USSS INV personnel may request another government agency to conduct a one-to-one comparison of two photographs or video stills for investigative use. 

INV will utilize the DHS Office of Biometric Identity Management (OBIM) repository to query images for investigation purposes. 

USSS INV personnel will query image galleries of known persons and may provide lists of potential matches. USSS INV personnel may use the potential matches to produce investigative leads that will assist in further identifying victims or suspects."
