# AI Pilot- Detection of data exfiltration
## USAID-2024-0029
_United States Agency for International Development_ (USAID) / USAID/Bureau for Management


+ **The topic area that most closely aligns with the AI use case**: Mission-Enabling
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: The AI Pilot Project was developed to demonstrate the use of AI at USAID through the detection of security events and anomalies in network data. While existing cybersecurity measures catch some attacks, it is highly likely that many are sneaking by undetected, either disguised as benign traffic or simply unnoticed in the mass of data. The objective of the AI Pilot was to develop an in-house capability to detect previously undetected anomalous actors, trends or events in network data through the use of machine learning algorithms. For the proof of concept, the machine learning models were constructed through reverse engineering. This means the attacks were found and labeled in the data before the models were created, allowing the AI team to evaluate the performance of the machine learning models. The attacks were detected through calculating statistics specific to the type of attack and data protocols used by DHS and identifying outlier values.
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: ML model that successfully detected known penetration attacks conducted on specific protocols ICMP, HTTP, HTTPS. Discontinued before testing on second data set.
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Retired
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Neither
+ **Date when the AI use case was retired or began the process of retirement**: 8/1/2021