# Cyber Threat Analysis (Recorded Future)
## DHS-2024-0061
_[Department of Homeland Security](<../3_agency/Department of Homeland Security.md>)_ (DHS) / CBP


+ **The topic area that most closely aligns with the AI use case**: Law & Justice
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: Cyber Threat Analysis quickly populates query results when searching against adversary tactics, techniques, and procedures, establishing a threat scorecard. This service can also provide cyber risk scorecards for third party vendors, companies, and organizations.
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: Actionable intelligence supporting Security Operations Center (SOC) and Cyber Risk Management (CRM) investigations and reports.
Recorded Future data query enables CBP Cyber Threat Intelligence (CTI) analysts to focus on investigating recently observed relevant cyber threat activity rather than manually identifying, formatting, and searching for such information in multiple locations. Enables these analysts to quickly view known cyber threat activity targeting known vulnerabilities, which will reduce the time to identify risks to the vulnerabilities that exist in CBP’s information technology environment. AI/ML is employed several ways on this platform: For representation of structured knowledge of the world, using ontologies and events; for transforming unstructured text into a language-independent, structured representation, using natural language processing; for classifying events and entities, primarily to help decide if they are important enough to require a human analyst to perform a deeper investigation; to forecast events and entity properties by building predictive models from historic data. This service can also provide cyber risk scorecards for third party vendors, companies, and organizations. 
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Operation and Maintenance
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Neither
+ **Date when the AI use case’s purpose and high-level requirements were first defined**: 4/1/2020
+ **Date when the acquisition and/or development of the AI system associated with the use case first began**: 4/1/2020
+ **Whether the AI use case supports a High-Impact Service Provider (HISP) public-facing service. The full list of HISP public-facing services can be found at https://www.performance.gov/cx/hisps/**: No
+ **Whether the AI use case disseminates information to the public**: No
+ **Whether the AI use case involves personally identifiable information (PII), as defined in OMB Circular A-130**: No
+ **Whether the AI use case made use of agency-wide infrastructure to quickly identify the right datasets to begin model development**: No
+ **General description of the data used for training, fine-tuning, and evaluation of the AI use case’s model(s). This should include a description of any data provided by the agency, whether the datasets are research datasets, publicly available, external, etc. and to the extent possible, sufficiently descriptive information from the vendor**: N/A - The Agency does not own any of the data used to train, fine-tune, and/or evaluate performance of the model(s) used in this use case.
+ **Whether this AI project includes custom-developed code**: No
+ **Whether the agency has access to the code associated with the AI use case**: No – agency does not have access to source code.
+ **Whether the AI use case itself has an associated Authority to Operate (ATO), or is part of a system that has an ATO**: No
+ **Whether the required IT infrastructure is identified and provisioned via a centralized process (such as a unified intake form) that enables product owners and developers to find the right development environment inside the agency**: No
+ **Explanation for whether the AI use case has an identifiable process to request computing resources (such as cloud computing credits or computing hardware) to develop and test models**: No