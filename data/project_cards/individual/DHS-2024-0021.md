# API Security Vulnerability Technology
## DHS-2024-0021
_Department of Homeland Security_ (DHS) / CBP


+ **The topic area that most closely aligns with the AI use case**: Mission-Enabling
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: With the necessity of leveraging application programing interfaces (APIs) for applications across the enterprise, this AI technology is intended to run thousands of custom attack scenarios against APIs on a continuous basis. This will help to identify potential security vulnerabilities prior to production level deployments, and enable the enterprise to develop essential remediations, if required.  Additionally, the techonlogy is intended to provide continuous monitoring on APIs to provide real-time alerts on new potential vulnerabilities.
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: The AI system is intended to output custom reports on identified vulnerabilities within application programing interfaces (APIs). These reports will include the identified risk and a summary of the risk, as well as tailored remediation guidance based on the applications, environment, data, and tests conducted for end-users.
Enabling user-access to a secure environment and robust cybersecurity posture is critical to CBP operations. In order to support these objectives, CBP is intending to leverage application programing interface (API) testing technology which machine learning (ML) coupled with natural language processing (NLP) and automated software testing techniques. This platform is intended to automatically scan and continuously monitor APIs to detect potential risks like unauthorized access, data leaks, or weaknesses. Once tests are conducted on APIs, a comprehensive vulnerability report will identify security risks such as broken authentication, exposed data, or misconfigurations. The software is also intended to provide clear remediation guidance based on the applications, environment, data, and tests conducted for end-users, offering step-by-step solutions to fix these vulnerabilities. Additionally, this capability will assign a risk score to help prioritize the most critical issues and ensures APIs comply with industry standards and regulations through detailed compliance checks. With continuous security monitoring, the platform also delivers real-time alerts for new vulnerabilities, empowering teams to maintain robust API security throughout the development and deployment lifecycle. 
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Initiated
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Neither
+ **Date when the AI use case’s purpose and high-level requirements were first defined**: 8/19/2024