# Automated Decision Support
## VA-2024-0168
_[Department of Veterans Affairs](../3_agency/Department of Veterans Affairs.md)_ (VA) / VBA: Veterans Benefits Administration


+ **The topic area that most closely aligns with the AI use case**: Government Services (includes Benefits and Service Delivery)
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: Intake of VA Claims materials as well as other Veteran, VSO, and stakeholder submissions results in contentions which are prescribed as eligible.  The platform ingests and takes initial actions on claims and contentions (largely those impacted by the PACT Act) which include medical record retrieval, review of the VBMS eFolder, generates a summary review document, drafting or submitting contract examination requests via robotics process automation (RPA), and/or changing the claim status to Ready For Decision (RFD).
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: Utilizing prescribed machine learning and Natural Language Processing (NLP), ADS utilizes Intelligent Form Recognition (IFR), Optical Character Recognition (OCR), Intelligent Character Recognition (ICR), and NLP to extract an average of 95 fields on over 1500 form layouts within VA’s purview.  The system generates a summary review document, drafting or submitting contract examination requests via robotics process automation (RPA), and/or changing the claim status to Ready For Decision (RFD).
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Operation and Maintenance
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Both
+ **Date when the AI use case’s purpose and high-level requirements were first defined**: 7/1/2021
+ **Date when the acquisition and/or development of the AI system associated with the use case first began**: 8/1/2021
+ **Date when the AI use case was fully implemented and deployed into use**: 1/27/2022
+ **Whether the AI system involved in the use case was developed, or is expected to be developed, exclusively with contracting resources, in-house, or a combination of both**: Developed with both contracting and in-house resources.
+ **Identification of the Procurement Instrument Identifier(s) (PIID) of the contract(s) used for the AI use case**: IDIQ 36C10E19D0018   APCAS 36C10D21N0013   MAS 36C10E20N0028   BTP 36C10D23N0010
+ **Whether the AI use case supports a High-Impact Service Provider (HISP) public-facing service. The full list of HISP public-facing services can be found at https://www.performance.gov/cx/hisps/**: Yes
+ **Identification of the High-Impact Service Provider (HISP) that the AI use case supports**: Veterans Benefits Administration
+ **Whether the AI use case disseminates information to the public**: No
+ **Description of how the agency is ensuring that this AI use case is compliant with Information Quality Act guidelines and OMB Memorandum M-19-15, if applicable**: Quoted below is a section from our white paper on ethical implementation of AI iaw the executive orders and recent legislation: Purposeful and performance-driven: IBM’s NLP services, when combined with OCR/ICR capabilities, enable our platform to interpret unstructured and semi-structured forms, correspondence, and other data types, including handwriting. To date, we have deployed 30+ custom, proprietary NLP models within the VA automation infrastructure, significantly improving upon out-of-the-box OCR capabilities by further extracting and classifying the data necessary for downstream actions. - Accurate, reliable, and effective: Applying NLP significantly improves our extraction quality across form types and variations and allows us to infuse intelligence into the business process. NLP processing enables us to uncover and reveal insights (e.g., identify critical “flash” conditions; linking Veteran written disabilities to a specific condition to include characterizing it as ‘secondary to’) into more complex processing determinations based on the information within the data. Cognitive AI models such as ML, vision, and speech are used throughout our solution to create functional capabilities that continuously improve over time. Safe, secure, and resilient: IBM’s solution resides upon a FedRAMP-certified Amazon Web Services (AWS) GovCloud environment and operates 24/7 within a current VA Authority to Operate (ATO). - Understandable: A foundation of ethical AI/ML techniques is explainability – that is, the ability to understand and explain how an automation arrived at a certain outcome. IBM’s approach to documenting requirements and our detailed processing audits provides the explainability necessary to provide for proper processing outcomes. - Regularly monitored: Supervision and Human-in-the-Loop (HIL) capabilities support immediate data correction and supervised learning to improve extraction accuracy. - Transparent and accountable: IBM’s current process is to provide detailed documentation to VBA prior to the release of new NLP models. This documentation details the purpose and output of the model, the training data and algorithms used, and the limitations and availability of the models. IBM works with VBA throughout the requirements, development, testing and post-production process to review the approach, models and methods used to meet their business requirements.
+ **Whether the AI use case involves personally identifiable information (PII), as defined in OMB Circular A-130**: Yes
+ **Whether the agency’s Senior Agency Official for Privacy (SAOP) has assessed the privacy risks associated with this AI use case**: Yes
+ **Whether the AI use case made use of agency-wide infrastructure to quickly identify the right datasets to begin model development**: Yes
+ **General description of the data used for training, fine-tuning, and evaluation of the AI use case’s model(s). This should include a description of any data provided by the agency, whether the datasets are research datasets, publicly available, external, etc. and to the extent possible, sufficiently descriptive information from the vendor**: NLP/ML has primarily focused around contents within the eFolder.  Please see the MOU/iSA within eMass and Vasi as the 46 page document delineates data optimization and boundaries.
+ **Whether the data has sufficient documentation of its integrity, quality, and validity as a training set for a specific task**: Documentation has been partially completed: Some documentation exists (detailing the composition and any statistical bias or measurement skew for training and evaluation purposes), but documentation took place within this use case’s development.
+ **Whether this AI project includes custom-developed code**: Yes
+ **Whether the agency has access to the code associated with the AI use case**: Yes – agency has access to source code, but it is not public.
+ **Whether the AI use case itself has an associated Authority to Operate (ATO), or is part of a system that has an ATO**: Yes
+ **Name of the system(s) associated with this AI use case, according to the ATO**: VBAAP - Vasi 2522 eMASS 1143
+ **Estimated length of time the AI project waited for basic computing and developer tools to build machine learning models. This includes Government Furnished Equipment (GFE), along with access to open-source code libraries, frameworks, and other coding software or developer environments**: Less than 6 months
+ **Whether the required IT infrastructure is identified and provisioned via a centralized process (such as a unified intake form) that enables product owners and developers to find the right development environment inside the agency**: No
+ **Explanation for whether the AI use case has an identifiable process to request computing resources (such as cloud computing credits or computing hardware) to develop and test models**: Yes
+ **Has the communication been timely**: Yes
+ **Whether the AI use case promotes re-use of existing infrastructure to promote AI development**: Use of existing data platforms: This use case is being developed on existing enterprise data and analytics platforms within the agency rather than procuring additional platforms or SaaS to operate.
+ **Whether information regarding the AI use case has been made widely accessible within the agency**: Documentation has been published: Complete documentation has been published to a repository or data catalog within the agency and is made accessible to other data science teams for review and feedback.
+ **Whether the agency requested an extension for this AI use case, in response to the CAIO’s request, of up to one year for the minimum requirements outlined in Section 5 of OMB Memorandum M-24-10**: Yes – Agency requested an extension for this use case.