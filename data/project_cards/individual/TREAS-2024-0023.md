# Modernization Accelerator - International Business Machines (IBM) Cognitive Data Mapper (CDM) and AWS SageMaker+LLAMA
## TREAS-2024-0023
_[Department of the Treasury](<../3_agency/Department of the Treasury.md>)_ (TREAS) / Internal Revenue Service


+ **The topic area that most closely aligns with the AI use case**: Mission-Enabling
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: The Business Masterfile Modernization (BMF Mod) project will reproduce the legacy BMF system, written in 60-year-old mainframe technology, into a modern, cloud-based system. BMF Mod will also add additional features to the system as new technology permits.

Note that this software will only be used in an isolated development (sandbox) environment, to assist developers in programming the new modernized system. It will not be promoted into Production. 

These Artificial Intelligence/Machine Language (AI/ML) tools analyze the existing legacy BMF system code, after it has been prepared by other non-AI/ML International Business Machines (IBM) tools, to automatically produce: Business logic in natural language, which describe what actions or data transformations the code performs: Modernized Java code to implement the business rules; Microservice recommendations, meaning that code snippets are grouped together by function and access patterns, to split very large programs that are hard to understand into smaller chunks that can be more easily maintained.

These tools take in code from the existing BMF system, after it has been prepared by other non-AI/ML IBM tools, and analyze the code to produce the business logic, code, and microservice recommendations.
IBM Cognitive Data Mapper (CDM) uses Natural Language Processing (NLP) Machine Learning (ML) models to automatically analyze the source system's data and metadata, map to a target model or business glossary, and/or classify the information. CDM will be used for automated data mapping to automatically identify and establish relationships between data elements in different data sources and source systems.
Amazon Web Services (AWS) SageMaker with LLAMA accepts prepared code from other non-AI/ML IBM tools, then further analyzes the code to extract business logic and convert the code to modern Java.

The tools analyze existing code from the BMF system, which are very large programs, and suggest how to translate the code into smaller, more manageable and understandable business logic, code, and microservices.

All output business logic, code, and microservice recommendations will be reviewed by both IBM and IRS employees prior to being used in development of the new modernized BMF system. The outputs will be put into a spreadsheet that can be shared with subject matter experts, who will then manually check accuracy of the work. Code will also be packaged and extensively tested to ensure accuracy.

These AI/ML tools will accelerate our development process, allowing us to deliver a modernized system a few years faster than otherwise. The output business logic and microservice recommendations are also very useful as documentation artifacts, helping to understand how the BMF system functions.

Approval will allow BMF Mod work to continue. Without approval we would need to extend our modernization plans to account for performing these functions manually.

While these AI/ML tools are only intended to be used by IBM consultants working on the BMF Mod program, its impacts will benefit all BMF stakeholders including IRS business operating divisions, Treasury, and taxpayers.
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: IBM CDM uses Natural Language Processing (NLP) Machine Learning (ML) models to automatically analyze the source system's data and metadata, map to a target model or business glossary, and/or classify the information. CDM will be used for automated data mapping to automatically identify and establish relationships between data elements in different data sources and source systems.
AWS SageMaker with LLAMA accepts prepared code from other non-AI/ML IBM tools, then further analyzes the code to extract business logic and convert the code to modern Java.
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Acquisition and/or Development
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Neither
+ **Date when the AI use case’s purpose and high-level requirements were first defined**: 6/6/2024
+ **Date when the acquisition and/or development of the AI system associated with the use case first began**: 6/14/2024
+ **Whether the AI system involved in the use case was developed, or is expected to be developed, exclusively with contracting resources, in-house, or a combination of both**: Developed with contracting resources.
+ **Identification of the Procurement Instrument Identifier(s) (PIID) of the contract(s) used for the AI use case**: 2032H5-24-F-00181
+ **Whether the AI use case supports a High-Impact Service Provider (HISP) public-facing service. The full list of HISP public-facing services can be found at https://www.performance.gov/cx/hisps/**: No
+ **Whether the AI use case made use of agency-wide infrastructure to quickly identify the right datasets to begin model development**: Yes
+ **General description of the data used for training, fine-tuning, and evaluation of the AI use case’s model(s). This should include a description of any data provided by the agency, whether the datasets are research datasets, publicly available, external, etc. and to the extent possible, sufficiently descriptive information from the vendor**: Existing legacy Business Master File code
+ **Whether the data has sufficient documentation of its integrity, quality, and validity as a training set for a specific task**: Documentation is complete: Documentation exists regarding the maintenance, composition, quality, and intended use of the training and evaluation data, as well as any statistical bias across model features and protected groups.
+ **Identification of the demographic features explicitly utilized in the AI use case’s data/model(s), if any**: None
+ **Whether the AI use case itself has an associated Authority to Operate (ATO), or is part of a system that has an ATO**: No
+ **Estimated length of time the AI project waited for basic computing and developer tools to build machine learning models. This includes Government Furnished Equipment (GFE), along with access to open-source code libraries, frameworks, and other coding software or developer environments**: Less than 6 months
+ **Whether the required IT infrastructure is identified and provisioned via a centralized process (such as a unified intake form) that enables product owners and developers to find the right development environment inside the agency**: Yes
+ **Explanation for whether the AI use case has an identifiable process to request computing resources (such as cloud computing credits or computing hardware) to develop and test models**: Yes
+ **Has the communication been timely**: Yes
+ **Whether the AI use case promotes re-use of existing infrastructure to promote AI development**: Re-use production level code and/or data products: This use case re-uses production level code as well as data products that have been published or made widely available for data science teams for within the agency.
+ **Whether information regarding the AI use case has been made widely accessible within the agency**: Documentation has been published: Complete documentation has been published to a repository or data catalog within the agency and is made accessible to other data science teams for review and feedback.