# Automated Basic-Applied Categorization of extramural grants
## HHS-2024-0193
_Department of Health and Human Services_ (HHS) / NIH


+ **The topic area that most closely aligns with the AI use case**: Government Services (includes Benefits and Service Delivery)
+ **Whether the use case is implemented solely with the commercial-off-the-shelf or freely available AI products identified in Appendix B**: None of the above.
+ **Description of the AI’s intended purpose, including: (1) what problem the AI is used to solve and (2) the expected benefits and positive outcomes from the AI for an agency’s mission and/or the general public**: This machine-learning algorithm is in development. Currently it uses information on NIMH-funded extramural research projects to categorize them as basic or applied research per the federal definitions for each. The data it is trained on is supplied from extramural grant applications and the same fields will be used for subsequent classification of new grants. For new grants, the algorithm will propose a categorization which can be reviewed, confirmed, or edited by an NIMH staff member. The resulting information will be used for internal, analytical purposes and annual reporting of NIMH-funded basic and applied research. The AI will NOT influence funding decisions, require or use PII, or use any other sensitive, personal, or health information.

The algorithm is intended to be consistent in identifying basic and applied research, reduce burden of review by NIMH staff, and provide a complementary perspective to human review.
+ **Description of what the AI system outputs, whether it’s a prediction, recommendation, decision, etc**: The algorithm produces categorization of basic and applied research that is used for internal analysis and annual reporting. The algorithm is trained on the following data from extramural grants from fiscal years (FY) 2000-2022 and will use the same for grants in FY2025 and going forward to propose a categorization of basic or applied research: Program Class Code, NIMH Division, NIH Research, Condition, and Disease Categorization (RCDC), Human Subjects Codes, Animal Subjects Code, Clinical Trial NIMH Division, text of grant title, abstracts, specific aims. These data categories are all obtained from NIH IMPACII and will be applied to 100% of NIMH extramural grants, excluding L activity codes. This constitutes approximately 1,500 new grants per FY. Algorithm performance will be assessed each year, comparing the proposed classifications to a manually reviewed sample, and input received from NIMH staff regarding edits to proposed classifications. The frequency of processing is yet to be determined. No anonymization or de-identification processes are employed as personal information is used neither to train, nor classify grants using this algorithm.
+ **The current stage of System Development Life Cycle (SDLC) for the AI use case (See System Development Life Cycle (SDLC) - Glossary | NIST CSRC)**: Acquisition and/or Development
+ **Whether the AI use case is rights-impacting or safety-impacting, as defined in Section 6 of OMB Memorandum M-24-10. Note also that Appendix I of that memorandum lists categories of use cases that are presumed by default to impact rights and safety. If your use case falls into those lists, you must not answer “neither” to this question without a formal determination made by your agency’s Chief AI Officer, pursuant to Section 5(b) of OMB Memorandum M-24-10**: Neither
+ **Date when the AI use case’s purpose and high-level requirements were first defined**: 6/1/2022
+ **Date when the acquisition and/or development of the AI system associated with the use case first began**: 11/1/2022
+ **Whether the AI system involved in the use case was developed, or is expected to be developed, exclusively with contracting resources, in-house, or a combination of both**: Developed in-house.
+ **Whether the AI use case made use of agency-wide infrastructure to quickly identify the right datasets to begin model development**: No
+ **General description of the data used for training, fine-tuning, and evaluation of the AI use case’s model(s). This should include a description of any data provided by the agency, whether the datasets are research datasets, publicly available, external, etc. and to the extent possible, sufficiently descriptive information from the vendor**: The algorithm is trained on the following data from extramural grants from fiscal years (FY) 2000-2022 and will use the same for grants in FY2025 and going forward to propose a categorization of basic or applied research: Program Class Code, NIMH Division, NIH Research, Condition, and Disease Categorization (RCDC), Human Subjects Codes, Animal Subjects Code, Clinical Trial, NIMH Division, text of grant title, abstracts, and specific aims. These data are all obtained from NIH IMPACII and will be applied to 100% of NIMH extramural grants, excluding L activity codes. This constitutes approximately 1,500 new grants per FY. No anonymization or de-identification processes are employed as personal information is used neither to train nor classify grants using this algorithm.
+ **Whether the data has sufficient documentation of its integrity, quality, and validity as a training set for a specific task**: Documentation is complete
+ **Whether the AI use case itself has an associated Authority to Operate (ATO), or is part of a system that has an ATO**: No
+ **Estimated length of time the AI project waited for basic computing and developer tools to build machine learning models. This includes Government Furnished Equipment (GFE), along with access to open-source code libraries, frameworks, and other coding software or developer environments**: Less than 6 months
+ **Whether the required IT infrastructure is identified and provisioned via a centralized process (such as a unified intake form) that enables product owners and developers to find the right development environment inside the agency**: Yes
+ **Explanation for whether the AI use case has an identifiable process to request computing resources (such as cloud computing credits or computing hardware) to develop and test models**: Yes
+ **Has the communication been timely**: No
+ **Whether the AI use case promotes re-use of existing infrastructure to promote AI development**: Re-use production level code and/or data products: This use case re-uses production level code as well as data products that have been published or made widely available for data science teams for within the agency.
+ **Whether information regarding the AI use case has been made widely accessible within the agency**: Limited documentation for review: Some information regarding the model’s performance on specific benchmarks are available or have been shared with specific stakeholders within the agency.