Use Case ID,Use Case Name,Agency,Component,Use Case Topic Area,Is the AI use case found in the below list of general commercial AI products and services?,What is the intended purpose and expected benefits of the AI?,Describe the AI system’s outputs.,Stage of Development,"Is the AI use case rights-impacting, safety-impacting, both, or neither?",Date Initiated,Date when Acquisition and/or Development began,Date Implemented,Date Retired,Was the AI system involved in this use case developed (or is it to be developed) under contract(s) or in-house? ,Provide the Procurement Instrument Identifier(s) (PIID) of the contract(s) used.,Is this AI use case supporting a High-Impact Service Provider (HISP) public-facing service?,Which HISP public-facing service is the AI use case supporting?,Does this AI use case disseminate information to the public?,"How is the agency ensuring compliance with Information Quality Act guidelines, if applicable?",Does this AI use case involve personally identifiable information (PII) that is maintained by the agency?,Has the Senior Agency Official for Privacy (SAOP) assessed the privacy risks associated with this AI use case?,Do you have access to an enterprise data catalog or agency-wide data repository that enables you to identify whether or not the necessary datasets exist and are ready to develop your use case?,"Describe any agency-owned data used to train, fine-tune, and/or evaluate performance of the model(s) used in this use case.",Is there available documentation for the model training and evaluation data that demonstrates the degree to which it is appropriate to be used in analysis or for making predictions?,"Which, if any, demographic variables does the AI use case explicitly use as model features?",Does this project include custom-developed code?,Does the agency have access to the code associated with the AI use case?,"If the code is open-source, provide the link for the publicly available source code.",Does this AI use case have an associated Authority to Operate (ATO) for an AI system?,System Name,How long have you waited for the necessary developer tools to implement the AI use case? ,"For this AI use case, is the required IT infrastructure provisioned via a centralized intake form or process inside the agency?",Do you have a process in place to request access to computing resources for model training and development of the AI involved in this use case?,Has communication regarding the provisioning of your requested resources been timely?,"How are existing data science tools, libraries, data products, and internally-developed AI infrastructure being re-used for the current AI use case?","Has information regarding the AI use case, including performance metrics and intended use of the model, been made available for review and feedback within the agency?"
HHS-ACF-00001,Design Your Facility,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The Office of Refugee Resettlement (ORR) manages many facilities for unaccompanied children and must regularly determine bed availability, configuration, and assignments. The current process for gathering this information takes lengthy training and assistance from system administrators.

The Design Your Facility interface leverages LLMs to help users more quickly configure the correct building, room, and bed layout needed to create their facility’s “digital twin” in the UC Bed Network Facility Mapper without lengthy training or deskside assistance from system administrators.","The Design Your Facility tool uses large language models (LLMs) to transform building layout information shared by users in a conversational manner into data about buildings, rooms, and bed layers within the Unaccompanied Children (UC) Bed Network tooling.

The AI model suggests object configurations that should be applied to correctly model a facility’s “digital twin” of the building, room, and bed layout. The workflow relies solely on user descriptions and user confirmations.",Acquisition and/or Development,Neither,02/2024,04/2024,N/A,N/A,Developed with contracting resources.,75D30122F15723,N/A,N/A,N/A,N/A,N/A,N/A,No,No training or fine-tuning; we are using secure commercially available LLMs.,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Horizon (ACF instance of Palantir Foundry),Less than 6 months,No,Yes,No,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00002,Discover Financial Business Intelligence System (FBIS) Report Analysis (Sub-CAN Line Items),HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"This project provides a resource for ACF Discover users in the budget community to identify related line items across disparate reports from FBIS. The process searches the data and aggregates information (e.g. supplier name, document number, total obligations) to create an up-to-date, real-time spend plan that pulls from the open-closed report, requisition purchase order report, and integrates with funds distribution report.

AI returns line items from the open-closed report and requisition purchase order report related to the sub-CAN line item description such as supplier name, document number, document type, and total obligations for that sub-CAN line item. The Discover FBIS Report Analysis (Sub-CAN Line Items) LLM helps find related obligations and line items from various reports and returns information crucial for a budget officer when they are creating a spend plan for their office. The LLM aids ACF Discover track various line items and pulls the information into one place: the Spend Plan module where ACF can track yearly budgets and monitor budget health.","A large-language model helps compile an aggregated report of costs by intaking a specific Congressional Appropriation Number (CAN), category, sub-CAN line item descriptions (which are not standardized), and a projection cost from the user (either by a CSV or manual entry).",Acquisition and/or Development,Neither,08/2024,09/2024,N/A,N/A,Developed with contracting resources.,75P00122A00010/75P00122F37003/P00004,N/A,N/A,N/A,N/A,N/A,N/A,No,No training or fine-tuning. HHS-FBIS reports are used as a data source for retrieval-augmented generation.,Documentation is complete,N/A,N/A,N/A,N/A,Yes,ACF Discover (HHS instance of Palantir Foundry),Less than 6 months,No,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00003,Grant Spend Health Analysis,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The mission of the Office of Grants Management (OGM)is to provide high-quality fiscal stewardship and management for ACF-funded recipients across the country and in U.S. territories. This includes responsive oversight and technical assistance for discretionary awards, non-discretionary awards, and cooperative agreements. OGM seeks ways to prioritize proactive technical assistance to grant recipients based on likelihood that awarded funds may not be fully utilized. 

The goal is to identify still-active grants that are potentially on the path towards deobligating funding. This information would be visible to grant specialists within ACF. OGM anticipates developing customized training and technical assistance materials that can assist recipients if we predict that their grant is trending towards leaving funds unutilized.","As part of this project, we are conducting exploratory analyses including supervised and unsupervised AI techniques to determine whether the data we have on grant spend over time can power a predictive model that reasonably identifies grants with a higher likelihood of under-utilizing funds. ",Acquisition and/or Development,Neither,03/2024,03/2024,N/A,N/A,Developed with contracting resources.,75ACF123F80045,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Grant financial data from usaspending.gov and the Payment Management System. Recipient data from SAM.gov.,Documentation is widely available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-ACF-00004,Structuring and Validating Completeness of Case Data Information,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"In accordance with the Ms L vs ICE settlement, the U.S. Customs and Border Protection (CBP) must provide specific pieces of information about family separations. Beginning November 2024, CPB will release this information. ACF's Office of Refugee Resettlement (ORR) plans to add family separation information to existing child profile information for reference.

The AI output structures free form data into a more easily searchable format. These data will be used to assist in the placement process.","Creates a structured data asset of  the critical data points needed about a separation case. AI will be used to conduct initial parsing of the data provided by CBP and highlight whether or not the required fields from the Ms L vs. ICE settlement are included and can therefore be updated into the child's profile in ORR's data system.  ORR's Intakes Team does final review and in cases where data appears to be missing, the ORR Intakes Team reaches back out to CBP for that information.",Acquisition and/or Development,Safety-Impacting,08/2024,11/2024,N/A,N/A,Developed with contracting resources.,75D30122F15723,N/A,N/A,N/A,N/A,N/A,N/A,No,No training or fine tuning; we are prompting secure commercially-available LLMs.,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Horizon (ACF instance of Palantir Foundry),Less than 6 months,No,Yes,No,Re-use production level code and/or data products,Documentation has been developed
HHS-ACF-00005,Triaging Notice of Concern Submissions,HHS,ACF,Government Services (includes Benefits and Service Delivery),None of the above.,"The Office of Refugee Resettlement (ORR) has amassed a large backlog of Notice of Concern (NOC) PDF forms that contain critical information regarding safety of children who have left ORR's care. 

The AI-powered triage tool will support Office of Refugee Resettlement staff more effectively and efficiently review NOCs by helping structure and prioritize received NOCs. Through more effective triage, ORR will begin to cut down on the large backlog that has accumulated.","In the NOC triage system, AI will be used for two purposes:

1. We will use AI to parse the NOCs to generate structured fields from the text and validate categorizations.

2. AI will provide prioritization recommendations -- but not make decisions -- on the most critical NOCs for the ORR team to review first. ",Acquisition and/or Development,Safety-Impacting,06/2024,06/2024,N/A,N/A,Developed with contracting resources.,75D30122F15723,N/A,N/A,N/A,N/A,N/A,N/A,No,No training or fine tuning.  Notional NOCs were used to prompt engineer secure commercially-available LLMs and evaluate performance. End-user testing was used to evaluate on real NOCs.,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Horizon (ACF instance of Palantir Foundry),Less than 6 months,No,Yes,No,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00006,Unaccompanied Children Program Policy & Procedure Research Tool,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The Office of Refugee Resettlement (ORR) conducts monitoring visits at least monthly to ensure that care providers meet minimum standards for the care and timely release of unaccompanied children, and that they abide by all Federal and State laws and regulations, licensing and accreditation standards, ORR policies and procedures, and child welfare standards. If ORR monitoring finds a care provider to be out of compliance with requirements, ORR issues corrective action findings and requires the care provider to resolve the issue within a specified time frame. Compliance determination involves research into the various laws, standards, policies, and procedures.

The UC Program Policy & Research Tool assists the UC monitoring team with research that in many cases take a long time. The goal of the  UC Program Policy & Research Tool is to speed up this research as children's health and well-being may be impacted before a corrective action finding is issued and the issue is resolved.","The UC Program Policy & Procedure Research Tool speeds up research of relevant laws, standards, policies, and procedures content curated and approved by ORR's policy team. This research is one part of the process that informs ORR's monitoring team's decisions on whether corrective actions are needed and if so, what corrective actions. AI is not used to suggest corrective actions but rather support determination of whether care providers are in compliance.",Acquisition and/or Development,Neither,10/2024,11/2024,N/A,N/A,Developed with contracting resources.,75D30122F15723,N/A,N/A,N/A,N/A,N/A,N/A,Yes,No training or fine-tuning. ORR-approved policy content are used as a data source for retrieval-augmented generation.,Documentation is complete,N/A,N/A,N/A,N/A,Yes,Horizon (ACF instance of Palantir Foundry),More than 12 months,No,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00007,Unaccompanied Children Process Model Digital Twins,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The Office of Refugee Resettlement (ORR) Unaccompanied Children Bureau provides a safe and appropriate environment to children who enter the United States without immigration status and without a parent or legal guardian who is able to provide for their physical and mental well-being (referred to as “unaccompanied children”). ORR funds residential care provider facilities that provide temporary housing and other services to unaccompanied children in ORR custody. ORR and its care providers work to ensure that children are released timely and safely from ORR custody to parents, other family members, or other adults (often referred to as “sponsors”) who can care for the child’s physical and mental well-being. Unaccompanied children remain in ORR’s care and custody until they are released to a parent or other sponsor in the United States, are repatriated to their home country, obtain legal status, or turn 18 years old, at which time they are transferred to the custody of DHS. There are many processes involved throughout.

The goal is for ORR to be more proactive in strategic planning and contingency planning.","ORR is exploring use of process digital twins to provide the ability to run ""what if"" scenarios",Initiated,Neither,10/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-ACF-00008,Analyzing Public Comments on Proposed Rule,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"In the federal rulemaking process, the public has an opportunity to provide comments on proposed new regulation. AI was used to support the public comment review process for a proposed rule to make quality improvements in the Head Start program.

The public comment analysis pipeline provided an Excel spreadsheet of comment segments that were tagged and Word files of topic-based summary drafts. Subject matter experts from the Office of Head Start reviewed comments by topic and further analyzed and refined the topic-based summaries.

The benefit of using AI for this purpose is improved baseline information following public comment to support more expeditious final rule development.","A large language model (LLM) was used to tag public comments by: topics selected primarily by policy experts; sentiment; and intent (e.g. question, suggestion) alongside first drafts of topic-based summaries. ",Retired,Neither,N/A,N/A,N/A,02/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-ACF-00009,Outreach List Segmentation,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The Office of External Affairs (OEA) is responsible for sharing information from ACF with external constituents. OEA had a long list of constituent email addresses that were without context. They wanted the ability to send targeted emails to different groups of people whose organizations work in particular policy spaces.

The AI tool returned a spreadsheet of the provided domains with structured information on likely organization name, summary of their mission, policy domains (e.g. public health, education), and website. This spreadsheet allows OEA to segment their lists and target organizations more efficiently.","An AI-enabled search tool was used to research likely organization name, purpose, and policy space based on the domains (e.g. ""@organization.com"")  from contact email addresses.",Retired,Neither,N/A,N/A,N/A,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-ACF-00010,Ask HR Policy,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"This project provides a resource for ACF Executive Officers/Administrative Officers and managers to easily navigate Human Resources (HR) Policy documentation and quickly get answers to their questions that are based on the official HR Policy Library that is on the HHS.gov website (https://www.hhs.gov/about/agencies/asa/ohr/hr-library/index.html)

Ask HR Policy provides a secure interface permissioned only to select ACF Executive Officers and Administrative Officers.  Users type in questions about managing employees covered by the HR Policy Library, and Ask HR Policy provides a narrative of its “thought process” then suggests an answer based in the documentation, alongside links that take the user to the relevant section of the official document.",We are using LLMs to analyze the questions inputted by users. The AI model synthesizes the provided documentation sources and then summarizes and answers the users questions with cited sources.,Operation and Maintenance,Neither,05/2024,05/2024,05/2024,N/A,Developed with contracting resources.,75P00122A00010/75P00122F37003/P00004,N/A,N/A,No,N/A,No,No,No,No training or fine-tuning. HHS HR Policies were used as a data source for retrieval-augmented generation.,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,ACF Discover (HHS instance of Palantir Foundry),Less than 6 months,No,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00011,Child Welfare Information Gateway OneReach Application,HHS,ACF,Government Services (includes Benefits and Service Delivery),None of the above.,"The Childrens Bureau runs the Children Welfare Information Gateway, a connection to trusted resources on the child welfare continuum. The Information Gateway has a hotline for answering questions or requesting information: https://www.childwelfare.gov/stay-connected/contact/

The Information Gateway hotline automates some of the more routine questions and requests, allowing staff to focus on more complex, nuanced situations.","The Information Gateway hotline connects to a phone interactive voice response (IVR) managed by OneReach AI. OneReach maintains a database of state hotlines for reporting child abuse and neglect that it can connect a caller to based on their inbound phone area code. Additionally, OneReach offers a limited FAQ texting service that utilizes natural language processing to answer user queries. User queries are used for reinforcement training by a human AI trainer and to develop additional FAQs.",Operation and Maintenance,Neither,03/2020,04/2020,06/2020,N/A,Developed with contracting resources.,20EMPO0106,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,Yes,No,No,N/A,Documentation is widely available,N/A,No,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,No,Yes,Yes,None,Documentation has been developed
HHS-ACF-00012,Collective Bargaining Compass,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"This project provides a resource for ACF managers to easily navigate Collective Bargaining Agreement documentation and quickly get answers to their questions that are based on the official 400-page rulebook.

The Collective Bargaining Compass provides a secure Virtual Assistant interface permissioned only to select ACF managers.  Users type in questions about managing employees covered by the Collective Bargaining Agreement, and the Virtual Assistant provides a narrative of its “thought process” then suggests an answer based in the documentation, alongside links that take the user to the relevant section of the official document.","We are using LLMs to analyze the questions inputted by users, which then the AI model synthesizes the provided documentation sources and then summarizes and answers the users questions with cited sources.",Operation and Maintenance,Neither,02/2024,02/2024,03/2024,N/A,Developed with contracting resources.,75P00122A00010/75P00122F37003/P00004,N/A,N/A,No,N/A,No,No,No,No training or fine-tuning. HHS-The NTEU 2023 Collective Bargaining Agreement was used as a data source for retrieval-augmented generation.,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,ACF Discover (HHS instance of Palantir Foundry),Less than 6 months,No,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00013,Discover User Assistant,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"This project provides a resource for ACF Discover Staff Management Module users (i.e. ACF Executive Officers and other ACF administrative and management staff) to easily navigate ACF Discover Staff Management platform and instructional documentation and quickly get answers to their questions about the module’s features.

The User Documentation Assistant provides a secure virtual assistant interface that is only available to ACF Discover Users.  Users are able to ask the assistant specific questions about the capabilities of ACF Discover along with how to leverage tools and applications. The Virtual Assistant is able to provide answers by referencing the User Reference guide.","We are using LLMs to analyze the questions inputted by users, which then the AI model synthesizes the provided documentation sources and then summarizes and answers the users' questions with cited sources.",Operation and Maintenance,Neither,01/2024,01/2024,01/2024,N/A,Developed with contracting resources.,75P00122A00010/75P00122F37003/P00004,N/A,N/A,No,N/A,No,No,No,No training or fine-tuning. HHS-The Discover Staff Management Module User Reference Guide was used as a data source for retrieval-augmented generation.,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,ACF Discover (HHS instance of Palantir Foundry),Less than 6 months,No,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-ACF-00014,Policy Knowledge Base Data Migration,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"The Office of Family Assistance (OFA) provides technical assistance to grantees, including answering questions about policy regarding the Temporary Assistance for Needy Families (TANF) program. Historically, OFA has tracked its accumulated TANF knowledge across disparate locations and file types.﻿

Given the quantity of knowledge base articles involved in this project (>1,100), the AI draft article topics and categories helped speed up the creation of the knowledge base minimum viable product.","As part of a broader effort to establish a TANF knowledge base on a unified platform, large language models were used to: 1) generate draft knowledge base article topics based on historical tracker information; and 2) categorize articles to help organize the knowledge base.",Operation and Maintenance,Neither,06/2024,06/2024,09/2024,N/A,Developed with both contracting and in-house resources.,75ACF123F80045,N/A,N/A,No,N/A,No,No,No,Historical trackers of questions and answers to TANF policy questions,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-ACF-00015,Qualitative analysis,HHS,ACF,Mission-Enabling (internal agency support),None of the above.,"ACF staff often conduct surveys and interviews, which generate qualitative data that needs to be analyzed for themes and trends.

The AI functionality assists users in identifying relevant passages in their narrative data related to specific topics.",We use commercial off-the-shelf software that have built-in AI functionality to suggest topic tagging of qualitative data.,Operation and Maintenance,Neither,03/2023,03/2023,09/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,Yes,No,No,N/A,Documentation is complete,N/A,No,No – agency does not have access to source code.,N/A,No,N/A,6-12 months,No,Yes,Yes,None,Documentation has been published
HHS-AHRQ-00001,AHRQ Search,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"Organization wide search that includes Relevancy Tailoring, Auto-generation Synonyms, Automated Suggestions,  Suggested Related Content, Auto Tagging, and ""Did you mean?"" to allow visitors to find specific content.

This AI use case enhances our agency's efficiency and user experience by optimizing search results, auto-completing queries, suggesting relevant searches and content tags, as well as proposing spelling corrections. ","This AI use case aims to optimize search results by adjusting their ranking, ensuring that the most pertinent information is displayed at the top. It also enhances search effectiveness by adding synonyms to queries behind the scenes. It further improves user experience by auto-completing queries as they are being typed, and showing related searches that might offer additional valuable insights. The system also proposes content tags automatically, leveraging machine learning to assess existing content tagging patterns. Additionally, it suggests spelling corrections and reformats search queries based on data from Google Analytics.",Operation and Maintenance,Neither,09/2019,09/2019,10/2020,N/A,Developed with contracting resources.,75Q80121A00001,N/A,N/A,N/A,N/A,No,No,No,N/A,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,AHRQ AWS Enclave,Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-AHRQ-00002,Chatbot,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"This use case introduces a conversational interface that enables users to ask questions about AHRQ content using natural language. This will serve as a modern, efficient replacement for the traditional public inquiry telephone line.

Improved user experience and reduced resources responding to public inquiries",An interactive interface that can respond to plain language queries in real time using natural language processing,Operation and Maintenance,Neither,10/2020,10/2020,02/2022,N/A,Developed with contracting resources.,75Q80121A00001,N/A,N/A,N/A,N/A,No,No,No,N/A,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,AHRQ AWS Enclave,Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-AHRQ-00003,Chatbot,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"For the Patient Safety Organization Privacy Protection Center website, this use case provides an interface that allows users to conversationally ask questions about content in natural language.

Improved user experience and reduced resources responding to public inquiries",An interactive interface that can respond to plain language queries in real time using natural language processing,Initiated,Neither,08/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-AHRQ-00004,Enhancing Diversity in Peer Review - Pilot,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"The Division of Scientific Review (DSR) is aiming to enhance diversity in AHRQ peer review groups by revising recruitment strategies, aiming for 20% representation from underrepresented minorities in each study section. This process, involving networking, outreach, and various resources, typically takes at least three months.

By utilizing AI to swiftly and accurately identify diverse and qualified grant reviewers, our agency will foster a more efficient process for identifying scientific reviewers and a more equitable and inclusive scientific review process. This will help us achieve our goal of providing safer, high-quality, accessible, and affordable healthcare to individuals and communities throughout the U.S., thereby improving the overall effectiveness of our agency.","This AI use case will involve training an artificial intelligence system to examine the background of peer reviewers - taking into account factors such as expertise, race/ethnicity, gender, and geographic area - and match these inputs to the relevant study section, subsequently referring the reviewer to the Scientific Review Officer (SRO). This flexible system will empower SROs to make the final recruitment decision or to refer the expert to another study section or Special Emphasis Panel (SEP).",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-AHRQ-00005,NLQuery- As Data or Pulse,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"As a feature to clinical dashboards available on a secured page on the Patient Safety Organization Privacy Protection Center website for PSOs who submit data, provides capability to allow user to type a question in common language and instantly get a response. Answers come in the form of automatic data visualizations, with no need to manually drag-and-drop fields or understand the nuances of user's data’s structure.

Improved functionality of the clinical dashboards.  Potential to encourage additional reporting of data in light of benefit to user.","Provide capability to allow user to type a question in common language and instantly get a response . Answers come in the form of automatic data visualizations, with no need to manually drag-and-drop fields or understand the nuances of user's data’s structure.",Initiated,Neither,08/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-AHRQ-00006,Quality and Safety Review System AI-enabled automated abstraction,HHS,AHRQ,Mission-Enabling (internal agency support),None of the above.,"The aim of this AI use case is to enhance or eliminate the need for manual abstraction of patient records and manual data entry into the QSRS tool, thereby streamlining the data entry process.

This AI use case has the potential to significantly help by increasing the volume of cases abstracted while maintaining or lowering government expenditure, thereby enabling more work to be done at the same or reduced cost. Additionally, it can maintain the number of cases abstracted with improved efficiency, thus also reducing government costs by achieving the same output at a lower cost. Furthermore, it will improve abstraction accuracy and expand AI/ML capabilities at both the national and local hospital levels while ensuring data quality improvements so there is trusted and reliable data for reporting purposes.","This AI use case is designed to automate the data abstraction process once the OCR system has transformed PDF images into text. It also aims to automate data entry into the Quality and Safety Review System (QSRS), thereby increasing efficiency and accuracy.",Acquisition and/or Development,Neither,06/2024,10/2024,N/A,N/A,Developed with contracting resources.,75Q80122F80006,N/A,N/A,N/A,N/A,N/A,N/A,No,N/A,Documentation is missing or not available,N/A,N/A,N/A,N/A,Yes,AHRQ AWS Enclave,Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-ASPR-00001,Document Q&A Interface ,HHS,ASPR,Law & Justice,None of the above.,"The SCCT consolidates a number of documents for every response that it monitors, and often analysts have questions about response context stored in those documents

Increase an analyst / user on Protect's knowledge of a specific response or MCM by allowing them to ""ask questions"" of associated / uploaded  SCCT media",Large Language Models are used to query existing documents for answers based on a user's query,Acquisition and/or Development,Neither,07/2024,08/2024,N/A,N/A,Developed with contracting resources.,000HCVL1-2022-66353,N/A,N/A,N/A,N/A,N/A,N/A,No,SCCT Distributor Data,Documentation is complete,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,No documentation is available
HHS-ASPR-00002,Emergency Inventory Redistribution Model,HHS,ASPR,Emergency Management,None of the above.,"Optimization models are needed to identify efficient preparedness and responses strategies for inventory management and distribution during an emergency.

This can be used to identify possible interventions.",This linear programming (constrained optimization) model can identify the optimal strategy for meeting demand for medical supplies during an emergency event.,Implementation and Assessment,Neither,08/2023,08/2023,N/A,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,Documentation has been published
HHS-ASPR-00003,emPOWER AI,HHS,ASPR,Health & Medical,None of the above.,"Public health authorities, first responders and others across the emergency management spectrum indicated that they had to be able to more rapidly access emPOWER publicly available data, particularly in unstable internet conditions, during disasters. emPOWER AI, an  Amazon Alexa Skill, was created to allow anyone with a smartphone to be able to request the data and informational resources.  

First responders, public health authorities, emergency managers, health care providers, and other community partners can use emPOWER AI prior to, during, and after an incident, emergency, or disaster to anticipate, plan for, and respond to the access and functional needs of at-risk populations in their communities using publicly available emPOWER data, informational resources and training.","emPOWER AI gives the user publicly available data from the HHS emPOWER Map on the number of electricity-dependent Medicare beneficiaries at the national, state, territory, county, and ZIP Code levels. It also provides information on other HHS emPOWER Program tools and resources that collectively support emergency preparedness, response, recovery, mitigation, and resilience activities. ",Operation and Maintenance,Neither,01/2018,09/2017,01/2019,N/A,Developed with contracting resources.,GSA Schedules,N/A,N/A,Yes,N/A,No,No,No,None,Documentation is complete,N/A,No,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-ASPR-00004,Entity Resolution Tool,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"SCCT receives order information that references thousands of manufacturers and customers. These data need to be standardized.

This allows analysts to aggregate data by manufacturer or customer to better characterize order and delivery patterns.","This tool uses embedding models, hierarchical clustering, and large language models to identify groups of duplicate entity names and assign a new standardized name.",Implementation and Assessment,Neither,06/2024,07/2024,N/A,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,No documentation is available
HHS-ASPR-00005,Executive Report Generation AI Copilot ,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"SCCT produces executive summaries and commercial product awareness reports (CPARs) on supply chain disruptions, weather events, shortages, etc. These utilize a large amount of SCCT data that needs to be summarized and explained in detail.

Used to decrease the amount of time needed to produce an executive report, reducing the need for SCCT analysts to create them from scratch every time",Large language models are utilized to summarize existing documents and data in order to produce the base text for an executive report. ,Operation and Maintenance,Neither,02/2024,02/2024,03/2024,N/A,Developed with contracting resources.,000HCVL1-2022-66353,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,No,Yes,No,Use of existing data platforms,No documentation is available
HHS-ASPR-00006,Flow Model Edge Prioritization Estimation Tool,HHS,ASPR,Emergency Management,None of the above.,"This model is needed to investigate potential impacts of supply disruptions.

This is one component in a simulation tool used to quantify the impact of supply chain disruptions on customers.",This model uses linear regression to summarize patterns in preferential order fulfillment and predict future fill rates.,Operation and Maintenance,Neither,05/2023,09/2023,08/2024,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,No documentation is available
HHS-ASPR-00007,Generalized Demand Model Sensitivity Analyzer,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"The generalized demand model is used by SCCT to create demand projections for critical medical products.

This is a diagnostic tool used to help analysts understand and refine their models.",This constrained regression model is used to identify the primary drivers of uncertainty in demand models and quantify their impact.,Operation and Maintenance,Neither,09/2023,12/2023,02/2024,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,None,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,No documentation is available
HHS-ASPR-00008,Google Search Model Alerts,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"Publicly available information can enhance the ability to identify supply chain disruptions.

This provides automated alerts that can help trigger review of the relevant data by analysts.","This model, based on exponentially weighted moving averages, identifies rising trends in timeseries related to google search volume for keywords of interest.",Operation and Maintenance,Neither,01/2023,06/2023,04/2024,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,None,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,Documentation has been published
HHS-ASPR-00009,Google Search Model Rising Trend Entity Extraction,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"Publicly available information can enhance the ability to identify supply chain disruptions.

The list of products produced by this model helps analysts identify products that may be in shortage.",This tool uses language models to identify the object in shortage from a list of shortage related rising search terms identified by Google.,Operation and Maintenance,Neither,01/2023,06/2023,04/2024,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,None,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,Documentation has been published
HHS-ASPR-00010,Manufacturer Name Standardization,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"The SCCT receives many manufacturer name variants from its many distributors that need to be consolidated and standardized

This allows analysts to have more standardized manufacturer names for reporting","An advanced grouping algorithm groups similar manufacturer names together, and a Large Language Model recommends a standardized name based on all variants",Operation and Maintenance,Neither,04/2024,04/2024,08/2024,N/A,Developed with contracting resources.,75A50122C00052,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,No,None,No documentation is available
HHS-ASPR-00011,Model based open source reporting search and summarization,HHS,ASPR,Law & Justice,None of the above.,"SCCT collects open source information for monitoring supply chain events.

Language models provide an initial summary that analysts can use to select topics of interest in order to focus on relevant events.",Large language models are used to search open source information and summarize topics related to supply chain events.,Initiated,Neither,08/2024,N/A,N/A,N/A,Developed with contracting resources.,000HCVL1-2022-66353,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-ASPR-00012,PPE Product Classification Model,HHS,ASPR,Mission-Enabling (internal agency support),None of the above.,"SCCT receives information about thousands of products from distributors.  This is used to predict if the product falls into one of the following 7 categories: 1) Gloves – Surgical & Exam, 2) Needles & Syringes, 3) Gowns – Isolation & Surgical, 4) Masks – N95, 5) Masks – Surgical/Procedural, 6) Eye / Face Shields, 7) Test Kits.

These classifications are used to aggregate data in order to make it possible to analyze trends.",This model uses bayesian anomaly detection and random forests to assign products to a list of predefined product classifications.,Operation and Maintenance,Neither,01/2023,01/2023,01/2023,N/A,Developed with contracting resources.,000HCVL1-2022-66353,N/A,N/A,No,N/A,No,No,Yes,SCCT Distributor Data,Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,6-12 months,No,Yes,No,None,No documentation is available
HHS-CDC-00002,Adverse Childhood Experiences (ACEs) Literature Review Dashboard,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This solution will impact the process of conducting literature reviews for scientific research related to ACEs.

Identifying relevant articles in a literature review is a time intensive process. Utilizing large language models, this system enables quick identification of relevant articles to be included in a ACEs literature database. This database allows ACEs researchers within CDC's National Center for Injury Prevention and Control a quick reference to develop hypotheses and identify gaps in the ACEs literature",This solution automatically determines the relevancy of published journal articles. Relevant articles are included in a master dataset that is linked to a PowerBI,Acquisition and/or Development,Neither,02/2024,03/2024,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,Data used are published journal articles which may or may not be owned by CDC but may be accessed either through freely accessible sources or specific agreements CDC has to research articles.,Documentation is missing or not available,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-CDC-00003,Automated Analysis of Injury Control Research Center (ICRC) Annual Progress Reports (APRs) using Large Language Models,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI affects the process of reviewing and analyzing the Annual Progress Reports (APRs) submitted by Injury Control Research Centers (ICRCs). Specifically, the AI will focus on identifying and analyzing text sections of the APRs that detail reported challenges, as well as other text-heavy sections in future stages of the project. The AI is designed to streamline the review process, improve efficiency, and support the evaluation of the performance and progress of ICRC-funded activities.

The output of the AI will help to quickly and efficiently identify key challenges and insights from ICRC APRs, enabling more effective decision-making in the review process. By automating the extraction and analysis of critical information, the AI allows the ICRC team to focus on higher-level evaluation and strategic planning. The AI will help reduce the time and resources needed for manual review, improve the consistency and accuracy of assessments, and facilitate faster responses to ICRC needs. Ultimately, this will support ICRCs in overcoming challenges and achieving their research and injury control goals, benefiting the public health system as a whole.","The AI analyzes the textual content of APRs. We have started our analysis by focusing on the sections detailing the challenges faced by ICRCs during the 2019 funding cycle. The AI identifies key themes, trends, and critical information that may require further attention. The AI methodology extracts insights and patterns from the data, which can then be compared with manual qualitative analysis outcomes. In subsequent stages, the AI will be expanded to analyze other sections of the APRs, such as progress toward goals and program impact.",Acquisition and/or Development,Neither,08/2023,12/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,Injury Control Research Center Annual Progress Reports,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CDC-00004,Detecting Stimulant and Opioid Misuse and Illicit Use,HHS,CDC,Health & Medical,None of the above.,"Federal Health Survey analysis. The machine learning models created in this project will have an impact on the statistical analysis of electronic health record (EHR) data gathered through the (NHCS) National Hospital Care Survey. Furthermore, when the model is made available to the public, it may also influence the analysis of other user datasets that contain EHR clinical notes.

Certain non-therapeutic models do not have corresponding medical codes available in clinical notes and the information is only available in free-text fields. The machine learning models help to discover non-therapeutic drug use as described in EHR clinical notes which are novel insights previously impossible to gleam from EHRs without AI.","Two machine learning models will be created, one for internal use and another for public release. In both instances, these models will be utilized alongside rule-based text analysis to ascertain whether a patient in a hospital setting has used a drug therapeutically (in accordance with medical prescription) or non-therapeutically. This information is used to gather new insights from EHRs for health statistics published through the NHCS.",Acquisition and/or Development,Neither,03/2024,09/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,National Hospital Care Survey 2020 clinical notes,Documentation has been partially completed,N/A,N/A,N/A,N/A,No,N/A,More than 12 months,Yes,Yes,No,None,Limited documentation for review
HHS-CDC-00005,DHP Virtual Assistant,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Literature Review for HIV research. The AI virtual assistant will help HIV researchers with information retrieval on information related to HIV and HIV research. 

Our AI virtual assistant will help increase productivity among our HIV researchers by retrieving information related to HIV and HIV research.",This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query and other documents.,Acquisition and/or Development,Neither,11/2024,11/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Internal documentation containing mapped eHARS LOINC codes, IQVIA data dictionaries, APRs",Documentation is complete,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-CDC-00006,Fuzzy matching tool,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Clearance and review management of CDC publication. CDC's Office of Science (OS) manages the eClearance information system, which is responsible for tracking the submission of CDC-authored journal manuscripts and Morbidity and Mortality Weekly Reports (MMWRs) for CDC's internal peer review process.

This tool will help ensure CDC-authored publications have completed the National Institutes of Health Manuscript Submission (NIHMS) process and are compliant with CDC's public access to publications policy. It will also be used to help centers and divisions identify publications from their organization for science prioritization and impact analyses.","The fuzzy matching tool uses pre-trained, open source LLMs to identify similar records between eClearance submissions and CDC-authored publications. This tool is intended for internal use only.",Acquisition and/or Development,Neither,09/2022,03/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,eClearance submissions data and Science Clips data,Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-CDC-00007,Global (GIB) Initiative for Influenza Vaccine Equity (GIIVE): Ensuring Universal Access,HHS,CDC,Health & Medical,None of the above.,"Literature Review

The output is a list of abstracts that may have related information to vaccine inequity. These identified abstracts will be reviewed ""by-hand"" and then those associated publications will be reviewed by epidemiologists further.","The Through APIs, large language models are used to review a large number of abstracts to help identify which kinds of groups may be least likely to obtain vaccines in the global space--marginalized groups within country, for example.",Acquisition and/or Development,Neither,10/2024,10/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,Data used are published journal articles which may or may not be owned by CDC but may be accessed either through freely accessible sources or specific agreements CDC has to research articles.,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-CDC-00008,HIV Data Virtual Assistant,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The AI will impact the data retrieval and automation process for HIV researchers, specifically in providing information from datasets and potentially generating code for desired variable names and analysis or generating information about a particular dataset.

This solution aims to alleviate the challenges faced by scientists searching for the appropriate HIV-related data to address their inquiries. This will improve productivity and research efforts.","This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query. Our aim is to input all dataset documentation and metadata into an index with the goal of creating a virtual assistant. This assistant offers support to our HIV researchers by providing the information they seek from the data and potentially generating SAS, R, or Python code for desired variable names. For instance, if we require a dataset containing HIV PrEP information, we can request it to generate a list of current datasets that contain data on PrEP medication usage in 2019, along with the associated variable names. Subsequently, we can instruct it to produce lines of code, such as a logistic regression, which can be readily copied and pasted into our analysis software of choice. Another example would be if our researchers would like information returned about a given dataset, this assistant could return specific information based on the researcher's query.",Acquisition and/or Development,Neither,11/2024,11/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Internal documentation containing mapped eHARS LOINC codes, IQVIA data dictionaries",Documentation is complete,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-CDC-00009,Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images,HHS,CDC,Health & Medical,None of the above.,"The physical environment, such as sidewalk availability, in areas may be correlated to levels of physical activity. The Physical Activity (PA) and Health Branch is responsible for monitoring and gathering data on physical activity behaviors, as well as assessing the environments that promote physical activity.

The implementation of this technology has the potential to streamline the surveillance of sidewalks, which play a crucial role in supporting physical activity (PA). The existing methods for cataloging sidewalks, such as manual inspection, are labor-intensive and costly. However, this technology has the capability to significantly minimize the effort required for such tasks.","The Division of Nutrition, Physical Activity, and Obesity within CDC's National Center for Chronic Disease Prevention and Health Promotion aims to explore and advance the use of machine learning methods for identifying sidewalks, bicycle lanes, and other relevant infrastructure in various types of images, including satellite and roadway images. The input data would consist of image-based data, while the outputs could take the form of geocoded data tables, maps, GIS layers, or summary reports. The goal is to develop and promote these techniques to enhance understanding and analysis of built environments related to physical activity.",Acquisition and/or Development,Neither,09/2022,09/2023,N/A,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,none - we used publicly-available images,Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,No,Re-use production level code from a different use-case,No documentation is available
HHS-CDC-00010,Immunization Information Systems Guidance Documentation Navigation and Management (IDAB EDAV Azure OpenAI Technology Use),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI solution (chatbot) helps with retrieving information and updating guidance documentation by increasing interactivity and discoverability of information in the Immunization Information Systems (IIS) domains of HL7 electronic data exchange standards, CDSi (Clinical decision support for immunizations), and IIS operational best practices. It provides a modernized approach to knowledge retrieval and real-time guidance, as well as support the creation of new guidance by leveraging the AI capabilities in natural language processing and content generation to draft, refine, and validate new guidance documents efficiently and accurately.

This AI solution creates a better, faster, and more actionable method for IIS SMEs to obtain IIS guidance from previously published and publicly available IIS documentation. This solution will provide a more modernized approach to knowledge retrieval and real-time guidance, as well as support the creation of new guidance by leveraging the chatbots capabilities in natural language processing and content generation to draft, refine, and validate new guidance documents efficiently and accurately.
This AI solution (chatbot) provides an efficient and user-friendly way to search, interact, and update these IIS guidance documents. It can help experts answer questions faster, new employees find information more easily, and employees better understand best practices.","This AI solution (chatbot) uses Retrieval Augmented Generation (RAG) to retrieve and synthesize information from a limited set of publicly available IIS guidance documents related to the HL7 Electronic Exchange Standard specification, Clinical Decision Support for Immunization (CDSi) and IIS Operational Best Practices. It does this using a Question-and-Answer style interface, allowing team members to retrieve answers in an efficient and user-friendly way.
On 07/26/2024 the CDC Information Technology and Data Governance (ITDG) Executive Committee has approved this investment “to use AI to create a system that can conduct a dialogue with a user and answer questions about the contents of already approved public documents”.",Acquisition and/or Development,Neither,10/2022,08/2024,N/A,N/A,Developed with both contracting and in-house resources.,"75D301-22-C-13291, 75D30124C20195",N/A,N/A,N/A,N/A,N/A,N/A,No,"We did not do any training or fine tuning, but we used the following materials to evaluate the chatbot: HL7 Documentation Data, CDSi Logic Specification 4.4 Data. This information is entirely publicly accessible.",Documentation is widely available,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Documentation has been developed
HHS-CDC-00011,LaserAI,HHS,CDC,Health & Medical,None of the above.,"This project aims to evaluate a commercial off the shelf, software as a service systematic review project management software. This software uses machine learning/ natural language processing to support title and abstract screening, PDF retrieval, full text review, and most importantly data extraction to reduce screening time and improve accuracy of all phases of a systematic review.

The extracted data will be synthesized and graded, and will be used to inform the development of evidence-based infection prevention and control recommendations for healthcare settings.","This AI uses natural language process to (1) identify potentially relevant articles and prioritize them for screening, (2) retrieve PDFs from PubMed, and (3) suggest data in PDFs for extraction.",Acquisition and/or Development,Neither,04/2024,04/2024,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"None: Any data used to train the AI is publicly available, peer-reviewed data.",Documentation is missing or not available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-CDC-00012,NewsScape,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Development of early warning indicators. News articles can form an early warning indicator of public health events and other pieces of information which can be utilized across all major domains of public health. Because of the quantity of news articles, manual efforts are impossible to gather this information.

There are a variety of endpoints that this AI output could help support. Various teams across the CDC have expressed interest in being able to quickly get the right news content, with summaries of those articles to help support outbreak detection, report generation, surveillance and monitoring of pathogen specific news, etc. AI lets us efficiently filter and summarize thousands of news articles a day into a handful of daily ""news events"" that user can glean information from. ","NewsScape is a AI enabled news aggregation and summarization that is hosted within the 1CDP platform. The main motivation to build  NewsScape was to develop a system that uses Large Language Models (LLMs) to surface relevant insight from recent news articles. NewsScape ingests a high volume of news articles, in the order of thousands of news articles everyday, and surfaces the information from them that related to the topic we were interested (for example, pathogen related news articles, or U.S. medical supply chain updates).  The tool can be customized based on specific program office needs, and can be deployed independently of one another so that one program office can have their own custom version of NewsScape installed.",Acquisition and/or Development,Neither,01/2023,01/2023,N/A,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,None,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,1 CDC Data Platform (1CDP),6-12 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-CDC-00014,RAPID Analysis of Policy and Program Documents (RAPID),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Policy and documentation awareness and evaluation

The web application will: 1) save staff time by streamlining laborious document reviews; 2) expand capacity by reducing the need for specialized staff training and skills; 3) provide complete, plain language answers to policy surveillance and evaluation questions along with binary codes or scores; 4) answer questions consistently (i.e., reduce intra-rater variability for redundant coding); and 5) enable easy validation of AI-provided answers.",An internal web application  will enable CDC users to: 1) import and securely store policy or program documents; 2) search for relevant documents; 3) ask questions of relevant text segments; 4) validate answers; and 5) collaborate on policy surveillance and evaluation projects.,Acquisition and/or Development,Neither,11/2021,09/2022,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"RAPID analysis of DNPAO policy and program data using GPT will results in project specific databases. To ensure accuracy and reliability of these AI-generated data, they will be compared to data of CDC manual reviews of the same documents by SMEs.  ",Documentation is missing or not available,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-CDC-00015,SewerScout: Automated on-site sewage facility detection from aerial imagery to identify failed systems,HHS,CDC,Health & Medical,None of the above.,"This business process focuses on the automation of the accurate identification of onsite wastewater systems in state, tribal, local, and territorial (STLT) health jurisdictions. This application scans aerial imagery and uses object detection and image classification models to detect onsite sewage facilities. Initial work is focusing on the ability to identify known systems.

 The intent of this project is to identify failed systems, which can be sources of soil and drinking water contamination as well as vectors that carry or transmit disease in the community. This project will allow STLT partners to readily characterize the location and functional status of septic systems without the time and resource consuming effort of visiting each household. The resources in many local health districts (LHDs) are barely adequate to undertake assessments of suitability  for new systems (if not entirely contracted out) and most LHDs do not have any program to routinely inspect current systems. If successful, this project will allow state, tribal, local, and territorial public health departments to more easily identify failing septic systems and work to address them.  If successful, subsequent work will work on differentiating functional from failed systems. Identification of septic systems during routine operations would help bolster and expedite disaster response efforts after major disasters  by having a ready catalog of systems and using pre- / post-disaster satellite images to direct resources in a much more efficient way than on-the-ground door-to-door surveys in rural / remote locations. ","The intent of this project is to identify failed wastewater systems, which can be sources of soil and drinking water contamination as well as vectors that carry or transmit disease in the community.",Acquisition and/or Development,Neither,01/2023,01/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,The project has not selected the final sources of data but no agency-owned data is anticipated to be used to train the model.,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,More than 12 months,Yes,Yes,No,Use of existing data platforms,Limited documentation for review
HHS-CDC-00016,Sidekick Comms bot Offering User-friendly Tips (SCOUT),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The AI will impact the content creation processes for CDC.GOV and reduce burden in creating new webpages. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.

The solution aims to reduce the workload of health communicators by simplifying the process of creating new web pages and social media posts. By leveraging Generative AI technology, we can produce new content much more quickly than if communications staff were to do it on their own. The goal is to make the published content more accessible and understandable for the general public, ensuring that CDC information reaches a wider audience. It's important to note that all content generated by the AI is carefully reviewed and edited by a human before it is used and the follow disclaimer is stated with public content that this tool has been used with: ""CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.""","CDC's National Center for Chronic Disease Prevention and Health Promotion use of Generative AI in this use case is to help convert existing web content into plain and clear language. This solution uses Gen AI to create new versions of publicly available content that are easier for end-users to understand. By incorporating prompts, the tool makes the content more suitable for a general lay audience. In addition to web articles, the Generative AI tool also allows for the creation of social media posts. The goal of this project is to make information more accessible by providing plain language content on various platforms. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.",Acquisition and/or Development,Neither,12/2024,01/2024,N/A,N/A,Developed with contracting resources.,NCCDPHP OD IAA,N/A,N/A,N/A,N/A,N/A,N/A,Yes,None,Documentation is complete,N/A,N/A,N/A,N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-CDC-00017,Transcribing Cognitive Interviews with Whisper,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Federal Health Survey Research. Specifically, Cognitive interviews are a form of qualitative research where interviewers ask probing questions to understand how the interviewee understands a concept which is being asked about in a federal survey. These interviews are a key part of survey design to identify any potential misconceptions and prevent lengthy and hard to answer questions which could create potentially wrong health statistics. These interviews are time consuming to perform and report as they are inherently individual and require extensive hours to transcribe. By using AI to transcribe the interviews, researchers can potentially cut down on the hours or qualitative review, increasing the speed of research publication and quality of survey questions used on federal surveys.

Without transcripts, these interviews have to be listened to repeatedly taking at least the same amount of time as the full length of the interview to find important pieces of information for their work. These transcripts can greatly reduce the burden on researchers by enabling immediate comparison of concepts and answers along with timestamps created for researchers to reference in review.",This AI generates transcripts from recorded interviews for staff to use when performing qualitative research to assist with Federal Health Survey research.,Acquisition and/or Development,Neither,10/2022,07/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"None, publicly available data was used to evaluate performance",Documentation has been partially completed,N/A,N/A,N/A,N/A,No,N/A,More than 12 months,Yes,Yes,No,Re-use production level code from a different use-case,Limited documentation for review
HHS-CDC-00018,Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This use case is aimed to assist in the review of public comments for Notices of Proposed Rulemaking. All responses are manually reviewed following this tool usage.

By law, Public comments are required to be manually review for any notice of public rule making. These comments are highly labor intensive due to both the quantity and wide range of potential opinions shared by the public. These comments can range in both length of response and quantity serving as a challenge for properly ensuring the insights from the public are accurately gathered in the review process. By using an LLM based Topic Modeling approach, manual reviewers can organize responses based upon theme to enhance both the insights gained, the speed of manual review, and ensure all topics mentioned can be accurately reported in all review processes. This process can use open source python libraries and open-source LLMs to complete different actions. This AI methodology enables manual review processes to be more effective in gaining insights from the public, better organized in themes and categories present within text, and reduce the burden of manual review of comments from notices of proposed rulemaking required by law.",Generates clusters of similar public comments to a 'notice of proposed rulemaking' to aid in manual review.,Acquisition and/or Development,Neither,02/2023,04/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,None,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,"Enterprise Data, Analytics, and Visualization Platform",Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-CDC-00019,Center for Forecasting and Outbreak Analytics Disease Modeling,HHS,CDC,Health & Medical,None of the above.,"Federal and State, Tribal, Local, and Territorial health department responses to disease outbreaks depends on being able to predict the future behavior of a given outbreak as well as the potential impact of different responses to the outbreak. This project aims to build models of disease spread that allow for (1) determining if and where infection/impact rates are growing or increasing (2) forecasting future disease progression (3) modeling specific scenarios such as the impact of vaccination.

We use model output to provide information to Federal and SLTT decision makers to improve disease response. This allows those decision makers to determine where and how to direct resources in a disease out break as well as the impact of potential response actions. This kind of insight is critically dependent on mathematical modeling.","This project  models disease spread and impact based upon a set of models, a variety of data sources, and allows for the inclusion of the impact of potential public health actions such as vaccinations. These insights can be used by public health decision makers to inform current and future responses to public health emergencies",Implementation and Assessment,Neither,04/2022,04/2022,N/A,N/A,Developed with both contracting and in-house resources.,75D30123F16628,N/A,N/A,No,N/A,No,No,Yes,"A wide array of public health data including hospital admissions data from NHSN, emergency department visit data from NSSP, case reports provided to CDC from local jurisdictions, variant prevalence data sourced from public health laboratory samples, wastewater data from NWSS, and other related sources.",Documentation is complete,N/A,Yes,Yes – source code is publicly available.,"https://github.com/cdcgov/dynode; https://github.com/cdcgov/ixa -- note, not all code is currently public",Yes,"Enterprise Data Analytics and Visualization (EDAV) Platform, EDAV-EXT, 1 CDC Data Platform (1CDP)",Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Documentation has been published
HHS-CDC-00020,ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Data Analysis),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI system is an extension of the GenAI chatbot but is only available to a small group of pilot testers as of November 5, 2024. It operates through an ATO'ed instance of Microsoft Azure OpenAI through CDC's Enterprise Data Analytics and Visualization Platform. Using a method called retrieval augmented generation (RAG), this enhancement enables staff to augment the existing GenAI chatbot with access and “knowledge” of internal or enterprise data such as documents, spreadsheets, and PDFs. Additionally, each chatbot response has citations referencing to the sections of source text that informed the response, which facilitates human-in-the-loop validation for accuracy and relevancy of AI-generated content.

One way users are using this tool is for data extraction, which accelerates analysis of large document sets. By extracting key points from large volumes of text in various file formats, the enterprise-data-enhanced chatbot streamlines access to critical insights from reports, internal documentation, publications, and other documents. For example, one team is using the chatbot to support literature review by extracting information related to housing status and HIV in the US from a set of pre-screened publications. Examples of this information include a binary yes/no on whether the research paper focuses on the topic of interest, the paper’s population of focus, and the type of paper.

The enterprise data chatbot’s ability to quickly and accurately extract relevant information reduces manual search time and errors associated with human data retrieval. The output will be leveraged for more accurate data analysis, timely insights, and better-informed decision-making processes.","When the user enters a prompt or query related to data extraction into the chatbot, the tool uses a GPT-4 model and Azure AI Search within a RAG architecture to retrieve relevant sections of text from the provided enterprise data sources and extract key information as instructed by the user’s prompt.",Implementation and Assessment,Neither,06/2024,06/2024,N/A,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,None,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-CDC-00021,ChatCDC- CDC Enterprise GenAI Chatbot: Bring your own Enterprise Data (Summarization),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI system is an extension of the GenAI chatbot but is only available to a small group of pilot testers as of November 5, 2024. It operates through an ATO'ed instance of Microsoft Azure OpenAI through CDC's Enterprise Data Analytics and Visualization Platform. Using a method called retrieval augmented generation (RAG), this enhancement enables staff to augment the existing GenAI chatbot with access and “knowledge” of internal or enterprise data such as documents, spreadsheets, and PDFs. Additionally, each chatbot response has citations referencing to the sections of source text that informed the response, which facilitates human-in-the-loop validation for accuracy and relevancy of AI-generated content.

The enterprise data chatbot’s summaries will enhance operational, informational, and decision-making processes that would otherwise require extensive research and reading time. For an example of a more informational use case, one team provided the chatbot with documentation and resources about a division’s organizational structure, projects, administrative processes, and tools to support the orientation of new staff and (re)orientation of existing staff. The chatbot enables the division’s staff to efficiently find resources for their roles; better understand the division’s initiatives; and track the activities involved in the onboarding process for new staff.","When the user enters a prompt or query related to summarization into the chatbot, the tool uses a GPT-4 model and Azure AI Search within a RAG architecture to retrieve relevant sections of text from the provided enterprise data sources and condense that information into concise summaries in response to the user’s prompt. ",Implementation and Assessment,Neither,06/2024,06/2024,N/A,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,None,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-CDC-00022,Leveraging AI for Metadata Tagging for Enterprise Data Catalog of CDC,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC’s Enterprise Data Catalog provides an internal single centralized inventory of available datasets within CDC staff. It provides data management and search tools to help users find what they need and aims to provide descriptions to aid in relevance determinations for users. This is from the appropriate metadata, e.g. project title, description, or other important information describing the dataset. Because of the previous manual metadata tagging process, many datasets catalogued do not have the appropriate tags to help staff determine the relevance of any particular dataset available within CDC for particular tasks.

Because of the lack of standardization and gaps in metadata fields, this AI's output will greatly increase the speed for applying the appropriate metadata fields for each dataset within the catalogue to increase the usability of the product. This reduces the time and effort required for manual tagging and improves the consistency and completeness of metadata. ",AI is used in this case to generate suggested metadata fields based upon existing metadata information provided by a dataset. These tags would then be used for staff accessing the enterprise data catalogue to discover datasets and find connections to support existing on-going work.,Implementation and Assessment,Neither,06/2024,06/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,Enterprise Data Catalog Metadata fields,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-CDC-00023,Malaria parasites DNA barcode geography classification,HHS,CDC,Health & Medical,None of the above.,"Epidemiological investigations of Malaria

To complement epidemiologic investigations of domestic malaria cases, including cases that were domestically acquired. This information can help assess the origin of the malaria strain in question, which can help us understand how the strain entered the US. For more information, please see the following manuscript: https://journals.asm.org/doi/full/10.1128/aac.01203-24","Algorithm examines a sequence barcode/genotype (our use case is for malaria, but it can be applied to other contexts) and it assigns the malaria parasite genotype to a geographic origin, which may be a continent or some other geographic regional category. While this use case has the barcode as a set of genetic loci from malaria parasites, and the categories are geographic (i.e., continents, subregions), the algorithm could be trained to assign genetic barcodes from other pathogens to any number of different categories assuming the appropriate training dataset exists.",Implementation and Assessment,Neither,07/2023,07/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,"Data used are a mixture of data generated at CDC and other data available publicly. All CDC data are accessible via the following links: https://www.ncbi.nlm.nih.gov/bioproject/PRJNA428490/, https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1092573/, https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA1110244. Travel histories from case patients were used to assess performance of the model to compare the generated output of the model and are available in the following manuscript: https://journals.asm.org/doi/full/10.1128/aac.01203-24. Non-CDC owned data are available through this link: https://apps.malariagen.net/apps/pf7/",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Advanced Molecular Detection Scientific Computing Platform,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00024,The School Closure Awareness System,HHS,CDC,Emergency Management,None of the above.,"Identifying unplanned school closures. CDC is responsible for supporting schools before, during, and after and emergency. During COVID 19 this included monitoring school closure or virtual status and reporting this to federal partners, the White House, and the public. Due to cost the process used during COVID was no longer feasible and ceased in DEC 2022. We explored multiple ways to capture this data and our current system met the need best. 

This AI has allowed us to save nearly 2-million-dollars from contracting fees and decrease human work hours by 200 hours. It has made the capture of some of this data possible after cessation of the process used during COVID 19 which we could no longer support. The AI supported system is faster and captures more information about individual closures than the original human-powered process.","This system uses publicly available Facebook posts from approximately 40,000 school or district Facebook accounts. Then uses a large language model to categorize posts as unplanned school closure for several types of events (weather, health, facility issues, safety). It also will denote the type of status change (full closure, virtual, hybrid, or early / late dismissal). The data is checked and recoded (if needed) by a staff person every 24 hours.",Implementation and Assessment,Neither,07/2022,11/2022,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,None,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,"Enterprise Data, Analytics, and Visualization Platform",More than 12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00025,Using Generative AI for Stance Analysis of Public Comments on CDC’s Proposed Rules,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"By law, Public comments are required to be manually review for any notice of public rule making. These comments are highly labor intensive due to both the quantity and wide range of potential opinions shared by the public. These comments can range in both length of response and quantity serving as a challenge for properly ensuring the insights from the public are accurately gathered in the review process. By using an LLM based Topic Modeling approach, manual reviewers can organize responses based upon theme to enhance both the insights gained, the speed of manual review, and ensure all topics mentioned can be accurately reported in all review processes. This process can use open source python libraries and open-source LLMs to complete different actions.

 As public feedback on various rules gets collected across the CDC’s divisions, this initiative along with other NLP approaches can potentially save time for CDC’s public policy experts during public comment review. ","Reviewing the public comments currently involves a manual review process that necessitates a high level of time and effort on the part of regulatory analysts. To improve the process of reviewing public comments as part of regulatory analysis, our team implemented topic modeling (Grootendorst et al., 2022) and sentiment analysis (Hartman et al., 2023) of comments published to the new amendment to foreign quarantine regulation published by CDC on July 10, 2023. This solution expands these efforts by using generative AI models  to try for capture stance expressed in each comment. While there is also an option to manually label and train models for stance detection, custom-trained text classification models may not be transferable to future rules due to rule-specific discussions and arguments. In contrast, using generative AI models for stance detection can be transferable to future rules irrespective of the discussion contexts and arguments.",Implementation and Assessment,Neither,07/2023,07/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,NA,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CDC-00026,A reusable NLP pipeline for clinical narratives preprocessing and characterization,HHS,CDC,Health & Medical,None of the above.,"Data cleaning of Clinical narratives from health records. At scale, clinical narratives are a dataset available to CDC currently underutilized as there is not a structured pipeline to identify structured information output. We are currently working on setting up a process to create a pipeline that cleans data markup (html, rtf, xml) and identifies signs and symptoms using pre-trained Named Entity Recognition (NER) tasks from relevant models published in peer review journals. 





The use of these pretrained models significantly reduces  the amount of time a human to spend tagging data and provides additional features and increased consistency from unstructured data for identification of more novel insights. ","The objective of this project is to take unstructured data, clean it, and use pretrained Named Entity Recognition (NER) tools to extract signs/symptoms in deidentified electronic health records that can be used to characterize a cohort or make further analysis.",Initiated,Neither,07/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00027,Autocoding to Support Adverse Drug Event Surveillance,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The model will help surveillance epidemiologists working at CDC to determine whether reported potential adverse drug events in the National Electronic Injury Surveillance System Cooperative Adverse Drug event Surveillance meet the agency's surveillance case definition for the same.

It will speed up coding of the drug event reports, helping epidemiologists produce prevalence estimates for the surveillance system.","The model will take a de-identified free-text description of the patient's emergency department visit encounter, along with a handful of other pre-coded variables, and output the probability that the encounter meets the case definition.",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00028,Automating LIMS Bioinformatics Workflow Configuration and Enhancing Lab Quality Management with AI,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The tool proposed will impact the laboratory bioinformatics workflow configuration within the Core Laboratory's Genomics Sequencing Lab (GSL). Specifically, it will improve the efficacy with Clarity LIMS for tracking and processing Next Generation Sequencing (NGS) samples. This includes the creation and customization of bioinformatics workflows in the Laboratory Information Management System, which is currently a time-consuming and expertise-intensive task for bioinformaticians and laboratory scientists.

The RAG system can potentially reduce the time required to configure Clarity LIMS workflows, enabling rapid deployment which is particularly crucial during pandemics or outbreak responses. By simplifying the workflow customization process through natural language inputs, it lowers the barrier to entry for laboratory scientists and bioinformaticians who may not be familiar with XML scripting. The system also enhances team learning and training by providing easy access to relevant documents on quality management and regulations, ensuring that all team members are well-informed about best practices.","We propose to use a Retrieval-Augmented Generation (RAG) framework for two primary functions: It converts natural language lab protocols into precise XML workflows that are compatible with Clarity LIMS. This conversion process involves understanding technical documentations and generating corresponding script code. In addition, it serves as an interactive knowledge base for documentation of Clarity LIMS and Laboratory Quality Management and Regulations. ",Initiated,Neither,01/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00029,DGMH AI Chatbot,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The DGMH AI chatbot would assist with developing an initial draft response to  inquiries where the response could have been found on our website. This would allow DGMH staff to have a starting point on a response to edit and clear. Additionally, the response could be adjusted for plain language to assist in ensuring the inquirer understands the response being sent back to them. The AI chatbot would allow inquiries to be responded to quicker and would allow staff to focus on other high priority items as well.   

The project will rely on using Retrieval-Augmentation Generation (RAG) to identify relevant information from CDC’s relevant website pages to generate relevant responses using AI. Evaluation of the project will assess how accurate the response was, how complete it was, and how much revision was needed. Evaluation would also explore the answer and if the answer that was generated was consistent throughout time if multiple people asked similar questions.   The goal is consistency of content rather than tone/plain language. The chatbot will help to reduce the turnaround time for responding to inquiries and free up time for staff to address other priorities.","CDC's Division of Global Migration Health receives inquires for information which is available publicly in some form but may be hard to find and requires staff responding to these inquiries to have a broad knowledge and can be time intensive to respond to. The AI Chatbot will draft an initial response to questions using content available on CDC’s public-facing webpages. Each response goes through the existing CDC clearance process regardless of if AI is used, but the Chatbot helps provide an initial draft based on previously published content. The goal is to help with responding to different inquiries the division receives, including but not limited to CDC-INFO and media. ",Initiated,Neither,10/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00030,Distiller SR: AI to screen research articles for Community Guide reviews,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This tool will be used to screen research articles that will be used to inform Community Preventive Services Task Force recommendations (a body that produces guidelines independent of CDC). 

Use of this technology may increase the speed with which systematic reviews can be conducted. This may expedite the time it takes to evaluate the effectiveness of public health programs for a CPSTF recommendation (not a CDC guideline). ",Machine learning will be used to more efficiently screen research articles relevant to evaluating the effectiveness of an intervention. ,Initiated,Neither,05/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00031,Evaluating Generative AI for polio containment.,HHS,CDC,Health & Medical,None of the above.,"The AI will impact the data retrieval and automation process for HIV researchers, specifically in providing information from datasets and potentially generating code for desired variable names and analysis or generating information about a particular dataset.

As polio eradication progresses, containment of poliovirus becomes critical. This project aims to identify and evaluate Generative AI tools to extract information from publications in an effort to identify poliovirus in places previously thought to be polio-free.  Identification of such a tool may diversify Polio and Picornavirus Branch's surveillance portfolio and increase Branch's capability of processing large volume of data for containment purposes. This project may support CDC PPLB’s polio surveillance activity and containment efforts.","This AI assistant will use retrieval augmented generation (RAG) to return information related to HIV based on a user's query. Our aim is to input all dataset documentation and metadata into an index with the goal of creating a virtual assistant. This assistant offers support to our HIV researchers by providing the information they seek from the data and potentially generating SAS, R, or Python code for desired variable names. For instance, if we require a dataset containing HIV PrEP information, we can request it to generate a list of current datasets that contain data on PrEP medication usage in 2019, along with the associated variable names. Subsequently, we can instruct it to produce lines of code, such as a logistic regression, which can be readily copied and pasted into our analysis software of choice. Another example would be if our researchers would like information returned about a given dataset, this assistant could return specific information based on the researcher's query.",Initiated,Neither,11/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00032,Respiratory Virus Response (RVR) Data Analysis Concept,HHS,CDC,Health & Medical,None of the above.,"This solution will impact the process of summarizing subject matter expert (SME) interpretations/knowledge during a response. 

Response efforts require prompt turnaround of essential information to the public. This project will impact public health by improving the efficiency of dissemination of information through production of key takeaways which can then be quickly reviewed by SMEs and cleared. This project will also allow for improved understanding of limitations and uncertainties in use of AI methods that could contribute to improved implementation of such methods in public health.","The goal of this solution is to evaluate how AI can be implemented in the process of summarizing subject matter expert (SME) interpretations/knowledge to improve efficiency in knowledge dissemination during a response.  As part of the proof-of-concept, we  seek to evaluate the limitations and uncertainties of AI methods in this use-case, such as bias and hallucinations as such issues will require mitigation before this method can be broadly adopted. Our proposed approach would make use of the ChatGPT interface through EDAV (or alternative accepted platform) as our prompts will include uncleared data from the Respiratory Virus Response (RVR). In this response,  SMEs from different groups provide bulleted information that then needs to be further summarized to address key takeaways.   Bullets from prior weeks will prompt AI to generate summaries. The initial approach will focus on engineering prompts to get key takeaways while future iterations may require fine-tuning to allow for better contextualization of responses as well as improvements in tone and style. ",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00033,School LLM initial abstract review process ,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Reviewing research related to school readiness science. CDC/DRRS' School Preparedness unit is responsible for developing research around readiness science. As part of this a large language model was used to abstract themes and code publications that were identified as related to school closure to aid us in supporting our research. If funding were to become available, we would like to develop this static, one-time product into a modifiable tool that could be used for ongoing article abstraction across school and other settings and population.

The AI allows us to efficiently categorize thousands of abstracts in a much shorter time-frame with much less human time required into a user-friendly dashboard. ",The AI used a LLM to extract data from an abstract review and categorize relevant themes and topics into a user-friendly dashboard. This dashboard can be used by a health scientist to pull resources from 2012-2022   for specific school closure outcomes or themes.,Initiated,Neither,08/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00034,ChatCDC - CDC Enterprise Generative AI Chatbot (Content Editing),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with editing text previously written, or content editing. This may refer to using the chatbot to help refine emails or messages to other CDC staff, reviewing internal documents, reviewing scheduling or other bureaucratic information and other such information. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. This includes internal guidance on using AI for External Communications.

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of data uploads. This tool can be used by all CDC staff to support general business operations and enables a quick review for finding any spelling or grammatical errors, fixing formatting, or other copy-editing type corrections and saves staff time will increasing the quality of communications. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user. In this case, responses will be recommendations on edits for content provided by the user such as a draft email. The chatbot's output can then be copied and pasted or manually entered based upon the users review. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.",Operation and Maintenance,Neither,10/2023,11/2023,02/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,Yes. A series of pilot projects was conducted to evaluate the performance of this chatbot and these pilot projects are included within this inventory.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00035,ChatCDC - CDC Enterprise Generative AI Chatbot (Data Extraction),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose tool to assist with extracting information from larger pieces of text. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

From larger documents which may be time consuming to find specific pieces of information, this AI system enables staff to extract key pieces of information to be used in later tasks. This can include action items from meeting transcripts, specific discussion focuses from larger meetings, specific mentions, or other such information. this makes the finding of information from larger document far faster and reduces the manual burden of reading larger documents for one or two specific pieces of information.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case about some larger piece of text and any specific pieces of information to extract. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task.",Operation and Maintenance,Neither,10/2023,11/2023,02/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,Yes. A series of pilot projects was conducted to evaluate the performance of this chatbot and these pilot projects are included within this inventory.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00036,ChatCDC - CDC Enterprise Generative AI Chatbot (Ideation),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with the development of ideas or to overcome writers block in different tasks. When doing a task, staff can ask this tool to ask questions to help evolve any ideas being developed. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of 3rd party AI powered general purpose chatbots. This ensures staff can provide information regarding a current task along with general information with current tasks to help organize thinking, actions to take, and developing ideas for staff to use or reject as a part of their process. This reduces the time spent by staff dealing with situations such as writers block.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task. The output must be copied and pasted or manually entered somewhere for the output to be used by staff.",Operation and Maintenance,Neither,10/2023,11/2023,02/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,Yes. A series of pilot projects was conducted to evaluate the performance of this chatbot and these pilot projects are included within this inventory.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00037,ChatCDC - CDC Enterprise Generative AI Chatbot (Software Development),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose to assist with the development of software code which can be used for research, data analysis, software development, or other such systems. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

When the AI chatbot is being used for coding assistance or software development, it affects several business processes related to agency operations and core task structures. Specifically, it can be utilized by various personnel within an organization such as the CDC, including software programmers using AI-specific code, those involved in encoding for software development, data analysts, scientific researchers conducting data analysis, data scientists implementing and testing new models, and software engineers developing or updating applications.
The chatbot enhances productivity and efficiency across these roles by providing coding assistance and acting as a learning tool. For instance, data engineers may use the chatbot to generate PySpark code for their data transformation scripts within a larger pipeline. Additionally, individuals new to programming languages like Python can leverage the chatbot as a tutor to help them with tasks such as cleaning up datasets for evaluation purposes.
In summary, the AI chatbot impacts business processes by aiding staff members in performing complex analytical tasks more efficiently and supporting their development work through guided coding assistance. This ultimately contributes to enhancing overall operations within the agency by streamlining research activities and internal process workflows.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case about either some software code, software code documentation, code concepts, or to help generate software code. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task.",Operation and Maintenance,Neither,10/2023,11/2023,02/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,Yes. A series of pilot projects was conducted to evaluate the performance of this chatbot and these pilot projects are included within this inventory.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00038,ChatCDC - CDC Enterprise Generative AI Chatbot (Summarization),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"CDC has an internal productivity tool available to all CDC staff which can be used in a variety of ways. This use case covers staff who will be using this general purpose tool to summarize and synthesize information from larger documents such as meeting transcripts, research articles, or other documents. Currently, CDC has internal Generative AI guidance determining how this tool can be used, and individual Centers, institutes, or Offices may implement their own policy to ensure safe and responsible AI. 

This tool enables CDC staff to have the productivity benefits of Generative AI powered chatbots without any of the security risks of data uploads to third party tools. Using ChatCDC, Staff can have smaller, more easily digestible summaries to save staff time from reading larger documents if the time to read the full document is not available.","This chatbot, powered by Azure OpenAI Large Language Models, will generate responses to questions asked by the user, in this case a summary of a larger document. The chatbot's output can then be copied and pasted or manually entered into the appropriate testing process by the staff to ensure any code used from the chatbot's output meets the criteria of the current task.",Operation and Maintenance,Neither,10/2023,11/2023,02/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,Yes. A series of pilot projects was conducted to evaluate the performance of this chatbot and these pilot projects are included within this inventory.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00039,DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (AI Summarization),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI solution impacts the process of investigating foodborne disease outbreaks. These foodborne outbreaks require cooperative efforts from CDC staff, FDA, USDA, and local agencies and the AI system is used through a centralized data platform System for Enteric Disease Response, Investigation, and Coordination (also known as SEDRIC). For more information on SEDRIC, please go to our website: https://www.cdc.gov/foodborne-outbreaks/php/foodsafety/tools/index.html

SEDRIC's AIP use case provides CDC epidemiologists the ability to accelerate their investigations of multi-state foodborne disease outbreaks by more effectively leveraging data available in a rich data source, such as receipts from grocery stores, that otherwise requires extensive time and human effort to parse through. In addition, this workflow would free up epidemiologists' time and, potentially, increase the frequency with which both CDC and STLT partners could utilize shopper card, receipts, and free text responses to support investigations. Using the summarization capability, the extensive process of mapping common names of different food items is done automatically, greatly reducing the human labor time to generate dashboards of information regarding current foodborne investigations to serve as a decision point to aid in outbreak response.","The Artificial Intelligence Platform (AIP) available within SEDRIC provides CDC epidemiologists the power to accelerate their investigations of multi-state foodborne disease outbreaks. Using the information previously extracted from receipts and other records, AIP can summarize these results to provide insights from information pulled from shopper receipts. Given ingredients can be found in multiple food products, and some ingredients such as herbs like coriander/cilantro may go by multiple names or be reported in multiple languages, this summarization tool provides a faster way to gather summary information from receipts on different food items which may be part of a foodborne investigation.",Operation and Maintenance,Neither,10/2023,10/2023,02/2024,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,"Data are used in outbreak/response scenarios, such as foodborne illness outbreak response. Data used is dependent on the situation and outbreak, and may be owned by CDC, FDA, USDA, State Health Departments, Tribal Health Departments, Local Health Departments, Territorial Health Departments, or other entities.",Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,1 CDC Data Platform (1CDP),Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00040,DCIPHER (SEDRIC) AIP for Advanced Foodborne Outbreak Investigation (Receipt Reading),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This AI solution impacts the process of investigating foodborne disease outbreaks. These foodborne outbreaks require cooperative efforts from CDC staff, FDA, USDA, and local agencies and the AI system is used through a centralized data platform System for Enteric Disease Response, Investigation, and Coordination (also known as SEDRIC). For more information on SEDRIC, please go to our website: https://www.cdc.gov/foodborne-outbreaks/php/foodsafety/tools/index.html

SEDRIC's AIP use case provides CDC epidemiologists the ability to accelerate their investigations of multi-state foodborne disease outbreaks by more effectively leveraging data available in a rich data source, such as receipts from grocery stores, that otherwise requires extensive time and human effort to parse through. In addition, this workflow would free up epidemiologists' time and, potentially, increase the frequency with which both CDC and STLT partners could utilize shopper card, receipts, and free text responses to support investigations. Manually entering receipt information, shopper card information, or other such free text field is traditionally error prone and time intensive for a variety of information. This AI system provides a human-in-the-loop opportunity to review and update data entry points while reducing time spent by staff to gain these insights. Having a set structured output as well increased standardization of this information and eases reporting in situations requiring cooperation from multiple organizations.","Palantir’s Artificial Intelligence Platform (AIP) available within SEDRIC provides CDC epidemiologists the power to accelerate their investigations of multi-state foodborne disease outbreaks. It can extract structured data from grocery receipts, shopper card records, and free-text responses in order to catalog the food items purchased by affected patients. It can also map those items to SEDRIC-defined vehicles which categorize the items and highlight commonalities across patients, helping to pinpoint potential outbreak vehicles.",Operation and Maintenance,Neither,10/2023,10/2023,02/2024,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,"Data are used in outbreak/response scenarios, such as foodborne illness outbreak response. Data used is dependent on the situation and outbreak, and may be owned by CDC, FDA, USDA, State Health Departments, Tribal Health Departments, Local Health Departments, Territorial Health Departments, or other entities.",Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,1 CDC Data Platform (1CDP),Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00041,DFWED Food Vehicle Investigation Module,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Foodborne outbreak investigation

Outbreak investigation by providing estimates of output of potential food vehicles can increase speed of tracking foodborne outbreaks in terms of identification of hypothesis generation. This reduces operational burdens in foodborne response efforts.","NLP and Food Vehicle Investigation Module (FVIM) uses language learning models and Text Classification Tools to identify potential vehicles. NLP tool uses text classification to provide probabilities that a food is associated with the outbreak based on reports in the SEDRIC line list. FVIM identifies past outbreak with similar key demographic and temporal characteristics to the selected outbreak to guide hypothesis generation. FVIM analyses reported food exposures uploaded to the SEDRIC line list and categorizes responses into food commodity types that are then compared to FoodNet Population survey results weighted by age, sex and ethnicity and generates a statistical comparison",Operation and Maintenance,Neither,07/2022,07/2022,05/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,Yes,No,No,"Data are used in outbreak/response scenarios, such as foodborne illness outbreak response. Data used is dependent on the situation and outbreak, and may be owned by CDC, FDA, USDA, State Health Departments, Tribal Health Departments, Local Health Departments, Territorial Health Departments, or other entities.",Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes, 1 CDC Data Platform (1CDP),Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CDC-00042,Genetic distance computation method for comparing complex multi-locus parasite (Cyclospora) genotypes,HHS,CDC,Health & Medical,None of the above.,"Investigating the similarity of infections used during epidemiologic investigations of cyclosporiasis outbreaks.

It helps produce a clustering output for massive datasets comprising genotypes that are too complex to be analyzed using traditional genetic distance computation methods and aid in identifying similarities of infections when tracking cyclosporiasis outbreaks and other potential parasites.","The AI algorithm compares sets of haplotypes sequenced from a set of clinical samples and computes a set of genetic distances. It performs these comparisons across thousands of genotypes to identify infections that are closely related or unrelated. The resultant genetic distances are then clustered to define groups of closely related infections. This information is used routinely to complement epidemiologic investigations of cyclosporiasis (Cyclospora) outbreaks, and traceback investigations performed by state public health agencies and FDA. While this AI has mostly been applied to Cyclospora, we have also applied it to other parasites, including malaria, and certain parasitic worms.",Operation and Maintenance,Neither,01/2018,01/2018,09/2019,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,"used Cyclospora sequence data that was generated by CDC, State Public Health Labs, and the Public Health Agency of Canada following a protocol for amplifying 8 genotyping markers. This protocol was developed by CDC. All sequence data generated by CDC and State Public Health Labs are publicly available through NCBI (https://www.ncbi.nlm.nih.gov/bioproject/PRJNA578931/). The sequence data from the Public Health Agency of Canada can typically be found on NCBI as well (https://www.ncbi.nlm.nih.gov/bioproject/PRJNA796535/).",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Advanced Molecular Detection Scientific Computing Platform,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been published
HHS-CDC-00043,MedCoder - Coding literal text cause of death information reported on death certificates to ICD-10,HHS,CDC,Health & Medical,None of the above.,"MedCoder is a subsystem of CDC's National Center for Health Statistics (NCHS) National Vital Statistics System for coding causes of death indicated on the death certificates to the International Classification of Diseases 10th Revision (ICD-10) codes.

With the implementation of MedCoder, the percentage of deaths that can be automatically and accurately coded has risen from 70-75% using the previous coding system to over 85%. This improvement translates into substantial cost savings, amounting to hundreds of thousands of dollars that would have been spent on manual coding. Additionally, it significantly enhances the timeliness of data related to urgent public health concerns such as COVID and drug overdose deaths, enabling near real-time surveillance.","MedCoder assists with the identifying cause of death codes from death certificates using ICD-10 Underlying cause codes and automatically identifies and rejects complex causes of death as well as frequently miscoded ones, requiring manual coding or review. Additionally, in production, MedCoder utilizes natural language processing (NLP) to cleanse and standardize literal text cause of death statements before performing coding.",Operation and Maintenance,Neither,10/2017,02/2018,06/2022,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,N/A,Documentation is widely available,Sex/Gender,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,National Vital Statistics System (NVSS),More than 12 months,Yes,No,Yes,None,Limited documentation for review
HHS-CDC-00044,NCIRD SmartFind ChatBots - Public and Internal ,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Internal partner mailbox email management including managing knowledge base. Previously, this included public facing chatbots but the public ChatBots are no longer active. This uses previously cleared FAQs and other reviewed information accessible publicly as the knowledge base.

The internal Knowledge-Bot's SharePoint component is helping program staff manage emails from partners more efficiently and effectively including creation and maintenance of a knowledge base that can be utilized across staff managing the mailbox. ","Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search, QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps. ",Operation and Maintenance,Neither,10/2020,03/2024,12/2024,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,"For the public-facing chatbots, we use public-facing FAQs.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDC OD ATO,Less than 6 months,Yes,yes,Yes,Re-use production level code and/or data products,Documentation has been published
HHS-CDC-00045,NIOSH Industry and Occupation Computerized Coding System (NIOCCS),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Replaces manual coding of industry and occupation text to standardized codes so that they can be used for research and analysis.

Reduces the high cost of manually coding industry and occupation data while promoting increased coding speed, accuracy, and consistency.",Uses machine learning models to translate industry and occupation text into standardized codes that can be used for research and analysis.,Operation and Maintenance,Neither,10/2024,10/2024,01/2024,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,Yes,STLT's death record data (received via NCHS) and BRFSS survey data,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Modernization Platform NIOSH (MPN),Less than 6 months,Yes,No,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-CDC-00046,Nowcasting Injury Trends ,HHS,CDC,Health & Medical,None of the above.,"Predicting current injury rates and real time estimates of injuries and deaths. The internal dashboard that will be created as a result of this effort will enhance the understanding of injury trends and expedite surveillance and research activities. This initiative will have a direct impact on the speed at which emerging trends in injuries resulting in deaths are identified and investigated.

Gold standard data take time to process and be made available. Real-time insight of injury trends when gold standard data are not available can be a resource resulting in timelier situational awareness to inform injury surveillance efforts. ","An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' injury death trends nationally on a week-to-week basis. ",Operation and Maintenance,Neither,01/2021,01/2021,01/2022,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,Emergendy Department data from the National Syndromic Surveillance Program,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CDC-00047,Risk Assessment Module (RAM) for the National Diabetes Prevention Program (National DPP) Operations Center.,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Tracking program progress. This AI assists in determining if an organization that is currently operating within the National DPP is at risk of improperly starting, at risk of going inactive, or at risk of not achieving the goals necessary to continue successfully in CDC’s Diabetes Prevention Recognition Program.

The RAM module will help program managers synthesize large amounts of organization-level data in making decisions on how best to assist organizations with their programs, ultimately leading to increased program participation and improved health outcomes in program participants. ","The RAM is a reporting tool within the National DPP Operations Center which already has an ATO. The RAM module ingests large amounts of organization-level data including National DPP participant enrollment records, demographics, and specific risk factors to perform supervised learning and model generation. This machine learning model is used to predict and quantitatively rank those organizations that are at highest risk of failing to meet program objectives. This information, both input and RAM output, is currently fully sequestered to associates of the National DPP of the CDC. In the future, with continued development and validation, the plan is to allow external-to-CDC State Quality Specialist (SQS) users access to the outputs of RAM for additional assistance with improving organization success.",Operation and Maintenance,Neither,08/2023,09/2023,08/2024,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,DDT DPRP Portal - historical data from organization's 6-mth submissions of participant attendance of Lifestyle change classes.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,DDT DPRP Portal,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-CDC-00048,Semi-Automated Nonresponse Detection for Surveys (SANDS),HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"SANDS is a fine-tuned large language model (LLM) designed to assist with human-in-the-loop procedures specifically for open-ended survey responses. Open-ended survey responses vary in quality and are challenging to use effectively because they are labor-intensive to review and therefore cost-prohibitive to use at scale. SANDS is intended to reduce the burden by filtering out clear and obvious non-response such as  ""This is so dumb, why I am I wasting my time on such a stupid question"" or ""Because It is true"" which provide no value to researchers. This LLM is available on HuggingFace and is not routinely updated, but it can be used like any open-source LLM through secure instances of Python.

Manual curation of open-ended survey responses is time-consuming, often requiring extensive hours to identify themes and review outputs. SANDS significantly reduces this manual burden by providing scores for responses, enabling researchers to quickly compile an initial high-quality dataset for qualitative research. SANDS also flags responses needing further examination, streamlining the review process.",CDC's National Center for Health Statistics (NCHS) has developed and released a model to detect nonresponses in open-text survey responses. This helps improve survey data quality and question and questionnaire design. The system is a natural language processing (NLP) model that has been fine-tuned on a custom dataset of survey responses. ,Operation and Maintenance,Neither,06/2021,09/2021,09/2022,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,Yes,No,No,"3,000 labeled open-ended responses to web probes on questions relating to the COVID-19 pandemic gathered from the Research and Development Survey or RANDS conducted by the Division of Research and Methodology at the National Center for Health Statistics",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,No,None,Documentation has been published
HHS-CDC-00049,Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage,HHS,CDC,Health & Medical,None of the above.,"CDC's National Center for Health Statistics (NCHS) Data Linkage Program has developed a record linkage program designed to maximize the scientific value of the Center’s population-based surveys. Linked data files enable researchers to examine the factors that influence disability, chronic disease, health care utilization, morbidity, and mortality. The linkage algorithms initially used by the program did not implement machine learning in either deterministic or probabilistic linkages and required several manual steps for these processes. 

Using machine learning in the CDC's National Center for Health Statistics (NCHS) Data Linkage Program offers several benefits. Machine learning algorithms help improve the accuracy and efficiency of data linkage by developing joining methods or blocking groups.  Working with very large datasets can be time-consuming and resource-intensive. By implementing supervised and unsupervised machine learning techniques, the Data Linkage Program can automate the process of developing and selecting blocking groups, reducing manual effort and increasing efficiency. This additionally improves the scalability of data linkages. Machine learning algorithms can continuously learn and adapt based on new data inputs and feedback. This allows the Data Linkage Program to refine their linkage algorithms over time.","CDC's National Center for Health Statistics (NCHS) Data Linkage Program has implemented both supervised and unsupervised machine learning (ML) techniques in their linkage algorithms. The Sequential Coverage Algorithm (SCA), a supervised ML algorithm, is used to develop joining methods (or blocking groups) when working with very large datasets. The unsupervised partial Expectation-Maximization (EM) estimation is used to estimate the proportion of pairs that are matches within each block. Both methods improve linkage accuracy and efficiency.",Operation and Maintenance,Neither,02/2019,08/2019,08/2020,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,Yes,No,No,"Data used to evaluate the models include data from the National Hospital Care Survey, the National Health and Nutrition Examination Survey, and the National Health Interview Survey as well as linked administrative data.",Documentation is widely available,Sex/Gender,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Consolidated Statistical Platform,6-12 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-CDC-00050,TowerScout: Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation,HHS,CDC,Health & Medical,None of the above.,"During Legionella outbreaks, the National Center for Immunization and Respiratory Diseases (NCIRD)/Division of Bacterial Diseases (DBD) needs to identify cooling towers that could potentially be spreading Legionella bacteria. 

Using AI object detection, TowerScout detects cooling towers approximately 600 times faster than manual searches, allowing researchers to more efficiently respond during outbreaks. ",TowerScout uses object detection and image classification models to detect cooling towers within aerial imagery.  ,Operation and Maintenance,Neither,01/2021,01/2021,05/2021,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,None,Documentation is widely available,N/A,Yes,Yes – source code is publicly available.,https://github.com/TowerScout/TowerScout,Yes,Enterprise Data Analytics and Visualization (EDAV) Platform,Less than 6 months,Yes,Yes,No,Use of existing data platforms,Documentation has been developed
HHS-CDC-00051,Creation of synthetic Survey-like Insurance Names for use coding NHIS private insurance responses,HHS,CDC,Health & Medical,None of the above.,"This solution will impact the process of manual coding and reviewing text errors in the National Health Interview Survey 

Previous efforts to augment the manual coding have proven ineffective. Given the complex nature of insurance programs, this results in over 200 FTE hours a year being spent on just the initial coding of open text insurance fields. Additional hours are spent reviewing the manual coding for errors. By creating survey-like insurance responses, this could theoretically save over 100 hours of staff labor a year, greatly increasing efficiency and timeliness.","The National Health Interview Survey calculates insurance coverage rates among the US non-institutionalized resident population, including statistics of the percentage of people with private insurance coverage. The collection of information on insurance coverage is accomplished in two parts. First, survey respondents self-identify the type of insurance they have. Secondly, to aid in the verification of insurance type, survey respondents also provide the name of the health plan or program they have in an open text field. The information collected in the open text field may include misspellings, acronyms, and rarely match exactly the true complete insurance plan name. 

This leads to a time intensive process as staff may need to decipher the plan name in the open text field mentioned by the respondent and/or abbreviated by the interviewer and if that plan name confirms the correct type of insurance initially indicated during the interview process. By creating AI generated known acronyms as data points for projects, as an example Blue Cross Blue Shield of Alabama to BCBS of AL and BC/BS of AL, this will create a more representative set of information for staff to use when coding potential saving up to hundreds of FTE hours reviewing responses. This also works in combination with existing efforts to augment manual coding with AI and Machine Learning to increase efficiency.
",Retired,Neither,N/A,N/A,N/A,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00052,Development of in-silico genomic and patient datasets using generative ML algorithms,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This solution will impact the process of finding reference genomes

Reduce the development time of custom tools, finding reference genomes, and additional administrative burdens. The datasets developed would be beneficial in testing out bioinformatic pipelines. ","This solution uses NLP generative AI toolsets (e.g. ChatGPT, co-pilot, etc.) to generate code for the development of bacterial and viral in-silico genomic sequences and patient data. This will be compared to already established pipelines to determine factors such as code viability, data accuracy, code licensing, and any drawbacks and/or advantages these services provide. For example, we would ask GPT-4 a prompt, ""generate python code to create Sars COV2 in-silico fastq sequencing data."". We will look at where did it reference the code base to generate the code and is it open source or have licensing requirements.  ",Retired,Neither,N/A,N/A,N/A,02/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00053,Mastering Metadata: AI-Powered Governance for Data Insights,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"The implementation of this solution will have a significant influence on the maintenance of data quality and data assets on the data.cdc.gov platform.

Accurate, reliable, and timely data available in data.cdc.gov is critical in making meaningful public health decisions. This publicly available data repository is used worldwide by researchers, policy makers, and general public to access, manage, analyze, and visualize public health data. Through this project, we will be able to scale up the magnitude and quality of datasets from NCIRD that’s made available via data.cdc.gov and thus maximizing public health impact for a diverse audience at multiple levels.","data.cdc.gov serves as a publicly accessible repository for CDC data, utilized by researchers, policymakers, and the general public to monitor and comprehend public health trends. Ensuring the accuracy and reliability of the data on data.cdc.gov is crucial for informed decision-making in public health. To achieve this, the proposed solution involves leveraging AI to maintain CDC's National Center for Immunization and Respiratory Diseases data assets on data.cdc.gov to automate various tasks such as checking metadata completeness, validating metadata against a schema, comparing metadata with other sources, and monitoring metadata changes over time.",Retired,Neither,N/A,N/A,N/A,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00055,PII detection using Private AI ,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"Numerous data sources contain personally identifiable information (PII) and protected health information (PHI), which cannot be publicly published or shared among federal partners due to confidentiality concerns. This includes sensitive records like death certificates, survey responses, and electronic health records. To enable broader utilization of this data and enhance insights, a PII detection system was explored in this project. Specifically, the availability of an off-the-shelf tool called Private AI was investigated for identifying PII. However, it is important to note that the license for this tool expired after one year and there are no current plans to renew the contract.

At present, the presence of PII within data and the labor intensive process to ensure PII redaction and removal has prevented broader sharing of data available within CDC. However, implementing an automated system which performs as well as humans and more quickly could significantly reduce the time required for human review, enabling faster dissemination of crucial public health information and data sources.","CDC's National Center for Health Statistics (NCHS) has been assessing the NLP solution provided by Private AI, which is specifically designed to detect, mask, and substitute personally identifiable information (PII) within textual data. This collection of models aims to securely identify and eliminate PII from unstructured text datasets across various platforms within the CDC network.",Retired,Neither,N/A,N/A,N/A,03/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00056,Reddit Post Analysis for Sexual Health Using Large Language Models,HHS,CDC,Health & Medical,None of the above.,"The AI will impact the data extraction and analysis processes for understanding how users seek sexual health advice online using Reddit.

In additional to traditional public health impacts this can include reducing administrative burdens and other ancillary benefits. This is an important criteria when selecting the initial round of projects.
Understand how and why people seek sexual health advice online. This may lead to finding gaps in online health resources, identifying underserved populations who resort to using online resources, and discovering changes in sexual health behavior over time.","Reddit is a social media website where users can submit and respond to posts around a wide variety of topics. Reddit is organized into subcommunities called subreddits, and many people turn to sexual health focused subreddits, such as the “r/STD” subreddit, for advice. The Reddit posts can be a valuable source of text and image data since these posts reveal immediate sexual health concerns and questions that may be overlooked. However, the volume of posts makes large scale manual analysis impractical, and extracting insights using conventional methods is difficult. This solution uses large language models (LLMs) to assist in and automate data extraction and analysis to better understand how users seek sexual health advice online.",Retired,Neither,N/A,N/A,N/A,02/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00057,Retrieval Augmented Generation (RAG) with Q-Bank,HHS,CDC,Mission-Enabling (internal agency support),None of the above.,"This solution will impact the process of searching CCQDER’s Q-Bank research publications on question evaluation for surveys. 

Q-Bank reports provide context needed to better understand and interpret data from survey estimates, as well as information about question performance and fit-for-use in various data collection contexts.
This project aims to improve access and visibility of CCQDER’s Q-Bank research publications on question evaluation for surveys. Additionally, indexing Q-Bank as part of this project should help to relieve some of the administrative burden of tagging and organizing reports.","This solution uses Retrieval Augmented Generation to develop an LLM-based search tool based on the Collaborating Center for Questionnaire Design and Evaluation Research’s (CCQDER) Q-Bank reports. The main motivation of the solution is to make it easier to navigate and identify reports relevant to a user’s research interests. Because the reports are already publicly available and they represent a relatively small corpus, they provide an excellent opportunity to develop prototype AI tools.",Retired,Neither,N/A,N/A,N/A,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CDC-00058,Using generative AI to gain insight of older adult falls,HHS,CDC,Health & Medical,None of the above.,"This solution will impact the process of extracting information from medical narratives 

Traditional methods of data and information extraction from medical narratives involve manual scrutiny and the use of rule-based models. These methods are time-consuming and can overlook crucial details. By utilizing generative AI, a more comprehensive understanding of the circumstances surrounding injuries from falls can be achieved. Understanding the specific causes, circumstances, and outcomes of falls can lead to more targeted public health interventions.",This solution extracts insights regarding older adult falls injuries from Emergency Department medical narratives and testing out methods submitted. The data source to be used is the National Electronic Injury Surveillance System (NEISS) data.,Retired,Neither,N/A,N/A,N/A,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00001,AI-assisted comment triaging tool,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Annual rulemaking-- the Physician Fee Schedule receives thousands of public comments and require assistance with reviewing and assigning the comments to the particular topics they address. 

Assists with workload for the PFS team","We use AI to assist in comment review, such as identifying form letters. ",Operation and Maintenance,Neither,06/2022,12/2021,06/2022,N/A,Developed with contracting resources.,N/A,No,N/A,No,N/A,No,No,Yes,None,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,No,Yes,Yes,None,No documentation is available
HHS-CMS-00002,Bankruptcy BOT,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The Bankruptcy/Overpayment Division of IFM is responsible for carrying out the Agency's oversight responsibilities for our contractors' debt management functions, and for protecting Medicare's interest in debt recoupment activities complicated by bankruptcy.

A timely identification of filed provider bankruptcies allows Medicare to secure recovery rights before timeframes to file a proof of claim expire.",The Bankruptcy BOT proactively identifies bankruptcy case with Medicare interest.,Operation and Maintenance,Neither,01/2020,01/2020,09/2021,N/A,Developed with contracting resources.,47QRAA18D001P,No,N/A,No,N/A,Yes,No,Yes,PECOS and BCRS,Documentation is missing or not available,Residency Status,No,"Yes – agency has access to source code, but it is not public.",N/A,Yes,PACER,Less than 6 months,Yes,Yes,Yes,None,No documentation is available
HHS-CMS-00003,Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool,HHS,CMS,Law & Justice,None of the above.,"Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits

Eliminates manual review of Medical Record (MR) submissions, expedites the Intake process and realizes cost savings in both time and resources.",The PA-BOT tool will replace the RADV audit Intake manual functions for Steps 2 & 3 of the RADV audit process.  The RADV Intake process conducts a review of the MAO Medical Record (MR) submissions and validates that the MR submissions from MAOs have met RADV audit intake requirements and can proceed to MR abstraction/coding.,Operation and Maintenance,Neither,09/2017,11/2017,04/2019,N/A,Developed with contracting resources.,N/A,No,N/A,No,N/A,Yes,No,No,"Yes, prior RADV results were used to train the models.",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Central Data Abstraction Tool - Modernized (CDAT-M),Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Documentation has been developed
HHS-CMS-00004,CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot),HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management

 - Empowers users to find information or troubleshoot issues more efficiently
 - Reduces load on system help desks
 - Provides better insight into customer inquiries and issues informing process and design improvements
"," - Automated text-based bot providing support to Portal users
 - Uses machine learning via Amazon Lex to answer a user’s question
 - Takes user input and finds the best match to the question or problem statement
 - Automates tasks such as: customer support; processing of user questions; and solving user problems/issues",Operation and Maintenance,Neither,08/2020,12/2020,04/2021,N/A,Developed with contracting resources.,N/A,No,N/A,No,N/A,No,No,No,CMS Enterprise Portal and CMS Identity Management (IDM) user guides,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CMS Enterprise Portal,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been published
HHS-CMS-00005,Enhanced Direct Enrollment Outlier Detection,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Enhanced Direct Enrollment (EDE) allows consumers to apply for and enroll in an exchange plan directly through an approved partner’s UI, without being redirected through the Healthcare.gov application. These partner systems directly interface with the APIs developed by the FFE. As EDE Partners gain more control over their application process, the FFE must ensure program integrity.

Ensure FFE EDE program integrity","This use-case will implement Machine Learning to identify anomalies/quality issues with partner-submitted person, application, and policy data​.",Operation and Maintenance,Neither,07/2019,01/2020,01/2020,N/A,Developed with contracting resources.,N/A,No,N/A,No,N/A,No,No,Yes,CMS,Documentation is widely available,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00006,Exchange Complaints Review Categorization  ML/AI ,HHS,CMS,Law & Justice,None of the above.,"The Exchange Complaints Review Contractor (ECRC) receives hundreds of consumer complaints from the Federally-facilitated Exchange (FFE) call center daily, who then must manually read each complaint and categorize each complaint into one or more categories according to the Complaint Review Standard Operating Procedure (SOP). The categorization assists CPI in determining the nature of the complaint, the action necessary, and the component within CMS who the complaint should be routed to. In general, each complaint can take up to 10 minutes to review and categorize, including a quality review component.   

The output (list of all complaints categorized) allows CMS to expediate routing the complaint to the appropriate CMS caseworker or Issuer to take the appropriate action necessary to make the consumer whole and ensure they can receive the necessary medical treatment. The output when done by AI is done in a matter of minutes, versus weeks when completed by human reviewers. ","CPI utilizes machine learning/artificial intelligence (AI) and continuously feeds the complaints review model thousands of complaints in order to teach the model how to accurately categorize the complaints, based on keywords. This is done in a matter of minutes instead of weeks by a human complaint reviewer.",Operation and Maintenance,Neither,01/2022,01/2022,10/2024,N/A,Developed with both contracting and in-house resources.,N/A,No,N/A,No,N/A,Yes,No,Yes,"HICS, Marketplace",Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,MIDAS,6-12 months,Yes,Yes,Yes,None,No documentation is available
HHS-CMS-00007,Feedback Analysis Solution (FAS),HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  

FAS help categorize stakeholder comments or feedback (collected in multiple venues), thereby enabling analysts to use the system to quickly identify comments that may impact program/policy decisions.","Feedback Analysis Solution (FAS) uses AI/ML/NLP tools to identify topics, themes, and sentiments outputs for the target datasets. Groups and offices within CCSQ use the solution in slightly different ways to ingest unstructured data, interpret and structure it for use in ML models after de-duplication of comments.",Operation and Maintenance,Neither,01/2021,09/2021,09/2021,N/A,Developed with both contracting and in-house resources.,75FCMC22A0018/75FCMC23F0001,No,N/A,No,N/A,No,No,Yes,CMS,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDRAP,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-CMS-00010,IT System Utilization Optimization,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The FFE application usage patterns vary and are dependent on differing environment usage periods. CMS resources are currently manually scaled, not allowing immediate actions in correlation with usage changes.

Automation of application scaling",This use-case will implement Machine Learning to determine optimized infrastructure/application scaling to support system volume.,Operation and Maintenance,Neither,07/2019,01/2020,01/2020,N/A,Developed with contracting resources.,Not Reported,No,N/A,No,N/A,No,No,Yes,CMS,Documentation is widely available,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00011,Knowledge Management Platform,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The business process it affects involves accessing and using structured and unstructured data sources to enable data-driven decision-making. 

It helps by creating efficiencies, reducing burden, and generating an increased return on investment in the achievement of CMS's mission and business objectives.","It leverages natural language processing, knowledge graphs, and large language models to make the knowledge within structured and unstructured data sources accessible and meaningful to users.",Operation and Maintenance,Neither,09/2021,10/2021,11/2021,N/A,Developed with contracting resources.,KMP / SEAS IT,No,N/A,No,N/A,No,No,No,CMS,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CEDAR,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00014,Risk Adjustment Outlier Analysis,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The RA program spreads the financial risk borne by Issuers due to offering a variety of plans meeting the need of the diverse population. RA payments are distributed based on population risk levels. The FFE uses a distributed data solution to calculate plan average actuarial risk and associated payments and must avoid potential impacts to annual calculations.

Maintain RA Program risk integrity",This use-case will implement Machine Learning to identify outliers in issuer data / behavior that may unduly influence risk adjustment payments.,Operation and Maintenance,Neither,07/2024,06/2024,01/2020,N/A,Developed with contracting resources.,Not Reported,No,N/A,No,N/A,No,No,No,CMS,Documentation is widely available,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00015,Agent/Broker Fraud Analysis,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Agent/Brokers (A/Bs) support the consumer enrollment and eligibility process. Because of this, they have learned the intricate details of the FFE for accessing applications, submitting eligibility determinations, and adding enrollments to their line of business, opening up the possibility of fraud. 

Improves the oversight and integrity of Marketplace Applications and Enrollments assisted by Agents and Brokers.  Helps CCIIO identify suspicious behaviors to refer to CPI.",Utilizes Machine Learning to identify suspicious behaviors of Agents and Brokers in the Marketplace,Operation and Maintenance,Neither,07/2024,01/2024,01/2024,N/A,Developed with contracting resources.,N/A,No,N/A,No,N/A,Yes,No,No,CMS,Documentation is widely available,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00016,CCSQ ServiceNow AI Search,HHS,CMS,Government Services (includes Benefits and Service Delivery),None of the above.,"CCSQ ServiceNow AI Search is a product inside ServiceNow (SaaS).  It replaces traditional Zing search tool (exact search), and enables users with more flexible searches to get relevant and actionable answers quickly.

* Improve search relevance
* Promote self-service by empowering users to find information independently, and potential reduce number of cases","AI Search will
* Display most relevant results first
* Support synonyms, auto-corrections, stop words, and auto-completion
AI Search analytics will provide insights into search usage, performance, trends, metrics, and how to improve search experiences.
Plan to do AI Search tune-up next",Operation and Maintenance,Neither,11/2023,02/2024,04/2024,N/A,Developed with contracting resources.,N/A,No,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,No,"ServiceNow knowledge articles, ideas, catalog items data",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,QSC,Less than 6 months,Yes,Yes,Yes,None,Documentation has been published
HHS-CMS-00017,MSP Assignment Bot,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"This impacts automatically retrieving records from a contractor's system, and importing them into an internal OPOLE Access database.  Once populated in the database the record is assigned to staff to review and adjudicate.

Pulls more cases out of BCRC and assigns much faster than an analyst. By allowing BOT to pull and assign cases instead of an analyst, this approach provides maximum time for staff to process cases which decreases the response time.",The Medicare Secondary Payer Operations Group (MSPOG) uses a BOT to pull compromise cases out of BCRC and assign to staff in our internal Management Information System (MIS),Implementation and Assessment,Neither,03/2022,04/2022,08/2022,N/A,Developed in-house.,N/A,No,N/A,No,N/A,Yes,No,Yes,case turn around times,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-CMS-00018,"Relationships, Events, Contacts, and Outreach Network (RECON)",HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"RECON AI for Recommender System| Sentiment Analysis

It has the potential to analyze data faster.","This was “native” Salesforce AI capabilities, not anything custom – and that platform-level AI is not being used in RECON at this time.",Retired,Neither,N/A,N/A,N/A,02/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00019,Complaint Analysis POC,HHS,CMS,Health & Medical,None of the above.,"The business process this AI could affect involves the analysis of complaint data used by the OPOLE team.

It could help the OPOLE team to understand the main issues and potential root causes of the complaints, enabling them to address these issues more efficiently and effectively.",It utilized data science techniques and an LLM to analyze complaint data.,Initiated,Neither,02/2024,N/A,N/A,N/A,N/A,N/A,No,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00020,Data Lake/Load-Extract-Transform-Load (L-ETL),HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"CMS is using Security Data Lake to modernize the Load-Extract-Transform-Load (L-ETL) pipelines and data tooling. There is no actual ML/AI work being done here today, rather, we are beginning work on the scaffolding that will open up these opportunities in 1-2 years time. 

Building on top of a modern data platform will provide opportunities to experiment with machine learning model development against this data--solving any number of problems that require decisions to be made about inferences over time series data. ","CMS will be enhancing Agency security to bring together more system, telemetry and program data in one place with a unifying governance model.",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00021,FOIA Document Review/Redaction Automation,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"OIT & OSORA partnership: Internal business process of reviewing and redacting CMS business documents subject to FOIA requests.

Reduces burden on FOIA staff to manually redacting business documents subject to FOIA requests.",Utilizes GenAI technology to automate review and redaction of CMS documents per FOIA requests/process.,Initiated,Neither,07/2024,N/A,N/A,N/A,N/A,N/A,No,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00022,Help Desk Responses,HHS,CMS,Government Services (includes Benefits and Service Delivery),None of the above.,"The Division of Issuer Management and Operations has talked with their contractor, LMI, about using an AI tool for the Help Desk contract.

This would reduce the amount of time staff contractors need to generate answers for SME review and approve responses to QHP issuers and other external entities that ask questions to the help desk.   ",This AI feature in the issuer help desk would help generate responses to common questions from issuers and external organizations based on previously cleared material.,Initiated,Neither,12/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00023,508 Accessibility Automation for Documents,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"OIT: Internal business process at individual employee level to automate review, identification, and correction of potential 508 accessibility issues in documents.

Reduces burden associated with making documents 508 compliant (for individual CMS employees).",Utilizes GenAI technology to automate review and generation of corrected documents compliant with 508 accessibility rules.,Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00024,Brand vs Generic Market Share,HHS,CMS,Health & Medical,None of the above.,"The Drug Data Processing System (DDPS) needs to predict changes in Medicare Part D costs 

Understanding beneficiary changes from Brand to Generic drugs allows for more accurate financial estimates.",Analyze generic drugs compared to brand drugs over time and forecast future market shares based on Part D claims volume,Initiated,Neither,10/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00025,Chat Client - Resource Library,HHS,CMS,Education & Workforce,None of the above.,"Continue to assess and refine content present in both the informational public side of QPP, Resource Library, Webinar Library, and Top Navigation as the site continues to grow.

The Chat Client would benefit the program by improving user experience through easier access to information, increased program understanding, and ability to communicate in multiple languages. ","Powered by Amazon Bedrock, by loading all resources, files, references etc. available to the QPP user community, we can establish a knowledge base that allows the bot to scan all available program documentation to construct a message that accurately answers a user's question. ",Initiated,Neither,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00026,Chatbot within Hub,HHS,CMS,Government Services (includes Benefits and Service Delivery),None of the above.,"Currently the following help support activities are handle by a person:
Personalized FAQ’s; 
Clarify questions with schema and onboarding etc.; 
Handle - Where is “My file” or “My Request” inquiries
Provide a - Talk to Agent feature
Scheduling a testing window
Provide data summarization and reporting for internal stakeholders
Report operational health of the system
Include training materials, Q/A about the system and such.

Help support team in day-to-day communication with external partners","Build a chatbot that will address some help support activates through:
Access to Internal Knowledge base Including RAG (Retrieval Augmented Generation).
Personalized FAQ’s & Contextual generation.
Interaction with Live Agent.
Chat & Talk Feature.
Ability to query custom data source for File or Case status.",Initiated,Neither,09/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00028,Drug cost anomaly detection,HHS,CMS,Health & Medical,None of the above.,"CMS Division of Payment Reconciliation is responsible for monitoring Prescription Drug Event  (PDE) data for accuracy

Allows for identification of outliers in PDE which can be corrected through Part D plan outreach in order to prevent overpayments.",Identify anomalies in drug costs on Part D claims,Initiated,Neither,10/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00029,Drug Cost Increase Predictions,HHS,CMS,Health & Medical,None of the above.,"The Drug Data Processing System (DDPS) needs to predict changes in Medicare Part D costs 

Machine Learning model uses multiple methods to predict changes to Part D drug costs based on market changes.",Use Historical drug costs increases to predict future increases,Initiated,Neither,10/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00030,Medicare Part C/D Marketing Material Review,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Drug and Health Plan Operations (DHPO) staff reviews both advertising mediums and channels materials that includes over 22  different types of media marketing materials ranging from written, digital, and more. The marketing materials are submitted to CMS from either the Medicare Health Plans and/or their third party marketing organizations. DHPO staff reviews these marketing materials to ensure they meet Medicare Marketing Guidelines. 

The current process is time consuming and resource intensive. This reduces the efficiency and quality of staff reviews. AI can improve the efficiency and quality of the marketing materials reviewed; with human validation of results. Incorporating AI into current review process can reduce the time it takes to review marketing materials, improve efficiency and allow existing FTE resources to be utilized more efficiently, and potentially reduce the volume of marketing misrepresentation complaints.  Ideally this will improve efficiency and quality, help beneficiaries access to care, and also ensure marketing materials meets Medicare Marketing Guidelines.",The AI tool required has not been identified as we still need to develop a proof of concept.  We anticipate AI would learn the various requirements for Marketing materials to help identify issues and compliance with applicable policies and regulations.,Initiated,Neither,10/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00031,Medicare Part C/D Plan Oversight of AI Used for Prior Authorization and Utilization Management,HHS,CMS,Law & Justice,None of the above.,"Medicare beneficiary access to benefits, services, and prescriptions associated with managed care plans and prescription drug plans.

AI tools can increase the capacity to analyze vast data sets based on combined sources. The results can then be further analyzed and refined by SMEs to issue compliance actions, identify plans for program auditing, and help protect the integrity of the Medicare program. ","Evaluate claims, payments, and complaints data to identify outliers. Determine if plans may be out of compliance with CMS rules or are negatively impacting beneficiary health outcomes based on plan use of AI and associated potential bias in system, process, or social determinates of health.",Initiated,Neither,11/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00032,Negotiated Drug Predictions,HHS,CMS,Health & Medical,None of the above.,"The Inflation Reduction Act authorizes Medicare to directly negotiate drug prices for certain high expenditure, single source Medicare Part B or Part D drugs. For the first year of the Negotiation Program, the Secretary will select 10 Part high expenditure, single source drugs for negotiation.

Will assist with drug price negotiation for selected drugs",Use historical drug data to predict costs and claim volume for Selected drugs,Initiated,Neither,10/2021,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00033,QPP Admin Bot,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Provides custom reporting and analysis to meet the ongoing and emerging needs to address analytics and reporting needs and supports key business processes in the QPP cycle - such as delivering feedback to providers, calculating final scores, and delivering payment adjustments to the Medicare contractors.

The Admin Bot would benefit the program by increasing availability of data, thus empowering users and informing decisions, through a simple-to-use communication platform.","Powered by Amazon Bedrock, the out-of-the-box solution can interface directly with data lakes like QPP's Universal Data Set (UDS) empowering users to ask very pointed questions on model data and/or model performance.",Initiated,Neither,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00034,Operational Efficiency Analytics ,HHS,CMS,Health & Medical,None of the above.,"OHI/MAG is responsible for providing Marketplace consumers with an accurate, efficient and timely appeals adjudication process.

Examples where we can use predictive analytics:
 * Identifying trends in operations for managing and completing appeals processing
* Predicting the number of appeals during open enrollment
* Looking for regional or demographic trends in appeal complexity, completion time, and success",Eligibility Appeals Case Management System (EACMS) - Training a model on the data in our future data lake to be able to do predictive analytics.,Initiated,Neither,07/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00035,ICPG Governance Tool,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The business process it will affect involves the processing and analysis of acquisition plans (APs).

It will help by streamlining the manual steps involved in validating and classifying acquisition plans, reducing the time and effort required. ",It will automate the processing and analysis of acquisition plans and classify them as IT-related or non-IT.,Implementation and Assessment,Neither,09/2021,09/2023,N/A,N/A,Developed with contracting resources.,KMP,No,N/A,No,N/A,No,No,No,CMS,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CEDAR,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00036,Innovation Center Investment Proposal (ICIP) Model Analysis POC,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"It will affect the process of document analysis, specifically the analysis of ICIP documents.

It will help in  ICIP document analysis, with the goal of extracting of insights and recommendations from these documents.","It will extract relevant insights and recommendations from the ICIPs, making use of a RAG-based architecture, and present them through a natural language interface. This interface will allow users to interact with the documents and retrieve the information they need easily.",Implementation and Assessment,Neither,08/2024,08/2024,N/A,N/A,Developed with contracting resources.,PPMS,No,N/A,No,N/A,No,No,No,ICIPs,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CEDAR,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00037,OAGM Rate Card,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The business process it will affect involves the analysis of historical price history/trends for labor categories in business proposals for the Office of Acquisition and Grants Management (OAGM).

It will help OAGM make better decisions on future contracts by providing them with a comprehensive and standardized view of historical price data for labor categories.","It will assist in normalizing labor categories, enabling the OAGM team to easily identify the most relevant labor category despite the variations in naming conventions found in business proposals.",Implementation and Assessment,Neither,09/2021,11/2022,N/A,N/A,Developed with contracting resources.,SEAS IT,No,N/A,No,N/A,No,No,No,CMS,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CEDAR,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00038,CCSQ Now Assist for CSM ,HHS,CMS,Government Services (includes Benefits and Service Delivery),None of the above.,"CCSQ Now Assist for CSM (Customer Service Management) is a product inside ServiceNow (SaaS).  It integrates Gen AI with CSM, and uses Now LLM (ServiceNow native Large Language Model) to generate contents based on machine learning (ML).  Now Assist for CSM helps agents to improve productivity and efficiency and deliver better services.  

Improve agents' responsiveness and productivity
* Quickly get familiar with a case/chat by getting case/chat summarization
* Quickly resolve the case by using auto-generated resolution notes.","Agents have quick access to 
- Case summarization
- Chat and agent hand-off summarization
- Resolution Notes Generation",Implementation and Assessment,Neither,02/2024,05/2024,N/A,N/A,Developed with contracting resources.,Not Reported,No,N/A,No,N/A,No,No,Yes,Historical ServiceNow case data,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,QSC,Less than 6 months,Yes,Yes,Yes,None,No documentation is available
HHS-CMS-00039,AI Workspace,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The business process this affects involves the ability to easily run AI experiments in a safe and secure environment. 

It helps by reducing barriers to AI experimentation, supporting strategic AI infrastructure enablement, and providing hands-on experience for teams to learn and understand the potential risks and benefits of AI.","It utilizes data science tooling, large language models, and other approved AWS services such as Sage Maker and Bedrock to provide a secure and supportive environment for AI experimentation and prototype development.",Acquisition and/or Development,Neither,09/2024,03/2024,N/A,N/A,Developed with contracting resources.,SEAS IT,No,N/A,N/A,N/A,N/A,N/A,No,None,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CEDAR,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00040,Citation Analysis and Survey Assistant (CASA - Nursing Home Survey CMS 2567),HHS,CMS,Law & Justice,None of the above.,"2567 (CASA) enhances the efficiency and effectiveness of monitoring and reviewing nursing home surveys across the US. It enhances how the Quality, Safety, and Oversight Group (QSOG) and Survey Operations Group (SOG) assess how State Survey Agencies (SSAs) are citing nursing home deficiencies, reported on CMS Form 2567, by employing advanced natural language processing and machine learning technologies.

 The system would support the Nursing Home Survey CMS Form 2567 survey work allowing QSOG and SOG staff to follow up on cases of under and over citations at the facilities that are flagged by the system and sent to the State Agencies","It will allow for real-time interaction with survey data, facilitating a deeper understanding of trends and individual case specifics. By flagging discrepancies in citations and providing a robust platform for detailed analysis. CASA supports CMS’s mission to ensure high standards of care and accountability in nursing homes",Acquisition and/or Development,Neither,09/2023,09/2024,N/A,N/A,Developed with both contracting and in-house resources.,N/A,No,N/A,N/A,N/A,N/A,N/A,Yes,CMS,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,CDRAP,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00042,Hazards & Threats Awareness Data Processing Automation,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"EPRO is responsible for developing agency-wide situation reports from various open web and email materials. 

More effective prioritization and processing of materials for situational awareness, faster delivery of usable work product to decision-makers agency-wide. The manual process takes 2-3 hours per day, and the AI system will reduce the work to a human quality assurance/inspection step estimated to take approximately 30 minutes.","The AI will scrape known websites and monitor relevant resource mailboxes, use a categorization algorithm, and summarize and format the significant events each morning.",Acquisition and/or Development,Neither,11/2024,11/2024,N/A,N/A,Developed with both contracting and in-house resources.,SEAS IT,No,N/A,N/A,N/A,N/A,N/A,Yes,EPRO,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Hazard and Threat Awareness,Less than 6 months,Yes,Yes,Yes,None,Documentation has been published
HHS-CMS-00043,Independent Dispute Resolution (IDR) Eligibility Rules Engine,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The current Independent Dispute Resolution (IDR) Technical Assistance (TA) process is very manual and time intensive which limits throughput.  The rules engine should significantly expedite processing and expand capacity. Automating more of the process may also increase consistency across recommendations and result in a more predictable timeframe for the workflow by better positioning disputes for analyst review.

The AI tool will help automate the eligibility review process, reducing time-intensive manual steps and increasing consistency of results.  ","Use of artificial intelligence (AI) models to identify the presence or absence of necessary data points within documentation.  AI tool searches documentation to identify and store necessary data points such as document title, file type, payment date, service code, claim number, and date of service. ",Acquisition and/or Development,Neither,08/2024,09/2024,N/A,N/A,Developed with contracting resources.,N/A,No,N/A,N/A,N/A,N/A,N/A,Yes,Federal Independent Dispute Resolution (IDR) Dispute Data,Documentation is complete,N/A,N/A,N/A,N/A,Yes,AWS,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been published
HHS-CMS-00044,Medicare Fee for Service Requirements Modernization (MFRM),HHS,CMS,Government Services (includes Benefits and Service Delivery),None of the above.,"EIG is developing a business process to parse, curate, and simplify Medicare coverage and coding requirements by medical condition using AI LLMs. 

After rigorous testing for accuracy, AI output will be uploaded to the MFRM application to be used to enhance CMS and healthcare operational efficiencies, including organization of guidance documents, and identification of source complexities to be triaged with owners.
","Utilizing an LLM (Anthropic’s Claude 3.5) to curate current, accurate, and reliable Medicare requirements information sourced from FFS policy and guidance documents.",Acquisition and/or Development,Neither,01/2021,01/2024,N/A,N/A,Developed with contracting resources.,N/A,No,N/A,N/A,N/A,N/A,N/A,No,Medicare Fee-for-Service coverage and coding information,Documentation has been partially completed,N/A,N/A,N/A,N/A,No,N/A,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00046,Review Regulatory Comments,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"The Division of Issuer Management and Operations is considering having our contractor, AIR, use an AI tool for comment analysis in the Letter to Issuers (LTI) and Notice of Benefits and Payment Parameters (NBPP). This would streamline review of stakeholder comments. 

This tool would reduce the amount of time and resources CCIIO and contracting staff would have to review the LTI and NBPP by 25%. ",The AI tool would identify trends in responses from stakeholders in policy and operational issues proposed by CMS.  ,Initiated,Neither,12/2023,N/A,N/A,N/A,Developed with contracting resources.,Not Reported,No,N/A,N/A,N/A,N/A,N/A,N/A,CMS,N/A,N/A,N/A,N/A,N/A,Yes,Not Reported,N/A,N/A,N/A,N/A,N/A,N/A
HHS-CMS-00047,Improved Data Quality Checks,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Improve consumer experience by providing an asynchronous solution to detect and provide near real time feedback via outreach to the consumer shortening the overall return cycle time without requiring UI changes. 

Improvement of user experience", develop a POC classifier model to identify incorrect document upload types / low-quality images through use of OCR.,Acquisition and/or Development,Neither,07/2024,01/2024,N/A,N/A,Developed with contracting resources.,N/A,No,N/A,N/A,N/A,N/A,N/A,No,CMS,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-CMS-00048,Plan Certification Recommendation Model,HHS,CMS,Mission-Enabling (internal agency support),None of the above.,"Identify trends/patterns within plan certification justification templates, containing free-form text data through use of NLP and classification techniques. 

Improve efficiency of the plan certification review process", build a supervised machine learning model using historical justification data and associated plan certification outcomes that can be recommended to CMS to build towards a more efficient review process.,Acquisition and/or Development,Neither,07/2024,01/2024,N/A,N/A,Developed with contracting resources.,Not Reported,No,N/A,N/A,N/A,N/A,N/A,No,CMS,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,FFM,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-COTS-00001,AI-Assisted Data Entry,HHS,HHS,Mission-Enabling (internal agency support),Inputting large amounts of data from paper forms into a digital system using AI.,"The intended purpose is to leverage AI technology to intake paper forms and assist in the data entry process, which will increase efficiency and reducing human error.",The output is a digital data set converted from physical forms with the assistance of AI tool.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00002,Transcription in Zoom and Teams,HHS,HHS,Mission-Enabling (internal agency support),Transcribing and summarizing a recorded meeting or interview using AI.,"Meetings scheduled via Zoom or Teams can be transcribed live or from recorded meetings, which improves communication. ",The output is a transcribed text from a live meeting or recorded meetings.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00003,Email Prioritization in Outlook,HHS,HHS,Mission-Enabling (internal agency support),Prioritizing and categorizing incoming emails using AI.,"The Outlook in Office365 suite can categorize incoming emails based on users' definitions, which can help users manage their inbox more efficiently. The output is categorized emails.",The output is categorized emails.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00004,AI-assisted Pattern Detection,HHS,HHS,Mission-Enabling (internal agency support),Identifying unusual patterns in system logs from a single incident report using AI.,"AI technologies have been integrated into many existing log systems to identify unusual patterns, which can help detect system log issues and raise alerts for human intervention. ",The output is alerts and reports that highlight unusual patterns in system logs.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00005,Report Summarization by commercial GenAI platform,HHS,HHS,Mission-Enabling (internal agency support),Summarizing the key points of a lengthy report using AI.,"Some GenAI platforms, such as ChatGPT and Google Gemini, can summarize documents with non-sensitive information. ",The output is a summary of provided paragraphs or documents.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00006,Information Search from Google,HHS,HHS,Mission-Enabling (internal agency support),Searching for information using AI.,Google's search engine provides AI-assisted techniques to process search requests efficiently. ,The output is relevant search results.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00007,Document Digitization by AdobePro,HHS,HHS,Mission-Enabling (internal agency support),Digitizing text from scanned documents or smart forms for archival purposes using AI.,Adobe Pro can convert scanned documents into digital data., The output is digital data with searchable functionality.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00008,Autocorrect in MS Word,HHS,HHS,Mission-Enabling (internal agency support),Improving the quality of written communications using AI tools.,"MS Word's autocorrect feature uses AI to suggest corrections, which improves the quality of written communications. ",The output is autocorrected words or sentences in written documents.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00009,AI-Assisted Real-time Collaboration,HHS,HHS,Mission-Enabling (internal agency support),Collaborating in real-time using AI-assisted tools in word processors.,"The AI-assisted real-time collaboration tool can process the inputs from team members and provide real-times stats using NLP, which offers real-time feedback for collaboration. ",The output includes summarization and statistical data derived from the inputs of multiple users.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00010,Presentation Design by MS PowerPoint,HHS,HHS,Mission-Enabling (internal agency support),Creating visually appealing presentations using AI-driven design suggestions.,MS PowerPoint can provide more appealing design suggestions based on the content. ,The output is multiple visual design suggestions for the user to select.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00011,Data modeling and visualization by MS Excel,HHS,HHS,Mission-Enabling (internal agency support),Creating visual representations of data sets for reports and presentations using AI.,"MS Excel contains many data analysis toolkits to provide AI-powered data analysis and visualization, which can improve understanding and presentation of data. ","The outputs from these features are machine learning models and statistical analyses of given data, along with their visual representations.",Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00012,News from commercial publisher such as Google News,HHS,HHS,Mission-Enabling (internal agency support),Curating news articles and updates based on user preferences using AI.,"Major news publishers, such as Google News, send selective news based on users' preferences and recent visits. ",The outputs from these news providers are more customized news feeds.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00013,Travel Route Optimization by Google Maps and Apple Maps,HHS,HHS,Mission-Enabling (internal agency support),Planning travel routes using AI-driven map applications.,"Major commercial map service providers, such as Google Maps or Apple Maps, can automate and optimize travel routes based on algorithms and live traffic data, which can save time and provide optimal routes. ",The output from these map services is an optimized travel route based on the user's preferences and live traffic data.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00014,AI-Powered Travel Booking,HHS,HHS,Mission-Enabling (internal agency support),Finding and booking travel accommodations using AI-powered platforms.,"Major travel booking websites, such as hotels.com, can provide booking options based on customers' preferences. Algorithms running in such services can optimize travel accommodations, which can save time and provide better deals. ",The output is a list of travel accommodations for customers to choose from and make booking decisions.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-COTS-00015,Facial Recognition Unlock,HHS,HHS,Mission-Enabling (internal agency support),Unlocking smartphones or other devices without the need for passwords or PINs using AI-based facial recognition technology.,The Face ID feature in iPhones takes advantage of AI technology to securely unlock the phone. ,This feature allows the phone to be unlocked using facial recognition technology.,Operation and Maintenance,Neither,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-DAB-00001,AI to Improve Public Access to the Administrative Appeals Process,HHS,DAB,Mission-Enabling (internal agency support),None of the above.,"The DAB adjudicates  disputes under more than 60 statutory authorities.  The workload is divided between the DAB's four adjudicatory divisions (e.g., the Board, the Civil Remedies Division, the Medicare Operations Division and the Alternative Disputes Resolution Division. Helping appellants decide which entity within the DAB is responsible for adjudicating their appeal will increase efficiency in adjudication and customer experience. 

The DAB's appellant community (e.g., e-file users) will be provided immediate assistance and accurate information; deaf and hard-of-hearing populations and individuals with limited English proficiency are helped without the use of intermediaries, such as interpreters, translators, and relay services. After determining the appropriate division within the DAB responsible for adjudicating the appeal, the Chatbot can provide a link to the e-file website directly connecting the user to the correct e-file system.  Other benefits include: Improve public access to the appeals process by providing instant, accurate and complete filing information; Increase the DAB's productivity by refocusing the workforce to case resolution instead of responding the filing inquires and processing and appropriately routing misfiled appeals; and Improve resource allocation based on each Division's actual workload.  ","A chatbot on the DAB's website can direct filers to the correct Division and e-file system with which the appeal should be filed by using natural language processing (e.g., questions and responses) with the ability to further refine and increase accuracy based on user response. ",Acquisition and/or Development,Neither,04/2023,07/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,None,Documentation is complete,N/A,N/A,N/A,N/A,Yes,DAB E-file,More than 12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-DAB-00002,AI Use Policy Tool,HHS,DAB,Mission-Enabling (internal agency support),None of the above.,"The DAB is responsible for issuing fair, impartial, legally correct and defensible determinations which serve as the final decision of the DHHS Secretary.  The AI Use Policy is designed to promote public confidence in the integrity of DAB decisions.  

More effective quality review tool and faster identification of data trends that require additional analysis.  ","AI Use Policy Tool will scan DAB decisions to ensure compliance with quality review standards (e.g., protect PHI, PII and FTI) and identify work product that potentially violates the prohibition of the use of generative AI in DAB decisions.  ",Acquisition and/or Development,Neither,04/2023,09/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,TBD,Documentation is complete,N/A,N/A,N/A,N/A,Yes,DABACTS,More than 12 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-DAB-00003,Resources to Assist the Advisory Board In Identifying AI Tools for Use In An Adjudication Environment,HHS,DAB,Mission-Enabling (internal agency support),None of the above.,"The adjudication process from docket analysis, case processing, issuing a decision and quality review (after adjudication) relies on the analysis of large quantities of data. 

AI or machine learning tools will help the Advisory Board determine which technology will best serve the Agency's needs in an adjudication environment. ",The use of AI to analyze the voluminous data received from appellants and interested parties to identify trends and increase efficiency in the adjudication process.  ,Acquisition and/or Development,Neither,04/2023,09/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,None,Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,More than 12 months,No,No,Yes,Use of existing data platforms,Documentation has been developed
HHS-FDA-00001,356H ML Facility Supply Chain Role Classification,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Applicants submit unstructured text to indicate a facility’s supply chain role, which range from manufacturing, testing, storing, packaging, etc. This use case extracts the supply chain role based on the text and presents it to data stewards who perform data operations

Improve the efficiency of evaluating 356H forms to assess a facility's supply chain role, thereby decreasing the time required for the processing of submissions.",Extracts a facility's supply chain role from industry submissions and displays identified roles on a data-stewards screen for human verification and final determination.,Operation and Maintenance,Neither,06/2022,06/2022,05/2023,N/A,Developed with both contracting and in-house resources.,Not Reported,N/A,N/A,No,N/A,No,No,No,Applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00002,AI Tool for Risk-based FAR Review & Decision Support,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Assist Field Alert Report (FAR) reviewers by providing risk-based intelligence and insights for review and decision support with a Human-in-the-Loop.

Assist with streamlining an efficient FAR review process by summarizing risk profiles for human exploration that is evaluated with additional data to assist human decisioning.","AI-based machine learning classification of FAR risk into low, medium, and high; provides insights on problem clusters, rare-events, and source variables.",Operation and Maintenance,Neither,06/2020,10/2020,10/2024,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,Internal Field Alert Reports data from LSMV,Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,6-12 months,Yes,Yes,No,Use of existing data platforms,Limited documentation for review
HHS-FDA-00003,Analytics-Driven Supplement Evaluation (ASE),HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"This AI use case supports the triage and staff assignment process for the review of post-market Change Being Effected (CBE) supplement submissions.

The output of the AI component contributes to the triage and staff assignment process, and summarizes submitted information to support the decision of the reviewers of the CBE 30/0 supplemental submissions.","Using a Convolutional Neural Network (NN) model, in combination with a rules-based approach, produces an output that helps staff triage CBE submission review",Acquisition and/or Development,Neither,10/2022,10/2022,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,Data submitted in applicants' supplemental submissions,Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,6-12 months,No,No,No,None,Limited documentation for review
HHS-FDA-00004,Augmenting death and cause of death ascertainment in observational data sources,HHS,FDA,Health & Medical,None of the above.,"Augment assessment of mortality in electronic health records to support investigations to develop probabilistic estimates for causes of death in the Sentinel system.

The extraction of mortality information improves studies in Sentinel using mortality as an endpoint by enhancing on the quality of mortality data.","Augment assessment of mortality (date of death, cause of death) by applying Natural Language Processing (NLP) on healthcare narrative text and administrative codes.",Operation and Maintenance,Neither,01/2022,01/2022,12/2023,N/A,Developed with contracting resources.,75F40119D10037 - 7540119F19002,N/A,N/A,No,N/A,No,No,Yes,"`- National Death Index (NDI) data
- State Death Certificate Registery",Documentation has been partially completed,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,Sentinel,6-12 months,No,No,Yes,None,No documentation is available
HHS-FDA-00005,CLAT (Computerized Labeling Assessment Tool) ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"CLAT uses computer programming, image processing, and AI to assist the human review of drug labeling, including container labels, carton labeling, prescribing information, and Instructions for Use. CLAT assists the human visual comparison of drug labeling against a library of FDA regulations, guidances, standards, and best practices. CLAT identifies potential labeling deviations for human evaluation. 

CLAT is used to improve efficiencies in the manual labeling review process to help the reviewer mitigate medication errors and standardize labeling across therapeutic drug classes and product types. CLAT also assists the reviewer to catch deviations between label versions so no unintended errors have been introduced.","The tool processes images of carton and container labeling to identify minimum requirements on a label, identify availability of objects on an image, color differentiation of strength, missing barcode and orientation, incorrect or missing strength statement, error prone abbreviation, look-alike labels and text prominence. This will assist the reviewer by  improving the efficiency of drug labeling reviews, including container labels, carton labeling, prescribing information, and Instructions for Use. ",Acquisition and/or Development,Neither,09/2020,09/2020,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Label and Container cartons,Documentation is complete,N/A,N/A,N/A,N/A,Yes,CDEROne Analytics: FISMA-high environment,6-12 months,Yes,Yes,Yes,None,No documentation is available
HHS-FDA-00006,Empirical evaluation of EHR-based signal detection approaches,HHS,FDA,Health & Medical,None of the above.,"This supports Electronic Health Record (EHR) signal detection by extracting information using Natural Language Processing (NLP) and expanding the tree based scan statistic (TBSS) methods for EHR-based signal detection.


Extracts data to facilitate the identification of signals for outcomes, improving the manual identification of signals for outcomes derived from electronic health records.",The AI component in this study leverages an Natural Language Processing (NLP) approach to extract data from unstructured clinical notes.,Acquisition and/or Development,Neither,09/2023,09/2023,N/A,N/A,Developed with contracting resources.,75F40119D10037 - 75F40123F19010,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Claims-Electronic Health Record (EHR),Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Sentinel ,Less than 6 months,No,No,Yes,None,No documentation is available
HHS-FDA-00007,FAR-based Facility Signal Detection Tool ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Identifies problem clusters for the flagged signals in an objective manner for triage/review. 

Assist with objectively identifying problem clusters for the flagged signals, which then go through a dedicated triage & review process for further actions, and if needed, CMS (inspection) work activities can be opened. ",Identifies problem clusters for the flagged signals in an objective manner for triage/review. ,Operation and Maintenance,Neither,06/2019,06/2020,06/2024,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,Internal Field Alert Reports data from LSMV (FAERS tool),Documentation has been partially completed,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,6-12 months,Yes,Yes,No,Use of existing data platforms,Limited documentation for review
HHS-FDA-00008,MedWatch Dashboard ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Assist with consistent monitoring and identification of product risks from MedWatch reporting patterns and report content to support review staff.

Supports efficient, objective, risk-based product quality assessments from MedWatch reports for verification by review staff ",Identify product risk signals from MedWatch reports by using time series analysis to flag products and topic modeling to summarize the comments.,Operation and Maintenance,Neither,01/2021,05/2021,04/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,MedWatch data from LSMV and IQVIA data,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,6-12 months,Yes,Yes,No,Use of existing data platforms,Limited documentation for review
HHS-FDA-00009,Quality Surveillance Dashboard (QSD),HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Extracts unstructured text from documents and pools that with other available data to form a dashboard that enables consistent assessment of CDER regulated manufacturing facilities

Assists in the efficient, objective, risk-based assessments of CDER regulated manufacturing facilities.",Identifies and extracts keywords/phrases from unstructured documents and presents sentences containing keywords/phrases in context.,Operation and Maintenance,Neither,01/2019,01/2019,03/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,FDA EIR documents,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,6-12 months,Yes,Yes,No,Use of existing data platforms,Limited documentation for review
HHS-FDA-00010,Scalable automated NLP-assisted chart abstraction and feature extraction tool,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Examine the usability of electronic medical records in conducting pharmacoepidemiology studies through a case study of montelukast use among patients with asthma and neuropsychiatric events

The project will involve an “end-to-end” implementation of a full pharmacoepidemiologic study using one or more product-outcome pairs to demonstrate how NLP and other advanced analytic methods or tools can be used to accurately identify study outcomes and covariates from unstructured Electronic Health Record (EHR) data.","Natural language processing (NLP), a computational linguistics technology, will be used to read, interpret and organize health data that may be contained within unstructured data fields within EHRs. This activity intends to build a semi-automated system that uses advanced methods and tools, including NLP, to enable large-scale outcome identification, confounder feature extraction, and longitudinal contextualization of Electronic Health Record (EHR) data.",Acquisition and/or Development,Neither,10/2022,09/2022,N/A,N/A,Developed with contracting resources.,75F40119D10037 - 7540119F19002,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Claims-Electronic Health Record (EHR) - (structured and unstructured),Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,Sentinel ,6-12 months,No,No,Yes,None,No documentation is available
HHS-FDA-00011,Annual Report CMC,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Objective of this use case was to extract CMC changes reported within unstructured annual report industry submission documents to build a complete repository for downstream analysis

The extracted data are presented in a dashboard (along with other data) for downstream human analysis.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,01/2024,01/2024,05/2024,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,Applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00012,Application-DMF Reference,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Extracts references to DMFs from marketing application (ANDA/NDA/BLA) submissions. These submission documents may be structured (356H form) or unstructured (eCTD module 1-4). This pipeline parses content from these documents, extracts DMF references (e.g., ANDA123456 references DMF123456), and exposes the data in a structured format for analysis. 

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis. The purpose of this use case is to build a comprehensive inventory of all application to DMF references to support OPQ in reviewing applications since many application to DMF references were previously missing from structured sources.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,05/2023,05/2023,12/2023,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,YEs,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00013,Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS) ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"The deduplication algorithm is applied to all historical and incoming case report submissions to the FDA Adverse Event Reporting System (FAERS) to identify duplicate individual case safety reports (ICSRs). Unstructured data that is in free text FAERS narratives is processed through a natural language processing system to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record linkage approach to identify duplicates. Application of the deduplication algorithm is optimized for processing entire FAERS database to support the data mining analytics process. 

Enhance the efficiency of removing duplicate FAERS reports to support data mining.",Uses Natural Language Processing (NLP) to extract out clinical features from free text narratives in a case safety report and uses them in the identification of duplicative case safety reports in the FAERS database.,Implementation and Assessment,Neither,12/2023,09/2024,N/A,N/A,Developed with contracting resources.,BAAFY23C2AWP1,N/A,N/A,No,N/A,Yes,No,Yes,Adverse Event data in FAERS,Documentation is complete,Sex/Gender,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,6-12 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-FDA-00014,Development of automation tools and data warehouse to facilitate BE assessments,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Enhancing and streamlining the data entry associated with the review of bioequivalence data in Abbreviated New Drug Application (ANDA) submissions

Reduce manual effort by preparing data for analysis and exporting results as part of the bioequivalence review. This tool will facilitate data collection and Information retrieval from the firm-submitted ANDA packages but will not involve reviewers' evaluation or judgement.",Transform submitted PK data into a usable format so that the reviewer can perform the routine bioequivalence analysis using the authorized pre-written SAS codes. Then it exports results to a draft bioequivalence review  document with the firm-submitted eCTD tables.,Acquisition and/or Development,Neither,05/2018,05/2018,N/A,N/A,Developed with both contracting and in-house resources.,75F40120F80605,N/A,N/A,N/A,N/A,N/A,N/A,No,N/A,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00015,DMF (Drug Master File) Facilities,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Extracts facility references from Type II (Drug Substance) DMF manufacturing submissions (i.e., DMF123456 discloses that it uses Facility X for manufacturing and Facility Y for stability testing). These DMF submissions may include structured documents (3938 form) or unstructured documents (eCTD module 3). This pipeline parses content from these documents, extracts facility references and supply chain roles (i.e., FEI 6789 – manufacturing facility), and exposes the data in a structured format for analysis. This allows OPQ to identify discrepancies between facilities reported on marketing applications and those disclosed by DMFs referenced by those applications. 

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis. The ultimate purpose of this use case is to build a comprehensive inventory of facilities reported within DMF submissions as well as the applications that reference those DMFs.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,06/2022,06/2022,06/2023,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,Applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00016,Four Part Harmony Identification,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Accuracy of language used to report back deficiencies to submitters.

This will reduce the amount of time it takes and reduce staff burden, thus allowing for MDUFA requirements to be met.",This will reduce the amount of time it takes to verify and identify issues with language used for deficiency letters and ensure the adherence to the language necessary.,Acquisition and/or Development,Neither,09/2023,09/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Submission data and documents,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,CEDh,6-12 months,Yes,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-FDA-00017,Information Visualization Platform (InfoViP) to Support Analysis of adverse event reports,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Information Visualization Platform (InfoVIP) supports post-market surveillance using AI to assist prioritization and analysis of adverse event reports by extracting data from unstructured case narratives and combining it with structured data to support analysis and review of adverse event reports. The tool assists with   case series analyses, creating data visualization, and classifying adverse event reports by information quality.

Improve the efficiency in preparing and analyzing data during the review and evaluation of adverse event reports.",Performs Natural Language Processing (NLP) and applying Machine Learning (ML) algorithm to extract data from unstructured case narratives and combine with structured data to support analysis and review of adverse event reports.,Acquisition and/or Development,Neither,09/2019,09/2019,N/A,N/A,Developed with contracting resources.,BAAFY23C2AWP1,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Adverse Event data in FAERS,Documentation has been partially completed,Sex/Gender,N/A,N/A,N/A,No,N/A,More than 12 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-FDA-00018,LLM-Assisted VAERS Analyses,HHS,FDA,Health & Medical,None of the above.,"Build capacity for and assess the application of a LLM to VAERS (Vaccine Adverse Events Reporting System) to provide reviewers adhoc VAERS queries and efficiently generate customized query outputs

Efficiently generate customized query outputs of VAERS queries for reviewers.",To provide reviewers adhoc VAERS queries.,Acquisition and/or Development,Neither,12/2023,12/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Yes,Adverse Events data in VAERS,Documentation is widely available,"Sex/Gender, Age, Race/Ethnicity ",N/A,N/A,N/A,Yes,CBER HIVE,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00019,Pharmacovigilance machine learning to detect excess safety signal,HHS,FDA,Government Services (includes Benefits and Service Delivery),None of the above.,"Post-market adverse event reporting

Using a computer algorithm assists FDA in finding ""needle in the haystack"" events that are difficult to uncover with manual review of reports",Generate potential safety signals to investigate further using statistical based algorithms,Operation and Maintenance,Neither,01/2015,01/2008,01/2015,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,N/A,N/A,Yes,N/A,N/A,Yes,PV Analyzer,N/A,No,Yes,Yes,None,No documentation is available
HHS-FDA-00020,Module 3 Faculties,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Objective of this use case was to identify and extract all drug manufacturing facilities reported within unstructured module 3 submissions from marketing applications to build an comprehensive inventory of drug facilities

The extracted data are presented in a dashboard, along with additional data, for downstream human analysis.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,07/2023,07/2023,02/2024,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00021,OPPQ Policy Bot (AKA Policy and Guidance Documents Search) ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Helps policy staff in searching documents containing regulations and responding to inquiries, and other policy related work. 

In developing policy and responding to inquiries, OPPQ staff often need to reference  previously published policy documents in order to ensure consistency. This AI-enabled tool will allow policy leads and other staff to quickly identify and query the appropriate documents.","Identifies applicable published MAPPS, guidances, and policy related documents based on queries from users. Includes link to the document for further human review.",Implementation and Assessment,Neither,09/2024,09/2024,N/A,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,CDER policy documents,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00022,Packaging Materials and Suppliers,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Objective of this use case aims is to extract data from unstructured sources to build an inventory of drug packaging materials and their suppliers to support staff on conducting drug supply chain analysis

The extracted data are presented in a dashboard for downstream analysis.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,07/2023,07/2023,09/2024,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,Applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00023,Process Large Amount of Submitted Docket Comments,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"To enhance the automatic process of dockets, we have created an AI/ML tool in CBER/HIVE that automatically download dockets and process them to accelerate the review of docket comments, significantly improving the efficiency and accuracy of our regulatory processes

Efficiently generate customized query outputs of VAERS queries for reviewers.",To provide reviewers adhoc VAERS queries.,Implementation and Assessment,Neither,09/2021,11/2021,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,Public comments for various dockets.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CBER HIVE,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00024,Real World Data/Evidence ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Identify industry unstructured submissions containing Real World Data/Evidence (RWD/E) by analyzing parsed content for likely indicators of Real World Data/Evidence RWD/E to support congressional reporting.

The extracted data are presented in a dashboard for downstream human analysis.",Supports extracting text from unstructured documents and tagging for documents containing Real World Evidence and Real World Data,Implementation and Assessment,Neither,02/2024,02/2024,N/A,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00025,Regulatory Starting Material ,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Extract RSMs and their suppliers from unstructured module 3 industry submissions to create an inventory that will illuminate the upstream supply chain.

The extracted data are presented in a dashboard for downstream analysis.",Support information extraction from unstructured documents,Operation and Maintenance,Neither,09/2022,09/2022,08/2023,N/A,Developed with both contracting and in-house resources.,75F40124A00003,N/A,N/A,No,N/A,No,No,No,applicant submissions,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-FDA-00026,Resource Capacity Planning,HHS,FDA,Mission-Enabling (internal agency support),None of the above.,"Forecasting human drug review program submissions and corresponding FDA workload 

Improve the forecasting of human drug review program expected workload in order to adjust fee revenue and fees to fund resources needed to complete expected workload  ",Forecasts workload submissions across major user fee programs to support fee setting for the human drug review programs,Operation and Maintenance,Neither,01/2016,01/2017,08/2020,N/A,Developed with both contracting and in-house resources.,HHSF223201510012B,N/A,N/A,No,N/A,No,No,Yes,FDA systems including DARRTS and Panorama,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,CDEROne Analytics: FISMA-high environment,Less than 6 months,Yes,Yes,Yes,None,Documentation has been developed
HHS-FDA-00027,Supply Chain Resilience Program,HHS,FDA,Emergency Management,None of the above.,"Forecasting demand of medical devices and supplies.

Forecast demand for critical devices during a variety of scenarios (e.g. natural disaster, PHE)  ",Aids in forecasting demand for critical devices under a variety of scenarios.    ,Operation and Maintenance,Neither,02/2022,02/2022,04/2023,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,N/A,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,FiDLE; RSCP and is being moved to CEDh-OSCR,6-12 months,N/A,Yes,Yes,Re-use production level code and/or data products,Documentation has been developed
HHS-HRSA-00001,AI Audit Resolution Assistant,HHS,HRSA,Mission-Enabling (internal agency support),None of the above.,"The objective of this initiative is to reduce the time for HRSA auditors to review/resolve Single audits. HRSA has experienced an exponential increase in Single audits which is attributable in COVID funding attributable to the Provider Relief Fund programs. 

Success will be measured through the increase in the number of Single audits assigned to each auditor.  e.g., improved technological capabilities should allow HRSA Auditors to more efficiently review and closeout Single audits. ","HRSA will utilize generative AI to streamline the Single Audit resolution process and the creation of Management Decision Letters to formally close out and resolve Single audit findings.  The AI Audit Resolution Assistant (AIARA) includes a vector database comprised of Single audit documents assigned to HRSA, creates a retrieval augmented generation which integrates with a large language model to intelligently summarize audit findings and recommendations, and provides chatbot capability and reduce the cognitive load on HRSA auditors for any audit-specific questions. ",Implementation and Assessment,Neither,01/2024,03/2024,N/A,N/A,Developed with both contracting and in-house resources.,75R60222F80097,N/A,N/A,N/A,N/A,No,No,No,HRSA did not use agency data to train or fine-tune the large language model. HRSA did use publicly-available data from the Federal Audit Clearinghouse to evaluate the accuracy and precision of LLM outputs. ,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Documentation has been developed
HHS-HRSA-00002,Knowledge Navigator,HHS,HRSA,Government Services (includes Benefits and Service Delivery),None of the above.,"The objective is to develop an AI model that can answer detailed and complex questions about the key programmatic document, Application and Program Guidance (APG), that is issued annually before the application cycle opens. The PoC LLM has Applicant and Program Guidance (APG) documents for 10 loan repayments and scholarship programs.

This will allow loan repayment and scholarship analysts and call center agents to  better respond to public inquiries from applicants and participants.  If successful the Knowledge Navigator could be made available to applicants and participants and reduce the volume of calls to the BHW Call Center along with the number of call center agents.  ",BHW has implemented a proof of concept Generative AI (GenAI) Large Language Model (LLM) Knowledge Navigator (KN) to support National Health Service Corps (NHSC) and Nurse Corps loan repayment and scholarship program analysts and call center agents respond to program applicants and participants. ,Acquisition and/or Development,Neither,02/2024,02/2024,N/A,N/A,Developed with both contracting and in-house resources.,75R60224F34005,N/A,N/A,N/A,N/A,N/A,N/A,No,HRSA Application and Program Guidance (APG) documents for 10 HRSA loan repayment and scholarship programs.  All of which are public documents.  Here is an example: https://nhsc.hrsa.gov/sites/default/files/nhsc/loan-repayment/nhsc-students2service-lrp-application-program-guidance.pdf,Documentation is widely available,N/A,N/A,N/A,N/A,Yes,Bureau of Health Workforce Management Information System Solution (BMISS) Platform (UII: 009-000004158,Less than 6 months,No,Yes,Yes,None,Limited documentation for review
HHS-HRSA-00004,Policy Assistant,HHS,HRSA,Mission-Enabling (internal agency support),None of the above.,"HRSA is looking forward to leveraging Generative AI tools to support and enhance the current drafting of several policy documents, funding opportunities, and notices. This could streamline the policy development process, reduce drafting time, and improve document quality by providing critical analysis and suggestions for improvement, thus enhancing the overall policy-making workflow.

Reduce the amount of time required to develop first drafts of key BHW policy documents including APGs, NOFOs, budget documents","The Policy Assistant (PA) is an innovative application utilizing large language models (LLMs) to generate first drafts of key policy documents. Inputs can include example documents, style guides, and key policy decisions and other documents in the Knowledge Navigator. PA also features an editing tool that scrutinizes drafts for inconsistencies or errors, offering feedback for refinement. Current planning leverages Cloud-based services, LLM, Text processing and analysis tools, Natural Language Generation (NLG) and Text Analysis for the implementation.",Initiated,Neither,03/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-HRSA-00006,Scholar Match,HHS,HRSA,Government Services (includes Benefits and Service Delivery),None of the above.,"The current candidate evaluations and placement process is complex and challenging for both analysts and participants. By enhancing this process with AI/ML support could optimize resource allocation and candidate satisfaction, significantly impacting workforce distribution and efficiency in critical health areas.

This would improve the process of matching NHSC and Nurse Corps Scholars going into clinical service in underserved communities."," The Scholar Match (SM) leverages AI to enhance the placement process of NHSC and Nurse Corps scholars in communities of need across the U.S. and territories. By analyzing candidate profiles and regional needs, SM recommends optimal placements, ensuring both the fulfillment of organizational needs and the satisfaction of the candidates. Current planning leverages Machine Learning, Recommendation Systems, Cloud-based platforms and Data analytics services for the implementation.",Initiated,Neither,01/2025,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-HRSA-00007,Scholarship Insight,HHS,HRSA,Government Services (includes Benefits and Service Delivery),None of the above.,"The NHSC and Nurse Corps Scholarship reviewers need to receive and score thousands of essays submitted and the manual process delays the application processes. We are looking forward to building a Generative AI program that looks at all of the previous essays and how the scoring rubric was done and train it to do the first cut at scoring the essays. This could enhance the fairness and efficiency of scholarship evaluations, ensuring a thorough review process that supports equitable student opportunities.

Reduce the amount of time required for internal or external reviews to evaluated NHSC and Nurse Corps scholarship applications and ensure that human reviewers are following the appropriate scoring rubric.","The Scholarship Insight (SI) is designed to support the evaluation of scholarship essays for both the NHSC and Nurse Corps Scholarship Programs by providing detailed analysis to human graders. Aligning with directives to ensure human oversight, SI identifies key themes, strengths, and weaknesses in essays, facilitating a more informed grading process without replacing human judgment. Current planning leverages Cloud-based services, Natural Language Understanding (NLU), Text Analysis, LLM API and Data analysis tools for the implementation.",Initiated,Rights-Impacting,01/2025,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-HRSA-00008,Site Application Analysis,HHS,HRSA,Government Services (includes Benefits and Service Delivery),None of the above.,"The current application review process requires internal analysis to review many complex documents to determine Site Eligibility to employ a member of the NHSC or Nurse Corps. By enhancing this process with AI/ML support could revolutionize and streamline the NHSC, Substance Use Disorder Treatment and Recovery (STAR)and Nurse Corps Site Application Process.

This would improve the current highly manual process for reviewing Site applications for internal analysts but ensure that clinical sites are being approved for NHSC, Nurse Corps, and STAR LRP.","The Site Application Analysis (SA) is designed to support the evaluation of NHSC, STAR and Nurse Corps Site Applications. SA will allow for faster more accurate review of Site Applications and allow BHW Regional Analysts to focus on a higher value task. Current planning leverages Cloud-based services, Machine Learning, Recommendation Systems, Natural Language Understanding (NLU) and Text Analysis for the implementation.",Initiated,Rights-Impacting,01/2025,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00001,A Cluster-Based Machine Learning Approach for Evaluating Factors Associated with Plasma Neurodegenerative Biomarkers,HHS,NIH,Health & Medical,None of the above.,"This AI Use Case is Retired, No Longer in Use. This study investigated whether incorporating health-related risk factors can improve the predictive power of plasma biomarkers (related to neurodegeneration and inflammation) for incident dementia. 

Improve incident dementia prediction using plasma neurodegeneration biomarkers in a diverse population. ","Using ~450 common health-related risk factors and plasma neurodegeneration and inflammation biomarkers from the population-based cohort with the follow-up period over 20 years - the Age, Gene/Environment Susceptibility – Reykjavik Study.   ",Retired,Neither,N/A,N/A,N/A,09/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00002,AccessGUDID Data Validation,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The artificial intelligence (AI) system for AccessGUDID will focus on enhancing data quality assurance by detecting anomalies in medical device metrics, such as inconsistent units of measurement or unusual device dimensions. It will analyze both structured data, like numerical measurements, and unstructured data, such as free text entries. The AI will not modify data directly but will flag potential issues for human review. Integrated into the U.S. Food and Drug Administration (FDA)'s processing workflow, it will leverage standard codes for precise grouping and employ advanced language models to process unstructured data. Deployed within the regulatory compliance and data management areas of NLM, this AI system aims to streamline data validation processes, reduce manual workload, and maintain the integrity of the AccessGUDID database, without overstepping into areas requiring human oversight.

The key problem the AI aims to address is the presence of inconsistent or incorrect data entries, such as mismatched units of measurement or outlier device dimensions, which can lead to regulatory compliance issues and potential risks in device usage. By automating the anomaly detection process, the AI will improve the efficiency of data validation, significantly reducing the manual effort required to identify and correct errors. This will not only enhance the accuracy of the data but also speed up the processing and integration of new submissions into the AccessGUDID database. Improved data integrity will lead to better decision-making for manufacturers, healthcare providers, and regulators, ensuring that medical devices on the market meet safety and performance standards. Ultimately, the positive outcomes of this AI application include increased trust in the medical device information provided to end users, which contributes to the broader goal of improving public health and ensuring patient safety across the nation.","For inputs, it handles structured data, such as numerical metrics (e.g., device dimensions, units of measurement), and unstructured data, such as free-hand text entries describing medical devices. This data is sourced from the AccessGUDID database, which aggregates information submitted by manufacturers to the FDA. The frequency of data processing aligns with the batch submissions from the FDA, typically occurring daily or whenever new data is received. The system processes large volumes of data to detect anomalies, making it scalable to accommodate growing datasets. For outputs, the AI generates predictions and classifications, specifically identifying potential anomalies in the data, such as incorrect units of measurement or outlier device specifications. The results are presented as flags or labels indicating the presence of an anomaly, which are then reviewed by human analysts. The AI produces these results in real-time as part of the batch processing workflow, ensuring that each data submission is evaluated promptly before being fully integrated into the AccessGUDID database. The output helps in streamlining the data validation process and improving overall data quality.",Initiated,Neither,03/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00003,AI Solution for Image Duplication Detection,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIA researchers generate a significant number of microscopic images for each publication, ranging from 100 to 200 TIFF files per study. Ensuring that these images are not duplicated or overlapped in any publications is crucial for maintaining research quality and credibility. The current manual verification process is time-consuming, prone to human error, and insufficient for handling large volumes of data. 

NIA researchers generate a significant number of microscopic images for each publication, ranging from 100 to 200 TIFF files per study. Ensuring that these images are not duplicated or overlapped in any publications is crucial for maintaining research quality and credibility.",Identification of image duplications.,Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00004,AI Solution for Research Funding Gap Analysis (RF-GAP),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIA is focusing on identifying and addressing funding and publication gaps in NIH-funded research. Using text-mining and artificial intelligence techniques on data from both NIH and external sources, NIA aims to uncover research areas that need more funding or lack sufficient publication coverage. This approach will help NIA leadership make informed decisions, refine funding strategies, and enhance the overall impact of NIH-funded research. Program officers will utilize a user-friendly dashboard for actionable insights, simplifying the tracking of research outputs and identification of gaps.  1. Improved allocation of NIH funding through targeted identification of underfunded research areas and initiatives to address publication gaps. 2. Enhanced integration of data sources will provide a comprehensive view of research trends. AI-driven analysis will offer actionable insights into emerging research areas and future funding needs.  3. Customized dashboards will empower program officers with efficient tools to monitor and manage research portfolios, fostering transparency and maximizing operational efficiency across NIA. 

This approach will help NIA leadership make informed decisions, refine funding strategies, and enhance the overall impact of NIH-funded research.",Publication and Gap analysis reports.  ,Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00005,AI/ML for Study Section Prediction in NICHD,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The project of AI/ML for Study Section Prediction is to classify the grant applications to specific Study Sections in the Scientific Review Branch in NICHD.  It employs human-in-the-loop development which enables human evaluation and offers the ability to override and alter model outputs.  Source data are from the NIH IMPAC II system via the eRA Review Module. The AI process and output data have no impact on the NIH IMPAC II system. The business area addressed is the alignment of appropriate Study Section for a given grant application to assist the Scientific Review Branch (SRB) at NICHD.

This project adapts the methods and systems developed for the RPAB AI/ML Referral System project to optimize the assignment of grant applications to the most suitable study sections. The AI system will contribute to NIH's mission by improving the efficiency and accuracy of alignment of grant applications to study sections, ensuring that applications are reviewed by the most appropriate researchers, leading to scientific discoveries and health advancement.",Internal: NIH ImpacII and eRA Review Module queries. Results are presented as study section (class) predictions and class probabilities.,Implementation and Assessment,Neither,10/2023,10/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,Yes,No,Yes,"NIH IMPAC II funded and unfunded grant application data is used. Unstructured text from project abstract, specific aims, and title are encoded and vectorized for model training and inference. Fiscal year, activity code, and RCDC terms are transformed via one-hot encoding for use in model training and inference. PII related to individuals associated with the grant is kept intact to preserve the integrity of the use case of grant application referral and the trends of researchers' focus on particular scientific areas.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-NIH-00006,AI-enabled landscape analysis of New Approach Methodologies (NAMs) in biomedical research literature,HHS,NIH,Health & Medical,None of the above.,"Part of NIH Common Fund strategic planning efforts for new program. Complement Animal Research in Experimentation (Complement-ARIE) aims to identify opportunities and use trends for NAMs in biomedical research. Methods development in using genAI for literature searching and extraction applicable to other use cases.

GenAI was used to survey the biomedical research literature to inform potential investment of resources and opportunities for the NIH Common Fund program. Methods are also applicable to other systematic literature review approaches.","Identify trends in use of New Approach Methodologies, gaps, and opportunities for investment by NIH.",Implementation and Assessment,Neither,01/2023,01/2023,N/A,N/A,Developed with contracting resources.,HHSN273201500010C; GS00Q14OADU417,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,N/A,No,"Input data are publicly available, published research studies.",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00007,Applying for Grants Chat Bot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"A chatbot can significantly aid prospective grantees by providing instant, detailed information on specific grants, including eligibility criteria, application deadlines, and required documentation. It can guide users through the application process step-by-step, recommend additional resources for grant writing, and help determine eligibility to save time. Additionally, chatbots can assist in tracking application status, address common FAQs, and gather data on user needs. A chatbot streamlines the grant application process, reduces frustration, and enhances the overall experience for those seeking funding. 

It can guide users through the application process step-by-step, recommend additional resources for grant writing, and help determine eligibility to save time.",Targets resources related to probing questions for end users.,Initiated,Neither,09/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00008,Assessment of DTT/NTP research effectiveness,HHS,NIH,Health & Medical,None of the above.,"Dextr/LaserAI does not use PII, PHI or demographic data. Dextr is FEDRAMP certified and ATO in the cloud. Data sources for Dextr are published PDFs accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).

Modification and customization of the DEXTR automated extraction tool has been implemented to identify and capture Division of Translational Toxicology (DTT) and National Toxicology Program (NTP) research citations in the published literature, regulations, and popular press. The DEXTR automated workflow with user-verification supports the identification of these citations that will be used to assess impact and effectiveness of DTT and NTP research. Division Directors and Branch Chiefs require an evidence-based approach to assess the effectiveness of current and past research. Such an approach would be highly valuable for research prioritization. ",Identifies how DTT/NTP research was used or impacted the publication.,Acquisition and/or Development,Neither,10/2024,10/2024,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"Data sources for Dextr are published PDFs accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).",Documentation is missing or not available,N/A,N/A,N/A,N/A,Yes,DEXTR,Less than 6 months,No,Yes,No,Use of existing data platforms,No documentation is available
HHS-NIH-00009,Assisted Referral Tool,HHS,NIH,Health & Medical,None of the above.,"Review activities of the Center for Scientific Review (CSR) are organized into Review Branches (RBs). Each RB represents a cluster of study sections around a general scientific area. Grant applications generally are assigned first to an RB, and then to a specific study section within that RB for evaluation of scientific merit.

To provide assistance in assigning appropriate scientific areas for grant applications.","The Assisted Referral Tool (ART) recommends potentially appropriate study sections, based on the scientific content of a user’s grant application.  The user enters the application text and hits the Submit button to get a list of relevant study sections (scientific areas) in two groups, as “Strong” and “Possible” matches. The information provided to ART is only used to recommend study sections and is not stored or persisted.   The recommendations made by ART are solely for the benefit of the user. ",Operation and Maintenance,Neither,01/2014,01/2014,01/2015,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,Yes,IMPACII,Documentation is missing or not available,N/A,Yes,No – agency does not have access to source code.,N/A,Yes,Center for Scientific Review  General Support System (CSR GSS) ,Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00010,Autism Spectrum Disorder (ASD) Classification Model for Children using Deep Neural Network,HHS,NIH,Health & Medical,None of the above.,"This AI Use Case is Retired, No Longer in Use. The AI was used for evaluating whether a child around the age of 10 is exhibiting Autism Spectrum Disorder (ASD), and its severity. 

This AI Use Case is Retired, No Longer in Use. The primary objective of the AI use case was to enhance the accuracy and efficiency of diagnosing Autism Spectrum Disorder (ASD) by automatically categorizing ASD using deep learning models trained on Inertial Measurement Unit (IMU) hand tracking data. The AI aimed to address the complexity and variability in ASD diagnosis, which currently relies on subjective behavioral assessments. ","The input data consists of four 3-dimensional vectors obtained from an IMU attached to the participant's hand while they perform cognitive and motor tasks. The classification result from the deep learning model outputs a value of 0 or 1, indicating ASD or typical development, respectively.",Retired,Neither,N/A,N/A,N/A,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00011,Automated annotation of study data using knowledge organization systems,HHS,NIH,Health & Medical,None of the above.,"Application to support automation of systematic review processes and annotation of extracted information from studies in the published literature.

Automating the annotation of extracted information from environmental health studies will support joining with other structured datasets to serve as training data for predictive model development, validation of new approaches, and more robust analyses on weight of evidence of chemical effects on biological systems.",Annotation of information using knowledge organization systems.,Implementation and Assessment,Neither,01/2021,01/2022,N/A,N/A,Developed with contracting resources.,GS00Q14OADU417,N/A,N/A,No,N/A,No,No,No,"Input data are publicly available, published research studies or publicly available through DTT in CEBS.",Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,More than 12 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00012,Automated approaches for table extraction,HHS,NIH,Health & Medical,None of the above.,"The Division of Translational Toxicology (DTT) is an intramural division at NIEHS. DTT's mission is to improve public health through data and knowledge development that are translatable, predictive, and timely. DTT scientists use a variety of traditional and cutting-edge approaches to better understand how factors in our environment may impact health. 

Automated approaches for identifying and extracting data from tables will save time and reduce level of effort for teams evaluating published studies (epidemiology reviews or meta-analyses, hazard assessments, etc.) and ultimately impacts development of health effect conclusions.","This project developed an automated, model-based processes to reduce the time and level of effort for manual  extraction of data from tables. Published data tables are a particularly data-rich and challenging presentation of critical information in published research.",Retired,Neither,N/A,N/A,N/A,01/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00013,Automated Basic-Applied Categorization of extramural grants,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"This machine-learning algorithm is in development. Currently it uses information on NIMH-funded extramural research projects to categorize them as basic or applied research per the federal definitions for each. The data it is trained on is supplied from extramural grant applications and the same fields will be used for subsequent classification of new grants. For new grants, the algorithm will propose a categorization which can be reviewed, confirmed, or edited by an NIMH staff member. The resulting information will be used for internal, analytical purposes and annual reporting of NIMH-funded basic and applied research. The AI will NOT influence funding decisions, require or use PII, or use any other sensitive, personal, or health information.

The algorithm is intended to be consistent in identifying basic and applied research, reduce burden of review by NIMH staff, and provide a complementary perspective to human review.","The algorithm produces categorization of basic and applied research that is used for internal analysis and annual reporting. The algorithm is trained on the following data from extramural grants from fiscal years (FY) 2000-2022 and will use the same for grants in FY2025 and going forward to propose a categorization of basic or applied research: Program Class Code, NIMH Division, NIH Research, Condition, and Disease Categorization (RCDC), Human Subjects Codes, Animal Subjects Code, Clinical Trial NIMH Division, text of grant title, abstracts, specific aims. These data categories are all obtained from NIH IMPACII and will be applied to 100% of NIMH extramural grants, excluding L activity codes. This constitutes approximately 1,500 new grants per FY. Algorithm performance will be assessed each year, comparing the proposed classifications to a manually reviewed sample, and input received from NIMH staff regarding edits to proposed classifications. The frequency of processing is yet to be determined. No anonymization or de-identification processes are employed as personal information is used neither to train, nor classify grants using this algorithm.",Acquisition and/or Development,Neither,06/2022,11/2022,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"The algorithm is trained on the following data from extramural grants from fiscal years (FY) 2000-2022 and will use the same for grants in FY2025 and going forward to propose a categorization of basic or applied research: Program Class Code, NIMH Division, NIH Research, Condition, and Disease Categorization (RCDC), Human Subjects Codes, Animal Subjects Code, Clinical Trial, NIMH Division, text of grant title, abstracts, and specific aims. These data are all obtained from NIH IMPACII and will be applied to 100% of NIMH extramural grants, excluding L activity codes. This constitutes approximately 1,500 new grants per FY. No anonymization or de-identification processes are employed as personal information is used neither to train nor classify grants using this algorithm.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,No,Re-use production level code and/or data products,Limited documentation for review
HHS-NIH-00014,Automated extraction of study methods and assessment of reliability,HHS,NIH,Health & Medical,None of the above.,"Application to support automation of systematic review processes and quality assessment of studies in the published literature (environmental health studies).

This project is focused on automating the identification of studies with reliable/well established methods (e.g., corresponding to regulatory guidelines) from the literature. Supervised and unsupervised methods are being applied to a) extract the methods details from known studies, and b) identify studies whose methods fulfill reliability criteria.   Identification and critical assessment of existing research is required for developing evidence-based conclusions, directing future research, and informing policy decisions by scientists, Branch Chiefs and Division Directors. Study reliability or quality are important considerations in the assessment of published research studies and are very time and labor intensive using manual approaches. ",Input: published environmental health studies; Output: identification of study methods and categorization of reliability/methods quality.,Acquisition and/or Development,Neither,01/2017,01/2018,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,"Input data are publicly available, published research studies or publicly available through DTT in CEBS.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,More than 12 months,No,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00015,Automation of Receipt & Referral Process of NIDDK grant applications,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"This use case is centrally reported under OER's Internal Referral Module. NIDDK receives about 100 to 500 applications per week. NIDDK referral staff uses the IMPAC II QVR tool to stratify the applications between divisions based on a “Like Matrix” function to match the Division’s portfolios and the Title, Abstract, and specific aims of grant applications. This process is laborious and manual. Hence, automation was proposed. The scope of the effort is to provide a capability for NIDDK to analyze grant applications using NIDDK-specific business rules, complete the pilot, and the full implementation of the Artificial Intelligence (AI) and Natural Language Processing (NLP) tools for auto assignment of program class codes.

NIDDK receives about 100 to 500 applications per week. The AI and machine learning tool will stratify the applications between programmatic divisions and Program Class Code (PCC) to match the Division’s portfolios based on the Title, Abstract, and specific aims of grant applications. It collectively saves NIDDK Program and Referral Staff 3000+ hours annually on Receipt and Referral activities. In addition, it instantly recommends PCC, allows Division designees to accept or change recommendations, tracks all grants that need PCC assignment, gives real-time information about the application status, and support business rules/generates reports.","Input: Title, Abstract, Public Health Narrative, Specific Aims of grant applications from the FY 2018 to 2022.

Output: Division and Program Class Code (PCC) of grants from FY 23/24.",Operation and Maintenance,Neither,10/2021,10/2021,10/2023,N/A,Developed with contracting resources.,2-DK22-560-02 and OER-23-014,N/A,N/A,No,N/A,No,No,Yes,"Yes, It used the NIH/NIDDK grants applications data submitted by research investigators. The prediction models use the Title, Abstract, Public Health Narrative, and specific aims of grant applications from the FY 2018 to 2022 to train the models and FY 23 and F24 grants applications data were used for predicting programmatic divisions and Program Class Codes (PCC).",Documentation is complete,N/A,Yes,No – agency does not have access to source code.,N/A,No,N/A,6-12 months,Yes,Yes,Yes,None,Limited documentation for review
HHS-NIH-00016,Best Match: New relevance search for PubMed,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. Best Match is a relevance search algorithm for NLM’s PubMed – a free search engine for biomedical literature accessed by millions of users around the world every day. 

Best Match increases the effectiveness of PubMed searches across the rapidly growing collection of biomedical literature to help users efficiently find the most relevant and high-quality information they need. PubMed comprises more than 37 million citations for biomedical literature from MEDLINE, life science journals, and online books.","This AI technique leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date-sort order that appears in many traditional search engines. Trained with past user searches with dozens of relevance-ranking factors, the Best Match algorithm demonstrates state-of-the-art retrieval performance and an improved user experience. ",Operation and Maintenance,Neither,06/2016,06/2016,01/2023,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,No,"The PubMed literature collection includes articles relevant to biomedicine and the life sciences, broadly defined to encompass the information needs of those working in healthcare and life sciences. The Best Match algorithm was trained on interaction data from clicks on lists of articles returned when users search the PubMed collection with search terms.",Documentation is widely available,N/A,Yes,Yes – source code is publicly available.,https://github.com/ncbi-nlp/PubMed-Best-Match,No,N/A,6-12 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00017,Biomedical Citation Selector (BmCS),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. 

Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.",The output is sets of citation records that are classified as relevant to biomedicine and the life sciences. Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. ,Implementation and Assessment,Neither,01/2021,06/2021,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,PubMed citation data that was submitted by publishers and stored in the agency database was used.,Documentation is complete,N/A,Yes,Yes – source code is publicly available.,https://github.com/ncbi/biomedical-citation-selector,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00018,Chatbot for researchers to find data sets for environmental health research efforts,HHS,NIH,Health & Medical,None of the above.,"This project is focused on the use of large language models and chatbot technology to provide a way for researchers to find data sets of relevance for environmental health research efforts.

The primary objective is providing a tool that aids researchers in finding useful resources, specifically data sets, thus benefitting research efforts in finding the best data to use quickly.","The AI will use description of data sets that come from both NIH and federal data catalogs.  This will be periodically updated.  As output, the AI will provide rank order listings of recommended data sets.",Acquisition and/or Development,Neither,05/2024,05/2024,N/A,N/A,Developed with contracting resources.,SOAR,N/A,N/A,N/A,N/A,N/A,N/A,No,Input data are publicly available.,Documentation is widely available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,No,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00019,Clinical Trial Predictor,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

The AI tool predicts whether grant applications may involve clinical trials based on the text of their titles, abstracts, narratives, specific aims, and research strategies. ","The Clinical Trial Predictor uses an ensemble of several NLP and ML algorithms to predict whether applications may involve clinical trials based on the text of their titles, abstracts, narratives, specific aims, and research strategies. The responses are only used to make extramural officers aware of the fact that an application submitted to a NOFO that doesn't allow clinical trials may contain a clinical trial.  The extramural officers then evaluate the identified applications for the presence of a clinical trial.  No decisions are made by the AI, nor is the AI output used as the principle basis of a decision; it is just used to help the extramural officers identify applications containing clinical trials more quickly.",Implementation and Assessment,Neither,01/2023,01/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,All data come from the internal NIH IMPAC II database.,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00020,ClinicalTrials.gov Protocol Registration and Results System Review Assistant,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"ClinicalTrials.gov is a website and online database of clinical research studies and information about their results. The purpose of ClinicalTrials.gov is to provide information about clinical research studies to the public, researchers, and health care professionals. 

This project aims to help ClinicalTrials.gov determine whether the addition of AI could make reviewing study records more efficient and effective.",The classifier takes as input free-text related to a study’s endpoint and returns a prediction of whether one or more issues is present. ,Acquisition and/or Development,Neither,02/2021,11/2021,N/A,N/A,Developed with contracting resources.,GSA Contract # GS-10F-0064W    NLM BPA Task Order: 75N97019A00005/75N97021F00006,N/A,N/A,N/A,N/A,N/A,N/A,No,"We utilized agency-owned data for training and evaluating the model's performance. The data consisted of clinical study record submissions from ClinicalTrials.gov's Protocol Registration and Results System (PRS) that were divided into two groups: 

Set A: This group included submissions that did not pass quality control review, meaning they were returned to data submitters for revision and, in certain cases, are versions of the record that were never posted on ClinicalTrials.gov (not accessible to the public). These submissions had a relevant issue identified during manual quality control review, providing examples of endpoints known to contain the specific issue.

Set B: This group included submissions that were posted on ClinicalTrials.gov with endpoints that had never been labeled as having the specific issue. These submissions provided examples of endpoints that were considered not to have the specific issue.The input to the classifiers consisted of endpoint attributes, including Measure Titles, Descriptions, Time Frames, Units of Measure, and labels indicating whether the issue was present. This data did not have any personal identifiers. The data was in a structured format in the PRS, but the specific endpoint attributes were provided as free-text.

We processed over 10,000 endpoints from Set A, which included examples with identified issues, and over 40,000 endpoints from Set B, which had not been flagged with issues. It is important to note that the labeling of issues in the dataset is not exhaustive. Some endpoints may present multiple issues combined and labeled as a single issue, and there is a possibility that some issues were missed by reviewers. Consequently, Set B might contain endpoints that actually have the issue despite not being labeled as such. ",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00021,Collections Summarization Chatbot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The artificial intelligence (AI) use case involves developing a chatbot that can answer contextual questions about collection objects that users are browsing within the NLM Digital Collections. The chatbot will not handle inquiries unrelated to collection objects or queries outside its defined scope. It utilizes the Retrieval-Augmented Generation (RAG) framework on Amazon Web Services (AWS) to generate summaries or detailed answers based on the content users are viewing. The chatbot interface will integrate with existing NLM web technologies, activating when a user spends an extended time on a resource page. The AI system will use text data from the collection objects and associated metadata to generate responses. The primary business area for deployment will be within NLM’s digital services, focusing on enhancing user interaction and accessibility. 

The main goal is to provide users with concise summaries and detailed answers about NLM Digital Collections.","The input consists of text from documents or books within the Collection objects that users are viewing. The frequency of AI processing depends on how long users spend on the resource page. If users linger, the AI chatbot will prompt them with a summary of the resource they are viewing. The AI-generated output will be a summary of the resource presented in text format. ",Initiated,Neither,07/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00022,Computed Author: author name disambiguation for PubMed,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. PubMed comprises more than 37 million citations for biomedical literature from MEDLINE, life science journals, and online books.

 NLM developed a machine-learning method to score the features for disambiguating a pair of papers with ambiguous names. Subsequently, agglomerative clustering is employed to collect all papers belonging to the same authors from those classified pairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering results, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate author name searches.","PubMed users frequently use author names in queries for retrieving scientific literature. However, author name ambiguity (different authors share the same name) may lead to irrelevant retrieval results.",Operation and Maintenance,Neither,05/2009,05/2009,01/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,Searches of the PubMed literature collection using author names were used to create training and testing data sets consisting of article sets.,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00023,COVID-19 Pandemic Vulnerability Index Dashboard,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The dashboard creates risk profiles, called PVI scorecards, for every county in the United States, continuously updated with the latest data that summarize and visualize overall disease risk. 

Aims to reduce the impact of COVID-19 on vulnerable populations by aiding equitable decision-making on resource allocation and implementation of local- and state-level interventions. Available at https://covid19pvi.niehs.nih.gov/. ","Inputs are location-specific current infection rates, baseline population concentration, current interventions, and health and environmental vulnerabilities. Outputs are data visualizations and vulnerability estimates.",Operation and Maintenance,Neither,03/2020,03/2020,03/2020,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,No,Source data is derived from publicly available resources detailed here: https://www.niehs.nih.gov/research/programs/coronavirus/covid19pvi/details/.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,No,No,No,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00024,CSR Public Chatbot (CPC),HHS,NIH,Health & Medical,None of the above.,"This tool is a chatbot that answers questions from potential applicants and reviewers. Instead of providing lists of links to look through, the chatbot provides answers with links where the answers were drawn from. Source materials are limited to official government web pages, and a disclaimer is included cautioning the user to check the source materials to confirm the accuracy of the answers.

This chatbot is intended to provide answers to the public about questions related to NIH peer review policies and procedures. ","Input: Applicant/Reviewer Questions. 
Output: Answers to the questions ",Operation and Maintenance,Neither,01/2021,01/2021,01/2021,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,Yes,Applicant FAQs and publicly available content from public.csr.nih.gov website.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Center for Scientific Review  General Support System (CSR GSS),Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00025,DAIT AIDS-Related Research Solution,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIAID administers HIV/AIDS grant portfolios.

The incoming grant applications are ranked based on these predictions and more highly-ranked applications are prioritized for review.","The tool uses natural language processing text extraction and classification algorithms to predict both priority (High, Medium, Low) and category (Area of research) for a grant application. After DAIT awards grants, they review all awarded grants to determine if any of the awardees are conducting research that could be considered AIDS-Related. NIH’s Office of AIDS Research (OAR) will fund all or part of the grants if the research is considered AIDS-Related. The DAIT AIDS-Related Research solution (DAIT ARR), categorizes the awarded grants into research topics. This categorization is based on the title and abstract of the grant application.",Operation and Maintenance,Neither,01/2017,01/2017,01/2018,N/A,Developed with contracting resources.,Not Reported,N/A,N/A,No,N/A,No,No,Yes,"Yes, a dataset was curated to train the model and is evaluated manually by user input.",Documentation is complete,N/A,Yes,Yes – source code is publicly available.,http://tfs.niaid.nih.gov:8080/tfs/BI/DAIT_ARR/_git/grants?path=/main.py,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00026,Detecting Overlapping Science (DOS),HHS,NIH,Health & Medical,None of the above.,"This tool detects applications that represent potential duplicate funding (funding the same research in different projects). It examines applications as they are submitted to the NIH and sends a report to relevant personnel in the agency.

Detect and prevent duplicate funding with real-time examination of incoming grant applications.","Input: Text of grant applications.
Output: Pairs of possible duplication.",Operation and Maintenance,Neither,01/2023,01/2023,01/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,IMPACII,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Center for Scientific Review General Support System (CSR GSS),Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00027,Detection of Implementation Science focus within incoming grant applications,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Grants management oversight and administration.

Assign the grant application to a particular division for routine grants management oversight and administration.","This tool uses natural language processing and machine learning to calculate an Implementation Science score that is used to predict if a newly submitted grant application proposes to use science that can be categorized as ""Implementation Science.""",Operation and Maintenance,Neither,01/2019,01/2019,01/2020,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,Leverages NIH application data from IRDB.,Documentation is complete,N/A,No,No – agency does not have access to source code.,N/A,Yes,Dimensions for NIH and Analyst Support Infrastructure (ATO Letter - https://nih.sharepoint.com/:b:/s/NHLBI-ITAC-SECURITY/Eb_TarkpZPRCnX5RsGEBgQ8BgK4XC2_hjlsAVeHHLEjdww),Less than 6 months,Yes,No,No,Re-use production level code and/or data products,Limited documentation for review
HHS-NIH-00028,DEXTR - automated data extraction tool,HHS,NIH,Health & Medical,None of the above.,"Dextr/LaserAI does not use PII, PHI or demographic data. Dextr is FEDRAMP certified and ATO in the cloud. Data sources for Dextr are published PDFs accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).

The primary objective of the DEXTR/Laser AI use case is to streamline the process of data extraction from published studies for literature reviews, addressing the key problem of time and labor intensity involved in manual data identification and capture. DEXTR leverages natural language processing (NLP) models, regular expressions and large language models to automatically identify and predict pertinent entities of data extraction within scientific studies. By doing so, it reduces the burden of manual extraction while still supporting user verification, offering a semi-automated approach that ensures accuracy and quality control. One of the key tasks DEXTR enhances is the annotation of studies during the normal workflow, allowing the tool to generate annotated corpora for the development of future models. Dextr also provides automated extraction of information from tables in PDFs expanding the supported data extraction capabilities.  As a dynamic platform for multiple AI projects, DEXTR/LaserAI is continually being optimized and expanded to support a growing number of use cases. This automation not only accelerates data extraction but also aids in creating a robust, scalable system for handling the ever-increasing volume of published research. The anticipated positive outcomes include improved efficiency and accuracy in data extraction, which is critical for developing evidence-based conclusions, guiding future research directions, and informing policy decisions. By enabling faster and more comprehensive reviews of existing literature the tool has the potential to significantly enhance the ability to process large volumes of scientific data.","DEXTR leverages natural language processing (NLP) models, regular expressions and large language models to automatically identify and predict pertinent entities of data extraction within scientific studies.",Implementation and Assessment,Neither,08/2020,08/2020,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,"Data sources for Dextr are published PDFs that are accessible through open source publications (e.g. PubMed Central) or through our subscriptions (e.g., NLM).",Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Dextr is FEDRAMP certified and ATO in the cloud,Less than 6 months,No,No,No,Re-use production level code and/or data products,No documentation is available
HHS-NIH-00029,Division of International Services Customer Service Chatbot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The initial version is designed to allow both foreign nationals and administrative officers (AOs) to interactively receive accurate answers to general questions about immigration policy and operations managed by NIH Division of International Services.

The AI data store is compiled from DIS Frequently Asked questions and other relevant policy and general information. The benefit of the AI is to alleviate manual calls to the division for questions that can be covered more efficiently and accurately.","Generates text, images and data. Input data source is a local database. Frequency is TBD.",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00030,Enhance NLM Website Accessibility,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is pilot testing the use of artificial intelligence (AI) to enhance the accessibility of the NLM website in alignment with Section 508 standards.  This initiative is critical to mitigate the enterprise risk associated with non-compliance with Section 508 standards covering web sites. The AI will focus solely on identifying and resolving accessibility errors associated with Section 508 standards for websites, including suggestions from the U.S. Web Design System framework when possible. The AI is currently being developed behind NIH's firewall for a select internal user base. The tool will not make direct changes to general web design or web content. The AI will integrate with existing web content management systems and accessibility compliance tools (like pa11y).  The AI will use website data (HTML, CSS, JavaScript) and accessibility compliance standards as input and will be deployed in the web development and IT departments, particularly those focused on accessibility and compliance.

The project may reduce costs and time associated with manual accessibility evaluation and remediation. Additionally, it is expected to enhance the accuracy and quality of accessibility features on the website. Importantly, the project aims to improve the user experience by making the site more accessible to a broader audience, thus increasing user access and discovery. Ultimately, this initiative will help reduce the enterprise risk associated with non-compliance and ensure that NLM's website meets the evolving standards for government web accessibility.","Inputs: Website data (HTML, CSS, JavaScript), accessibility standards.

Outputs: Accessibility issue reports, suggested code fixes, task lists for implementation.

Frequency: The AI performs both site-wide scans and single URL audits on demand. ",Acquisition and/or Development,Neither,11/2023,05/2023,N/A,N/A,Developed with contracting resources.,75N97023A00004/75N97023F00005,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Website data (HTML, CSS, JavaScript), accessibility standards. Measures taken to ensure data accuracy and reliability: grounding, testing, evaluation, NIST framework.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00031,Enhancing Responses to Customer Questions about NLM Products,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is piloting the creation of an application which uses the GPT family of models from OpenAI (via Azure) and data retrieved from public facing NIH/NLM web domains to answer questions about select NLM products. This is currently being developed behind NIH's firewall for a select internal user base. The artificial intelligence (AI) will generate responses to questions but will not engage in direct conversations with customers. Additional safeguards would make sense in a production environment. The AI will integrate with a knowledge base and use text data from user technical questions and knowledge base articles. It will be deployed within customer service and technical support offices.

Primary Objectives: Provide accurate and timely responses to technical questions about NLM products. 

Anticipated Positive Outcomes: Improved efficiency and accuracy in customer service, better user experience, and higher satisfaction rates.","Inputs: User technical questions, knowledge base articles.

Outputs: AI-generated responses, gold standard responses, knowledge base links.

Frequency: Responses generated in real-time based on user inquiries.",Acquisition and/or Development,Neither,11/2023,05/2023,N/A,N/A,Developed with contracting resources.,75N97023A00004/75N97023F00008,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Website data (HTML, CSS, JavaScript), accessibility standards. Measures taken to ensure data accuracy and reliability: grounding, testing, evaluation, NIST framework.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00032,Environmental health research annotation for model development,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"By creating annotated datasets that account for diverse study types, the project will enable the development of AI and machine-learning models that can significantly reduce the time and effort required to identify and capture critical data from environmental health studies. This improvement will streamline tasks for teams conducting literature assessments and reviews, improving their efficiency.

The primary objective of this AI use case is to enhance the development of datasets specifically focused on toxicology and environmental health. The key problem it aims to address is the current scarcity of relevant training datasets or corpora, which limits the ability to create effective AI models for identifying and extracting environmental health data from published studies. This challenge is compounded by the diverse nature of environmental health research, which includes various study designs such as epidemiological studies, in vitro research, exposure assessments, and experimental animal studies.  ","Input: published environmental health studies.

Output: annotated corpus to support model development (e.g., BRAT format).",Acquisition and/or Development,Neither,01/2020,01/2020,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,N/A,Documentation is missing or not available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,No,Yes,None,No documentation is available
HHS-NIH-00033,Expansion of Generative AI (GenAI) Caption Generation for all Collections Videos,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The artificial intelligence (AI) use case builds on an existing Generative AI (GenAI) workflow in NLM Digital Collections that generates transcripts and captions for all videos stored in the Digital Repository dark archive. The expansion of this workflow will apply to all videos and films targeted for Digital Collections. The AI will not be used for content outside of these collections or for non-video materials, as well as already captioned videos. It will integrate with existing video processing systems to automate the captioning process. The types of data utilized will include video files and associated metadata. The deployment will occur within NLM’s Digital Collections management area, with the primary goals being cost savings by reducing reliance on third-party vendors and standardizing video caption workflows across all collections.

The objective is to expand AI-driven captioning across all videos in the NLM Digital Collections, ensuring standardized and accuracy. ",The inputs consist of video or audio mp4 or mp3 format comes from Collections videos that don't have captions. The AI generated captions will be in text format.,Implementation and Assessment,Neither,02/2020,03/2020,N/A,N/A,Developed with contracting resources.,HHSN316201200013W/75N97019F00066,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,Yes,"The agency-owned data used in this AI use case consists of U-Matic videos in MP4 format, hosted on collections.nlm.nih.gov. Each month, 8 uncaptioned U-Matic videos of various length are selected for processing, where the AI-generated captions are applied. The audio is extracted from the video files and used as input for AWS Transcribe, which is a pre-trained model that generates captions. During the QA process, there is a human reviews process that checks the quality and accuracy of the output captions, and a disclaimer is added to the videos indicating that the captions were AI-generated.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,No,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-NIH-00034,Federal IT Acquisition Reform Act (FITARA) Tool,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIAID administers contracts to execute mission initiatives.

The tool's classifications inform SOW clarifications/revisions relevant to the FITARA.",The tool classifies contract statement of work (SOW) documents as being IT-related or not. ,Operation and Maintenance,Neither,01/2017,01/2017,07/2017,N/A,Developed with contracting resources.,Not Reported,N/A,N/A,No,N/A,No,No,Yes,"Yes, a dataset was curated using NIAID SOWs which were manually labelled to train the classification model.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00035,Generative AI (GenAI) Still Image Tagging,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The artificial intelligence (AI) use case will focus on identifying still images within the NLM Digital Collections that lack descriptions. This use case will employ Generative AI (GenAI) tools such as Amazon Web Services (AWS) Recognition and/or AWS Bedrock to identify concepts and embedded text within these images. The AI system will not generate metadata for images that already have detailed descriptions or analyze images outside the NLM Digital Collections. The AI will connect with existing NLM metadata management systems, where the generated metadata will be stored and indexed. The primary types of data used will include image files from the digital collections and textual data derived from embedded text within those images. The AI system will be deployed within the NLM's business area, focusing specifically on enhancing the search and retrieval capabilities of the NLM Digital Collections.

The use case aims to automatically generate accurate metadata for under-described images in the NLM Digital Collections, enhancing their searchability and discoverability. This improvement will increase access to valuable medical and scientific resources, supporting research and public health initiatives. ","Input consists of image binaries (tif, jpeg or PDF format) served from Collections website can be hosted on S3; Amount consists of untagged images within the repository, ballparked about 75,000 image objects, then about 10-100 per month based on monthly content ingestions. 

Output should be AI generated classifications tags and/or AI generated image summary in text form. ",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00036,Grant Application Subject-Matter Classification Tool,HHS,NIH,Health & Medical,None of the above.,"The algorithm is used to recommend a specific scientific area within the Division's portfolio with a specific confidence level. This reduces the time it takes to assign a Program Class Code and personnel assignment to every grant application received by NIEHS. It searches for key words within the title, abstract and specific aims in each grant application to determine the best scientific category. It is not used in combination with any other data sets. It uses grant application data from IMPAC II, which is imported into the Grants Funding Decision Tool (a NIEHS Custom Product).

Natural language processing of grant applications to assign scientific topics and corresponding Program Officer staff.  The subject-matter classification tool improves the efficiency of the grant administration process by automatically assigning incoming applications a subject matter classification based on the text content of their abstracts using a model derived from past human-classified examples. This classification helps route each application to the program officer with the greatest expertise in the inferred field of study.",Training set consists of an Excel spreadsheet containing human-classified grant proposal abstracts. Input file is an Excel table containing new unclassified grant proposal abstracts. Output is input file updated to include tool-assigned subject matter classifications.,Operation and Maintenance,Neither,01/2016,01/2016,02/2020,N/A,Developed with contracting resources.,Not Reported,N/A,N/A,No,N/A,No,No,No,"Input data is provided to NIEHS by grant applicants, via the IMPAC II database.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,No,No,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00037,HIV-related grant classifier tool,HHS,NIH,Health & Medical,None of the above.,"A front-end application for scientific staff to input grant information, which then runs an automated algorithm to classify HIV-related grants. 

The tool allows OAR staff to determine the best categorization for a grant application after reviewing data and visualization of confidence levels through a heat map. Natural language processing of grant applications to assign scientific topics and corresponding Program Officer staff.  The subject-matter classification tool improves the efficiency of the grant administration process by automatically assigning incoming applications a subject matter classification based on the text content of their abstracts using a model derived from past human-classified examples. This classification helps route each application to the program officer with the greatest expertise in the inferred field of study.","Input: Grant text data.

Output: Predicted categorization.",Implementation and Assessment,Neither,11/2022,12/2022,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,"Grant text data (Title, Abstract and Specific Aims).",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,No,Yes,None,Limited documentation for review
HHS-NIH-00038,Improving Customer Response,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is pilot testing the utilization of artificial intelligence (AI) to assist Customer Service Representatives (CSRs) in drafting responses to customer inquiries. It is currently being developed behind NIH's firewall for a select internal user base. The AI is focused on generating draft responses for customer service but will not make final decisions or engage in direct communication with customers. CSRs are instructed to not enter personally identified info into the AI system. In the event this info is entered, the AI system is automatically prompted to not include any personally identified information in its generated response. Additional safeguards would make sense in a production environment or if it was released to the public. The AI will integrate with customer service platforms and databases like Medline Plus and DailyMed. The AI will use text data from customer inquiries and publicly accessible NLM-managed biomedical information services and be deployed within the customer service department. 

The project aims to enhance customer response metrics, increase customer satisfaction, and improve the efficiency of handling customer service inquiries.","Inputs: Customer inquiries, publicly accessible, NLM-managed biomedical information services (such as Medline Plus, DailyMed, etc.).

Outputs: Draft responses, resource links, disclaimers.

Frequency: Responses generated in real-time as inquiries are received.",Acquisition and/or Development,Neither,11/2023,05/2023,N/A,N/A,Developed with contracting resources.,75N97023A00004/75N97023F00006,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Website data (HTML, CSS, JavaScript), accessibility standards. Measures taken to ensure data accuracy and reliability: grounding, testing, evaluation, NIST framework.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00039,Improving Metadata Retrieval and Transformation for Metadata Management,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The Dataset Catalog (catalog) is a catalog of biomedical datasets from various repositories for users to search, discover, retrieve, and connect with datasets to accelerate scientific research. Metadata from included repositories and their datasets are needed to appropriately index them in the catalog. This manual process can be labor intense, and thus NLM is pilot testing the development of a working interface for internal users to retrieve the metadata information from external repositories' websites and then transform the data to a specific format used in internal metadata management for the Dataset Catalog. This is currently being developed behind NIH's firewall for a select internal user base. The artificial intelligence (AI) will automate the retrieval and transformation of metadata but will not replace human oversight in critical metadata curation tasks. Additional safeguards would make sense in a production environment. The AI uses information from publicly available biomedical data repository websites and internal metadata management systems. The AI uses metadata from biomedical repositories and will be deployed within data management and IT departments, particularly those involved in cataloging and metadata management.

Primary Objectives: Streamline metadata retrieval and transformation to improve efficiency and accuracy. 

Anticipated Positive Outcomes: Resource savings, enhanced data quality, and improved management of the Data Set Catalog.","Inputs: Metadata from various biomedical repositories, internal schemas.

Outputs: Transformed metadata, Python scripts, user-friendly tools for metadata retrieval.

Frequency: Continuous retrieval and transformation as new metadata is ingested.",Acquisition and/or Development,Neither,11/2023,05/2023,N/A,N/A,Developed with contracting resources.,75N97023A00004/75N97023F00007,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"Website data (HTML, CSS, JavaScript), accessibility standards. Measures taken to ensure data accuracy and reliability: grounding, testing, evaluation, NIST framework.",Documentation is complete,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00041,Internal Referral Module ,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The NIH Extramural Research Program uses the eRA system to efficiently award and manage grants.

The AI system is designed for use by IC ‘internal referral’ officers who manage a pool of applications and are responsible for assigning the applications to program officials. It creates efficiencies by automating the ‘internal referral’ assignments, currently done manually on spreadsheets by the ICs. The inputs are grant applications, the outputs are referrals to Program Officers, Program Class Codes, Organizational units - Divisions and Branches and Scientific Research Clusters.","The Internal Referral initiative automates a manual process by using AI and NLP capabilities to help assign grant applications to NIH Institute and Center Program Officers to make informed decisions.

The inputs are grant applications, the outputs are referrals to Program Officers, Program Class Codes, Organizational units - Divisions and Branches and Scientific Research Clusters.",Operation and Maintenance,Neither,01/2018,01/2019,02/2023,N/A,Developed with contracting resources.,Not Reported,N/A,N/A,No,N/A,No,No,Yes,"We used eRA grant application data for all fine tuning and optimization for the models. Specially, we extract the title, abstract, specific aims and public health narrative to train our models for prediction. ",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,eRA,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00042,IT System Outage Alerts,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Use Generative AI to create maintenance and IT system outage alerts that will be sent to NIDCD staff.

General communication to the NIDCD staff. The GenAI tool will reduce staff time to create and distribute e-mail alerts.","Communicates alerts for IT System outages. Output: System, building, day, time.",Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00043,JIT Automated Calculator (JAC),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

NIGMS needs to know how much total support an investigator has to ensure that it is not funding Principal Investigators who are already adequately resourced. The tool can determine how much funding a Principal Investigators has been awarded.",The JIT Automated Calculator (JAC) uses NLP to parse Just-In-Time (JIT) Other Support forms and determine how much outside support PIs are receiving from sources other than the pending application.,Operation and Maintenance,Neither,03/2024,03/2023,05/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,All data come from the internal NIH IMPAC II database.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-NIH-00044,Large Language Automation,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Automate use cases as indicated below.

1. Automate BOT to locate and extract Resource Sharing Plan from post awarded grant application and feed into Microsoft Azure AI to teach it to determine if grant application as written has met compliance. The RFA provides guidelines for grantees.
2. Generate summary for published papers.
3. Generate summary for papers for concept development, research data analysis or other internal work.
4. Generate summary as part of a preliminary review of documents.
5. Generate summary of public meetings.
6. Utilize existing MS Excel worksheets to automate templated emails.
7. Generate FAQs.
8. Produce training materials. 

The RFA: 
1) provides guidelines for grantees, 
2) generates summary for published papers, 
3) generates summary for papers for concept development, research data analysis or other internal work,
4) generates summary as part of a preliminary review of documents,
5) generates summary of public meetings,
6) utilizes existing MS Excel worksheets to automate templated emails,
7) generates FAQs, and
8) produces training materials. ","Input: Push data into Microsoft Azure AI from QVR post awarded grant application data.

Output: Integration of Microsoft Azure AI with UiPath. ",Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00045,Leveraging User-Generated Content for Digital Behavioral Interventions,HHS,NIH,Health & Medical,None of the above.,"The project uses AI-based automated text classification technology to build a predictive model to categorize smoking-related tweets into six distinct categories (e.g., quitting strategies). Specifically, the project uses the AI-based BERT pre-trained language model, which will be further fine-tuned using neural network models to capture the contextual nuances of our use case. AI will also be used to select data for the training dataset that will form the basis of the predictive model. Then, we use ChatGPT to classify extracted and labelled tweets according to its sentiment, presence of sarcasm, presence of irony, presence of emojis. 

The primary objective of the project is to classify thousands of tweets to six categories (e.g., strategies for quitting, quitting benefits) and according to their sentiment and presence of irony, sarcasm, and emojis. Tweets that are positive, not ironic, nor sarcastic would then be tested with target audiences for message effectiveness and possible integration in a smoking cessation intervention.","Input: Publicly available tweets.

Output: sentiment (very positive, positive, neutral, negative, very negative), presence of sarcasm (yes, no), presence of irony (yes, no), presence of emojis (yes, no - and if yes, a description of the emojis present in the tweet).",Implementation and Assessment,Neither,01/2024,01/2024,N/A,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,Corpus of 5 million tweets extracted for the purposes of the research by a colleague who had access to twitter archives.,Documentation is missing or not available,N/A,No,No – agency does not have access to source code.,N/A,No,N/A,More than 12 months,No,No,No,None,No documentation is available
HHS-NIH-00046,LLM Support for Admin Services,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"This project aims to explore the integration of large language models (LLMs) into administrative operations, aiming to enhance efficiency, accuracy, and productivity. By leveraging LLMs, repetitive tasks can be automated including data analysis, documentation drafting, and customer support, thereby freeing up valuable time for administrative personnel to focus on more strategic initiatives. Additionally, LLMs can facilitate natural language processing (NLP) for documentation, ensuring consistency and accuracy in communication across various channels. Through process automation, policy monitoring, and virtual assistance, LLMs offer the potential to streamline our administrative workflow, reduce manual workload, and mitigate the risk of errors. This assessment will provide valuable insights into the feasibility and effectiveness of integrating LLMs into our administrative framework, ultimately optimizing our operations and enhancing organizational performance.

It will reduce the burden of administrative tasks, faster response to administrative inquiries, fewer resources required to support administrative operations.","Uses NLM administrative and operational data to output procedures, forms, schedules, etc.",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00047,Mapping Sequence Data to Research Outcomes,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"A proof-of-principle analysis is being conducted to identify downstream research products related to sequence records included in NLM-managed repositories.

To identify sequence records in NLM-NCBI-managed data repositories and related research products to inform operations and prioritize resources.",Sequence records included in NLM-NCBI-managed data repositories and abstracts for citations records indexed in PubMed; outputs are text summaries identifying in a yes/no fashion if research products were identified,Initiated,Neither,12/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00048,Medical Text Indexer-NeXt Generation (MTIX) MEDLINE Indexing,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Machine learning-based system for the automated indexing of MEDLINE citation records using Medical Subject Heading (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach.

MeSH indexing has been shown to improve information retrieval in PubMed, but manual indexing was not sustainable due to the increasing volume of published biomedical literature. Automated indexing allows for cost-effective and timely indexing of MEDLINE citation records.","The input is PubMed citation data including the article title and abstract, and the output is a set of MeSH terms describing the topic of the article.",Operation and Maintenance,Neither,01/2021,01/2022,05/2023,N/A,Developed with contracting resources.,Black Canyon Consulting LLC 47QTCA18D00JA/75N97023F00098,N/A,N/A,No,N/A,No,No,Yes,"The MTIX dataset is approximately 10 million PubMed MEDLINE citations published after 2006. It is publicly available data, used for training and evaluation of the MeSH terms predicted by the algorithm. ",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00049,MetaMap,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. MetaMap is a program providing access from biomedical text to the concepts in the Unified Medical Language System Metathesaurus. 

MetaMap uses NLP to provide a link between the text of biomedical literature and the knowledge.","Metamap is used to map biomedical text to the Unified Medical Language System Metathesaurus or, equivalently, to discover Metathesaurus concepts referred to in text. ",Operation and Maintenance,Neither,01/1996,01/1996,01/1998,N/A,Developed with contracting resources.,GSA Contract Number:  47QTCA18D00JA,N/A,N/A,No,N/A,No,No,Yes,"UMLS Metathesaurus is used by MetaMap to map the incoming text to concepts that exist in the UMLS Metathesaurus.  MEDLINE citations from the MEDLINE baseline were used in the development, training, and testing of MetaMap.   ",Documentation is missing or not available,N/A,Yes,Yes – source code is publicly available.,https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/run-locally/Sources.html,No,N/A,Less than 6 months,Yes,No,Yes,Re-use production level code and/or data products,No documentation is available
HHS-NIH-00050,MicroStrategy Evaluation,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The software to be evaluated should provide a business intelligence/reporting/visualization interface for possible use for 2 systems (Azure DevOps and OneStream). This software should provide robust development capabilities for manually-generated reports and AI capabilities for end-users to generate additional reports without the need for development. 

This software should provide robust development capabilities for manually-generated reports and AI capabilities for end-users to generate additional reports without the need for development. ","Input: Financial data from OneStream and Project Management data from Azure DevOps.

Output: Data driven business intelligence dashboards. ",Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00051,MTIX,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. 

This is a machine learning-based system for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach. ",Automated indexing allows for cost-effective and timely indexing of MEDLINE articles.,Implementation and Assessment,Neither,01/2021,01/2022,N/A,N/A,Developed with contracting resources.,Black Canyon Consulting LLC 47QTCA18D00JA/75N97023F00098,N/A,N/A,No,N/A,No,No,Yes,"The MTIX dataset is approximately 10 million PubMed MEDLINE citations published after 2006. It is publicly available data, used for training and evaluation of the MeSH terms predicted by the algorithm. ",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00052,NanCI: Connecting Scientists,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NCI is helping to connect scientists.

NanCI is the app for biomedical scientists that helps discover scientific papers, build a career network, and explore events. ",NanCI is a new mobile application that uses machine learning algorithms to match users’ interests and provide a unique experience by recommending tailored content.,Operation and Maintenance,Neither,01/2021,01/2022,01/2024,N/A,Developed with contracting resources.,Google & Barnacle.ai via STRIDES mechanism,N/A,N/A,No,N/A,No,N/A,No,N/A,Documentation is missing or not available,N/A,No,No – agency does not have access to source code.,N/A,No,N/A,6-12 months,No,No,No,None,No documentation is available
HHS-NIH-00053,NBS Virtual Assistant,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The NIH Business System (NBS) is NIH's financial system.

Streamlined Service Desk Operations. The AI-powered chatbot can handle routine user inquiries, reducing the burden on IT service desk. Provides self-service options for users to resolve issues independently.","The NIH Business System (NBS) Assistant is an AI-powered chatbot  to redefine how NBS users engage, and to offer seamless support and personalized assistance across various NBS workstreams. NBS is NIH's financial system.",Implementation and Assessment,Neither,01/2024,07/2024,N/A,N/A,Developed with contracting resources.,Software - 75N97024F00051. System Integrator - 75N97022F00084,N/A,N/A,No,N/A,No,No,No,"G-Invoicing: This dataset includes detailed information related to the G-Invoicing process, such as transaction records and invoicing workflows documentation.

User Provisioning: This includes data related to user access management, including roles, permissions, and user activity logs within the NIH systems. 

PRISM-Related Job Aids and Documents: This dataset comprises job aids, guides, and documentation related to PRISM, which supports various administrative and operational functions at NIH.",Documentation is complete,N/A,No,"Yes – agency has access to source code, but it is not public.",N/A,Yes,NBS AI will be part of the NBS Cloud (NBSC) ATO. System name is NBSC.,6-12 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00054,"NCI-DOE Collaboration, MOSSAIC project (Modeling Outcomes using Surveillance Data and Scalable AI for Cancer)",HHS,NIH,Health & Medical,None of the above.,"MOSSAIC applies deep learning natural language processing (NLP) and foundation models to population-based cancer data collected by NCI's Surveillance, Epidemiology, and End Results (SEER) program. DOE's Oak Ridge National Lab (ORNL) has data use agreements (DUAs) with multiple SEER registries to access and train models using SEER data. To date, the MOSSAIC pathology-coding API is deployed in 22 SEER registries, moving the US towards near real-time cancer incidence reporting. Other APIs are still in the validation phase or research and development phase.

MOSSAIC enhances the infrastructure of the SEER cancer registries by providing tools that can increase the efficiency and accuracy of manual data abstraction by automatically extracting cancer surveillance data elements.  SEER registries receive millions of unstructured clinical text documents that must be manually reviewed, leading to a lag in reporting of US cancer incidence trends.  Automated tools such as those developed by MOSSAIC will help us achieve near real-time incidence trends and ultimately a more meaningful report card on the status of cancer in the US.","Input: unstructured (free text) cancer pathology reports. 

Output: varies depending on the algorithm but generally a predicted class (eg, tumor site) and associated relative confidence score that can be used to tune accuracy.",Implementation and Assessment,Neither,01/2017,10/2017,N/A,N/A,Developed with contracting resources.,Developed under an Interagency Agreement with the US Department of Energy,N/A,N/A,No,N/A,Yes,No,No,"Data is owned by the NCI SEER registries, which are funded by the NCI",Documentation is complete,N/A,No,Yes – source code is publicly available.,https://computational.cancer.gov/view-model-new?f%5B0%5D=project%3Amossaic&search_api_fulltext=&sort_by=title_1&sort_order=ASC&items_per_page=10,No,N/A,Less than 6 months,No,No,No,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00055,NHLBI Chat,HHS,NIH,Health & Medical,None of the above.,"NHLBI Chat is a secure LLM tooling providing access to the Azure OpenAI API so that all NHLBI staff can explore generative AI for their day-to-day need.

NHLBI Chat is a secure LLM tooling providing access to the Azure OpenAI API so that all NHLBI staff can explore generative AI for their day-to-day need.",The Azure OpenAI API accepts text as input and return text as output. Users enter text through a chat interface in a website.,Operation and Maintenance,Neither,05/2023,05/2023,09/2024,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,Documentation is missing or not available,N/A,Yes,Yes – source code is publicly available.,https://github.com/NHLBI/LLM_Chat_Interface,Yes,NHLBI Chat - https://trac.nhlbi.nih.gov/trac/openTracRequest?tracIDNumber=47124&type=simple ,Less than 6 months,Yes,No,Yes,Use of existing data platforms,No documentation is available
HHS-NIH-00056,NIAID GenAI Toolkit,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The NIAID GenAI Chat and Document Bot are Azure-hosted GenAI applications that leverage commercially available large language models from the Azure OpenAI Service to assist NIAID employees in a variety of task such as content generation, summarization, etc.

The Azure-hosted NIAID GenAI Chat and Document Bot helps employees be more efficient with a wide variety of administrative tasks, such as summarizing/querying documents, drafting emails, and creating presentation outlines​, etc. ","Input: natural text in the form of user questions, user uploaded documents. 

Output: Generated text in the form of answers to user questions, generated answers (summaries/queries) based on user documents. ",Operation and Maintenance,Neither,02/2024,02/2024,07/2024,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,"No, training, fine-tuning, and performance evaluation was not conducted.",Documentation is missing or not available,N/A,Yes,Yes – source code is publicly available.,https://github.com/SEMOSS/Semoss,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-NIH-00057,NIAMS AI Chatbot Pilot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"To develop a secured AI Chatbot environment where NIAMS staff can 1) conduct general research, 2) help staff in writing grants/publications/papers (e.g. foreign researcher with their English grammar, sentence structure, etc.), 3) scientific and IT code generation, 4) summarizing meeting minutes and 5) providing a platform to learn how AI can be used in their daily work tasks.

Aside from what is described in 'Use Case Scope', other expected benefits are to assess the cost vs benefit value of having our own chatbot vs paying per user per month to use the NIH Enterprise versions of MS Copilot and OpenAI ChatGPT. This pilot will also be used to understand and develop a tiered business case on which NIAMS staff would fit which chatbot (NIAMS chatbot, MS copilot and OpenAI ChatGPT).","Inputs: Text input, text-based documents or PDF uploaded by users entered into a prompt. Amount or frequency of data are based on how often users use the chatbot, which will be determined during or after the pilot. 

Outputs: Text summaries, information, recommendations and classifications. Output will be presented in text form. The frequency the AI produces the results is based on how often users use the chatbot.",Acquisition and/or Development,Neither,08/2024,08/2024,N/A,N/A,Developed with contracting resources.,47QTCA19D00A8,N/A,N/A,N/A,N/A,N/A,N/A,No,N/A,Documentation is missing or not available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00058,NICHD RPAB AI/ML Application Referral System,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The NICHD RPAB AI/ML Application Referral System leverages the advanced AI/ML technologies to predict extramural branch assignments of new, incoming NICHD grant applications.  It employs human-in-the-loop development which enables human evaluation and offers the ability to override and alter model outputs.  Source data are from the NIH IMPAC II system and stored in the existing NICHD IT application CHIRP (Child Health Information Retrieval Program).  The AI process and output data have no impact on the NIH IMPAC II system. The business area addressed is the internal referral assignment performed by RPAB.

The primary objective is to enhance the efficiency, accuracy, and consistency of grant application referral assignments, while reducing the burden on Subject Matter Experts in RPAB. The AI system is expected to streamline the process of internal referral of new grant applications.",Internal: NIH ImpacII and CHIRP results are presented as class predictions and class probabilities.,Implementation and Assessment,Neither,10/2023,10/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,Yes,No,Yes,"NIH IMPAC II funded and unfunded grant application data is used. Unstructured text from project abstract, specific aims, and title are encoded and vectorized for model training and inference. Fiscal year, activity code, and RCDC terms are transformed via one-hot encoding for use in model training and inference. PII related to individuals associated with the grant is kept intact to preserve the integrity of the use case of grant application referral and the trends of researchers' focus on particular scientific areas.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00059,NLM-Chem: towards automatic chemical indexing in PubMed articles,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. Chemical indexing improves literature retrieval and information access. 

To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. ","Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. ",Initiated,Neither,09/2019,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00060,NLM-Gene: towards automatic gene indexing in PubMed articles,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. MEDLINE is NLM's bibliographic database that contains references to journal articles in life sciences, with a concentration on biomedicine. Gene indexing improves literature retrieval and information access. 

 To assist this time-consuming and resource-intensive process, NLM developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature using advanced natural language processing and deep learning methods. ","Gene indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, gene indexing is performed manually by expert indexers.",Initiated,Neither,01/2020,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00061,NLP Automated Referral,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Publicly reported under OER. NIGMS worked with eRA for over a year to incorporate natural language processing (NLP) and machine learning (ML) algorithms into eRA's Internal Referral Module (IRM).  IRM is now capable of using ML/NLP to assign applications directly to program officers (POs) based on the titles, abstracts, narratives, and specific aims of those applications, as well as the application histories of the PIs. The current process runs in the background on eRA's AWS cloud instances, and assigns the majority of new NIGMS applications to POs as soon as they are referred to NIGMS by CSR.  ML/NLP is also used to provide POs with the three most relevant NIH institutions to applications to facilitate IC fit determinations.

Automated referral allows NIGMS to retain institutional referral knowledge by training on historical data, eliminates delays in referral by assigning applications as soon as they come in, and reduces burden on staff members and allows them to allocate more of their time to other high value tasks.","The tools uses IMPAC II application data, including titles, abstracts, narratives and specific aims to produce a top three of most relevant ICs and POs. ",Operation and Maintenance,Neither,08/2018,12/2019,08/2020,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,All data come from the internal NIH IMPAC II database.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00062,OCIO GenAI Advisor,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The OCIO GenAI Advisor is a general productivity enhancement tool that uses Retrieval Augmented Generation (RAG) setup and user-provided data to answer questions about that data. This is a pilot project for experimentation to discover specific use cases, data needs, security and privacy concerns.

If used effectively, the OCIO GenAI Advisor can shorten time to find the correct information and generate a non-trivial response for a complex question in a desired format such as security, architecture, PMO policy, reports.","Publicly available OMB, NIST policy in pdf format as user-provided data. Prompt and output are in natural language. ",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00063,OIT Help Desk Chatbot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"A general productivity enhancement tool that uses Retrieval Augmented Generation (RAG) setup to answer questions about that data. This is a proof of concept project for experimentation to discover specific use cases, data needs, security and privacy concerns.

If used effectively, the OIT help desk can shorten resolution time for tickets, help empower users and  generate a non-trivial response for a complex question in a desired format such as security, architecture, PMO policy, reports.","Publicly available help desk data, NIST policy in pdf format as user-provided data. Prompt and output are in natural language. ",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00064,Person-level disambiguation for PubMed authors and NIH grant applicants,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The Office of Portfolio Analysis employs AI-based approaches to support analysis of the biomedical research landscape and inform data-driven decision-making by NIH leadership and extramural research administrators in other federal agencies.

High-quality disambiguation is required to correctly link researchers to their grants and outputs including articles, patents, and clinical trials. ","The NIH Office of Portfolio Analysis developed a disambiguation solution that used article level metadata to assign 24.5M unique papers from the PubMed database to 16.0M unique author names, then used a novel neural network model to determine whether author-publication pairs refer to variant representations of the same person. ",Operation and Maintenance,Neither,02/2021,02/2021,02/2023,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,More than 12 months,Yes,Yes,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00065,Portfolio Analysis Summarization Tool (PAST),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"This AI Use Case is leveraging Power BI to present a dynamic view of grants within their portfolio, enabling program staff to explore their data interactively. Program staff face challenges in navigating and understanding extensive narratives within grants due to time constraints and the volume of information. The proposed Open AI sandbox will address these challenges by providing concise, AI-generated summaries of grant-related texts, including Titles, Abstracts, Specific Aims, and Research Strategies.  

Rapid summarization of custom research portfolios which will be used to support program staff and others across the institute.","Input: Grants data from QVR.

Output: Summaries of grant-related texts ",Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00066,Program Classification Coding,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"A machine learning model has been developed to provide Program Classification Code (PCC) suggestions to assist NIA Division Staff with their work. The model is trained using IMPAC II data and generates a report of the top three PCC suggestions for a selected council date. Users can filter the data view by IC/OrgCode and Program Officer names to further customize the results.

The Division staff is responsible for handling a large volume of applications during each council round, with the task of processing and assigning PCCs. To aid users, a solution has been developed that suggests the specific PCC that should be assigned to each application.","Model Inputs: Impac II data fields (Specific Aims, Project Title, and Study Section). 

Output is top 3 predicted PCCs. User views list of applications and top 3 suggestions by clicking on a report for the selected council date. User can filter view by IC/OrgCode and Program Officers names.  ",Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00067,RCDC AI Validation Tool,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Annually, NIH reports the support level for various research, condition, and disease categories based on grants, contracts, and other funding mechanisms used across the agency.

To provide the public the transparency into the reporting of NIH's funded research.",The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. ,Retired,Neither,N/A,N/A,N/A,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00068,Remediate Adobe .pdf documents to be more accessible,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Manual curation and remediation of PDF files is time-consuming and can require substantial expertise to remediate previously published artifacts.  

PDF documents should conformed to Section 508 accessibility standards. NLM is using AI to remediate Adobe .pdf files not currently accessible to Section 508 standards. ",PDF improved files are more accessible to readers who use assistive technology.,Initiated,Neither,10/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00069,Research Performance Progress Report (RPPR) Report Comparison,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The National Institute on Aging (NIA) handles a significant number of grant applications annually, requiring thorough review to prevent duplication, identify changes, and ensure optimal resource allocation. The current manual review process involves detailed comparisons across grant documents from different years, checking for overlaps with other projects, and summarizing extensive scientific text. With each Program Officer (PO) managing between 50 to 200+ grants and overseeing a total of $4 billion in grant funding, the process is highly time-consuming and prone to errors. 

Streamline the NIA grant application review process.","Input: Grants data from QVR.

Output: Identification of duplication and overlap in grants year over year.",Initiated,Neither,05/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00070,Scientific summaries tool,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"The goal is to generate justifications for personnel actions including appointments, conversions, pay adjustments, and hiring/retention incentives for physicians, scientists, and veterinarians.

Within NIAID DIR, we have team that drafts justifications for personnel actions based on the research being performed. This tool will be created to help them quickly and effectively prepare justifications for personnel actions for investigators in specific research fields.","Inputs: scientific publications, CV/Bib, BSC submissions and outcome memos, prior justifications, and, clinical protocols. 

Outputs: Scientific summary.",Implementation and Assessment,Neither,07/2024,07/2024,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,Documentation is widely available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Not Reported,Less than 6 months,Yes,No,Yes,None,Limited documentation for review
HHS-NIH-00071,Semantic group prediction in the UMLS Metathesaurus,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Developing AI approaches (neural networks, heuristics) to predict the semantic groups of new terms to be added to the Unified Medical Language System (UMLS) Metathesaurus.   This is used during new concept integration into the UMLS Metathesaurus and is only intended to interact with the new concepts that will be added and existing UMLS Metathesaurus concepts.  There is no training or intended use of this product for sensitive data.  The hybrid system combining deep learning and heuristics should be able to effectively support UMLS editing and quality assurance. 

Support UMLS Metathesaurus editing.  This should dramatically reduce the time needed to integrate new concepts into the UMLS Metathesaurus and increase the consistency. ","Input: UMLS Metathesaurus (new concepts). 

Output: Semantic group(s) for the new concept. Concepts are typically text words or phrases for example """"Lung Cancer"""", """"heart attack"""". This is used yearly when it is time to add new concepts to the UMLS Metathesaurus. ",Acquisition and/or Development,Neither,07/2021,11/2021,N/A,N/A,Developed with contracting resources.,GSA Contract Number: 47QTCA18D00JA,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"UMLS Metathesaurus was used for development, training, and testing of the developed software. ",Documentation is missing or not available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,No,Yes,Re-use production level code and/or data products,No documentation is available
HHS-NIH-00072,Similarity-based Application and Investigator Matching (SAIM),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

NIGMS needs to know how much total support an investigator has to ensure that it is not funding Principal Investigators who are already adequately resourced. The tool can determine if an application has significant overlap (Just-In-Time Other Support) with an application that is funded by another agency.",The Similarity-based Application and Investigator Matching (SAIM) system uses NLP to find non-NIH grants awarded to NIGMS Principal Investigators.,Operation and Maintenance,Neither,06/2023,06/2023,01/2024,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,"Data for this project come from the internal NIH IMPAC II database, the publicly available NSF grants database, the publicly available SBIR grants database, and the publicly available HHS grants database, TAGGS.",Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00073,SingleCite: Improving single citation search in PubMed,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NLM is the world’s largest biomedical library. SingleCite is search algorithm designed to improve single citation searches in the PubMed database. 

SingleCite helps increase the effectiveness of PubMed searches by making a user’s search for a specific document in PubMed more successful.","SingleCite predicts the probability of a retrieved document being the target of a query based on predefined variables. This search is important for scholarly databases, such as PubMed.",Operation and Maintenance,Neither,06/2017,06/2017,01/2023,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,No,PubMed literature collectionAn earlier tool that perfomed the same task,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,No,No,Re-use production level code and/or data products,Limited documentation for review
HHS-NIH-00074,SRDMS NLP COI,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIAID administers grant portfolios in the extramural research program areas including Allergy, Immunology, & Transplantation, Infectious Diseases, and HIV/AIDS.

Detect individuals who may pose a conflict-of-interest during the grant review process. ",The tool allows NIAID’s Scientific Review Program team to more easily identify conflicts of interest (COI) between grant reviewers and applicants using NLP methods.,Operation and Maintenance,Neither,01/2019,01/2019,01/2019,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,Yes - Labeled dataset of grant applications and associated conflicts of interest is used to calculate pipeline evaluation metrics.,Documentation is complete,N/A,Yes,Yes – source code is publicly available.,http://tfs.niaid.nih.gov:8080/tfs/BI/SRP_COI/_git/srp_coi?path=%2F&version=GBmain&_a=contents,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00075,Stem Cell Auto Coder,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"NIGMS supports basic research that increases our understanding of biological processes and lays the foundation for advances in disease diagnosis, treatment, and prevention. NIGMS-funded scientists investigate how living systems work at a range of levels from molecules and cells to tissues and organs, in research organisms, humans, and populations.

Manually coding Stem Cell Research subcategories is a time intensive process. NIGMS sped up this process by using automation.","The Stem Cell Auto Coder uses NLP and ML to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic.",Implementation and Assessment,Neither,02/2023,02/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,All data come from the internal NIH IMPAC II database.,Documentation is missing or not available,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,No documentation is available
HHS-NIH-00076,Study Section Clustering Tool (SSCT),HHS,NIH,Health & Medical,None of the above.,"This tool suggests how study sections might be organized into groups of similar scientific fields to decide how applications might be grouped into new study sections. Subject matter experts ultimately finalize the study section groupings. 

This tool helps to ensure that applications are grouped into study sections in a way that maps on to the current state of the science.  ","Input: Text of grant applications. 

Output: Lists of study sections that should be grouped together for further review.  ",Operation and Maintenance,Neither,01/2022,01/2022,01/2023,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,IMPACII,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Center for Scientific Review  General Support System (CSR GSS) ,Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,No documentation is available
HHS-NIH-00077,Synonymy prediction in the UMLS Metathesaurus,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Developing artificial intelligence (AI) approaches (neural networks) to predict synonymy among biomedical concepts in the Unified Medical Language System (UMLS) Metathesaurus, with application to the insertion of new concepts into the UMLS Metathesaurus.  This is used during new concept integration into the UMLS Metathesaurus and is only intended to interact with the new concepts that will be added and existing UMLS Metathesaurus concepts.  There is no training or intended use of this product for sensitive data. Preliminary results indicate the performance of the system should be sufficient to support the insertion of new terms into the UMLS Metathesaurus. 

Support UMLS Metathesaurus editing.  This should dramatically reduce the time needed to integrate new concepts into the UMLS Metathesaurus and increase the consistency. ","Input: UMLS Metathesaurus (new concepts). 

Output: Synonymy with existing Metathesaurus concepts. Concepts are typically text words or phrases for example """"Lung Cancer"""", """"heart attack"""". This is used yearly when it is time to add new concepts to the UMLS Metathesaurus.   ",Acquisition and/or Development,Neither,09/2019,03/2020,N/A,N/A,Developed with contracting resources.,GSA Contract Number: 47QTCA18D00JA,N/A,N/A,N/A,N/A,N/A,N/A,Yes,"UMLS Metathesaurus was used for development, training, and testing of the developed software. ",Documentation is missing or not available,N/A,N/A,N/A,N/A,No,N/A,Less than 6 months,Yes,No,Yes,Re-use production level code and/or data products,No documentation is available
HHS-NIH-00078,TB Case Browser Image Text Detection,HHS,NIH,Health & Medical,None of the above.,"The NIAID TB Portals Program is a multi-national collaboration for tuberculosis (TB) data sharing and analysis to advance TB research.

A tool that uses AWS Recognition managed AI service to detect text in images which could be potentially Personally Identifiable Information (PII)/ Protected Health Information (PHI) in TB Portals data. ",The tool detects and counts instances of text and if above a threshold throws a warning to the user who is uploading the image. User must then affirmatively bypass to upload.,Operation and Maintenance,Neither,01/2019,01/2019,01/2019,N/A,Developed with contracting resources.,N/A,N/A,N/A,No,N/A,No,No,Yes,"Yes, used to evaluate performance.",Documentation is complete,N/A,Yes,Yes – source code is publicly available.,https://github.com/niaid/tbportals_data_pii_check,Yes,Not Reported,Less than 6 months,Yes,Yes,Yes,Re-use production level code and/or data products,Limited documentation for review
HHS-NIH-00079,Tech Support Chatbot,HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"It is designed to address two usage scenarios: (1) provide the ORS/ORF community with an interactive customer service chat interface for inquiries related to OIIT technology services, policy, and general information and (2) provide OIIT staff with the ability to receive answers in a variety of technical areas as they troubleshoot or manage efforts in their respective teams.

The benefit of the AI is to improve administrative questions and efficiency of the information to the internal OIIT team.","Provides text, images and data. Input data source is local database. Frequency is TBD.",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00080,Tool for PO Lookup Assignment (TPAL),HHS,NIH,Government Services (includes Benefits and Service Delivery),None of the above.,"Similar to publicly reported IRM use case. The Tool for PO Assignment Lookup (TPAL) provides NIGMS Program staff with the ability to automatically search for appropriate Program Officers (POs), including their corresponding Program Area Codes (PACs), and NIH ICs to assign or reassign project proposals, or to provide advice to prospective applicants. TPAL uses natural language processing and machine learning to predict the three most relevant NIGMS POs, including their corresponding PACs, and the three most relevant NIH ICs from the project description/abstract text entered into a textbox. Note that because the PO and IC prediction algorithms are independent of each other, TPAL will always try to provide the most relevant program​ officers, even when NIGMS is not one of the top three recommended NIH ICs.  

There are many occasions in which Division Directors, Branch Chiefs, and Program Officers wish to receive suggestions for the most appropriate people to talk to about a project proposal or where to send a proposal that might not be appropriate for NIGMS.","Input: Free form text in an online textbox. 

Output: Top three most relevant ICs and POs and their probabilities. ",Operation and Maintenance,Neither,03/2020,03/2020,07/2020,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,Yes,All data comes from the internal NIH IMPAC II database.,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,No,N/A,Less than 6 months,Yes,Yes,Yes,Use of existing data platforms,Limited documentation for review
HHS-NIH-00081,Transformative Research Award Anonymization Check (TRAAC),HHS,NIH,Health & Medical,None of the above.,"This tool helps to determine whether grant applications for NIH Director's Transformative Research Awards are properly anonymized by quickly detecting information that might identify the applicant in the Specific Aims or Research Strategy sections. 

This tool automatically screens many pages and highlights any text that might allow identification of the applicants. The highlighted text is then examined by subject matter experts. This streamlines content screening and aids both NIH staff and the external scientific community in making more rapid and efficient determinations about whether anonymity has been compromised. ","Input: PDF files including text and images from two sections of the NIH grant applications.

Output: Spreadsheets containing records of identified text/phrases as well as PDF files with text/phrases highlighted. ",Operation and Maintenance,Neither,01/2021,01/2021,01/2022,N/A,Developed in-house.,N/A,N/A,N/A,Yes,This use case is operated in compliance with HHS's agencywide Information Quality Act policy and procedures.,No,No,Yes,IMPACII ,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,Center for Scientific Review  General Support System (CSR GSS) ,Less than 6 months,Yes,No,Yes,Re-use production level code from a different use-case,Limited documentation for review
HHS-NIH-00082,Machine learning pipeline for mining citations from full-text scientific articles,HHS,NIH,Health & Medical,None of the above.,"The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003). 

Retired use case","The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service.",Retired,Neither,N/A,N/A,N/A,09/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-NIH-00083,Machine learning system to predict translational progress in biomedical research,HHS,NIH,Health & Medical,None of the above.,"A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. Translational progress in biomedicine can therefore be assessed and predicted in real time based on information conveyed by the scientific community’s early reaction to a paper. For more information see the publication describing this system: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416) 

Retired use case",A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. ,Retired,Neither,N/A,N/A,N/A,09/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-OASH-00001,"Assessing developing possible version of ""HHSGPT"" for OIDP-specific internal use",HHS,OASH,Mission-Enabling (internal agency support),None of the above.,"OIDP's HIV.gov: an exploration of possibly using a custom knowledge-based walled/isolated version of ""Chat GPT"" for our internal OIDP users to access information to help with internal operational efficiencies related to our work on national strategies.  We have been meeting for almost 1 year with senior HHS officials working on AI to keep them up to date on our approach and efforts in both RAG LLM and generative AI. We describe our work as an internal library. The tool is called Ask ABE! (v3.0.0-alpha.1) - AI-Driven. Beneficial. Equitable (ABE). It's like having a digital librarian who can help us at OIDP easily access and use all the valuable resources from HIV.gov to support our work in ending new HIV transmissions! Our work is critical to ensuring the following issues are addressed: (1) Security: FedRAMP certified Azure Open AI 3.5 Turbo / 4o Global. (2) Privacy: Not tracking conversations nor usage. PII stripped. (3) Equity: HIV Language and HIV Language Guideline through internal system prompt. (4) Hallucinations: Internal system prompt  - ABE HIV.gov knowledge base and conversation history. There is a low risk of this occurring compared to open systems like ChatGPT. (5) Risk: NIST AI Risk Management Framework: Govern, Map, Measure, Manage for Responsible AI, Observable AI, and Explainable AI (6) Certifications / Training / Support: Azure AI Certifications / Data Science DoJo / Corporate Thought Leadership Support: Responsible AI Framework.","OIDP internal federal staff would possibly be able to ask questions, develop content, and revise existing content using a unique dataset of OIDP information. Inclusion of NIH HIV guideline is embedded in the internal prompting. ",Initiated,Neither,09/2023,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-OASH-00002,Informal generative AI research for OIDP's HIV.gov,HHS,OASH,Education & Workforce,None of the above.,"OIDP's HIV.gov monitors (1) new and emerging AI tools/policies, generative AI use in the field of communications, and (2) the impact of generative AI on HIV federal content delivery through major search engines. This work is done by an ORISE fellow in conjunction with the HIV.gov communications team. The information is synthesized and discussed during a weekly communications meeting to determine any possible application or if additional follow-up is needed. The purpose of this activity is to determine potential tools that we may be able to use to extend the reach of our work. For example, we have been monitoring tools that potentially can synthesize weekly content into a short narrated video.",This practice helps us guide our planning.,Implementation and Assessment,Neither,11/2022,11/2022,N/A,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,Documentation has been partially completed,N/A,No,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,No,Yes,None,Limited documentation for review
HHS-OASH-00003,Presenting/providing technical assistance on HIV.gov's cautious & transparent use of generative AI,HHS,OASH,Education & Workforce,None of the above.,"OIDP's HIV.gov hosts generative AI workshops, 1-on-1 trainings, and limited generative AI labs to share our cautious and transparent use of generative AI to create communications content. These activities also include information on generative AI basics and information on federal guidance. Our limited AI-generated content is disclosed with a watermark or a tag saying, ""Created by AI, Reviewed By Humans."" These trainings have occurred at 5 national HIV-related conferences and include multiple 1-1 training sessions and workshops that reinforce the importance of following best practices, being transparent, and being cautious. We have trained over 500 people on the cautious and transparent use of generative AI.","These offerings help our audiences understand the importance of cautious and transparent use, federal resources, and additionally promote information about our office's HIV programs.",Operation and Maintenance,Neither,03/2023,03/2023,03/2023,N/A,Developed with both contracting and in-house resources.,N/A,N/A,N/A,No,N/A,No,No,No,N/A,Documentation is widely available,N/A,No,No – agency does not have access to source code.,N/A,No,N/A,Less than 6 months,No,Yes,Yes,None,Documentation has been developed
HHS-OASH-00004,Utilizing HHSGPT Pilot for writing/editing ,HHS,OASH,Mission-Enabling (internal agency support),None of the above.,"Limited OIDP staff have been selected to have access to HHSGPT, an internal generative AI tool in its pilot phase. Team members have been using it for editing, brainstorming, idea generating, drafting text, revisions, gap analysis, organization/structure, evaluations, etc. HHSGPT has been used to assess national strategies, such as the 2026-2030 vaccine national strategy, the 2026-2030 viral hepatitis strategy, and others. When utilizing HHSGPT, we work to report back how this use has reduced labor burden and note any interesting findings when using the tool. Use reporting is done on an Excel file. ","HHSGPT uses a closed tool to generate suggestions, responses, edits, and information that may be useful for OIDP tasks related to infectious diseases or HIV information/policies. Team members have been using it for editing, brainstorming, idea generating, drafting text, revisions, gap analysis, organization/structure, evaluations, etc.  ",Operation and Maintenance,Neither,10/2023,10/2023,10/2023,N/A,Developed in-house.,N/A,N/A,N/A,No,N/A,No,No,No,HHS,Documentation is complete,N/A,Yes,"Yes – agency has access to source code, but it is not public.",N/A,Yes,HHS,Less than 6 months,Yes,Yes,Yes,None,Documentation has been developed
HHS-OCIO-00001,HHSGPT,HHS,OCIO,Government Services (includes Benefits and Service Delivery),None of the above.,"ChatGPT is an AI-powered chatbot developed by OpenAI, and it can be integrated with Azure, Microsoft's cloud computing platform. ChatGPT leverages the power of OpenAI's language model to provide natural language understanding and generation capabilities.

Scalability: As an AI-powered chatbot, ChatGPT can handle multiple conversations simultaneously, scaling up to meet high demand without the need for additional human resources.
Increased Efficiency: ChatGPT can automate repetitive tasks, freeing up human agents to focus on more complex or value-added activities, improving overall efficiency.

Persona Benefits:
Assist data scientists in data exploration, model prototyping, analysis, collaboration, and accessing relevant knowledge, enhancing their productivity and efficiency.

Assist policy analysts by providing instant insights, answering complex policy-related questions, and facilitating interactive discussions, enabling faster and more informed decision-making. 
Assist in writing large policy documents by providing suggestions, generating coherent content, and offering language refinement, streamlining the writing process and ensuring high-quality outputs.","At present, HHSGPT is undergoing a pilot phase throughout the entire HHS organization under an IATT.",Acquisition and/or Development,Neither,09/2023,09/2023,N/A,N/A,Developed in-house.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No,None,Documentation has been partially completed,N/A,N/A,N/A,N/A,Yes,HHSGPT,Less than 6 months,Yes,No,No,None,Limited documentation for review
HHS-SAMHSA-00001,DECIDE,HHS,SAMHSA,Health & Medical,None of the above.,"At present, SAMHSA's Office of Behavioral Health Equity (OBHE) manually reviews grantee organizations' progress towards achieving their health disparity reduction goals. This process involves manually extracting Disparity Impact Statements, annual reports, enrollment data, and external population data to verify the accuracy of grantees' reported progress. This is a time-consuming process, thus the development of an AI-based tool for doing this review is in development.

DECIDE will reduce the administrative burden on OBHE staff and allow them to provide feedback to grantees more quickly.","DECIDE will use generative AI to automate the process of extracting data from various sources, then comparing across data sources to determine (a) whether a grantee has accurately reported the demographic data of the population they serve and (b) how much progress they have made towards decreasing health disparities for the vulnerable population they have identified.",Initiated,Neither,06/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-SAMHSA-00002,Document drafting and editing,HHS,SAMHSA,Mission-Enabling (internal agency support),None of the above.,"SAMHSA employees routinely write internal reports, public-facing written products, and other documents. Some parts of the writing process, such as structuring thoughts into an outline and proofreading, can be enhanced through the use of AI.

The document drafting and editing tool will increase employee productivity and help produce polished written work products.","The document drafting and editing tool will serve as a writing assistant to help SAMHSA employees present their ideas clearly and effectively. It will function similarly to a standard large language model chatbot, allowing the user to query the model to perform specific writing tasks, such as outlining and proofreading.",Initiated,Neither,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-SAMHSA-00003,Document summarization,HHS,SAMHSA,Mission-Enabling (internal agency support),None of the above.,"SAMHSA employees routinely read and summarize large amounts of documentation for grantmaking, management, and other day-to-day work. Ingesting and condensing such vast amounts of information can take time away from SAMHSA's most important mission-driven work.

The document summarization tool will expedite day-to-day workflows and help employees ingest large amounts of information more quickly.","The document summarization tool will allow users to upload documents and produce a summary of these documents. The tool will have enhanced data privacy mechanisms. Additionally, the tool will not use any SAMHSA-provided input as training data, ensuring that private information stays private to SAMHSA.",Initiated,Neither,08/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
HHS-SAMHSA-00004,Smart Search,HHS,SAMHSA,Government Services (includes Benefits and Service Delivery),None of the above.,"SAMHSA.gov team would like to procure ""Kendra""to implement a smart search on store.samhsa.gov—improving access to the Federal Government’s leading source of behavioral health information. Currently the search on store.samhsa.gov relies on key words pulled from document titles, descriptions, and manually generated tags. Both anecdotal evidence and results of usability testing have demonstrated that the Store’s search capability is the single greatest barrier to users accessing materials they need

Kendra will allow for scanning of all documents in the store to respond more accurately to consumer queries while providing a faster search. ","Kendra is not generative AI and does not provide AI-generated responses to queries. Kendra operates within strict guardrails to ensure the security and privacy of information, particularly concerning the handling of sensitive data like Personally Identifiable Information (PII).",Initiated,Neither,09/2024,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
